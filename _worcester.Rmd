##  The Worcester survey


 The Worcester survey was a long-term study of
all myocardial-infarction^[Heart attack.] victims admitted to hospitals in the
Worcester, Massachusetts area.^[Worcester is pronounced, by locals, *Woo-stuh*.] 
The data have been well studied, and can be found in
the file [link](http://ritsokiguess.site/datafiles/whas100.csv).



(a) Read the data and
 display the first few rows of the data frame. You might get an extra
 column, which you can ignore.
For your information, the variables are:


* patient ID code

* admission date

* date of last followup (this is the date of death if the
patient died)

* length of hospital stay (days)

* followup time (days) (time between admission and last followup)

* followup status: 1=dead, 0=alive

* Age in years (at admission)

* gender (0=male, 1=female)

* body mass index (kg/m$^2$)

 
Solution


```{r worcester-1 }
my_url <- "http://ritsokiguess.site/datafiles/whas100.csv"
whas100 <- read_csv(my_url)
whas100
```

     

I seem to have an extra column called `X1`. This is because I
saved my version of the data using the old `write.csv`, which
comes with row names, and I forgot to
get rid of them. These came back as an extra unnamed variable to which
`read_delim` gave the name `X1`.
 
$\blacksquare$

(b) Create a suitable response variable for a Cox proportional
hazards model for time of survival, using the followup time and
followup status.
 
Solution


`Surv`. The event here is death, so the two parts of the
response variable are followup time `lenfol` and followup
status, 1 being "dead", `fstat`:

```{r worcester-2 }
y <- with(whas100, Surv(lenfol, fstat == 1))
y
```

     

Just using `fstat` alone as the second thing in `Surv`
also works, because anything that gives `TRUE` or 1 when the
event (death) occurs is equally good. (In R, `TRUE` as a number
is 1 and `FALSE` as a number is 0.) 

I listed the values by way of checking. The ones with a `+` are
censored: that is, the patient was still alive the last time the
doctor saw them. Most of the censored values are longer times. Usually
this happens because the patient was still alive at the end of the study.

 

$\blacksquare$

(c) Fit a Cox proportional hazards model predicting survival time
from age, gender and BMI. Obtain the `summary` (but you don't
need to comment on it yet).

 
Solution


This, using the `Surv` that we just created:

```{r worcester-3 }
whas100.1 <- coxph(Surv(lenfol, fstat == 1) ~ age + gender + bmi, data = whas100)
summary(whas100.1)
```


Gender is actually categorical, but because there are only two different values (0 and 1) in the dataset, we can get away with treating it as quantitative here. (The coefficient is actually the effect on the log-hazard of being gender 1, female, rather than gender 0, male).   
 
$\blacksquare$

(d) Test the overall fit of the model. What does the result mean?
 
Solution


Look at those three P-values at the bottom.  They are all small,
so something in the model is helping to predict survival. As to
what? Well, that's the next part.
 
$\blacksquare$

(e) Can any of your explanatory variables be removed from the
model? Explain briefly.
 
Solution


`gender` has a (very) large P-value, so that can be taken
out of the model. The other two variables have small P-values
(`bmi` only just under 0.05), so they need to stay.
The other way to think about this is `step`, or `drop1`:

```{r worcester-4 }
drop1(whas100.1, test = "Chisq")
```

     

This is here equivalent to^[Not exactly the same as that output, because it  is doing a test that would be the same if you had an infinitely  large sample, but is slightly different with an ordinary finite number of observations.] the output 
from `summary`, but where it
scores is if you have a categorical explanatory variable like
"treatment" with more than two levels: `drop1` will tell you
about keeping or dropping it as a whole.^[Our categorical  variable *gender* has only two levels.]

If you prefer: 

```{r worcester-5 }
step(whas100.1, trace = 0, test = "Chisq")
```

     
`gender` comes out, but the others stay. As usual, put
`trace=1` or `trace=2` to get more output, which will
look like a sequence of `drop1`'s one after the other.
 
$\blacksquare$

(f) Remove your most non-significant explanatory variable from
the model and fit again. Take a look at the results. Are all your
remaining explanatory variables significant? (If all your
explanatory variables were previously significant, you can skip this part.)
 
Solution


So, take out `gender`:

```{r worcester-6 }
whas100.2 <- update(whas100.1, . ~ . - gender)
summary(whas100.2)
```

     

Both explanatory variables are significant: `age` definitely,
`bmi` only just. This is the same model as `step` gave me.
 
$\blacksquare$

(g) Calculate the 1st quartile, median, and 3rd quartiles of
age and BMI. (`quantile`.) Round these off to the
nearest whole number. (Do the rounding off yourself, though R has a
function `round` that does this, which you can investigate if
you want.) As an alternative, you can get these by passing the whole
data frame, or the columns of it you want, into `summary`.
 
Solution


```{r worcester-7 }
quantile(whas100$age)
quantile(whas100$bmi)
```

 

or

```{r worcester-8 }
whas100 %>%
  select(age, bmi) %>%
  summary()
```

 
Or, pure tidyverse: summarize the two columns you want using `across`. This one is `reframe` rather than `summarize` because `quantile` returns five values (the five-number summary) rather than just one. The challenge with this kind of thing is getting the brackets right: there should be one bracket closed after `bmi` (the one  belonging to `c`), but the `across` has to include both the columns to work with *and* the thing to do with them (work out the 5-number summary of each one), so there are no more close-brackets before the `\(x) quantile(x)` but several after: the one closing the `quantile`, the one closing the `across`, and the one closing the `reframe`. When you close a bracket, R Studio shows you the corresponding open bracket, and if you close too many, the offending one will get a red squiggly line under it:

```{r worcester-9 }
whas100 %>%
  reframe(across(c(age, bmi), \(x) quantile(x)))
```

Using whichever of this multitude of ways appeals to you:

60, 71 and 80 for age, 24, 27 and 30 for BMI. 
 
$\blacksquare$

(h) Make a data frame out of all the combinations of
age and BMI values (that you obtained in the previous part) suitable for predicting
with. 
 
Solution


The inevitable `datagrid`. This is probably quickest, with the best model being the second one:

```{r worcester-10 }
whas100.new <- datagrid(model = whas100.2, age = c(60, 71, 80), bmi = c(24, 27, 30))
whas100.new
```

Extra: I set it up this way so that you would find the median and quartiles and then type the values into the `datagrid` (easier conceptually), but there is nothing stopping us doing it all in one step:

```{r}
datagrid(model = whas100.2, 
         age = quantile(whas100$age, c(0.25, 0.5, 0.75)),
         bmi = quantile(whas100$bmi, c(0.25, 0.5, 0.75))) %>% 
  mutate(across(everything(), \(x) round(x)))
```

The last line rounds everything off to the (default) 0 decimal places. The repetitiousness of the preceding two lines makes me wonder whether I should have written a function. 
 
 
$\blacksquare$

(i) Obtain predicted survival probabilities for each of the values
in your new data frame. Use your best model. (You don't need to look
at the results, though you can if you want to.)
 
Solution

This is an edited version of an old problem where the above was all you needed to do, but to use `predictions` from `marginaleffects`, you need to add a column of times as well. In this problem, the times are in `lenfol`, so we'll use the median and quartiles of those as well, rounded off. It doesn't really matter what times you use, as long as they show the passage of survival probabilities over time in some reasonable way:

```{r}
quantile(whas100$lenfol)
```

so say, 700, 1900, and 2100:

```{r}
whas100.new <- datagrid(model = whas100.2, age = c(60, 71, 80), 
                        bmi = c(24, 27, 30), lenfol = c(700, 1900, 2100))
whas100.new

```

and then

```{r}
cbind(predictions(whas100.2, newdata = whas100.new, type = "survival")) %>% 
  select(age, bmi, lenfol, estimate)
```

This is getting unwieldy to look at, but the hint here is that the effect of increasing  `bmi` is to *increase* the probability of survival (comparing the same age and the same `lenfol`, as in the first, fourth, and seventh rows).


$\blacksquare$

(j) Make a graph depicting the survival curves from
`survfit` with different colours distinguishing the different
survival curves.
 
Solution

Let's do it all in one go this time:

```{r}
plot_predictions(whas100.2, condition = c("lenfol", "age", "bmi"), type = "survival")
```

This puts time on the  $x$-axis, age as colours (it selects some values for you), and `bmi` as facets. Both `age` and `bmi` are quantitative, so there is no reason why they should be this way around rather than `bmi` first and `age` second, which would be equally good.

If you will find this a bit much to interpret, do two graphs, one for age and one  for BMI:

```{r}
plot_predictions(whas100.2, condition = c("lenfol", "age"), type = "survival")
```

```{r}
plot_predictions(whas100.2, condition = c("lenfol", "bmi"), type = "survival")
```


 
$\blacksquare$

(k) What is the effect of age on survival? What is the effect
of BMI on survival? Explain briefly. (You will have to disentangle
the meaning of the different coloured lines on the plot to do this.)
 
Solution


Bear in mind that up-and-to-the-right is best for a survival
curve, since that means that people in the upper-right group have
a higher chance of surviving for longer.   

The best survival curve of all is the red one in the last facet. This goes with the youngest age (32), but the *highest* BMI, and therefore it is better to be younger in terms of survival (no surprise) but to have a *higher* BMI, which you might find surprising given the relationship between high BMI and obesity.

If you prefer to interpret the separate plots for age and BMI, which are respectively for an average BMI, presumably about 27 and an average age, presumably about 70: a younger age is better in terms of survival (the red curve), and a higher BMI is better for survival (the pink curve).

Extra: That's the end of what I wanted you to do, but:

A higher BMI is usually associated with being obese (and therefore
unhealthy), so you'd expect the effect of BMI to be the other way
around. According to Wikipedia
([link](http://en.wikipedia.org/wiki/Body_mass_index)), the BMI values
here are "overweight" or close to it. Maybe being heavier helps
the body recover from a heart attack. 

Let's start with the martingale residual plot:

```{r worcester-15 }
whas100.2 %>% augment(whas100) %>% 
  ggplot(aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth()
```

     

There is a suspicion of bendiness here, though the left side of the
curve is entirely because of that one positive residual on the
left. In any case, this suggests that nonlinearity (evidently in terms
of BMI, since that's the relationship that currently makes no sense)
would be worth exploring. 

Thus:

```{r worcester-16 }
whas100.3 <- update(whas100.2, . ~ . + I(bmi^2))
summary(whas100.3)
```

     

Ah, that seems to be it. The significant positive coefficient on
`bmi`-squared 
means that the "hazard of dying" increases faster with increasing
`bmi`, so there ought to be an optimal BMI beyond which
survival chances decrease again. 
Have we improved the residuals by adding the squared term?

```{r worcester-17 }
whas100.3 %>% augment(whas100) %>% 
  ggplot(aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth()
```

 

I call those "inconsequential wiggles" now, so I think we are good.
Let's explore the quadratic relationship on a graph. What matters now is how survival depends on BMI, so we can use an average age such as the one that `plot_predictions` will give us, and hence:

```{r}
plot_predictions(whas100.3, condition = c("lenfol", "bmi"), type = "survival")
```


This time, the blue and green survival curves are best, which go with BMI of about 30 and 27, values that are in the middle of the range. Both the low BMIs (red and yellow curves) and the highest one (pink, about 40) are associated with worse survival.
But it's still true
that having a very *low* BMI is worst, which is why our (linear)
model said that having a higher BMI was better.

It would have been better to have you put a squared term in the model,
but the question was already long and complicated enough, and I
didn't want to make your lives more of a nightmare than they are
already becoming!
 
$\blacksquare$



