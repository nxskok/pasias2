{
  "hash": "162c4b55c9c7412aeab3f0086a6f5a1d",
  "result": {
    "markdown": "# Data exploration\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  North Carolina births\n\n\n The data in file\n[link](http://ritsokiguess.site/datafiles/ncbirths2.csv) are about\n500 randomly chosen births of babies in North Carolina. There is a lot\nof information: not just the weight at birth of the baby, but whether\nthe baby was born prematurely, the ages of the parents, whether the\nparents are married, how long (in weeks) the pregnancy lasted (this is\ncalled the \"gestation\") and so on. \n\n\n\n(a) Read in the data from the file into R, bearing in mind what\ntype of file it is. \n\n\n\n(b) From your output, verify that you have the\nright number of observations and that you have several\nvariables. Which of your variables correspond to birthweight,\nprematureness and length of pregnancy? (You might have to make guesses\nbased on the names of the variables.) \n\n\n\n\n(c) The theory behind the $t$-test (which we do later) says that the\ndistribution of birth weights should be (approximately) normally\ndistributed. Obtain a histogram of the birth weights. Does it look\napproximately normal?  Comment briefly. (You'll have to pick a number\nof bins for your histogram first. I don't mind very much what you\npick, as long as it's not obviously too many or too few bins.)\n\n\n\n\n\n\n\n\n\n\n##  More about the NC births\n\n\n This is an exploration of\nsome extra issues around the North Carolina births data set.\n\n\n\n\n(a) How short does a pregnancy have to be, for the birth to be\nclassified as \"premature\"? Deduce this from the data, by drawing a\nsuitable graph or otherwise. \n\n\n\n\n(b) Explore the relationship between birth weight and\nlength of pregancy (\"gestation\") using a suitable graph. What do you\nsee?\n\n\n\n\n(c) Do a web search to find the standard (North American)\ndefinition of a premature birth. Does that correspond to what you saw\nin the data? Cite the website you used, for example by saying\n\"according to `URL`, ...\", with `URL` replaced by\nthe address of the website you found.\n\n\n\n\n\n\n\n##  Nenana, Alaska\n\n\n Nenana, Alaska, is about 50 miles west of Fairbanks.\nEvery spring, there is a contest in Nenana. A wooden tripod is\nplaced on the frozen river, and people try to guess the exact minute\nwhen the ice melts enough for the tripod to fall through the ice. The\ncontest started in 1917 as an amusement for railway workers, and has\ntaken place every year since. Now, hundreds of thousands of people\nenter their guesses on the Internet and the prize for the winner can\nbe as much as \\$300,000.\n\nBecause so much money is at stake, and because the exact same tripod\nis placed at the exact same spot on the ice every year, the data are\nconsistent and accurate. The data are in\n[link](http://ritsokiguess.site/datafiles/nenana.txt). \n\n\n\n(a) Read the data into R.  Note that the values are\nseparated by *tabs* rather than spaces, so you'll need an\nappropriate `read_` to read it in.\n\n\n\n(b) Find a way of displaying how many rows and columns your\ndata frame has, and some of the values. Describe the first and last\nof the variables that\nyou appear to have.\n\n\n\n(c) Dates and times are awkward to handle with software. (We\nsee more ways later in the course.)  The column `JulianDate`\nexpresses the time that the tripod fell through the ice as a\nfractional number of days since December 31. This enables the time\n(as a fraction of the way through the day) to be recorded as well,\nthe whole thing being an ordinary number.\nMake a histogram of the Julian dates. Comment briefly on its shape.\n\n\n\n(d) Plot `JulianDate` against `Year` on a\nscatterplot. What recent trends, if any, do you see? Comment briefly.\n\n\n\n\n\n\n\n\n##  Computerized accounting\n\n\n Beginning accounting students need to\nlearn to learn to audit in a computerized environment. A sample of\nbeginning accounting students took each of two tests: the Computer\nAttitude Scale (CAS) and the Computer Anxiety Rating Scale (CARS). A\nhigher score in each indicates greater anxiety around computers. The test scores are scaled to be between 0 and 5. Also\nnoted was each student's gender. The data are in\n[http://ritsokiguess.site/datafiles/compatt.txt](http://ritsokiguess.site/datafiles/compatt.txt). The data values are separated by spaces.\n\n\n\n(a) Read the data into R. Do you have what you expected? Explain briefly. \n\n\n\n(b) How many males and females were there in the sample?\n\n\n\n(c) Do the CAS scores tend to be higher for females or for males? Draw a suitable graph to help you decide, and come to a conclusion.\n\n\n\n(d) Find the median CAS scores for each gender. Does this support what you saw on your plot? Explain briefly.\n\n\n\n(e) Find the mean and standard deviation of both CAS and CARS scores (for all the students combined, ie.\\ not separated by gender) *without* naming those columns explicitly.\n\n\n\n\n\n\n\n\n##  Test scores in two classes\n\n\n  Open R Studio. Create a new Text File by selecting File, New File\nand Text File. You should see a new empty, untitled window appear at\nthe top left. In that window, type or copy the data below (which are\nscores on a test for students in two different classes):\n\n```\n\nclass score\nken 78\nken 62\nken 59\nken 69\nken 81\nthomas 83\nthomas 77\nthomas 63\nthomas 61\nthomas 79\nthomas 72\n\n```\n\nSave the file, using a filename of your choice (with, perhaps, extension\n`.txt`). Or, if you prefer, use the one at\n[link](http://ritsokiguess.site/datafiles/marks.txt). \n\n\n(a) Read the data into a data frame called `marks`, using\n`read_delim`, and list the data frame (by typing its name)\nto confirm that you read the data values properly. Note that the\ntop line of the data file contains the names of the variables, as\nit ought to.\n\n\n\n(b) <a name=\"part:sbsbox\">*</a> Obtain side-by-side boxplots of the scores for each class.\n \n \n\n(c) Do the two classes appear to have similar or different\nscores, on average? Explain briefly. \n \n\n(d) Obtain a boxplot of all the scores together, regardless\nof which class they came from. \n\n\n\n(e) Compute the median score (of all the scores\ntogether). Does this seem about right, looking at the boxplot?\nExplain briefly.\n\n\n\n\n## Unprecedented rainfall\n\n In 1997, a company in Davis, California, had problems with\nodour in its wastewater facility. According to a company official, the\nproblems were caused by \"unprecedented weather conditions\" and \"because\nrainfall was at 170 to 180 percent of its normal level, the water in\nthe holding ponds took longer to exit for irrigation, giving it more\ntime to develop an odour.\"\n\nAnnual rainfall data for the Davis area is [here](http://ritsokiguess.site/datafiles/rainfall.txt).\nNote that clicking on the link will display the file, and *right*-clicking on the link will give you some options, one of which is Copy Link Address, which you can then paste into your Quarto document.\n\nThe rainfall is\nmeasured in inches.\n\n\n\n\n\n(a) Read in and display (some of) the data.\n\n\n\n(b) Summarize the data frame.\n\n\n\n(c) Make a suitable plot of the rainfall values. (We are not,\nfor the time being, concerned about the years.)\n\n\n\n(d) How would you describe the shape of the distribution of\nrainfall values?\n\n\n\n(e) In the quote at the beginning of the question, where do you\nthink the assertion that the 1997 rainfall was \"at 170 to 180\npercent of its normal level\" came from? Explain briefly.\n\n\n\n(f) Do you think the official's calculation was reasonable? \nExplain briefly. (Note that this is not the same as asking whether\nthe official's calculation was *correct*. This is an important\ndistinction for you to make.)\n\n\n\n(g) Do you think that the official was right to use the word\n\"unprecedented\" to describe the 1997 rainfall? Justify your answer\nbriefly. \n\n\n\n\n\n\n\n## Learning algebra\n\n At a high  school in New Jersey, teachers were interested in what might help students to learn algebra. One idea was laptops as a learning aid, to see whether having access to one helped with algebra scores. (This was some time ago.) The 20 students in one class were given laptops to use in school and at home, while the 27 students in another class were not given laptops. For all of these students, the final exam score in algebra was recorded. The data are in [http://ritsokiguess.site/datafiles/algebra.txt](http://ritsokiguess.site/datafiles/algebra.txt), with two columns, one indicating whether the student received a laptop or not, and the other giving their score on the algebra final exam.\n\n\n\n(a) Read in and display (some of) the data. Do you have (i) the correct number of observations, and (ii) the correct *type* of columns? Explain briefly.\n\n\n\n(b) Make a suitable graph of these data.\n\n\n\n(c) Comment briefly on your graph, thinking about what the teachers would like to know.\n\n\n\n(d) Work out the median and  inter-quartile range for the students who did and who did not have laptops, and compare with the boxplot. (In R, the inter-quartile range is `IQR` in uppercase.)\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n\n\n\n\n\n\n## North Carolina births\n\nThe data in file\n[link](http://ritsokiguess.site/datafiles/ncbirths2.csv) are about 500\nrandomly chosen births of babies in North Carolina. There is a lot of\ninformation: not just the weight at birth of the baby, but whether the\nbaby was born prematurely, the ages of the parents, whether the parents\nare married, how long (in weeks) the pregnancy lasted (this is called\nthe \"gestation\") and so on.\n\n(a) Read in the data from the file into R, bearing in mind what type of\n    file it is.\n\nSolution\n\nThis is a `.csv` file (it came from a spreadsheet), so it needs reading\nin accordingly. Work directly from the URL:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyurl <- \"http://ritsokiguess.site/datafiles/ncbirths2.csv\"\nbw <- read_csv(myurl)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 500 Columns: 10\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (10): father_age, mother_age, weeks_gestation, pre_natal_visits, marital...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\nThis shows you which variables the data set has (some of the names got a\nbit mangled), and it shows you that they are all integers except for the\nbirth weight (a decimal number).\n\nThe easiest way to find out how many rows and columns there are is\nsimply to list the data frame:\n\n::: {.cell}\n\n```{.r .cell-code}\nbw\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 500 x 10\n   father_age mother_age weeks_gestation pre_natal_visits marital_status\n        <dbl>      <dbl>           <dbl>            <dbl>          <dbl>\n 1         27         26              38               14              1\n 2         35         33              40               11              1\n 3         34         22              37               10              2\n 4         NA         16              38                9              2\n 5         35         33              39               12              1\n 6         32         24              36               12              1\n 7         33         33              38               15              2\n 8         38         35              38               16              1\n 9         28         29              40                5              1\n10         NA         19              34               10              2\n# i 490 more rows\n# i 5 more variables: mother_weight_gained <dbl>, low_birthweight <dbl>,\n#   weight_pounds <dbl>, premie <dbl>, few_visits <dbl>\n```\n:::\n:::\n\nor you can take a \"glimpse\" of it, which is good if you have a lot of\ncolumns:\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(bw)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 500\nColumns: 10\n$ father_age           <dbl> 27, 35, 34, NA, 35, 32, 33, 38, 28, NA, 28, 34, N~\n$ mother_age           <dbl> 26, 33, 22, 16, 33, 24, 33, 35, 29, 19, 26, 31, 1~\n$ weeks_gestation      <dbl> 38, 40, 37, 38, 39, 36, 38, 38, 40, 34, 39, 39, 3~\n$ pre_natal_visits     <dbl> 14, 11, 10, 9, 12, 12, 15, 16, 5, 10, 15, 15, 0, ~\n$ marital_status       <dbl> 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2~\n$ mother_weight_gained <dbl> 32, 23, 50, NA, 15, 12, 60, 2, 20, NA, 45, 22, 20~\n$ low_birthweight      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0~\n$ weight_pounds        <dbl> 6.8750, 6.8125, 7.2500, 8.8125, 8.8125, 5.8125, 6~\n$ premie               <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0~\n$ few_visits           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0~\n```\n:::\n:::\n\nEither of these displays show that there are 500 rows (observations,\nhere births) and 10 columns (variables), and they both show what the\nvariables are called. So they're both good as an answer to the question.\n\nExtra: As is rather too often the way, the original data weren't like\nthis, and I had to do some tidying first. Here's the original:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_old_url <- \"http://ritsokiguess.site/datafiles/ncbirths_original.csv\"\nbw0 <- read_csv(my_old_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 500 Columns: 10\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (10): Father Age, Mother Age, Weeks Gestation, Pre-natal Visits, Marital...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nbw0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 500 x 10\n   `Father Age` `Mother Age` `Weeks Gestation` `Pre-natal Visits`\n          <dbl>        <dbl>             <dbl>              <dbl>\n 1           27           26                38                 14\n 2           35           33                40                 11\n 3           34           22                37                 10\n 4           NA           16                38                  9\n 5           35           33                39                 12\n 6           32           24                36                 12\n 7           33           33                38                 15\n 8           38           35                38                 16\n 9           28           29                40                  5\n10           NA           19                34                 10\n# i 490 more rows\n# i 6 more variables: `Marital Status` <dbl>, `Mother Weight Gained` <dbl>,\n#   `Low Birthweight?` <dbl>, `Weight (pounds)` <dbl>, `Premie?` <dbl>,\n#   `Few Visits?` <dbl>\n```\n:::\n:::\n\nWhat you'll notice is that the variables have *spaces* in their names,\nwhich would require special handling later. The `glimpse` output shows\nyou what to do about those spaces in variable names:\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(bw0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 500\nColumns: 10\n$ `Father Age`           <dbl> 27, 35, 34, NA, 35, 32, 33, 38, 28, NA, 28, 34,~\n$ `Mother Age`           <dbl> 26, 33, 22, 16, 33, 24, 33, 35, 29, 19, 26, 31,~\n$ `Weeks Gestation`      <dbl> 38, 40, 37, 38, 39, 36, 38, 38, 40, 34, 39, 39,~\n$ `Pre-natal Visits`     <dbl> 14, 11, 10, 9, 12, 12, 15, 16, 5, 10, 15, 15, 0~\n$ `Marital Status`       <dbl> 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2,~\n$ `Mother Weight Gained` <dbl> 32, 23, 50, NA, 15, 12, 60, 2, 20, NA, 45, 22, ~\n$ `Low Birthweight?`     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,~\n$ `Weight (pounds)`      <dbl> 6.8750, 6.8125, 7.2500, 8.8125, 8.8125, 5.8125,~\n$ `Premie?`              <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,~\n$ `Few Visits?`          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,~\n```\n:::\n:::\n\nWhat you have to do is to surround the variable name with \"backticks\".\n(On my keyboard, that's on the key to the left of number 1, where the\nsquiggle is, that looks like a backwards apostrophe. Probably next to\n`Esc`, depending on the layout of your keyboard.) For example, to get\nthe mean mother's age, you have to do this:\n\n::: {.cell}\n\n```{.r .cell-code}\nbw0 %>% summarize(mom_mean = mean(`Mother Age`))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 1\n  mom_mean\n     <dbl>\n1     26.9\n```\n:::\n:::\n\nAlthough almost all of the variables are stored as integers, the ones\nthat have a question mark in their name are actually \"logical\", true or\nfalse, with 1 denoting true and 0 false. We could convert them later if\nwe want to. A question mark is not a traditional character to put in a\nvariable name either, so we have to surround these variables with\nbackticks too.\n\nIn fact, all the variables have \"illegal\" names in one way or another:\nthey contain spaces, or question marks, or brackets. So they *all* need\nbackticks, which, as you can imagine, is rather awkward. The Capital\nLetters at the start of each word are also rather annoying to type every\ntime.\n\nPeople who collect data are not always the people who analyze it, so\nthere is not always a lot of thought given to column names in\nspreadsheets.\n\nSo how did I get you a dataset with much more sane variable names? Well,\nI used the `janitor` package, which has a function in it called\n`clean_names`. This is what it does:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(janitor)\nbw0 %>% clean_names() %>% glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 500\nColumns: 10\n$ father_age           <dbl> 27, 35, 34, NA, 35, 32, 33, 38, 28, NA, 28, 34, N~\n$ mother_age           <dbl> 26, 33, 22, 16, 33, 24, 33, 35, 29, 19, 26, 31, 1~\n$ weeks_gestation      <dbl> 38, 40, 37, 38, 39, 36, 38, 38, 40, 34, 39, 39, 3~\n$ pre_natal_visits     <dbl> 14, 11, 10, 9, 12, 12, 15, 16, 5, 10, 15, 15, 0, ~\n$ marital_status       <dbl> 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2~\n$ mother_weight_gained <dbl> 32, 23, 50, NA, 15, 12, 60, 2, 20, NA, 45, 22, 20~\n$ low_birthweight      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0~\n$ weight_pounds        <dbl> 6.8750, 6.8125, 7.2500, 8.8125, 8.8125, 5.8125, 6~\n$ premie               <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0~\n$ few_visits           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0~\n```\n:::\n:::\n\nAll the spaces have been replaced by underscores, the question marks and\nbrackets have been removed, and all the uppercase letters have been made\nlowercase. The spaces have been replaced by underscores because an\nunderscore is a perfectly legal thing to have in a variable name. I\nsaved this dataset into the file you read in.\n\n$\\blacksquare$\n\n(b) From your output, verify that you have the right number of\n    observations and that you have several variables. Which of your\n    variables correspond to birthweight, prematureness and length of\n    pregnancy? (You might have to make guesses based on the names of the\n    variables.)\n\nSolution\n\nAs a reminder:\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(bw)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 500\nColumns: 10\n$ father_age           <dbl> 27, 35, 34, NA, 35, 32, 33, 38, 28, NA, 28, 34, N~\n$ mother_age           <dbl> 26, 33, 22, 16, 33, 24, 33, 35, 29, 19, 26, 31, 1~\n$ weeks_gestation      <dbl> 38, 40, 37, 38, 39, 36, 38, 38, 40, 34, 39, 39, 3~\n$ pre_natal_visits     <dbl> 14, 11, 10, 9, 12, 12, 15, 16, 5, 10, 15, 15, 0, ~\n$ marital_status       <dbl> 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2~\n$ mother_weight_gained <dbl> 32, 23, 50, NA, 15, 12, 60, 2, 20, NA, 45, 22, 20~\n$ low_birthweight      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0~\n$ weight_pounds        <dbl> 6.8750, 6.8125, 7.2500, 8.8125, 8.8125, 5.8125, 6~\n$ premie               <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0~\n$ few_visits           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0~\n```\n:::\n:::\n\nI do indeed have 500 observations (rows) on 10 variables (columns;\n\"several\"). (If you don't have several variables, check to see that you\ndidn't use `read_delim` or something by mistake.) After that, you see\nall the variables by name, with what type of values they\nhave,[^_ncbirths-1] and the first few of the values.[^_ncbirths-2]\n\n[^_ncbirths-1]: these are mostly `int`, that is, integer.\n\n[^_ncbirths-2]: Other possible variable types are *num* for (real,\n    decimal) numbers such as birth weight, *chr* for text, and *Factor*\n    (with the number of levels) for factors/categorical variables. We\n    don't have any of the last two here. There is also *lgl* for\n    *logical*, things that were actually recorded as TRUE or FALSE. We\n    have some variables that are actually logical ones, but they are\n    recorded as integer values.\n\nThe variable `weight_pounds` is the birthweight (in pounds), `premie` is\n1 for a premature baby and 0 for a full-term baby, and `weeks_gestation`\nis the number of weeks the pregnancy lasted.\n\n$\\blacksquare$\n\n(c) The theory behind the $t$-test (which we do later) says that the\n    birth weights should be (approximately) normally distributed. Obtain\n    a histogram of the birth weights. Does it look approximately normal?\n    Comment briefly. (You'll have to pick a number of bins for your\n    histogram first. I don't mind very much what you pick, as long as\n    it's not obviously too many or too few bins.)\n\nSolution\n\nYou'll have seen that I often start with 10 bins, or maybe not quite\nthat many if I don't have much data, and this is a decent general\nprinciple. That would give\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bw, aes(x = weight_pounds)) + geom_histogram(bins = 10)\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-4-1.pdf){fig-pos='H'}\n:::\n:::\n\nwhich is perfectly acceptable with 500 observations. You can try\nsomething a bit more or a bit less, and see how you like it in\ncomparison. What you are looking for is a nice clear picture of *shape*.\nIf you have too few bins, you'll lose the shape:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bw, aes(x = weight_pounds)) + geom_histogram(bins = 4)\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n(is that leftmost bin an indication of skewness or some observations\nthat happen to be smallish?)\n\nAnd if you have too many, the shape will be there, but it will be hard\nto make out in all the noise, with frequencies going up and down:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bw, aes(x = weight_pounds)) + geom_histogram(bins = 30)\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-6-1.pdf){fig-pos='H'}\n:::\n:::\n\nI generally am fairly relaxed about the number of bins you use, as long\nas it's not clearly too few or too many. You might have done exercises\nin the past that illustrate that the choice of number of bins (or the\nclass intervals where you move from one bin to the next, which is\nanother issue that I won't explore here) can make an appreciable\ndifference to how a histogram looks. \n\nExtra: I had some thoughts about\nthis issue that I put in a blog post, that you might like to read:\n[link](http://ritsokiguess.site/docs/2017/06/08/histograms-and-bins/).\nThe nice thing about Sturges' rule, mentioned there, is that you can\nalmost get a number of bins for your histogram in your head (as long as\nyou know the powers of 2, that is). What you do is to start with your\nsample size, here $n=500$. You find the next power of 2 above that,\nwhich is here $512=2^9$. You then take that power and add 1, to get 10\nbins. If you don't like that, you can get R to calculate it for you:\n\n::: {.cell}\n\n```{.r .cell-code}\nnclass.Sturges(bw$weight_pounds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10\n```\n:::\n:::\n\nThe place where Sturges' rule comes from is an assumption of normal data\n(actually a binomial approximation to the normal, backwards though that\nsounds). If you have less than 30 observations, you'll get fewer than 6\nbins, which won't do much of a job of showing the shape. Rob Hyndman\nwrote a [critical note](https://robjhyndman.com/papers/sturges.pdf)\nabout Sturges' rule in which he asserts that it is just plain wrong (if\nyou have taken B57, this note is very readable).\n\nSo what to use instead? Well, judgment is still better than something\nautomatic, but if you want a place to start from, something with a\nbetter foundation than Sturges is the Freedman-Diaconis rule. This, in\nits original formulation, gives a bin width rather than a number of\nbins:\n\n$$ \nw=2(IQR)n^{-1/3}\n$$\n\nThe nice thing about this is that it uses the interquartile range, so it\nwon't be distorted by outliers. `geom_histogram` can take a bin width,\nso we can use it as follows:\n\n::: {.cell}\n\n```{.r .cell-code}\nw <- 2 * IQR(bw$weight_pounds) * 500^(-1 / 3)\nw\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4094743\n```\n:::\n\n```{.r .cell-code}\nggplot(bw, aes(x = weight_pounds)) + geom_histogram(binwidth = w)\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-8-1.pdf){fig-pos='H'}\n:::\n:::\n\nR also has\n\n::: {.cell}\n\n```{.r .cell-code}\nnc <- nclass.FD(bw$weight_pounds)\nnc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 26\n```\n:::\n:::\n\nwhich turns the Freedman-Diaconis rule into a number of bins rather than\na binwidth; using that gives the same histogram as we got with\n`binwidth`.\n\nIn my opinion, Freedman-Diaconis tends to give too many bins (here there\nare 26 rather than the 10 of Sturges). But I put it out there for you to\nmake your own call.\n\nAnother way to go is a \"density plot\". This is a smoothed-out version of\na histogram that is not obviously frequencies in bins, but which does\nhave a theoretical basis. It goes something like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bw, aes(x = weight_pounds)) + geom_density()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-10-1.pdf){fig-pos='H'}\n:::\n:::\n\n`geom_density` has an optional parameter that controls how smooth or\nwiggly the picture is, but the default is usually good.\n\nAlright, before we got distracted, we were assessing normality. What\nabout that?\n\nIt is mostly normal-looking, but I am suspicious about those *very* low\nbirth weights, the ones below about 4 pounds. There are a few too many\nof those, as I see it.\n\nIf you think this is approximately normal, you need to make some comment\nalong the lines of \"the shape is approximately symmetric with no\noutliers\". I think my first answer is better, but this answer is worth\nsomething, since it is a not completely unreasonable interpretation of\nthe histogram.\n\nI have been making the distinction between a histogram (for one\nquantitative variable) and side-by-side boxplots (for one quantitative\nvariable divided into groups by one categorical variable). When you\nlearned the boxplot, you probably learned it in the context of one\nquantitative variable. You can draw a boxplot for that, too, but the\n`ggplot` boxplot has an `x` as well as a `y`. What you do to make a\nsingle boxplot is to set the `x` equal 1, which produces a weird\n$x$-axis (that you ignore):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bw, aes(x = 1, y = weight_pounds)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-11-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe high weight is actually an outlier, but look at all those outliers\nat the bottom![^_ncbirths-3]\n\n[^_ncbirths-3]: When Tukey, a name we will see again, invented the\n    boxplot in the 1950s, 500 observations would have been considered a\n    big data set. He designed the boxplot to produce a sensible number\n    of outliers for the typical size of data set of his day, but a\n    boxplot of a large data set tends to have a lot of outliers that are\n    probably not really outliers at all.\n\n*I* think the reason for those extra very low values is that they are\nthe premature births (that can result in *very* small babies). Which\nleads to the additional question coming up later.\n\n$\\blacksquare$\n\n\n##  More about the NC births\n\n\n This is an exploration of\nsome extra issues around the North Carolina births data set.\n\n\n\n\n(a) How short does a pregnancy have to be, for the birth to be\nclassified as \"premature\"? Deduce this from the data, by drawing a\nsuitable graph or otherwise. \n\n\n\nSolution\n\n::: {.cell}\n\n:::\n\n\n\nTo figure it out from the data, we can\nsee how `weeks_gestation` depends\non `premie`. Some possibilities are boxplots or a\nscatterplot. Either of the first two graphs would get full credit (for\nthe graphing part: you still have to do the explanation) if this\nwere being marked:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bw,aes(x=factor(premie), y=weeks_gestation)) + geom_boxplot()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 rows containing non-finite values (`stat_boxplot()`).\n```\n:::\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-extra-2-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe warning is because the prematurity of one of the babies is not known.\nOr\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bw,aes(x=premie, y=weeks_gestation)) + geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-extra-3-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe same warning again, for the same reason.\n\nNotice how the graphs are similar in syntax, because the\nwhat-to-plot is the same (apart from the `factor` thing) and we\njust make a small change in \nhow-to-plot-it. In the boxplot, the thing on the $x$-scale needs to be\ncategorical, and `premie` is actually a number, so we'd better\nmake it into a `factor`, which is R's version of a categorical\nvariable. \n`premie` *is* actually a categorical variable (\"premature\" or\n\"not premature\")\nmasquerading as a quantitative one (1 or 0). It is an \"indicator variable\", if\nyou're familiar with that term.\n\nIt looks as if the breakpoint is 37 weeks: a pregnancy at least that\nlong is considered normal, but a shorter one ends with a premature\nbirth. Both plots show the same thing: the `premie=1` births\nall go with short pregnancies, shorter than 37 weeks. This is\ncompletely clear cut.\n\nAnother way to attack this is to use `summarize`, finding the\nmax and min:\n\n::: {.cell}\n\n```{.r .cell-code}\nbw %>% summarize( n=n(),\nmin=min(weeks_gestation),\nmax=max(weeks_gestation))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n      n   min   max\n  <int> <dbl> <dbl>\n1   500    NA    NA\n```\n:::\n:::\n\nonly this is for *all* the babies, premature or not.^[I  explain the missing values below.] So we want it by prematurity,\nwhich means a `group_by` first:\n\n::: {.cell}\n\n```{.r .cell-code}\nbw %>% group_by(premie) %>%\nsummarize( n=n(),\nmin=min(weeks_gestation),\nmax=max(weeks_gestation))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 4\n  premie     n   min   max\n   <dbl> <int> <dbl> <dbl>\n1      0   424    37    45\n2      1    75    20    36\n3     NA     1    NA    NA\n```\n:::\n:::\n\n`group_by` with a number works, even though using the number\nin `premie` in a boxplot didn't. `group_by` just uses\nthe distinct values, whether they are numbers, text or factor levels.\n\nAny of these graphs or summaries will help you answer the question, in\nthe same way. The ultimate issue here is \"something that will get the job done\": it doesn't matter so much what.\n\nExtra: In R, `NA` means \"missing\". When you try to compute something\ncontaining a missing value, the answer is usually missing (since you\ndon't know what the missing value is). That's why the first\n`summarize` gave us missing values: there was one missing weeks\nof gestation in with all the ones for which we had values, so the max\nand min had to be missing as well. In the second `summarize`,\nthe one by whether a baby was born prematurely or not, we learn a bit\nmore about that missing `premie`: evidently its weeks of\ngestation was missing as well, since the min and max of that were\nmissing.^[If there had been a weeks of gestation, we could have figured out whether it was premature or not, according to whether the weeks of gestation was less than 37.]\n\nHere's that baby. I'm doing a bit of fiddling to show all the columns\n(as rows, since there's only one actual row). Don't worry about the\nsecond line of code below; we will investigate that later in the course. Its job here is to show the values nicely:\n\n::: {.cell}\n\n```{.r .cell-code}\nbw %>% \n  filter(is.na(premie)) %>% \n  pivot_longer(everything(), names_to=\"name\", values_to=\"value\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 x 2\n   name                 value\n   <chr>                <dbl>\n 1 father_age           33   \n 2 mother_age           32   \n 3 weeks_gestation      NA   \n 4 pre_natal_visits      9   \n 5 marital_status        1   \n 6 mother_weight_gained 25   \n 7 low_birthweight       0   \n 8 weight_pounds         7.19\n 9 premie               NA   \n10 few_visits            0   \n```\n:::\n:::\n\nThe *only* thing that was missing was its weeks of gestation, but\nthat prevented anyone from figuring out whether it was premature or\nnot. \n                            \n$\\blacksquare$\n\n(b) Explore the relationship between birth weight and\nlength of pregancy (\"gestation\") using a suitable graph. What do you\nsee?\n\n\n\nSolution\n\n\n\nThis needs\nto be a scatterplot because these are both quantitative variables:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bw,aes(x=weeks_gestation, y=weight_pounds)) + geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-extra-7-1.pdf){fig-pos='H'}\n:::\n:::\n\nYou see a rather clear upward trend. Those very underweight babies\ncame from very short pregnancies, but the vast majority of pregnancies\nwere of more or less normal length (40 weeks is normal) and resulted\nin babies of more or less normal birth weight.\n\nExtra: I want to illustrate something else: how about *colouring* the\nbirths that were premature? Piece of cake with `ggplot`:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bw,aes(x=weeks_gestation, y=weight_pounds, colour = premie)) + \n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-extra-8-1.pdf){fig-pos='H'}\n:::\n:::\n\nThat was rather silly because `ggplot` treated prematureness as a *continuous* variable, and plotted the values on a dark blue-light blue scale. This is the same issue as on the boxplot above, and has the same solution:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bw,aes(x=weeks_gestation, y=weight_pounds, \n              colour = factor(premie))) + geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/ncbirths-extra-9-1.pdf){fig-pos='H'}\n:::\n:::\n\nBetter.\n\nWith the normal-length pregnancies (red), there seems to be no\nrelationship between length of pregnancy and birth weight, just a\nrandom variation. But with the premature births, a shorter pregnancy\ntypically goes with a *lower* birth weight. This would be why the\nbirth weights for the premature births were more variable.\n\n\n$\\blacksquare$\n\n(c) Do a web search to find the standard (North American)\ndefinition of a premature birth. Does that correspond to what you saw\nin the data? Cite the website you used, for example by saying\n\"according to `URL`, ...\", with `URL` replaced by\nthe address of the website you found.\n\n\n\nSolution\n\n\nThe website [http://www.mayoclinic.org/diseases-conditions/premature-birth/basics/definition/con-20020050](http://www.mayoclinic.org/diseases-conditions/premature-birth/basics/definition/con-20020050)\nsays that \"a premature birth is one that occurs before the start of the 37th week of pregnancy\", \nwhich is exactly what we found. (Note\nthat I am citing the webpage on which I found this, and I even made it\ninto a link so that you can check it.) The Mayo Clinic is a famous\nhospital system with locations in several US states, so I think we can\ntrust what its website says.\n\n$\\blacksquare$\n\n\n\n\n##  Nenana, Alaska\n\n\n Nenana, Alaska, is about 50 miles west of Fairbanks.\nEvery spring, there is a contest in Nenana. A wooden tripod is\nplaced on the frozen river, and people try to guess the exact minute\nwhen the ice melts enough for the tripod to fall through the ice. The\ncontest started in 1917 as an amusement for railway workers, and has\ntaken place every year since. Now, hundreds of thousands of people\nenter their guesses on the Internet and the prize for the winner can\nbe as much as \\$300,000.\n\nBecause so much money is at stake, and because the exact same tripod\nis placed at the exact same spot on the ice every year, the data are\nconsistent and accurate. The data are in\n[link](http://ritsokiguess.site/datafiles/nenana.txt). \n\n\n\n(a) Read the data into R.  Note that the values are\nseparated by *tabs* rather than spaces, so you'll need an\nappropriate `read_` to read it in.\n\n\nSolution\n\n\nThese are \"tab-separated values\", so `read_tsv` is the\nthing, as for the Australian athletes:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyurl <- \"http://ritsokiguess.site/datafiles/nenana.txt\"\nnenana <- read_tsv(myurl)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 87 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \"\\t\"\nchr (1): Date&Time\ndbl (2): Year, JulianDate\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n       \n\nUse whatever name you like for the data frame. One that is different\nfrom any of the column headers is smart; then it is clear whether you\nmean the whole data frame or one of its columns. `ice` or\n`melt` or anything like that would also be good.\n\nI haven't asked you to display or check the data (that's coming up),\nbut if you look at it and find that it didn't work, you'll know to\ncome back and try this part again. R usually gets it right or gives\nyou an error. \n\nIf you look at the data, they do appear to be separated by spaces, but\nthe text version of the date and time *also* have spaces in them,\nso things might go astray if you try and read the values in without\nrecognizing that the actual separator is a tab:\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- read_delim(myurl, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 87 Columns: 1\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (1): Year\tJulianDate\tDate&Time\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n \n\nOuch! A hint as to what went wrong comes from looking at the read-in\ndata frame:\n\n::: {.cell}\n\n```{.r .cell-code}\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 87 x 1\n   `Year\\tJulianDate\\tDate&Time`         \n   <chr>                                 \n 1 \"1917\\t120.4795\\tApril 30 at 11:30 AM\"\n 2 \"1918\\t131.3983\\tMay 11 at 9:33 AM\"   \n 3 \"1919\\t123.6066\\tMay 3 at 2:33 PM\"    \n 4 \"1920\\t132.4490\\tMay 11 at 10:46 AM\"  \n 5 \"1921\\t131.2795\\tMay 11 at 6:42 AM\"   \n 6 \"1922\\t132.5559\\tMay 12 at 1:20 PM\"   \n 7 \"1923\\t129.0837\\tMay 9 at 2:00 AM\"    \n 8 \"1924\\t132.6323\\tMay 11 at 3:10 PM\"   \n 9 \"1925\\t127.7726\\tMay 7 at 6:32 PM\"    \n10 \"1926\\t116.6691\\tApril 26 at 4:03 PM\" \n# i 77 more rows\n```\n:::\n:::\n\n \n\nThose `t` symbols mean \"tab character\", which is our hint that\nthe values were separated by tabs rather than spaces.\n\nMore detail (if you can bear to see it) is here:\n\n::: {.cell}\n\n```{.r .cell-code}\nproblems(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 87 x 5\n     row   col expected  actual    file \n   <int> <int> <chr>     <chr>     <chr>\n 1     2     5 1 columns 5 columns \"\"   \n 2     3     5 1 columns 5 columns \"\"   \n 3     4     5 1 columns 5 columns \"\"   \n 4     5     5 1 columns 5 columns \"\"   \n 5     6     5 1 columns 5 columns \"\"   \n 6     7     5 1 columns 5 columns \"\"   \n 7     8     5 1 columns 5 columns \"\"   \n 8     9     5 1 columns 5 columns \"\"   \n 9    10     5 1 columns 5 columns \"\"   \n10    11     5 1 columns 5 columns \"\"   \n# i 77 more rows\n```\n:::\n:::\n\n \n\nThe first line of the data file (with the variable names in it) had no\nspaces, only tabs, so `read_delim` thinks there is *one*\ncolumn with a very long name, but in the actual data, there are\n*five* space-separated columns.  The text date-times are of the\nform \"April 30 at 11:30 AM\", which, if you think it's all separated\nby spaces, is actually 5 things: April, 30, at and so on. These are\nthe only things that are separated by spaces, so, from that point of\nview, there are five columns.\n\n\n$\\blacksquare$\n\n(b) Find a way of displaying how many rows and columns your\ndata frame has, and some of the values. Describe the first and last\nof the variables that\nyou appear to have.\n\n\nSolution\n\n\nThe easiest is just to display the tibble:\n\n::: {.cell}\n\n```{.r .cell-code}\nnenana\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 87 x 3\n    Year JulianDate `Date&Time`         \n   <dbl>      <dbl> <chr>               \n 1  1917       120. April 30 at 11:30 AM\n 2  1918       131. May 11 at 9:33 AM   \n 3  1919       124. May 3 at 2:33 PM    \n 4  1920       132. May 11 at 10:46 AM  \n 5  1921       131. May 11 at 6:42 AM   \n 6  1922       133. May 12 at 1:20 PM   \n 7  1923       129. May 9 at 2:00 AM    \n 8  1924       133. May 11 at 3:10 PM   \n 9  1925       128. May 7 at 6:32 PM    \n10  1926       117. April 26 at 4:03 PM \n# i 77 more rows\n```\n:::\n:::\n\n       \nAlternatively, you can take a `glimpse` of it:\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(nenana)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 87\nColumns: 3\n$ Year        <dbl> 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926~\n$ JulianDate  <dbl> 120.4795, 131.3983, 123.6066, 132.4490, 131.2795, 132.5559~\n$ `Date&Time` <chr> \"April 30 at 11:30 AM\", \"May 11 at 9:33 AM\", \"May 3 at 2:3~\n```\n:::\n:::\n\n \n\nThere are 87 years, and 3 columns (variables).\nThe first column is year, and the last\ncolumn is the date and time that the tripod fell into the river,\nwritten as a piece of text. I explain the second column in a moment.\n\n\n$\\blacksquare$\n\n(c) Dates and times are awkward to handle with software. (We\nsee more ways later.)  The column `JulianDate`\nexpresses the time that the tripod fell through the ice as a\nfractional number of days since December 31. This enables the time\n(as a fraction of the way through the day) to be recorded as well,\nthe whole thing being an ordinary number.\nMake a histogram of the Julian dates. Comment briefly on its shape.\n\n\nSolution\n\n\nWith a `ggplot` histogram, we need a number of bins\nfirst. I can do Sturges' rule in my head: the next power of 2 up\nfrom 87 (our $n$) is 128, which is $2^7$, so the base 2 log of\n87 rounds up to 7. That plus one is 8, so we need 8 bins. For\nyou, any not-insane number of bins will do, or any not-insane\nbin width, if you want to go that way:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(nenana, aes(x = JulianDate)) + geom_histogram(bins = 8)\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/nenana-7-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \n\nNote that you need to type `JulianDate` exactly as it\nappears, capital letters and all. R is case-sensitive.\n\nThis histogram looks more or less symmetric (and, indeed, normal). I\nreally don't think you can justify an answer other than \"symmetric\"\nhere. (Or \"approximately normal\": that's good too.) If your\nhistogram is different, say so. I think that \"hole\" in the middle is\nnot especially important.\n\nWe haven't done normal quantile plots yet, but looking ahead:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(nenana, aes(sample = JulianDate)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/nenana-8-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nThat hugs the line pretty well, so I would call it close to\nnormally-distributed. It bulges away from the line because there are\nmore values just below 120 than you would expect for a\nnormal. This corresponds to the histogram bar centred just below 120\nbeing taller than you would have expected.^[That is to say, the  principal deviation from normality is not the hole on the histogram, the bar centred around 123 being too short, but that the bar centred just below 120 is too *tall*.]\n\nExtra: looking *way* ahead, this is how you handle the dates and times:\n\n::: {.cell}\n\n```{.r .cell-code}\nnenana %>%\n  mutate(longdt = str_c(Year, \" \", `Date&Time`)) %>%\n  mutate(datetime = ymd_hm(longdt, tz = \"America/Anchorage\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 87 x 5\n    Year JulianDate `Date&Time`          longdt              datetime           \n   <dbl>      <dbl> <chr>                <chr>               <dttm>             \n 1  1917       120. April 30 at 11:30 AM 1917 April 30 at 1~ 1917-04-30 11:30:00\n 2  1918       131. May 11 at 9:33 AM    1918 May 11 at 9:3~ 1918-05-11 09:33:00\n 3  1919       124. May 3 at 2:33 PM     1919 May 3 at 2:33~ 1919-05-03 14:33:00\n 4  1920       132. May 11 at 10:46 AM   1920 May 11 at 10:~ 1920-05-11 10:46:00\n 5  1921       131. May 11 at 6:42 AM    1921 May 11 at 6:4~ 1921-05-11 06:42:00\n 6  1922       133. May 12 at 1:20 PM    1922 May 12 at 1:2~ 1922-05-12 13:20:00\n 7  1923       129. May 9 at 2:00 AM     1923 May 9 at 2:00~ 1923-05-09 02:00:00\n 8  1924       133. May 11 at 3:10 PM    1924 May 11 at 3:1~ 1924-05-11 15:10:00\n 9  1925       128. May 7 at 6:32 PM     1925 May 7 at 6:32~ 1925-05-07 18:32:00\n10  1926       117. April 26 at 4:03 PM  1926 April 26 at 4~ 1926-04-26 16:03:00\n# i 77 more rows\n```\n:::\n:::\n\nThe function `ymd_hm` is from the `lubridate` package, which gets loaded with the tidyverse. Its job is to read a piece of text that contains a year, month, day, hour, and minute in that order, and to convert it into an R date-time.^[R has a special class for date-times. Internally, they are recorded as seconds since Jan 1, 1970 at midnight, but they display in a human-readable form and can also be used on (typically the $x$-axis of) graphs and will plot properly with sensible axis labels. That isn't very helpful here, since we have the Julian dates, but can be helpful elsewhere.]\n \n\nI am not doing any further analysis with these, so just displaying them is good. \n\nI have to do a preliminary step to get the date-times *with* their year in one place. `str_c` glues pieces of text together: in this case, the year, a space, and then the rest of the \n`Date&Time`. I stored this in `longdt`. The second `mutate` is the business end of it: `ymd_hm` takes a piece of text containing a year, month (by name or number), day, hours, minutes *in that order*, and extracts those things from it, storing the whole thing as an R date-time. Note that the AM/PM was handled properly.\nThe benefit of doing that is we can extract anything from the dates, such as the month or day of week, or take differences between the dates. Or even check that the Julian dates were calculated correctly (the `lubridate` function is called `yday` for \"day of year\"):\n\n::: {.cell}\n\n```{.r .cell-code}\nnenana %>%\n  mutate(longdt = str_c(Year, \" \", `Date&Time`)) %>%\n  mutate(datetime = ymd_hm(longdt, tz = \"America/Anchorage\")) %>%\n  mutate(jd = yday(datetime)) ->\nnenana2\nnenana2 %>% select(JulianDate, jd, datetime)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 87 x 3\n   JulianDate    jd datetime           \n        <dbl> <dbl> <dttm>             \n 1       120.   120 1917-04-30 11:30:00\n 2       131.   131 1918-05-11 09:33:00\n 3       124.   123 1919-05-03 14:33:00\n 4       132.   132 1920-05-11 10:46:00\n 5       131.   131 1921-05-11 06:42:00\n 6       133.   132 1922-05-12 13:20:00\n 7       129.   129 1923-05-09 02:00:00\n 8       133.   132 1924-05-11 15:10:00\n 9       128.   127 1925-05-07 18:32:00\n10       117.   116 1926-04-26 16:03:00\n# i 77 more rows\n```\n:::\n:::\n\n The Julian days as calculated are the same. Note that these are not rounded; the Julian day begins at midnight and lasts until the next midnight. Thus Julian day 132 is May 12 (in a non-leap year like 1922) and the reason that the Julian date given in the file for that year would round to 133  is that it is after noon (1:20pm as you see). \n\n\n\n$\\blacksquare$\n\n(d) Plot `JulianDate` against `Year` on a\nscatterplot. What recent trends, if any, do you see? Comment briefly.\n\n\nSolution\n\n\n\n`geom_point`:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(nenana, aes(x = Year, y = JulianDate)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/nenana-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n \nThis is actually a small-but-real downward trend, especially since\nabout 1960, \nbut the large amount\nof variability makes it hard to see, so I'm good with either \"no trend\" \nor \"weak downward trend\" \nor anything roughly like that. There is definitely not much trend\nbefore 1960, but most of the really early break-ups (less than about\n118) have been since about 1990.\n\nYou can even add to the `ggplot`, by putting a smooth trend on it:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(nenana, aes(x = Year, y = JulianDate)) + geom_point() + geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/nenana-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nThis is R's version of a trend that is not constrained\nto be linear (so that it \"lets the data speak for itself\").\n\nNow there is something obvious to see: after about 1960, there is a clear\ndownward trend: the ice is breaking up earlier on average every\nyear. Even though there is a lot of variability, the overall trend,\nviewed this way, is clear.\n\nWhat does this mean, in practice? This notion of the ice melting\nearlier than it used to is consistent all over the Arctic, and is one\nmore indication of climate change. Precisely, it is an indication that\nclimate change is happening, but we would have to delve further to\nmake any statements about the *cause* of that climate change.\n\n$\\blacksquare$\n\n\n\n\n\n\n##  Computerized accounting\n\n\n Beginning accounting students need to\nlearn to learn to audit in a computerized environment. A sample of\nbeginning accounting students took each of two tests: the Computer\nAttitude Scale (CAS) and the Computer Anxiety Rating Scale (CARS). A\nhigher score in each indicates greater anxiety around computers. The test scores are scaled to be between 0 and 5. Also\nnoted was each student's gender. The data are in\n[http://ritsokiguess.site/datafiles/compatt.txt](http://ritsokiguess.site/datafiles/compatt.txt). The data values are separated by spaces.\n\n\n\n(a) Read the data into R. Do you have what you expected? Explain briefly. \n\n\nSolution\n\n\nRead in and display the data. This, I think, is the easiest way.\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/compatt.txt\"\nanxiety=read_delim(my_url,\" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 35 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (1): gender\ndbl (2): CAS, CARS\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nanxiety\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 35 x 3\n   gender   CAS  CARS\n   <chr>  <dbl> <dbl>\n 1 female  2.85  2.9 \n 2 male    2.6   2.32\n 3 female  2.2   1   \n 4 male    2.65  2.58\n 5 male    2.6   2.58\n 6 male    3.2   3.05\n 7 male    3.65  3.74\n 8 female  2.55  1.9 \n 9 male    3.15  3.32\n10 male    2.8   2.74\n# i 25 more rows\n```\n:::\n:::\n\nThere is a total of 35 students with a CAS score, a CARS score and a\ngender recorded for each. This is in line with what I was\nexpecting. (You can also note that the genders appear to be a mixture\nof males and females.)\n    \n$\\blacksquare$\n\n(b) How many males and females were there in the sample?\n\n\nSolution\n\n\nMost easily `count`:\n\n::: {.cell}\n\n```{.r .cell-code}\nanxiety %>% count(gender)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n  gender     n\n  <chr>  <int>\n1 female    15\n2 male      20\n```\n:::\n:::\n\nThis also works (and is therefore good):\n\n::: {.cell}\n\n```{.r .cell-code}\nanxiety %>% group_by(gender) %>% summarize(count=n())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n  gender count\n  <chr>  <int>\n1 female    15\n2 male      20\n```\n:::\n:::\n\nI want you to use R to do the counting (that is, don't just go through\nthe whole data set  and count the males and\nfemales yourself). This is because you might have thousands of data\nvalues and you need to learn how to get R to count them for\nyou.\n\n15 females and 20 males, *which you should say*. I made a point\nof *not* saying that it is enough to get the output with the\nanswers on it, so you need to tell me what the answer is.\n    \n$\\blacksquare$\n\n(c) Do the CAS scores tend to be higher for females or for males? Draw a suitable graph to help you decide, and come to a conclusion.\n\n\nSolution\n\n\nGender is categorical and CAS score is quantitative, so a boxplot would appear to be the thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(anxiety,aes(x=gender,y=CAS))+geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/compatt-4-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe median for males is slightly higher, so male accountants are more anxious around computers than female accountants are.\n\nIf you wish, side-by-side (or, better, above-and-below) histograms\nwould also work:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(anxiety,aes(x=CAS))+geom_histogram(bins=6)+\nfacet_wrap(~gender,ncol=1)\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/compatt-5-1.pdf){fig-pos='H'}\n:::\n:::\n\nIf you go this way, you have to make a call about where the centres of the histograms are. I guess the male one is slightly further to the right, but it's not so easy to tell. (Make a call.)\n    \n$\\blacksquare$\n\n(d) Find the median CAS scores for each gender. Does this support what you saw on your plot? Explain briefly.\n\n\nSolution\n\n\nGroup-by and summarize:\n\n::: {.cell}\n\n```{.r .cell-code}\nanxiety %>% group_by(gender) %>% summarize(med=median(CAS))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n  gender   med\n  <chr>  <dbl>\n1 female  2.55\n2 male    2.85\n```\n:::\n:::\n\nThe median is a bit higher for males, which is what I got on my\nboxplot (and is apparently the same thing as is on the histograms, but\nit's harder to be sure there).\n    \n$\\blacksquare$\n\n(e) Find the mean and standard deviation of both CAS and CARS scores (for all the students combined, ie.\\ not separated by gender) *without* naming those columns explicitly.\n\n\nSolution\n\n\nWithout naming them explicitly means using some other way to pick them out of the data frame, `summarize` with `across`. \n\nThe basic `across` comes from asking yourself what the *names* of those columns have in common: they start with C and the gender column doesn't:\n\n::: {.cell}\n\n```{.r .cell-code}\nanxiety %>% summarize(across(starts_with(\"C\"), list(m = ~mean(.), s = ~sd(.))))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 4\n  CAS_m CAS_s CARS_m CARS_s\n  <dbl> <dbl>  <dbl>  <dbl>\n1  2.82 0.484   2.77  0.671\n```\n:::\n:::\n\n\nAnother way is to ask what *property* these two columns have in common: they are the only two numeric (quantitative) columns. This means using an `across` with a `where` inside it, thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nanxiety %>% summarize(across(where(is.numeric), list(m = ~mean(.), s = ~sd(.))))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 4\n  CAS_m CAS_s CARS_m CARS_s\n  <dbl> <dbl>  <dbl>  <dbl>\n1  2.82 0.484   2.77  0.671\n```\n:::\n:::\n\nRead the first one as \"across all the columnns whose names start with S, find the mean and SD of them.\" The second one is a little clunkier: \"acrosss all the columns for which `is.numeric` is true, find the mean and SD of them\". A shorter way for the second one is \"across all the numeric (quantitative) columns, find their mean and SD\", but then you have to remember exactly how to code that. The reason for the `list` is that we are calculating two statistics for each column that we find. I am using a \"named list\" so that the mean gets labelled with an `m` on the end of the column name, and the SD gets an `s` on the end.\n\nEither of these is good, or anything equivalent (like noting that the two anxiety scales both `ends\\_with` S):\n\n::: {.cell}\n\n```{.r .cell-code}\nanxiety %>% summarize(across(ends_with(\"S\"), list(m = ~mean(.), s = ~sd(.))))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 4\n  CAS_m CAS_s CARS_m CARS_s\n  <dbl> <dbl>  <dbl>  <dbl>\n1  2.82 0.484   2.77  0.671\n```\n:::\n:::\n\nBecause I didn't say otherwise, you should tell me what the means and SDs are, rounding off suitably: the CAS scores have mean 2.82 and SD 0.48, and the CARS scores have mean 2.77 and SD 0.67.\n\nYet another way to do it is to select the columns you want first (which\nyou can do by number so as not to name them), and then find the mean\nand SD of all of them:\n\n::: {.cell}\n\n```{.r .cell-code}\nanxiety %>% select(2:3) %>% \n    summarize(across(everything(), list(m = ~mean(.), s = ~sd(.))))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 4\n  CAS_m CAS_s CARS_m CARS_s\n  <dbl> <dbl>  <dbl>  <dbl>\n1  2.82 0.484   2.77  0.671\n```\n:::\n:::\n\nThis doesn't work:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(anxiety)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    gender               CAS             CARS      \n Length:35          Min.   :1.800   Min.   :1.000  \n Class :character   1st Qu.:2.575   1st Qu.:2.445  \n Mode  :character   Median :2.800   Median :2.790  \n                    Mean   :2.816   Mean   :2.771  \n                    3rd Qu.:3.150   3rd Qu.:3.290  \n                    Max.   :3.750   Max.   :4.000  \n```\n:::\n:::\n\nbecause, although it gets the means, it does not get the standard\ndeviations. (I added the SD to the original question to make you find\na way other than this.)\n\nIn summary, find a way to get those answers without naming those\ncolumns in your code, and I'm good.\n\nIn case you were wondering about how to do this separately by gender, well, put the `group\\_by` in like you did before:\n\n::: {.cell}\n\n```{.r .cell-code}\nanxiety %>% group_by(gender) %>%\nsummarize(across(where(is.numeric), list(m = ~mean(.), s = ~sd(.))))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 5\n  gender CAS_m CAS_s CARS_m CARS_s\n  <chr>  <dbl> <dbl>  <dbl>  <dbl>\n1 female  2.64 0.554   2.51  0.773\n2 male    2.94 0.390   2.96  0.525\n```\n:::\n:::\n\nor\n\n::: {.cell}\n\n```{.r .cell-code}\nanxiety %>% group_by(gender) %>%\nsummarize(across(starts_with(\"C\"), list(m = ~mean(.), s = ~sd(.))))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 5\n  gender CAS_m CAS_s CARS_m CARS_s\n  <chr>  <dbl> <dbl>  <dbl>  <dbl>\n1 female  2.64 0.554   2.51  0.773\n2 male    2.94 0.390   2.96  0.525\n```\n:::\n:::\n\nThe male means are slightly higher on both tests, but the male\nstandard deviations are a little smaller.\nYou might be wondering whether the test scores are related. They are both quantitative, so the obvious way to find out is a scatterplot:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(anxiety,aes(x=CAS,y=CARS))+geom_point()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/compatt-14-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe two variables can be on either axis, since there is no obvious\nresponse or explanatory variable. A higher score on one scale goes\nwith a higher score on the other, suggesting that the two scales are\nmeasuring the same thing.\n\nThis plot mixes up the males and females, so you might like to distinguish them, which goes like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(anxiety,aes(x=CAS,y=CARS,colour=gender))+geom_point()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/compatt-15-1.pdf){fig-pos='H'}\n:::\n:::\n\nThere is a slight (but only slight) tendency for the males to be up\nand to the right, and for the females to be down and to the left. This\nis about what you would expect, given that the male means are slightly\nbigger on both scores, but the difference in means is not that big\ncompared to the SD.\n    \n$\\blacksquare$\n\n\n\n\n\n\n##  Test scores in two classes\n\n\n  Open R Studio. Create a new Text File by selecting File, New File\nand Text File. You should see a new empty, untitled window appear at\nthe top left. In that window, type or copy the data below (which are\nscores on a test for students in two different classes):\n\n```\n\nclass score\nken 78\nken 62\nken 59\nken 69\nken 81\nthomas 83\nthomas 77\nthomas 63\nthomas 61\nthomas 79\nthomas 72\n\n```\n\nSave the file, using a filename of your choice (with, perhaps, extension\n`.txt`). Or, if you prefer, use the one at\n[link](http://ritsokiguess.site/datafiles/marks.txt). \n\n\n(a) Read the data into a data frame called `marks`, using\n`read_delim`, and list the data frame (by typing its name)\nto confirm that you read the data values properly. Note that the\ntop line of the data file contains the names of the variables, as\nit ought to.\n\n\nSolution\n\n\nI was lazy and used the one on the web, the\nvalues being separated (\"delimited\") by exactly one space:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/marks.txt\"\nmarks <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 11 Columns: 2\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (1): class\ndbl (1): score\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nmarks\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 x 2\n   class  score\n   <chr>  <dbl>\n 1 ken       78\n 2 ken       62\n 3 ken       59\n 4 ken       69\n 5 ken       81\n 6 thomas    83\n 7 thomas    77\n 8 thomas    63\n 9 thomas    61\n10 thomas    79\n11 thomas    72\n```\n:::\n:::\n\n    \n\nIf you copied and pasted, or typed in, the data values yourself, use the local file name (such as `marks.txt`) in place of the URL.\n\nExtra: in the old days, when we used `read.table` (which actually also\nworks here), we needed to also say `header=T` to note that the\ntop line of the data file was variable names. With\n`read_delim`, that's the default, and if the top line is\n*not* variable names, that's when you have to say so. If I cheat,\nby skipping the first line and saying that I then have no column names, I get:\n\n::: {.cell}\n\n```{.r .cell-code}\nread_delim(my_url, \" \", col_names = F, skip = 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 11 Columns: 2\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (1): X1\ndbl (1): X2\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 x 2\n   X1        X2\n   <chr>  <dbl>\n 1 ken       78\n 2 ken       62\n 3 ken       59\n 4 ken       69\n 5 ken       81\n 6 thomas    83\n 7 thomas    77\n 8 thomas    63\n 9 thomas    61\n10 thomas    79\n11 thomas    72\n```\n:::\n:::\n\n \n\nColumn names are supplied (`X1` and `X2`). I could also\nsupply my own column names, in which case the file needs not to have\nany, so I need the `skip` again:\n\n::: {.cell}\n\n```{.r .cell-code}\nread_delim(my_url, \" \", col_names = c(\"instructor\", \"mark\"), skip = 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 11 Columns: 2\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (1): instructor\ndbl (1): mark\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 11 x 2\n   instructor  mark\n   <chr>      <dbl>\n 1 ken           78\n 2 ken           62\n 3 ken           59\n 4 ken           69\n 5 ken           81\n 6 thomas        83\n 7 thomas        77\n 8 thomas        63\n 9 thomas        61\n10 thomas        79\n11 thomas        72\n```\n:::\n:::\n\n \n \n$\\blacksquare$\n\n(b) <a name=\"part:sbsbox\">*</a> Obtain side-by-side boxplots of the scores for each class.\n \nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nggplot(marks, aes(x = class, y = score)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/paignton-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \n\nRemember: on a regular boxplot,^[Boxplots can also go across the page, but for us, they don't.] \nthe groups go across ($x$), the\nvariable measured goes up ($y$).\n\nExtra: this might work:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(marks, aes(x = class, y = score)) + geom_boxplot() +\n  coord_flip()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/thomas-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nIt does. That was a guess. So if you want sideways boxplots, this is\nhow you can get them. Long group names sometimes fit better on the $y$-axis, in which case flipping the axes will help.\n(The `x` and `y` happen\n*before* the coordinate-flip, so they are the same as above, not\nthe same way they come out.)\n \n$\\blacksquare$\n \n\n(c) Do the two classes appear to have similar or different\nscores, on average? Explain briefly. \n \nSolution\n\n\nThe median for Thomas's class appears to be quite a bit higher\nthan for Ken's class (the difference is actually about 6\nmarks). It's up to you whether you think this is a big\ndifference or not: I want you to have *an* opinion, but I\ndon't mind so much what that opinion is.\nHaving said that the medians are quite a bit different, note\nthat the boxes overlap substantially, so that the\n*distributions* of scores are pretty similar (or, the\nquartiles of scores are similar, or, the IQR of scores is\nsimilar for the two groups). If you say that, it's good, but I'm\nnot insisting that you do.\n \n$\\blacksquare$ \n\n(d) Obtain a boxplot of all the scores together, regardless\nof which class they came from. \n\n\nSolution\n\n\nReplace your $x$-coordinate by some kind of dummy thing like\n`1` (`factor(1)` also works):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(marks, aes(x = 1, y = score)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/torquay-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \n\nThe $x$-axis is kind of dopey, so you just ignore it. It is possible\nto remove it, but that is more work than it's worth, and I didn't get\nrid of the ticks below:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(marks, aes(x = 1, y = score)) + geom_boxplot() +\n  theme(\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank()\n  )\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/thomas-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \n \n$\\blacksquare$\n\n(e) Compute the median score (of all the scores\ntogether). Does this seem about right, looking at the boxplot?\nExplain briefly.\n\n\nSolution\n\n\n\nThree ways to get the median score. I like the first one best:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks %>% summarize(med = median(score))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 1\n    med\n  <dbl>\n1    72\n```\n:::\n\n```{.r .cell-code}\nwith(marks, median(score))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 72\n```\n:::\n\n```{.r .cell-code}\nmedian(marks$score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 72\n```\n:::\n:::\n\n \n`summarize` is the `tidyverse` \"verb\" that does what\nyou want here. (The same idea gets the mean score for each class, below.)\n\nThe other ways use the basic function `median`. To make that\nwork, you need to say that the variable `score` whose median\nyou want lives in the data frame `marks`. These are two ways to\ndo that.\n\nExtra: if you wanted median by group, this is the approved\n(`tidyverse`) way:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks %>%\n  group_by(class) %>%\n  summarize(med = median(score))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n  class    med\n  <chr>  <dbl>\n1 ken     69  \n2 thomas  74.5\n```\n:::\n:::\n\n \n\nTo get something by group, the extra step is `group_by`, and\nthen whatever you do after that is done for *each* group.\n\nYou can now go back and compare these medians with the ones on the\nboxplots in (<a href=\"#part:sbsbox\">here</a>). They should be the same. Or you can even do this:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks %>%\n  group_by(class) %>%\n  summarize(\n    q1 = quantile(score, 0.25),\n    med = median(score),\n    q3 = quantile(score, 0.75)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 4\n  class     q1   med    q3\n  <chr>  <dbl> <dbl> <dbl>\n1 ken     62    69    78  \n2 thomas  65.2  74.5  78.5\n```\n:::\n:::\n\n \n\nYou can calculate as many summaries as you like. These ones should\nmatch up with the top and bottom of the boxes on the boxplots. The\nonly restriction is that the things on the right side of the equals\nshould return a *single* number. If you have a function like\n`quantile` without anything extra that returns more than one number:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(marks$score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  0%  25%  50%  75% 100% \n59.0 62.5 72.0 78.5 83.0 \n```\n:::\n:::\n\n \n\nyou're in trouble. Only read on if you *really* want to know how\nto handle this. Here's step 1:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks %>%\n  nest_by(class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n# Rowwise:  class\n  class                data\n  <chr>  <list<tibble[,1]>>\n1 ken               [5 x 1]\n2 thomas            [6 x 1]\n```\n:::\n:::\n\n \n\nThis is kind of a funky `group_by`. The things in the\n`data` column are the *whole* rest of the data frame:\nthere were 5 students in Ken's class and 6 in Thomas's, and they each\nhad a `score`, so 5 or 6 rows and 1 column. The column\n`data` is known in the trade as a \"list-column\".\n\nNow, for each of those mini-data-frames, we want to calculate the\nquantiles of `score`. This is `rowwise`:\nfor each of our\nmini-data-frames `data`, calculate the five-number summary of the column called `score` in *it*:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks %>%\n  nest_by(class) %>%\n  rowwise() %>% \n  mutate(qq = list(quantile(data$score)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 3\n# Rowwise: \n  class                data qq       \n  <chr>  <list<tibble[,1]>> <list>   \n1 ken               [5 x 1] <dbl [5]>\n2 thomas            [6 x 1] <dbl [5]>\n```\n:::\n:::\n\n  \n\nI have to be a little bit careful about which data frame I want the\n`score` to come from: the ones hidden in `data`, which\nare the things we're for-eaching over.\n\nThis obtains a new list-column called `qq`, with the\nfive-number summary for each group.^[It's actually a  coincidence that the five-number summary and Ken's class both have  five values in them.] \n\nNow we want to display the quantiles. This is the easiest way:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks %>%\n  nest_by(class) %>%\n  rowwise() %>% \n  mutate(qq = list(quantile(data$score))) %>% \n  unnest(qq)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 x 3\n   class                data    qq\n   <chr>  <list<tibble[,1]>> <dbl>\n 1 ken               [5 x 1]  59  \n 2 ken               [5 x 1]  62  \n 3 ken               [5 x 1]  69  \n 4 ken               [5 x 1]  78  \n 5 ken               [5 x 1]  81  \n 6 thomas            [6 x 1]  61  \n 7 thomas            [6 x 1]  65.2\n 8 thomas            [6 x 1]  74.5\n 9 thomas            [6 x 1]  78.5\n10 thomas            [6 x 1]  83  \n```\n:::\n:::\n\n  \n\nThe `unnest` turns the list-column back into actual data, so we\nget the five quantiles for each class.\n\nThe only thing this doesn't do is to show us which quantile is which\n(we know, of course, that the first one is the minimum, the last one\nis the max and the quartiles and median are in between). It would be\nnice to see which is which, though. A trick to do that is to use\n`enframe`, thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(marks$score) %>% enframe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  name  value\n  <chr> <dbl>\n1 0%     59  \n2 25%    62.5\n3 50%    72  \n4 75%    78.5\n5 100%   83  \n```\n:::\n:::\n\n \n\nor thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nenframe(quantile(marks$score))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  name  value\n  <chr> <dbl>\n1 0%     59  \n2 25%    62.5\n3 50%    72  \n4 75%    78.5\n5 100%   83  \n```\n:::\n:::\n\n \n\nI don't normally like the second way with all the brackets, but we'll\nbe using it later.\n\nThe idea here is that the output from a quantile is a vector, but one\nwith \"names\", namely the percentiles themselves. `enframe`\nmakes a two-column data frame with the names and the values. (You can\nchange the names of the columns it creates, but here we'll keep track\nof which is which.)\n\nSo we have a *two*-column data frame with a column saying\nwhich quantile is which. So let's rewrite our code to use this:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks %>%\n  nest_by(class) %>%\n  rowwise() %>% \n  mutate(qq = list(enframe(quantile(data$score)))) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 3\n# Rowwise: \n  class                data qq              \n  <chr>  <list<tibble[,1]>> <list>          \n1 ken               [5 x 1] <tibble [5 x 2]>\n2 thomas            [6 x 1] <tibble [5 x 2]>\n```\n:::\n:::\n\n \n\nNote that the `qq` data frames in the list-column now\nthemselves have two columns.\n\nAnd finally `unnest` `qq`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks %>%\n  nest_by(class) %>%\n  rowwise() %>% \n  mutate(qq = list(enframe(quantile(data$score)))) %>% \n  unnest(qq)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 x 4\n   class                data name  value\n   <chr>  <list<tibble[,1]>> <chr> <dbl>\n 1 ken               [5 x 1] 0%     59  \n 2 ken               [5 x 1] 25%    62  \n 3 ken               [5 x 1] 50%    69  \n 4 ken               [5 x 1] 75%    78  \n 5 ken               [5 x 1] 100%   81  \n 6 thomas            [6 x 1] 0%     61  \n 7 thomas            [6 x 1] 25%    65.2\n 8 thomas            [6 x 1] 50%    74.5\n 9 thomas            [6 x 1] 75%    78.5\n10 thomas            [6 x 1] 100%   83  \n```\n:::\n:::\n\n \n\nSuccess! Or even:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarks %>%\n  nest_by(class) %>%\n  rowwise() %>% \n  mutate(qq = list(enframe(quantile(data$score)))) %>% \n  unnest(qq) %>% \n  mutate(qn = parse_number(name)) %>%\n  select(-name) %>%\n  pivot_wider(names_from = qn, values_from = value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 7\n  class                data   `0`  `25`  `50`  `75` `100`\n  <chr>  <list<tibble[,1]>> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 ken               [5 x 1]    59  62    69    78      81\n2 thomas            [6 x 1]    61  65.2  74.5  78.5    83\n```\n:::\n:::\n\n \n\nThis deliberately untidies the final answer to make it nicer to look\nat. (The lines before that create a numeric quantile, so that it sorts\ninto the right order, and then get rid of the original quantile\npercents. Investigate what happens if you do a similar `pivot_wider`\nwithout doing that.)\n\n\n\n\n\n\n## Unprecedented rainfall\n\n In 1997, a company in Davis, California, had problems with\nodour in its wastewater facility. According to a company official, the\nproblems were caused by \"unprecedented weather conditions\" and \"because\nrainfall was at 170 to 180 percent of its normal level, the water in\nthe holding ponds took longer to exit for irrigation, giving it more\ntime to develop an odour.\"\n\nAnnual rainfall data for the Davis area is [here](http://ritsokiguess.site/datafiles/rainfall.txt).\nNote that clicking on the link will display the file, and *right*-clicking on the link will give you some options, one of which is Copy Link Address, which you can then paste into your Quarto document.\n\nThe rainfall is\nmeasured in inches.\n\n\n\n\n\n(a) Read in and display (some of) the data.\n\nSolution\n\n\n\n\nLook at the data file, and see that the values are separated by a\nsingle space, so \\verb=read_delim= will do it. Read straight from\nthe URL; the hint above tells you how to copy it, which would even work if the link spans two lines.\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/rainfall.txt\"\nrain <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 47 Columns: 2\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\ndbl (2): Year, Rainfall\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nrain\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 47 x 2\n    Year Rainfall\n   <dbl>    <dbl>\n 1  1951     20.7\n 2  1952     16.7\n 3  1953     13.5\n 4  1954     14.1\n 5  1955     25.4\n 6  1956     12.0\n 7  1957     28.7\n 8  1958     11.0\n 9  1959     12.6\n10  1960     12.8\n# i 37 more rows\n```\n:::\n:::\n\nNote for later that the \\verb=Year= and the \\verb=Rainfall= have\nCapital Letters. You can call the data frame whatever you like, but I\nthink something descriptive is better than eg.\\ \\verb=mydata=.\n\n\n\nExtra: this works because there is exactly one space between the year and the\nrainfall amount. But the year is always four digits, so the columns\nline up, and there is a space all the way down between the year and\nthe rainfall. That means that this will also work: \n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/rainfall.txt\"\nrain <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  Year = col_double(),\n  Rainfall = col_double()\n)\n```\n:::\n\n```{.r .cell-code}\nrain\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 47 x 2\n    Year Rainfall\n   <dbl>    <dbl>\n 1  1951     20.7\n 2  1952     16.7\n 3  1953     13.5\n 4  1954     14.1\n 5  1955     25.4\n 6  1956     12.0\n 7  1957     28.7\n 8  1958     11.0\n 9  1959     12.6\n10  1960     12.8\n# i 37 more rows\n```\n:::\n:::\n\n\nThis is therefore also good.\n\nIt also looks as if it could be tab-separated values, since the rainfall\ncolumn always starts in the same place, but if you try it, you'll find\nthat it doesn't work:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/rainfall.txt\"\nrain_nogood <- read_tsv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 47 Columns: 1\n-- Column specification --------------------------------------------------------\nDelimiter: \"\\t\"\nchr (1): Year Rainfall\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nrain_nogood\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 47 x 1\n   `Year Rainfall`\n   <chr>          \n 1 1951 20.66     \n 2 1952 16.72     \n 3 1953 13.51     \n 4 1954 14.1      \n 5 1955 25.37     \n 6 1956 12.05     \n 7 1957 28.74     \n 8 1958 10.98     \n 9 1959 12.55     \n10 1960 12.75     \n# i 37 more rows\n```\n:::\n:::\n\n\nThis looks as if it worked, but it didn't, because there is only\n*one* column, of years and rainfalls smooshed together as text,\nand if you try to do anything else with them later it won't work.\n\nHence those values that might have been tabs actually were\nnot. There's no way to be sure about this; you have to try something\nand see what works. An indication, though: if you have more than one\nspace, and the things in the later columns are *left*-justified,\nthat could be tab-separated; if the things in the later columns are\n*right*-justified, so that they finish in the same place but\ndon't start in the same place, that is probably aligned columns. \n\n\n\n$\\blacksquare$\n\n\n(b) Summarize the data frame.\n\nSolution\n\n\nI almost gave the game away: this is `summary`.\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(rain)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Year         Rainfall    \n Min.   :1951   Min.   : 6.14  \n 1st Qu.:1962   1st Qu.:12.30  \n Median :1974   Median :16.72  \n Mean   :1974   Mean   :18.69  \n 3rd Qu.:1986   3rd Qu.:25.21  \n Max.   :1997   Max.   :37.42  \n```\n:::\n:::\n\nThe summary of the years may not be very helpful, but the summary of the annual rainfall values might be. It's not clear yet why I asked you to do this, but it will become clearer later.\n\n\n$\\blacksquare$\n\n\n(c) Make a suitable plot of the rainfall values. (We are not,\nfor the time being, concerned about the years.)\n\nSolution\n\n\nThis is one quantitative variable, so a histogram is your first\nthought. This means picking a number of bins. Not too many, since\nyou want a picture of the shape:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(rain, aes(x=Rainfall)) + geom_histogram(bins=8)\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/rainfall-5-1.pdf){fig-pos='H'}\n:::\n:::\n\nIf you picked fewer bins, you'll get a different picture:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(rain, aes(x=Rainfall)) + geom_histogram(bins=6)\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/rainfall-6-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe choice of the number of bins depends on what you think the story\nabout shape is that you want to tell (see next part). You will\nprobably need to try some different numbers of bins to see which one\nyou like best. You can say something about what you tried, for example \"I also tried 8 bins, but I like the histogram with 6 bins better.\"\n\n\n\n$\\blacksquare$\n\n\n(d) How would you describe the shape of the distribution of\nrainfall values?\n\nSolution\n\n\nThis will depend on the histogram you drew in the previous\npart. If it looks like the first one, the best answer is\n\"bimodal\": that is, it has two peaks with a gap between them. If\nit looks like the second one, you have an easier time; this is\nordinary right-skewness.\n\n\n$\\blacksquare$\n\n\n(e) In the quote at the beginning of the question, where do you\nthink the assertion that the 1997 rainfall was \"at 170 to 180\npercent of its normal level\" came from? Explain briefly.\n\nSolution\n\n\nFirst we\nneed the 1997 rainfall. Go back and find it in the data. I am borrowing an idea from later in the course (because I am lazy):\n\n::: {.cell}\n\n```{.r .cell-code}\nrain %>% filter(Year==1997)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 2\n   Year Rainfall\n  <dbl>    <dbl>\n1  1997     29.7\n```\n:::\n:::\n\n29.7 inches.\n\nNow, what would be a \"normal level\" of rainfall? Some kind of average, like a mean or a median, maybe. But we have those, from our summary that we made earlier, repeated here for (my) convenience:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(rain)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Year         Rainfall    \n Min.   :1951   Min.   : 6.14  \n 1st Qu.:1962   1st Qu.:12.30  \n Median :1974   Median :16.72  \n Mean   :1974   Mean   :18.69  \n 3rd Qu.:1986   3rd Qu.:25.21  \n Max.   :1997   Max.   :37.42  \n```\n:::\n:::\n\nThe mean is 18.69 and the median is 16.72 inches.\n\nSo divide the 1997 rainfall by each of the summaries, and see what happens, using\nyour calculator, or using R as a calculator:\n\n::: {.cell}\n\n```{.r .cell-code}\n29.7/18.69\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.589085\n```\n:::\n\n```{.r .cell-code}\n29.7/16.72\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.776316\n```\n:::\n:::\n\nThe 1997 rainfall was about 178 percent of the normal level if the normal\nlevel was the *median*.\n\n\n\n$\\blacksquare$\n\n\n(f) Do you think the official's calculation was reasonable? \nExplain briefly. (Note that this is not the same as asking whether\nthe official's calculation was *correct*. This is an important\ndistinction for you to make.)\n\nSolution\n\nThere are several approaches to take. Argue for yours.\n\nIf you came to the conclusion that the distribution was\nright-skewed, you can say that the sensible \"normal level\" is\nthe median, and therefore the official did the right thing. Using\nthe mean would have been the wrong thing.\n\nIf you thought the distribution was bimodal, you can go a couple\nof ways: (i) it makes no sense to use any measure of location for\n\"normal\" (in fact, the mean rainfall is almost in that low-frequency bar,\nand so is not really a \"normal level\" at all). Or, (ii) it looks\nas if the years split into two kinds: low-rainfall years with\naround 15 inches, and high-rainfall years with more than 25\ninches. Evidently 1997 was a high-rainfall year, but 29.7 inches\nwas not especially high for a high-rainfall year, so the\nofficial's statement was an exaggeration. (I think (ii) is more\ninsightful than (i), so ought to get more points.)\n\nYou could even also take a more conspiratorial approach and say\nthat the official was trying to make 1997 look like a freak year,\nand picked the measure of location that made 1997 look more\nunusual. \n\n\"Normal level\" here has nothing to do with a normal\n*distribution*; for this to make sense, the official would\nhave needed to say something like \"normal shape\". This is why\nlanguage skills are also important for a statistician to have.\n\n\n$\\blacksquare$\n\n\n(g) Do you think that the official was right to use the word\n\"unprecedented\" to describe the 1997 rainfall? Justify your answer\nbriefly. \n\nSolution\n\n\"Unprecedented\" means \"never seen before\" or \"never having\nhappened or existed in the past\".^[Searching for \"define\" followed by a word is a good way to find out exactly what that word means, if you are not sure, but you should at least say where you got the definition from if you had to look it up.] \nThat came out of my head; [this link](https://www.dictionary.com/browse/unprecedented) has a very similar \"never before known or experienced\").\n\nIf you look back at your histogram, there are several years that\nhad over about 30 inches of rain: five or six, depending on your\nhistogram. One of them was 1997, but there were others too, so\n1997 was in no way \"unprecedented\". \n\nAnother approach that you have seen is to `View` your dataframe:\n\n::: {.cell}\n\n```{.r .cell-code}\nView(rain)\n```\n:::\n\nThat will come out as a  separate tab in your R Studio and you can look at it (yourself; it won't appear in the Preview). You can look at the 1997 rainfall (29.69 inches) and count how many were bigger than that, 4 of them. Or, save yourself some effort^[When you have a computer at your disposal, it's worth taking a few minutes to figure out how to use it to make your life easier.]     and sort the rainfall values in descending order (with the biggest one first), by clicking on the little arrows next to Rainfall (twice). Mine looks like this:\n\n![](Screenshot_2020-09-11_15-17-51.png){height=50%}\n\nLater, we learn how to sort in code, which goes like this (to sort highest first):\n\n::: {.cell}\n\n```{.r .cell-code}\nrain %>% arrange(desc(Rainfall))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 47 x 2\n    Year Rainfall\n   <dbl>    <dbl>\n 1  1982     37.4\n 2  1981     31.3\n 3  1994     31.2\n 4  1992     29.8\n 5  1997     29.7\n 6  1957     28.7\n 7  1972     27.7\n 8  1977     27.7\n 9  1966     27.6\n10  1985     27.5\n# i 37 more rows\n```\n:::\n:::\n\n\nA more sophisticated way that we learn later:\n\n::: {.cell}\n\n```{.r .cell-code}\nrain %>% summarize(max=max(Rainfall))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 1\n    max\n  <dbl>\n1  37.4\n```\n:::\n:::\n\nThis is greater than the rainfall for 1997, ruling out \"unprecedented\".\n\n\n1997 was only the *fifth* highest rainfall, and two of the\nhigher ones were also in the 1990s. Definitely not\n\"unprecedented\". The official needs to get a new dictionary!\n\n\n$\\blacksquare$\n\n\n\n\n\n\n## Learning algebra\n\n At a high  school in New Jersey, teachers were interested in what might help students to learn algebra. One idea was laptops as a learning aid, to see whether having access to one helped with algebra scores. (This was some time ago.) The 20 students in one class were given laptops to use in school and at home, while the 27 students in another class were not given laptops. For all of these students, the final exam score in algebra was recorded. The data are in [http://ritsokiguess.site/datafiles/algebra.txt](http://ritsokiguess.site/datafiles/algebra.txt), with two columns, one indicating whether the student received a laptop or not, and the other giving their score on the algebra final exam.\n\n\n\n(a) Read in and display (some of) the data. Do you have (i) the correct number of observations, and (ii) the correct *type* of columns? Explain briefly.\n\nSolution\n\n\nTake a look at the data file first: the data values are *aligned in columns* with variable numbers of spaces between, so `read_table` is the thing. Read directly from the URL, rather than trying to copy the data from the website:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/algebra.txt\"\nalgebra <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  laptop = col_character(),\n  score = col_double()\n)\n```\n:::\n\n```{.r .cell-code}\nalgebra\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 47 x 2\n   laptop score\n   <chr>  <dbl>\n 1 yes       98\n 2 yes       84\n 3 yes       97\n 4 yes       93\n 5 yes       88\n 6 yes       57\n 7 yes      100\n 8 yes       84\n 9 yes      100\n10 yes       81\n# i 37 more rows\n```\n:::\n:::\n\n\nThere were $20+27=47$ students altogether in the two classes, and we do indeed have 47 rows, one per student. So we have the right number of rows. This is two independent samples; each student was in only one of the two classes, either the class whose students got laptops or not.\nThe values in the `laptop` column are text (see the `chr` at the top), and the values in the `score` column are numbers (`dbl` at the top). Alternatively, you can look at the R Console output in which you see that `laptop` is `col_character()` (text) and `score` is `col_double()` (numerical, strictly a decimal number).\n\n\nExtra 1: `read.table` also works but it is *wrong* in this course (because it is not what I taught you in class).\n\nExtra 2: with more than one space between the values, `read_delim` will not work. Or, perhaps more confusing, it will appear to work and then fail later, which means that you need to pay attention:\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 47 Columns: 2\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (2): laptop, score\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 47 x 2\n   laptop score   \n   <chr>  <chr>   \n 1 yes    \"    98\"\n 2 yes    \"    84\"\n 3 yes    \"    97\"\n 4 yes    \"    93\"\n 5 yes    \"    88\"\n 6 yes    \"    57\"\n 7 yes    \"   100\"\n 8 yes    \"    84\"\n 9 yes    \"   100\"\n10 yes    \"    81\"\n# i 37 more rows\n```\n:::\n:::\n\nThis *looks*  all right, but look carefully: the `laptop` column is correctly text, but the `score` column, which should be numbers (`dbl`), is actually text as well.  An easier way to see this is to look at the output from the console, which is the descriptions of the columns: they are *both* `col_character` or text, while `score` should be numbers. You might be able to see exactly what went wrong: with more than one space separating the values, the remaining spaces went into `score`, which then becomes a piece of text with some spaces at the front and then numbers.\n\nThis will actually work for a while, as you go through the question, but will come back to bite you the moment you need `score` to be numerical (eg. when you try to draw a boxplot), because it is actually not numerical at all.\n\nExtra 3: this is the standard R way to lay out this kind of data, with all the outcome values in one column and a second (categorical) column saying which group each observation was in. In other places you might see two separate columns of scores, one for the students with laptops and one for the students without, as below (you won't understand the code below now, but you will by the end of the course):\n\n::: {.cell}\n\n```{.r .cell-code}\nalgebra %>% \nmutate(row = c(1:20, 1:27)) %>% \npivot_wider(names_from = laptop, values_from = score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 27 x 3\n     row   yes    no\n   <int> <dbl> <dbl>\n 1     1    98    63\n 2     2    84    83\n 3     3    97    97\n 4     4    93    93\n 5     5    88    52\n 6     6    57    74\n 7     7   100    83\n 8     8    84    63\n 9     9   100    88\n10    10    81    86\n# i 17 more rows\n```\n:::\n:::\n\nA column of `yes` and a column of `no`. The classes were of different sizes, so the `yes` column, with only 20 observations, has some `NA` (\"missing\") observations at the end (scroll down to see them) to enable  the dataframe to keep a rectangular shape.\n\nWe will learn later what to call these layouts of data:  \"longer\" and \"wider\" (respectively), and how to convert between them. R usually likes \"longer\" data, as in the data file, but you will often see data sets displayed wider because it takes up less space.\n\n\n\n$\\blacksquare$\n\n\n(b) Make a suitable graph of these data.\n\nSolution\n\n\nThe teachers were hoping to see how the laptop-yes and the laptop-no groups compared in terms of algebra scores, so side-by-side boxplots would be helpful. More simply, we have one quantitative and one categorical variable, which is a boxplot according to the table in the notes:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(algebra, aes(x = laptop, y = score)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/algebra-4-1.pdf){fig-pos='H'}\n:::\n:::\n\nExtra: as you will note below, the median score for the students with laptops is a little higher for the students who had laptops. This is easy to see on a boxplot because that is what a boxplot does. (That was what Tukey, who we will meet later, *designed* the boxplot to do.)\n\nAnother plot you might have drawn is a histogram for each group, side by side, or, as they come out here, above and below. This works using facets:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(algebra, aes(x = score)) + \ngeom_histogram(bins = 10) +\nfacet_wrap(~laptop, ncol = 1)\n```\n\n::: {.cell-output-display}\n![](data-summaries_files/figure-pdf/algebra-5-1.pdf){fig-pos='H'}\n:::\n:::\nLooking  at those, can you *really* say that the median is slightly higher for the `yes` group? I really don't think you can. Certainly it is clear from the histograms that the spread for the `yes` group is less, but comparing the medians is much more easily done from the boxplot. The teachers were interested in whether the laptops were associated with higher scores on average, so the kind of comparison that the boxplot affords is clearly preferred here. \n\nIf you are interested in the code: you imagine you're  going to make a histogram of scores regardless of group, and then at the end you facet by your grouping variable. I added the `ncol = 1` to make the plots come out in one column (that is, one above the other). If you don't do this, they come out left and right, which makes the distributions even harder to compare.\n\n\n$\\blacksquare$\n\n\n(c) Comment briefly on your graph, thinking about what the teachers would like to know.\n\nSolution\n\n\nThere are three things to say something about, the first two of which would probably interest the teachers:\n\n- comparison of centre: the *median* score for the group that had laptops is (slightly) higher than for the group that did not.\n- comparison of spread: the scores for the group that had laptops are less spread out (have smaller *interquartile range*) than for the group that did not.\n- assessment of  shape: both groups have low outliers, or are skewed to the left in shape.\n\nSome comments from me:\n\n- boxplots say *nothing* about mean and standard deviation, so don't mention those here. You should say something about the measures of centre (median) and spread (IQR) that they *do* use.\n- I think of skewness as a property of a whole distribution, but outlierness as a property of individual observations. So, when you're looking at this one, think about where the evidence about shape is coming from: is it coming from those one or two low values that are different from the rest (which would be outliers), or is it coming from the whole distribution (would you get the same story if those maybe-outliers are taken away)? My take is that if you take the outliers away, both distributions are close to symmetric, and therefore what you see here is outliers rather than skewness. If you see something different, make the case for it.\n\nOne reason to suspect skewness or something  like it is that test scores have an upper limit (100) that some of the scores got close to, and no effective lower limit (the lower limit is 0 but no-one got very close to that). In this sort of situation, you'd expect the scores to be skewed away from the limit: that is, to the left. Or to have low outliers rather than high ones.\n\n\n$\\blacksquare$\n\n\n(d) Work out the median and  inter-quartile range for the students who did and who did not have laptops, and compare with the boxplot. (In R, the inter-quartile range is `IQR` in uppercase.)\n\nSolution\n\n\nThis is easy to make way harder than it needs to be: `group_by` and `summarize` will do it. Put the two summaries in one `summarize`:\n\n::: {.cell}\n\n```{.r .cell-code}\nalgebra %>% \ngroup_by(laptop) %>% \nsummarize(med = median(score), iqr = IQR(score))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 3\n  laptop   med   iqr\n  <chr>  <dbl> <dbl>\n1 no        81    20\n2 yes       84    13\n```\n:::\n:::\n\nThen relate these to the information on the boxplot: the centre line of the box is the median. For the `no` group this is just above 80, so 81 makes sense; for the `yes` group this is not quite halfway between 80 and 90, so 84 makes sense.\n\nThe inter-quartile range is the height of the box for each group. Estimate the top and bottom of the two boxes from the boxplot scale, and subtract. For the  `no` group this is something like $88-68$ which *is* 20, and for the `yes` group it is something like $93-80$ which is indeed 13.\n\nExtra: I didn't ask you here about whether the difference was likely meaningful. The focus here was on getting the graph and summaries. If I had done so, you would then need to consider things like whether a three-point difference in medians could have been chance, and whether we really had random allocation of students to groups.\n\nTo take the second point first: these are students who chose to take two different classes, rather than being randomly allocated to classes as would be the case in a true experiment. What we have is really in between an experiment and an observational study; yes, there was a treatment (laptop or not) that was (we hope) randomly allocated to one class and not the other, but the classes could have been different for any number of other reasons that had nothing to do with having  laptops or not, such as time of day, teacher, approach to material, previous ability at algebra, etc.\n\nSo even if we are willing to believe that the students were as-if randomized to laptop or not, the question remains as to whether that three-point difference in medians is reproducible or indicative of a real difference or not. This is the kind of thing we would try a two-sample $t$-test with. In this case, we might doubt whether it will come out significant (because of the small difference in medians and presumably means, compared to the amount of variability present), and, even then, there is the question of whether we *should* be doing a $t$-test at all, given the outliers.\n\n\n$\\blacksquare$\n\n\n",
    "supporting": [
      "data-summaries_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}