{
  "hash": "2e45c695fa719d70a943fb3db28a9a84",
  "result": {
    "markdown": "# Matched pairs t and sign test\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(smmr)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Measuring body fat\n\n\n Athletes are concerned with measuring their body fat\npercentage. Two different methods are available: one using ultrasound,\nand the other using X-ray technology. We are interested in whether\nthere is a difference in the mean body fat percentage as measured by\nthese two methods, and if so, how big that difference is. Data on 16\nathletes are at\n[link](http://ritsokiguess.site/datafiles/bodyfat.txt). \n\n\n\n(a) Explain briefly why a matched pairs analysis is more\nsuitable for these data than a two-independent-samples analysis\n(using a two-sample $t$-test). You might find that looking at the\ndata (clicking on the link) helps you figure this out.\n\n\n\n(b) Read in the data and check that you have a sensible number of\nrows and columns.\n\n\n\n\n(c) Carry out a suitable test to determine whether the means are\nthe same or different. (At this point, obtain the R output including a P-value.)\n\n\n\n\n(d) What do you conclude from the test?\n\n\n\n\n(e) Obtain a 95\\% confidence interval for the population mean\ndifference. How is the interval consistent with your test?\n\n\n\n\n(f) Calculate the differences, and make a normal quantile plot of\nthem. Is there any evidence that normality of differences fails?\nExplain briefly. \n\n\n\n\n\n\n\n\n\n\n##  Throwing baseballs and softballs\n\n\n Can students throw a baseball farther than a softball? A\nstatistics class, containing 24 students, went out to a football field\nto try to answer this question. Each student warmed up and then threw\neach type of ball as far as they could. The order of ball types was\nrandomized: some students threw the baseball first, and some threw the\nsoftball first. (A softball is bigger than a baseball, so we might\nexpect that a softball would be harder to throw a long way than a\nbaseball.) The data are in\n[http://ritsokiguess.site/datafiles/throw.txt](http://ritsokiguess.site/datafiles/throw.txt) in three\ncolumns: the first is a number identifying the student, the second is\nthe distance thrown with the baseball (in yards) and the third is the\ndistance thrown with the softball (also in yards).\n\n\n\n(a) Read the data into R. You'll need to supply some names\nto the columns.\n\n\n\n(b) Calculate a column of differences, baseball minus softball,\n*in* the data frame.\n\n\n\n(c) Carry out a sign test in R, testing the null hypothesis\nthat the median difference is zero, against the alternative that\nit is greater than zero. Obtain a P-value. Your option whether you use\n`smmr` or not.\n\n\n\n\n\n\n\n\n##  Throwing baseballs and softballs, again\n\n\n Previously, you carried out a sign test to determine\nwhether students could throw a baseball farther than a softball. This\ntime, we will calculate a confidence interval for the median\ndifference baseball minus softball, using the results of sign tests.\n\n\n\n(a) Read the data into R from\n[link](http://ritsokiguess.site/datafiles/throw.txt), giving\nappropriate names to the columns, and add a column of\ndifferences. \n\n\n\n(b) Use `smmr` to find a 95\\% confidence interval for the\nmedian difference.\n\n\n\n(c) What function in `smmr` will run a two-sided sign test\nand return only the P-value? Check that it works by testing whether the\nmedian difference for your data is zero or different from zero.\n\n\n\n(d) Based on your P-value, do you think 0 is inside the confidence\ninterval or not? Explain briefly.\n\n\n\n(e) Obtain a 95\\% confidence interval for the population\nmedian difference, baseball minus softball, using a\ntrial-and-error procedure that determines whether a number of\npossible medians are inside or outside the CI.\n\n\n\n\n\n\n\n\n## Changes in salary\n\n\n\n A company is growing and would like to attract more\nemployees. The company would like to advertise that salaries there are\nincreasing. To do this, the company randomly samples 20 employees that\nhave been working there since January 2016, and for each of these\nemployees, records their salary in January 2016 and January 2017. The\ndata, with salaries in thousands of dollars, are in\n[link](http://ritsokiguess.site/datafiles/salaryinc.txt). \n\n\n\n(a) Read the data into R and demonstrate that you have two\nsalaries for each of 20 employees.\n\n\n(b) To compare the salaries, explain briefly why a\nmatched-pairs test would be better than a two-sample test.\n\n\n(c) Make a suitable graph to assess the assumptions for a\nmatched-pairs $t$-test. What does your graph tell you?\n\n\n(d) Carry out a suitable matched-pairs $t$-test on these data. (If you\nthought in the previous part that this was the wrong thing to do, do\nit anyway for the purposes of this assignment.) What do you conclude?\n\n\n(e) The company would like to estimate  \n*how\nmuch* salaries are increasing, on average. Obtain some output that\nwill enable the company to assess this, and tell the CEO which piece\nof the output they should look at.\n\n\n\n\n\n##  Body fat revisited\n\n\n Athletes are concerned with measuring their body fat\npercentage. Two different methods are available: one using ultrasound,\nand the other using X-ray technology. We are interested in whether\nthere is a difference in the mean body fat percentage as measured by\nthese two methods, and if so, how big that difference is. Data on 16\nathletes are at\n[link](http://ritsokiguess.site/datafiles/bodyfat.txt). \n\nWe saw this data set before.\n\n\n\n\n(a) Read in the data again.\n\n\n\n\n(b) Calculate the differences, and make a normal quantile plot of\nthem. Is there any evidence that normality of differences fails?\nExplain briefly. \n\n\n\n\n(c) Previously, we did a matched-pairs $t$-test for these data. In\nthe light of your normal quantile plot, do you think that was a good\nidea? Explain briefly.\n\n\n\n\n(d) Use the sign test appropriately to compare the two methods for\nmeasuring body fat. (Use `smmr` if you wish.) What do you\nconclude, as ever in the context of the data?\n\n\n\n\n\n\n\n\n## The dentist and blood pressure\n\n Going to the dentist is scary for a lot of people. One way in which this might show up is that people might have higher blood pressure on average before their dentist's appointment than an hour after the appointment is done. Ten randomly-chosen individuals have their (systolic) blood pressure measured while they are in a dentist's waiting room, and then again one hour after their appointment is finished.\n\nThe data are in [http://ritsokiguess.site/datafiles/blood_pressure1.csv](http://ritsokiguess.site/datafiles/blood_pressure1.csv).\n\n\n(a) Read in and display the data.\n\n\n\n(b) What kind of experimental design is this? How do you know? Explain briefly.\n\n\n\n(c) Run a suitable $t$-test on these data. What do you conclude, in the context of the data?\n\n\n\n(d) Run a suitable sign test on these data. What do you conclude, in the context of the data?\n\n\n\n(e) Draw a suitable normal quantile plot of these data, one that will enable you to decide between the tests you ran in the previous two parts.\n\n\n\n(f) Discuss briefly which of your two tests is the more appropriate one to run.\n\n\n\n\n\n\n\n\n## French teachers\n\n Twenty high-school French teachers attended a summer institute to improve their French skills. At the beginning of their session, each teacher took a listening test (to test their understanding of spoken French). After 4 weeks of immersion in French, each teacher took a similar listening test again. (The actual French spoken in the two tests was different, so simply taking the first test should not improve the score in the second one; the tests were otherwise similar.) The maximum score on each test was 36, and a higher score is better. The data are [here](http://ritsokiguess.site/datafiles/frenchtest.txt). (Right-click on the link, select \"copy link address\", and then paste that URL into R Studio.) The data values are separated by *tabs*.\n\nThe data file has three columns:\n\n- an identification for each teacher\n- the teacher's score in the first test\n- the teacher's score in the second test\n\n\n\n(a) Read in and display (some of) the data.\n\n\n\n(b) Explain briefly why this is a matched-pairs study. \n\n\n\n(c) Run a suitable matched-pairs $t$-test to see whether the teachers' scores have on average *improved* over the four weeks.\n\n\n\n(d) What do you conclude from your test, in the context of the data?\n\n\n\n(e) How much is the teachers' listening skill improving, on average? Give a suitable interval to support your answer.\n\n\n\n(f) Make a suitable plot to assess any assumptions for this test.\n\n\n\n(g) Do you trust the result of your matched-pairs $t$-test? Explain briefly. \n\n\n\n(h) Run a suitable sign test, and obtain a suitable (95%) confidence interval. Comment briefly on your results.\n\n\n\n(i) Comment briefly on the comparison between your inferences for the mean and the median. \n\n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n\n##  Measuring body fat\n\n\n Athletes are concerned with measuring their body fat\npercentage. Two different methods are available: one using ultrasound,\nand the other using X-ray technology. We are interested in whether\nthere is a difference in the mean body fat percentage as measured by\nthese two methods, and if so, how big that difference is. Data on 16\nathletes are at\n[link](http://ritsokiguess.site/datafiles/bodyfat.txt). \n\n\n\n(a) Explain briefly why a matched pairs analysis is more\nsuitable for these data than a two-independent-samples analysis\n(using a two-sample $t$-test). You might find that looking at the\ndata (clicking on the link) helps you figure this out.\n\n\nSolution\n\n\nThe data file looks like this:\n\n```\n\nathlete xray ultrasound\n1 5.00 4.75\n2 7 3.75\n3 9.25 9\n4 12 11.75\n5 17.25 17\n6 29.5 27.5\n7 5.5 6.5\n8 6 6.75\n9 8 8.75\n10 8.5 9.5\n11 9.25 9.5\n12 11 12\n13 12 12.25\n14 14 15.5\n15 17 18\n16 18 18.25\n\n```\n\nThe data are two measurements for each of the 16 athletes: that\nis, each athlete had their body fat percentage measured using\n*both* of the two methods. \nExtra: a two-sample $t$ approach would be reasonable if one set of 16\nathletes had been measured by X-ray and *another different*\nset of 16 athletes had been measured by ultrasound. (That is, if\nthere had been 32 athletes in total, with each one randomly\nassigned to *one* of the measurement methods.) But that's not\nwhat happened. It is easy to measure one athlete's body fat\npercentage using both of the two methods, so a matched pairs\ndesign is easy to implement (as well as being better). If you use\ntwo independent samples (each athlete doing only one measurement\nmethod), you introduce an extra source of variability: athletes\ndiffer one from another in body fat, as well as differing possibly\nby measurement method. If you use a matched-pairs design, you\nremove the athlete-to-athlete differences, leaving only the\ndifferences due to measurement method.\n\n\n$\\blacksquare$\n\n(b) Read in the data and check that you have a sensible number of\nrows and columns.\n\n\n\nSolution\n\n\nThis kind of thing. Since you looked at the data (didn't you?),\nyou'll know that the values are separated by single spaces:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyurl <- \"http://ritsokiguess.site/datafiles/bodyfat.txt\"\nbodyfat <- read_delim(myurl, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 16 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\ndbl (3): athlete, xray, ultrasound\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nbodyfat\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"athlete\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"xray\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ultrasound\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"5.00\",\"3\":\"4.75\"},{\"1\":\"2\",\"2\":\"7.00\",\"3\":\"3.75\"},{\"1\":\"3\",\"2\":\"9.25\",\"3\":\"9.00\"},{\"1\":\"4\",\"2\":\"12.00\",\"3\":\"11.75\"},{\"1\":\"5\",\"2\":\"17.25\",\"3\":\"17.00\"},{\"1\":\"6\",\"2\":\"29.50\",\"3\":\"27.50\"},{\"1\":\"7\",\"2\":\"5.50\",\"3\":\"6.50\"},{\"1\":\"8\",\"2\":\"6.00\",\"3\":\"6.75\"},{\"1\":\"9\",\"2\":\"8.00\",\"3\":\"8.75\"},{\"1\":\"10\",\"2\":\"8.50\",\"3\":\"9.50\"},{\"1\":\"11\",\"2\":\"9.25\",\"3\":\"9.50\"},{\"1\":\"12\",\"2\":\"11.00\",\"3\":\"12.00\"},{\"1\":\"13\",\"2\":\"12.00\",\"3\":\"12.25\"},{\"1\":\"14\",\"2\":\"14.00\",\"3\":\"15.50\"},{\"1\":\"15\",\"2\":\"17.00\",\"3\":\"18.00\"},{\"1\":\"16\",\"2\":\"18.00\",\"3\":\"18.25\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\n16 rows (athletes) and 3 columns, one for each measurement\nmethod and one labelling the athletes. All good.\n\nSince 16 is not too much bigger than 10, I got the whole data frame\nhere. (At least, I think that's the reason I got more than 10 rows.)\nIn an R Notebook, you'll see the first ten rows as normal, with a\nbutton to click to see the other six.\n\n\n\n\n$\\blacksquare$\n\n(c) Carry out a suitable test to determine whether the means are\nthe same or different. (At this point, obtain the R output including a P-value.)\n\n\n\nSolution\n\n\nFeed the two columns into `t.test` along with\n`paired=T`. This is a two-sided test, so we don't have to\ntake any special steps for that. Note that we're back to the\n\"old-fashioned\" version of `t.test` that *does not*\nallow `data=`, so we have to go the `with` way:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(bodyfat, t.test(xray, ultrasound, paired = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  xray and ultrasound\nt = -0.30801, df = 15, p-value = 0.7623\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.7425068  0.5550068\nsample estimates:\nmean difference \n       -0.09375 \n```\n:::\n:::\n\n \n\n\n\n$\\blacksquare$\n\n(d) What do you conclude from the test?\n\n\n\nSolution\n\n\nThe P-value of 0.7623 is not at all small, so there is no way we can\nreject the null hypothesis.^[My hat stays on my head.] There\nis no evidence of a difference in means; we can act as if the two\nmethods produce the same mean body fat percentage. \nThat is to say, on this evidence we can use either method, whichever\none is cheaper or more convenient.\n\n\n\n\n$\\blacksquare$\n\n(e) Obtain a 95\\% confidence interval for the population mean\ndifference. How is the interval consistent with your test?\n\n\n\nSolution\n\n\nYou don't even need to do any more coding: the test was two-sided,\nso just pick the confidence interval off the output above: $-0.74$\nto 0.56. \nThe interval includes both positive and negative values (or, 0 is\ninside the interval), so the difference could go either way. This is\nentirely consistent with not being able to reject the null.\n\n\n\n$\\blacksquare$\n\n(f) Calculate the differences, and make a normal quantile plot of\nthem. Is there any evidence that normality of differences fails?\nExplain briefly. \n\n\n\nSolution\n\n\nThe smoothest^[I learned yesterday that the Welsh word for \"ironing\" is *smwddio*, which seems weird until you say    it out loud: it sounds like \"smoothio\".] \nway to do this is to\nuse a pipeline: use a `mutate` to create the column of\ndifferences, and then pipe that into `ggplot`, omitting the\ndata frame that would normally go first (the input data frame here\nis the new one with the differences in it, which doesn't have a\nname). I'll make a normal quantile plot in a moment, but if you\nhaven't seen that yet, the plot to make is a histogram:\n\n::: {.cell}\n\n```{.r .cell-code}\nbodyfat %>%\n  mutate(diff = xray - ultrasound) %>%\n  ggplot(aes(x = diff)) + geom_histogram(bins = 6)\n```\n\n::: {.cell-output-display}\n![](matched-pairs-sign_files/figure-html/bodyfat-3-1.png){width=672}\n:::\n:::\n\n   \n\nI don't know whether you'd call that \"approximately normal\" or\nnot. We are in kind of a double-bind with this one: the sample size is\nsmall, so normality matters, but with a small sample, the data might\nnot look very normal. It's kind of skewed right, but most of the\nevidence for the skewness is contained in those two observations with\ndifference 2 and above, which is pretty flimsy evidence for\nanything. (In the normal quantile plot below, the suggestion is that\nthose two observations really are a bit too large. It's easier to tell\nthere.) \n\nBelow, I'm repeating the calculation of the differences, which is\ninefficient. If I'm going to draw two graphs of the differences, the\nright way is to calculate the differences *and save the data\nframe*, then use that new data frame twice. But you're probably only\ngoing to draw either the histogram or the normal quantile plot, not\nboth, so you can use the appropriate one of my two bits of code. The\nnormal quantile plot:\n\n::: {.cell}\n\n```{.r .cell-code}\nbodyfat %>%\n  mutate(diff = xray - ultrasound) %>%\n  ggplot(aes(sample = diff)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](matched-pairs-sign_files/figure-html/bodyfat-4-1.png){width=672}\n:::\n:::\n\n   \nThis is showing a little evidence of skewness or outliers  (depending\non your point of view: either is good). The lowest and highest values\nare both too high, and the pattern of points on the plot is kind of\ncurved (which would be evidence of skewness). Or you could say that\nthe two highest values are too high, with the other values being more\nor less in line (that would be evidence of outliers at the upper\nend). I like outliers better than skewness, since those bottom-end\npoints are not far off the line. I would also accept \n\"no substantial problems\", \nif you can make the case that those two highest points are\nnot too far off the line. With only 16 observations as we have here,\neven truly normal data would stray off the line a bit.\n\nAs ever, your explanation is more important than your conclusion. Can\nyou justify what you think?\n\nIf you took your differences the other way around, as\n`ultrasound` minus `xray`, your plot will also be the\nother way around, with the \"outliers\" at the bottom. That's good\ntoo.\n\nWhere this is going (which I didn't ask you) is whether or not we\ntrust the result of the matched pairs test. I would say that the test\nis so far from being significant, and the failure of normality is not\ngross, that it is hard to imagine *any* alternative test coming\nup with a significant result. So I would be happy to trust this paired\n$t$-test.\n\n$\\blacksquare$\n\n\n\n\n\n\n\n##  Throwing baseballs and softballs\n\n\n Can students throw a baseball farther than a softball? A\nstatistics class, containing 24 students, went out to a football field\nto try to answer this question. Each student warmed up and then threw\neach type of ball as far as they could. The order of ball types was\nrandomized: some students threw the baseball first, and some threw the\nsoftball first. (A softball is bigger than a baseball, so we might\nexpect that a softball would be harder to throw a long way than a\nbaseball.) The data are in\n[http://ritsokiguess.site/datafiles/throw.txt](http://ritsokiguess.site/datafiles/throw.txt) in three\ncolumns: the first is a number identifying the student, the second is\nthe distance thrown with the baseball (in yards) and the third is the\ndistance thrown with the softball (also in yards).\n\n\n\n(a) Read the data into R. You'll need to supply some names\nto the columns.\n\n\nSolution\n\n\nThis kind of thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyurl=\"http://ritsokiguess.site/datafiles/throw.txt\"\nthrows=read_delim(myurl,\" \",col_names=c(\"student\",\"baseball\",\"softball\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 24 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\ndbl (3): student, baseball, softball\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nthrows\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"student\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"baseball\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"softball\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"65\",\"3\":\"57\"},{\"1\":\"2\",\"2\":\"90\",\"3\":\"58\"},{\"1\":\"3\",\"2\":\"75\",\"3\":\"66\"},{\"1\":\"4\",\"2\":\"73\",\"3\":\"61\"},{\"1\":\"5\",\"2\":\"79\",\"3\":\"65\"},{\"1\":\"6\",\"2\":\"68\",\"3\":\"56\"},{\"1\":\"7\",\"2\":\"58\",\"3\":\"53\"},{\"1\":\"8\",\"2\":\"41\",\"3\":\"41\"},{\"1\":\"9\",\"2\":\"56\",\"3\":\"44\"},{\"1\":\"10\",\"2\":\"70\",\"3\":\"65\"},{\"1\":\"11\",\"2\":\"64\",\"3\":\"57\"},{\"1\":\"12\",\"2\":\"62\",\"3\":\"60\"},{\"1\":\"13\",\"2\":\"73\",\"3\":\"55\"},{\"1\":\"14\",\"2\":\"50\",\"3\":\"53\"},{\"1\":\"15\",\"2\":\"63\",\"3\":\"54\"},{\"1\":\"16\",\"2\":\"48\",\"3\":\"42\"},{\"1\":\"17\",\"2\":\"34\",\"3\":\"32\"},{\"1\":\"18\",\"2\":\"49\",\"3\":\"48\"},{\"1\":\"19\",\"2\":\"48\",\"3\":\"45\"},{\"1\":\"20\",\"2\":\"68\",\"3\":\"67\"},{\"1\":\"21\",\"2\":\"30\",\"3\":\"27\"},{\"1\":\"22\",\"2\":\"26\",\"3\":\"25\"},{\"1\":\"23\",\"2\":\"28\",\"3\":\"25\"},{\"1\":\"24\",\"2\":\"26\",\"3\":\"31\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nThis is one of those times where we have to tell R what names to give\nthe columns. Or you can put `col_names=F` and leave the\ncolumns called `X1, X2, X3` or whatever they end up as.\n\n\n$\\blacksquare$\n\n(b) Calculate a column of differences, baseball minus softball,\n*in* the data frame.\n\n\nSolution\n\n\nAdd it to the data frame using `mutate`. Use the\nright-arrow assignment to create what I called\n`throws2` below, or put something like\n`throws2 <-` on the beginning of the line. Your choice.\n\n::: {.cell}\n\n```{.r .cell-code}\nthrows %>% mutate(diff=baseball-softball) ->\n  throws2\n```\n:::\n\n\n$\\blacksquare$\n\n(c) Carry out a sign test in R, testing the null hypothesis\nthat the median difference is zero, against the alternative that\nit is greater than zero. Obtain a P-value. Your option whether you use\n`smmr` or not.\n\n\nSolution\n\n\nI think using `smmr` is way easier, so I'll do that\nfirst. There is even a shortcut in that the null median defaults to\nzero, which is exactly what we want here:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(smmr)\nsign_test(throws2,diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$above_below\nbelow above \n    2    21 \n\n$p_values\n  alternative      p_value\n1       lower 9.999971e-01\n2       upper 3.302097e-05\n3   two-sided 6.604195e-05\n```\n:::\n:::\n\nWe want, this time, the upper-tailed one-sided test, since we want to\nprove that students can throw a baseball a *longer* distance\nthan a softball. Thus the P-value we want is 0.000033.\n\nTo build it yourself, you know the steps by now.\nFirst step is to count how many differences are greater and less than zero:\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(throws2$diff>0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFALSE  TRUE \n    3    21 \n```\n:::\n:::\n\nor\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(throws2$diff<0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFALSE  TRUE \n   22     2 \n```\n:::\n:::\n\nor, since we have things in a data frame,\n\n::: {.cell}\n\n```{.r .cell-code}\nthrows2 %>% count(diff>0)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"diff > 0\"],\"name\":[1],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"FALSE\",\"2\":\"3\"},{\"1\":\"TRUE\",\"2\":\"21\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nor count those less than zero. I'd take any of those.\n\nNote that these are *not all the same*. One of the differences is\nin fact exactly zero. The technically right thing to do with the zero\ndifference is to throw it away (leaving 23 differences with 2 negative\nand 21 positive). I would take that, or 2 or 3 negative differences\nout of 24 (depending on whether you count \"greater than zero\" or\n\"less than zero\"). We hope that this won't make a material\ndifference to the P-value; it'll make some difference, but won't (we\nhope) change the conclusion about whether to reject.\n\nSecond step is to get a P-value for whichever one of those you got,\nfrom the appropriate binomial distribution. \n\nThe P-value is the probability of getting 21 (or 22) positive\ndifferences out of 24 (or 23) or more, since this is the end of the\ndistribution we should be at if the alternative hypothesis is correct.\nThus any of these will get you a defensible P-value:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(dbinom(21:23,23,0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3.302097e-05\n```\n:::\n\n```{.r .cell-code}\nsum(dbinom(22:24,24,0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.7941e-05\n```\n:::\n\n```{.r .cell-code}\nsum(dbinom(21:24,24,0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0001385808\n```\n:::\n\n```{.r .cell-code}\nsum(dbinom(0:2,23,0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3.302097e-05\n```\n:::\n\n```{.r .cell-code}\nsum(dbinom(0:2,24,0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.7941e-05\n```\n:::\n\n```{.r .cell-code}\nsum(dbinom(0:3,24,0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0001385808\n```\n:::\n:::\n\nThe first and fourth of those are the same as `smmr` (throwing\naway the exactly-median value). \n\nAs we hoped, there is no *material* difference here: there is no\ndoubt with any of these possibilities that we will reject a median\ndifference of zero in favour of a median difference greater than\nzero. \n\n$\\blacksquare$\n\n\n\n\n\n\n##  Throwing baseballs and softballs, again\n\n\n Previously, you carried out a sign test to determine\nwhether students could throw a baseball farther than a softball. This\ntime, we will calculate a confidence interval for the median\ndifference baseball minus softball, using the results of sign tests.\n\n\n\n(a) Read the data into R from\n[link](http://ritsokiguess.site/datafiles/throw.txt), giving\nappropriate names to the columns, and add a column of\ndifferences. \n\n\nSolution\n\n\nI did it this way, combining the reading\nof the data with the calculation of the differences in *one* pipe:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyurl <- \"http://ritsokiguess.site/datafiles/throw.txt\"\nthrows <- read_delim(myurl, \" \", col_names = c(\"student\", \"baseball\", \"softball\")) %>%\n  mutate(diff = baseball - softball)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 24 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\ndbl (3): student, baseball, softball\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nthrows\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"student\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"baseball\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"softball\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"diff\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"65\",\"3\":\"57\",\"4\":\"8\"},{\"1\":\"2\",\"2\":\"90\",\"3\":\"58\",\"4\":\"32\"},{\"1\":\"3\",\"2\":\"75\",\"3\":\"66\",\"4\":\"9\"},{\"1\":\"4\",\"2\":\"73\",\"3\":\"61\",\"4\":\"12\"},{\"1\":\"5\",\"2\":\"79\",\"3\":\"65\",\"4\":\"14\"},{\"1\":\"6\",\"2\":\"68\",\"3\":\"56\",\"4\":\"12\"},{\"1\":\"7\",\"2\":\"58\",\"3\":\"53\",\"4\":\"5\"},{\"1\":\"8\",\"2\":\"41\",\"3\":\"41\",\"4\":\"0\"},{\"1\":\"9\",\"2\":\"56\",\"3\":\"44\",\"4\":\"12\"},{\"1\":\"10\",\"2\":\"70\",\"3\":\"65\",\"4\":\"5\"},{\"1\":\"11\",\"2\":\"64\",\"3\":\"57\",\"4\":\"7\"},{\"1\":\"12\",\"2\":\"62\",\"3\":\"60\",\"4\":\"2\"},{\"1\":\"13\",\"2\":\"73\",\"3\":\"55\",\"4\":\"18\"},{\"1\":\"14\",\"2\":\"50\",\"3\":\"53\",\"4\":\"-3\"},{\"1\":\"15\",\"2\":\"63\",\"3\":\"54\",\"4\":\"9\"},{\"1\":\"16\",\"2\":\"48\",\"3\":\"42\",\"4\":\"6\"},{\"1\":\"17\",\"2\":\"34\",\"3\":\"32\",\"4\":\"2\"},{\"1\":\"18\",\"2\":\"49\",\"3\":\"48\",\"4\":\"1\"},{\"1\":\"19\",\"2\":\"48\",\"3\":\"45\",\"4\":\"3\"},{\"1\":\"20\",\"2\":\"68\",\"3\":\"67\",\"4\":\"1\"},{\"1\":\"21\",\"2\":\"30\",\"3\":\"27\",\"4\":\"3\"},{\"1\":\"22\",\"2\":\"26\",\"3\":\"25\",\"4\":\"1\"},{\"1\":\"23\",\"2\":\"28\",\"3\":\"25\",\"4\":\"3\"},{\"1\":\"24\",\"2\":\"26\",\"3\":\"31\",\"4\":\"-5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\n$\\blacksquare$\n\n(b) Use `smmr` to find a 95\\% confidence interval for the\nmedian difference.\n\n\nSolution\n\n\n`ci_median`, with 95\\% being the default confidence level:\n\n::: {.cell}\n\n```{.r .cell-code}\nci_median(throws, diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.002930 8.999023\n```\n:::\n:::\n\n \n\n2 to 9. The ends of a CI for the median will be data values, which are\nall whole numbers, so round off that 8.999.\n\n$\\blacksquare$\n\n(c) What function in `smmr` will run a two-sided sign test\nand return only the P-value? Check that it works by testing whether the\nmedian difference for your data is zero or different from zero.\n\n\nSolution\n\n\nThe rest of the way, we are trying to reproduce that confidence\ninterval by finding it ourselves.\nThe function is called `pval_sign`. If you haven't run into it\nbefore, in R Studio click on Packages, find `smmr`, and\nclick on its name. This will bring up package help, which\nincludes a list of all the functions in the package, along with\na brief description of what each one does. (Clicking\non a function name brings up the help for that function.)\nLet's check that it works properly by repeating the previous\n`sign_test` and verifying that `pval_sign` gives\nthe same thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nsign_test(throws, diff, 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$above_below\nbelow above \n    2    21 \n\n$p_values\n  alternative      p_value\n1       lower 9.999971e-01\n2       upper 3.302097e-05\n3   two-sided 6.604195e-05\n```\n:::\n\n```{.r .cell-code}\npval_sign(0, throws, diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.604195e-05\n```\n:::\n:::\n\n       \n\nThe P-values are the same (for the two-sided test) and both small, so\nthe median difference is not zero.\n\n$\\blacksquare$\n\n(d) Based on your P-value, do you think 0 is inside the confidence\ninterval or not? Explain briefly.\n\n\nSolution\n\n\nAbsolutely not. The median difference is definitely not\nzero, so zero cannot be in the confidence interval.\nOur suspicion, from the one-sided test from earlier, is that\nthe differences were mostly positive (people could throw a\nbaseball farther than a softball, in most cases). So the\nconfidence interval ought to contain only positive values.\nI ask this because it drives what happens below.\n\n$\\blacksquare$\n\n(e) Obtain a 95\\% confidence interval for the population\nmedian difference, baseball minus softball, using a\ntrial-and-error procedure that determines whether a number of\npossible medians are inside or outside the CI.\n\n\nSolution\n\n\n I've given you a fair bit of freedom to tackle this as you\n wish. Anything that makes sense is good: whatever mixture of\n mindlessness, guesswork and cleverness that you want to employ.\nThe most mindless way to try some values one at a time and see what\n you get, eg.:\n \n::: {.cell}\n\n```{.r .cell-code}\npval_sign(1, throws, diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.001489639\n```\n:::\n\n```{.r .cell-code}\npval_sign(5, throws, diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.168188\n```\n:::\n:::\n\n  \n\nSo median 1 is outside and median 5 is inside the 95\\% interval. Keep\ntrying values until you've figured out where the lower and upper ends\nof the interval are: where the P-values cross from below 0.05 to\nabove, or vice versa.\n\nSomething more intelligent is to make a long list of potential\nmedians, and get the P-value for each of them, eg.:\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- tibble(my.med = seq(0, 20, 2))\nd %>% rowwise() %>% \n  mutate(pvals = pval_sign(my.med, throws, diff))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"my.med\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"pvals\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\",\"2\":\"6.604195e-05\"},{\"1\":\"2\",\"2\":\"5.247879e-02\"},{\"1\":\"4\",\"2\":\"8.388197e-01\"},{\"1\":\"6\",\"2\":\"6.776395e-01\"},{\"1\":\"8\",\"2\":\"2.100396e-01\"},{\"1\":\"10\",\"2\":\"2.265584e-02\"},{\"1\":\"12\",\"2\":\"1.489639e-03\"},{\"1\":\"14\",\"2\":\"6.604195e-05\"},{\"1\":\"16\",\"2\":\"3.588200e-05\"},{\"1\":\"18\",\"2\":\"5.722046e-06\"},{\"1\":\"20\",\"2\":\"2.980232e-06\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\n2 is just inside the interval, 8 is also inside, and 10 is\noutside. Some closer investigation:\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- tibble(my.med = seq(0, 2, 0.5))\nd %>% rowwise() %>% \n  mutate(pvals = pval_sign(my.med, throws, diff))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"my.med\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"pvals\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.0\",\"2\":\"6.604195e-05\"},{\"1\":\"0.5\",\"2\":\"2.771616e-04\"},{\"1\":\"1.0\",\"2\":\"1.489639e-03\"},{\"1\":\"1.5\",\"2\":\"2.265584e-02\"},{\"1\":\"2.0\",\"2\":\"5.247879e-02\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nThe bottom end of the interval actually is 2, since 2 is inside and\n1.5 is outside.\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- tibble(my.med = seq(8, 10, 0.5))\nd %>% rowwise() %>% \n  mutate(pvals = pval_sign(my.med, throws, diff))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"my.med\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"pvals\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"8.0\",\"2\":\"0.21003962\"},{\"1\":\"8.5\",\"2\":\"0.15158963\"},{\"1\":\"9.0\",\"2\":\"0.05247879\"},{\"1\":\"9.5\",\"2\":\"0.02265584\"},{\"1\":\"10.0\",\"2\":\"0.02265584\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n \n\nThe top end is 9, 9 being inside and 9.5 outside.\n\nSince the data values are all whole numbers, I think this is accurate enough.\nThe most sophisticated way is the \"bisection\" idea we saw before. We\nalready have a kickoff for this, since we found, mindlessly, that 1 is\noutside the interval on the low end and 5 is inside, so the lower\nlimit has to be between 1 and 5. Let's try halfway between, ie.\\ 3:\n\n::: {.cell}\n\n```{.r .cell-code}\npval_sign(3, throws, diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3833103\n```\n:::\n:::\n\n \n\nInside, so lower limit is between 1 and 3. This can be automated, thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nlo <- 1\nhi <- 3\nwhile (abs(hi - lo) > 0.1) {\n  try <- (lo + hi) / 2\n  ptry <- pval_sign(try, throws, diff)\n  if (ptry > 0.05) {\n    hi <- try\n  } else {\n    lo <- try\n  }\n}\nc(lo, hi)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.9375 2.0000\n```\n:::\n:::\n\n \n\nThe difficult bit is to decide whether the value `try` becomes\nthe new `lo` or the new `hi`. If the P-value for the\nmedian of `try` is greater than 0.05, `try` is inside\nthe interval, and it becomes the new `hi`; otherwise it's\noutside and becomes the new `lo`. Whatever the values are,\n`lo` is always outside the interval and `hi` is always\ninside, and they move closer and closer to each other.\n\nAt the other end of the interval, `lo` is inside and\n`hi` is outside, so there is a little switching around within\nthe loop. For starting values, you can be fairly mindless: for\nexample, we know that 5 is inside and something big like 20 must be outside:\n\n::: {.cell}\n\n```{.r .cell-code}\nlo <- 5\nhi <- 20\nwhile (abs(hi - lo) > 0.1) {\n  try <- (lo + hi) / 2\n  ptry <- pval_sign(try, throws, diff)\n  if (ptry > 0.05) {\n    lo <- try\n  } else {\n    hi <- try\n  }\n}\nc(lo, hi)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8.984375 9.042969\n```\n:::\n:::\n\n \n\nThe interval goes from 2 to (as calculated here) about 9. (This is\napparently the same as `ci_median` in `smmr` got.)\n`ci_median` uses the bisection method with a smaller \"tolerance\" than we\ndid, so its answer is more accurate. It looks as if the interval goes\nfrom 2 to 9: that is, students can throw a baseball on average between\n2 and 9 feet further than they can throw a softball.\n\n$\\blacksquare$\n\n\n\n\n\n\n## Changes in salary\n\n\n\n A company is growing and would like to attract more\nemployees. The company would like to advertise that salaries there are\nincreasing. To do this, the company randomly samples 20 employees that\nhave been working there since January 2016, and for each of these\nemployees, records their salary in January 2016 and January 2017. The\ndata, with salaries in thousands of dollars, are in\n[link](http://ritsokiguess.site/datafiles/salaryinc.txt). \n\n\n\n(a) Read the data into R and demonstrate that you have two\nsalaries for each of 20 employees.\n\nSolution\n\n\nLooking at the file, we see that the values are separated by\nexactly one space:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/salaryinc.txt\"\nsalaries <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 20 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (1): employee\ndbl (2): jan2016, jan2017\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nsalaries\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"employee\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"jan2016\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"jan2017\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"A\",\"2\":\"36.00\",\"3\":\"39.50\"},{\"1\":\"B\",\"2\":\"41.25\",\"3\":\"47.00\"},{\"1\":\"C\",\"2\":\"40.00\",\"3\":\"45.00\"},{\"1\":\"D\",\"2\":\"42.80\",\"3\":\"49.00\"},{\"1\":\"E\",\"2\":\"51.00\",\"3\":\"57.75\"},{\"1\":\"F\",\"2\":\"50.50\",\"3\":\"54.00\"},{\"1\":\"G\",\"2\":\"56.00\",\"3\":\"62.00\"},{\"1\":\"I\",\"2\":\"57.80\",\"3\":\"69.90\"},{\"1\":\"J\",\"2\":\"62.00\",\"3\":\"66.80\"},{\"1\":\"K\",\"2\":\"65.50\",\"3\":\"71.00\"},{\"1\":\"L\",\"2\":\"66.00\",\"3\":\"72.00\"},{\"1\":\"M\",\"2\":\"68.90\",\"3\":\"74.00\"},{\"1\":\"N\",\"2\":\"71.00\",\"3\":\"80.00\"},{\"1\":\"O\",\"2\":\"72.30\",\"3\":\"79.00\"},{\"1\":\"P\",\"2\":\"74.65\",\"3\":\"80.00\"},{\"1\":\"Q\",\"2\":\"77.00\",\"3\":\"83.10\"},{\"1\":\"R\",\"2\":\"79.90\",\"3\":\"82.50\"},{\"1\":\"S\",\"2\":\"81.00\",\"3\":\"92.00\"},{\"1\":\"T\",\"2\":\"83.25\",\"3\":\"85.00\"},{\"1\":\"U\",\"2\":\"90.00\",\"3\":\"101.00\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n     \n\nThere are 20 employees (rows), and two columns of salaries: for each\nemployee in the data set, their salary in January 2016 and in January\n2017 (thus, two salaries for each employee).\n\n$\\blacksquare$\n\n(b) To compare the salaries, explain briefly why a\nmatched-pairs test would be better than a two-sample test.\n\nSolution\n\n\nA matched-pairs test would be better because we have two\nobservations (salaries) for each subject (employee). A two-sample\ntest would be appropriate if we had two separate sets of\nemployees, one set with their salaries recorded in 2016 and the\nother with their salaries recorded in 2017. That is not what we\nhave here.\nYou can go after this either way: why a matched-pairs approach is\nappropriate, or why a two-sample approach is not (or a bit of both).\n\n$\\blacksquare$\n\n(c) Make a suitable graph to assess the assumptions for a\nmatched-pairs $t$-test. What does your graph tell you?\n\nSolution\n\n\nThis requires thought first before you do any coding (and this is\nthe reason for this one being four points). What has to be at\nleast approximately normally distributed is the set of\n*differences*, salary at one time point minus the salary at\nthe other, for each employee. The individual salaries don't have\nto be normally distributed at all. \nWe don't have the differences here, so we have to calculate them\nfirst. The smoothest way is to make a pipeline:\n\n::: {.cell}\n\n```{.r .cell-code}\nsalaries %>%\n  mutate(diff = jan2017 - jan2016) %>%\n  ggplot(aes(sample = diff)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](matched-pairs-sign_files/figure-html/salaryinc-2-1.png){width=672}\n:::\n:::\n\n     \n\nA couple of coding notes: (i) you can take the differences 2016 minus\n2017 if you like (then they will tend to be negative), (ii)\n`ggplot` used in a pipeline like this does *not* have a\ndata frame first (the data frame used is the nameless output from the\n`mutate`, with the differences in it). \n\nAlso, there's no problem doing the `mutate`, saving that, and\nthen feeding the saved data frame into `ggplot`. If you find\nthat clearer, go for it.\n\nAs for what I see: I think those points get a bit far from the\nline at the high and low ends: the high values are too high and the\nlow values are too low, which is to say that we have outliers at both\nends, or the distribution has long tails (either way of saying it is\ngood). \n\nThe important conclusion here is whether these differences are normal\n*enough* to trust a matched pairs $t$-test here. We have a sample\nof size 20, so the central limit theorem will help us some, but you\ncan reasonably say that these tails are too long and that we should\nnot trust a matched-pairs $t$-test.\n\nI actually wanted you to practice doing a matched-pairs $t$-test\nanyway, hence my comment in the next part, but the result is probably\nnot *so* trustworthy.\n\n$\\blacksquare$\n\n(d) Carry out a suitable matched-pairs $t$-test on these data. (If you\nthought in the previous part that this was the wrong thing to do, do\nit anyway for the purposes of this assignment.) What do you conclude?\n\nSolution\n\n\nThe company is trying to prove that salaries are *increasing*\nover time, so we need a one-sided alternative.\nFollowing through the procedure, even though you may not trust it much:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(salaries, t.test(jan2016, jan2017, alternative = \"less\", paired = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  jan2016 and jan2017\nt = -10.092, df = 19, p-value = 2.271e-09\nalternative hypothesis: true mean difference is less than 0\n95 percent confidence interval:\n      -Inf -5.125252\nsample estimates:\nmean difference \n         -6.185 \n```\n:::\n:::\n\n     \n\nYou could also have the years the other way around, in which case the\nalternative has to be the other way around as well:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(salaries, t.test(jan2017, jan2016, alternative = \"greater\", paired = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  jan2017 and jan2016\nt = 10.092, df = 19, p-value = 2.271e-09\nalternative hypothesis: true mean difference is greater than 0\n95 percent confidence interval:\n 5.125252      Inf\nsample estimates:\nmean difference \n          6.185 \n```\n:::\n:::\n\n \n\nOr, if you saved the data frame with the differences in it, do a\none-sample test on those, again making sure that you get the\n`alternative` right. I didn't save it, so I'm calculating the\ndifferences again:\n\n::: {.cell}\n\n```{.r .cell-code}\nsalaries %>%\n  mutate(diff = jan2017 - jan2016) %>%\n  with(., t.test(diff, mu = 0, alternative = \"greater\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  diff\nt = 10.092, df = 19, p-value = 2.271e-09\nalternative hypothesis: true mean is greater than 0\n95 percent confidence interval:\n 5.125252      Inf\nsample estimates:\nmean of x \n    6.185 \n```\n:::\n:::\n\n \n\nWhichever way you do it, the P-value is the same $2.271 \\times\n10^{-9}$, which is a whole lot less than 0.05, so there is no doubt at\nall that salaries are increasing.\n\n(Your intuition ought to have expected something like this, because\neveryone's 2017 salary appears to be greater than their 2016 salary.)\n\nExtra: you might be feeling that we ought to be doing a matched-pairs\nsign test, which you could do this way:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(smmr)\nsalaries %>%\n  mutate(diff = jan2017 - jan2016) %>%\n  sign_test(diff, 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$above_below\nbelow above \n    0    20 \n\n$p_values\n  alternative      p_value\n1       lower 1.000000e+00\n2       upper 9.536743e-07\n3   two-sided 1.907349e-06\n```\n:::\n:::\n\n \n\nand then take the \"upper\" P-value, which is in the same ballpark as\nthe one from the $t$-test. So the salaries really are increasing,\nwhether you believe the $t$-test or not. And note that *every  single employee's salary increased*.\n\n(Again, the \"missing\" data frame in `sign_test` is the nameless\none with the differences in it.)\n\n\n$\\blacksquare$\n\n(e) The company would like to estimate  *how\nmuch* salaries are increasing, on average. Obtain some output that\nwill enable the company to assess this, and tell the CEO which piece\nof the output they should look at.\n\nSolution\n\n\nA confidence interval. 95\\% is fine. As before, we have to run\n`t.test` again because we ran a one-sided test and a\nconfidence interval for us is two-sided:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(salaries, t.test(jan2017, jan2016, paired = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  jan2017 and jan2016\nt = 10.092, df = 19, p-value = 4.542e-09\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 4.902231 7.467769\nsample estimates:\nmean difference \n          6.185 \n```\n:::\n:::\n\n     \n\nBetween about \\$5,000 and about \\$7,500. This is what to tell the CEO.\n\n$\\blacksquare$\n\n\n\n\n##  Body fat revisited\n\n\n Athletes are concerned with measuring their body fat\npercentage. Two different methods are available: one using ultrasound,\nand the other using X-ray technology. We are interested in whether\nthere is a difference in the mean body fat percentage as measured by\nthese two methods, and if so, how big that difference is. Data on 16\nathletes are at\n[link](http://ritsokiguess.site/datafiles/bodyfat.txt). \n\nWe saw this data set before.\n\n\n\n\n(a) Read in the data again.\n\n\n\nSolution\n\n\nThis kind of thing. Since you looked at the data (didn't you?),\nyou'll know that the values are separated by single spaces:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyurl <- \"http://ritsokiguess.site/datafiles/bodyfat.txt\"\nbodyfat <- read_delim(myurl, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 16 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\ndbl (3): athlete, xray, ultrasound\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nbodyfat\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"athlete\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"xray\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ultrasound\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"5.00\",\"3\":\"4.75\"},{\"1\":\"2\",\"2\":\"7.00\",\"3\":\"3.75\"},{\"1\":\"3\",\"2\":\"9.25\",\"3\":\"9.00\"},{\"1\":\"4\",\"2\":\"12.00\",\"3\":\"11.75\"},{\"1\":\"5\",\"2\":\"17.25\",\"3\":\"17.00\"},{\"1\":\"6\",\"2\":\"29.50\",\"3\":\"27.50\"},{\"1\":\"7\",\"2\":\"5.50\",\"3\":\"6.50\"},{\"1\":\"8\",\"2\":\"6.00\",\"3\":\"6.75\"},{\"1\":\"9\",\"2\":\"8.00\",\"3\":\"8.75\"},{\"1\":\"10\",\"2\":\"8.50\",\"3\":\"9.50\"},{\"1\":\"11\",\"2\":\"9.25\",\"3\":\"9.50\"},{\"1\":\"12\",\"2\":\"11.00\",\"3\":\"12.00\"},{\"1\":\"13\",\"2\":\"12.00\",\"3\":\"12.25\"},{\"1\":\"14\",\"2\":\"14.00\",\"3\":\"15.50\"},{\"1\":\"15\",\"2\":\"17.00\",\"3\":\"18.00\"},{\"1\":\"16\",\"2\":\"18.00\",\"3\":\"18.25\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\n\n\n$\\blacksquare$\n\n(b) Calculate the differences, and make a normal quantile plot of\nthem. Is there any evidence that normality of differences fails?\nExplain briefly. \n\n\n\nSolution\n\n\nThis is a good place to look ahead. We'll need the differences in two\nplaces, most likely: first for the normal quantile plot, and second\nfor the matched-pairs sign test. So we should calculate and save them first:\n\n::: {.cell}\n\n```{.r .cell-code}\nbodyfat %>% mutate(diff = xray - ultrasound) -> bodyfat2\n```\n:::\n\n \n\nI seem to be using a 2 on the end to name my\ndataframe-with-differences, but you can use whatever name you like.\n\nThen, not forgetting to use the data frame that we just made:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bodyfat2, aes(sample = diff)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](matched-pairs-sign_files/figure-html/bodyfat-sign-3-1.png){width=672}\n:::\n:::\n\n   \nThis is showing a little evidence of skewness or outliers  (depending\non your point of view: either is good). The lowest and highest values\nare both too high, and the pattern of points on the plot is kind of\ncurved (which would be evidence of skewness). Or you could say that\nthe two highest values are too high, with the other values being more\nor less in line (that would be evidence of outliers at the upper\nend). I like outliers better than skewness, since those bottom-end\npoints are not far off the line. I would also accept \n\"no substantial problems\", \nif you can make the case that those two highest points are\nnot too far off the line. With only 16 observations as we have here,\neven truly normal data would stray off the line a bit.\n\nAs ever, your explanation is more important than your conclusion. Can\nyou justify what you think?\n\nIf you took your differences the other way around, as\n`ultrasound` minus `xray`, your plot will also be the\nother way around, with the \"outliers\" at the bottom. That's good\ntoo.\n\n\n\n\n$\\blacksquare$\n\n(c) Previously, we did a matched-pairs $t$-test for these data. In\nthe light of your normal quantile plot, do you think that was a good\nidea? Explain briefly.\n\n\n\nSolution\n\n\nWe are looking for the differences to be approximately normal,\nbearing in mind that we have a sample of size 16, which is not\nthat large. Say what you think here; the points, if I were giving\nany here, would be for the way in which you support it.\nThe comment I made before when we did a matched-pairs $t$-test\nwas that the P-value was so large and non-significant that it was\nhard to imagine any other test giving a significant\nresult. Another way of saying that is that I considered these\ndifferences to be \"normal enough\", given the circumstances.\nYou might very well take a different view. You could say that\nthese differences are clearly not normal, and that the sample size\nof 16 is not large enough to get any substantial help from the\nCentral Limit Theorem. From that point of view, running the\n$t$-test is clearly not advisable.\n\n\n\n$\\blacksquare$\n\n(d) Use the sign test appropriately to compare the two methods for\nmeasuring body fat. (Use `smmr` if you wish.) What do you\nconclude, as ever in the context of the data?\n\n\n\nSolution\n\n\nThat means using a sign test to test the null hypothesis that the\nmedian difference is zero, against the alternative that it is not\nzero. (I don't see anything here to indicate that we are looking only\nfor positive or only for negative differences, so I think two-sided is\nright. You need some reason to do a one-sided test, and there isn't\none here.)\n\nRemembering again to use the data frame that has the differences in it:\n\n::: {.cell}\n\n```{.r .cell-code}\nsign_test(bodyfat2, diff, 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$above_below\nbelow above \n   10     6 \n\n$p_values\n  alternative   p_value\n1       lower 0.2272491\n2       upper 0.8949432\n3   two-sided 0.4544983\n```\n:::\n:::\n\n \n\nThe two-sided P-value is 0.4545, so we are nowhere near rejecting the\nnull hypothesis that the median difference is zero. There is no\nevidence that the two methods for measuring body fat show any\ndifference on average.\n\nThe table of aboves and belows says that there were 6 positive\ndifferences and 10 negative ones. This is not far from an even split,\nso the lack of significance is entirely what we would expect. \n\nExtra: this is the same conclusion that we drew the last time we\nlooked at these data (with a matched-pairs $t$-test). That supports\nwhat I said then, which is that the $t$-test was so far from being\nsignificant, that it could be very wrong without changing the\nconclusion. That is what seems to have happened.\n\n$\\blacksquare$\n\n\n\n\n\n## The dentist and blood pressure\n\n Going to the dentist is scary for a lot of people. One way in which this might show up is that people might have higher blood pressure on average before their dentist's appointment than an hour after the appointment is done. Ten randomly-chosen individuals have their (systolic) blood pressure measured while they are in a dentist's waiting room, and then again one hour after their appointment is finished.\n\nThe data are in [http://ritsokiguess.site/datafiles/blood_pressure1.csv](http://ritsokiguess.site/datafiles/blood_pressure1.csv).\n\n\n(a) Read in and display the data.\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/blood_pressure1.csv\"\nblood_pressure <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 10 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): person\ndbl (2): before, after\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nblood_pressure\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"person\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"before\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"after\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"p1\",\"2\":\"132\",\"3\":\"118\"},{\"1\":\"p2\",\"2\":\"135\",\"3\":\"137\"},{\"1\":\"p3\",\"2\":\"149\",\"3\":\"140\"},{\"1\":\"p4\",\"2\":\"133\",\"3\":\"139\"},{\"1\":\"p5\",\"2\":\"119\",\"3\":\"107\"},{\"1\":\"p6\",\"2\":\"121\",\"3\":\"116\"},{\"1\":\"p7\",\"2\":\"128\",\"3\":\"122\"},{\"1\":\"p8\",\"2\":\"132\",\"3\":\"124\"},{\"1\":\"p9\",\"2\":\"119\",\"3\":\"115\"},{\"1\":\"p10\",\"2\":\"110\",\"3\":\"103\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nAside: A blood pressure is usually given as two numbers, like ``120 over 80''. The first number, which is the one shown in our data, is called the systolic blood pressure. It is the pressure in the arteries when the heart is pumping. The second is called the diastolic blood pressure, and it is the pressure in the arteries when the heart is resting.\n\n$\\blacksquare$\n\n\n(b) What kind of experimental design is this? How do you know? Explain briefly.\n\nSolution\n\n\nThis is a matched pairs design. We know this because we have two measurements on each person, or the same people were measured before and after seeing the dentist. (The thing that it is *not* is one group of people measured before seeing the dentist, and a *different* group of people measured afterwards, so a two-sample test is *not* the right thing.)\n\n\n$\\blacksquare$\n\n\n(c) Run a suitable $t$-test on these data. What do you conclude, in the context of the data?\n\nSolution\n\n\nA matched-pairs $t$-test, then. Remember, we want to see whether blood pressure is *lower* afterwards (that is, before is *greater* than after), so this needs to be one-sided:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(blood_pressure, t.test(before, after, alternative = \"greater\", paired = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  before and after\nt = 2.9945, df = 9, p-value = 0.007545\nalternative hypothesis: true mean difference is greater than 0\n95 percent confidence interval:\n 2.210659      Inf\nsample estimates:\nmean difference \n            5.7 \n```\n:::\n:::\n\nThere are some variations possible here: `before` and `after` could be switched (in which case `alternative` must be reversed also).\n\nOr, you can do a one-sample $t$ on the differences, with the right `alternative` corresponding to the way you took differences. If you are looking ahead, you might realize that working out the differences *now* and adding them to the dataframe will be a good idea:\n\n::: {.cell}\n\n```{.r .cell-code}\nblood_pressure %>% \nmutate(difference = before - after) -> blood_pressure\nblood_pressure\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"person\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"before\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"after\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"difference\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"p1\",\"2\":\"132\",\"3\":\"118\",\"4\":\"14\"},{\"1\":\"p2\",\"2\":\"135\",\"3\":\"137\",\"4\":\"-2\"},{\"1\":\"p3\",\"2\":\"149\",\"3\":\"140\",\"4\":\"9\"},{\"1\":\"p4\",\"2\":\"133\",\"3\":\"139\",\"4\":\"-6\"},{\"1\":\"p5\",\"2\":\"119\",\"3\":\"107\",\"4\":\"12\"},{\"1\":\"p6\",\"2\":\"121\",\"3\":\"116\",\"4\":\"5\"},{\"1\":\"p7\",\"2\":\"128\",\"3\":\"122\",\"4\":\"6\"},{\"1\":\"p8\",\"2\":\"132\",\"3\":\"124\",\"4\":\"8\"},{\"1\":\"p9\",\"2\":\"119\",\"3\":\"115\",\"4\":\"4\"},{\"1\":\"p10\",\"2\":\"110\",\"3\":\"103\",\"4\":\"7\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nI took the differences this way around since I was expecting, if anything, the before numbers to be bigger than the after ones. And then:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(blood_pressure, t.test(difference, mu = 0, alternative = \"greater\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  difference\nt = 2.9945, df = 9, p-value = 0.007545\nalternative hypothesis: true mean is greater than 0\n95 percent confidence interval:\n 2.210659      Inf\nsample estimates:\nmean of x \n      5.7 \n```\n:::\n:::\n\nIf you did the differences the other way around, your `alternative` will need to be the other way around also.\n\nThe P-value (either way) is 0.008,^[Give the P-value, and round it off to about this accuracy so that your reader can see easily (i) how it compares to 0.05, and (ii) about how big it is. More than two decimal places is too many.] so we have evidence that the mean blood pressure before is greater than the mean blood pressure after.\n\n\n$\\blacksquare$\n\n\n(d) Run a suitable sign test on these data. What do you conclude, in the context of the data?\n\nSolution\n\n\nA sign test on the differences. By this point, you will realize that you will need to have obtained the differences. Get them here if you did not already get them:\n\n::: {.cell}\n\n```{.r .cell-code}\nsign_test(blood_pressure, difference, 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$above_below\nbelow above \n    2     8 \n\n$p_values\n  alternative   p_value\n1       lower 0.9892578\n2       upper 0.0546875\n3   two-sided 0.1093750\n```\n:::\n:::\n\nThis one gives us all three P-values. The way around I found the differences, the one we want is \"upper\", 0.055. There is not quite evidence that median blood pressure before is higher. \n\n\n$\\blacksquare$\n\n\n(e) Draw a suitable normal quantile plot of these data, one that will enable you to decide between the tests you ran in the previous two parts.\n\nSolution\n\n\n\nThe *differences* are supposed to be approximately normal if a matched-pairs $t$-test is the thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(blood_pressure, aes(sample=difference)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](matched-pairs-sign_files/figure-html/vilingers-1.png){width=672}\n:::\n:::\n\n\n$\\blacksquare$\n\n\n(f) Discuss briefly which of your two tests is the more appropriate one to run.\n\nSolution\n\n\nMake a call about whether the differences are normal enough. You have a couple of angles you can take:\n\n- the lowest two values are too low, so we have two outliers at the low end\n- the lowest *and* highest values are too extreme, so that we have a long-tailed distribution\n\nEither of these would suggest a non-normal distribution, which I think you have to conclude from this plot.\n\nThe best answer also considers the sample size: there are only 10 differences, a small sample size, and so we will not get much help from the Central Limit Theorem (the sample size is likely not enough^[But see the Extra.] to overcome those two outliers or the long tails). Thus, we should *not* trust the $t$-test and should prefer the sign test.\n\nExtra: you might be disappointed to go through this and come to the conclusion that there was not a decrease in blood pressure between before and after.\n\nWhat has happened, I think, is that we have only a small sample (10 people), and having 8 positive differences and 2 negative ones is not quite unbalanced enough (with such a small sample) to rule out chance: that is to say, a median difference of zero. The $t$-test accounted for the size of the differences, and if you believed the normality was satisfactory, you could demonstrate a difference between before and after. But if you didn't like the normality, you were out of luck: the only test you have is an apparently not very powerful one.\n\nIf you wanted to, you could bootstrap the sampling distribution of the sample mean and see how normal it looks:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim =  1:10000) %>% \n  rowwise() %>% \n  mutate(the_sample = list(sample(blood_pressure$difference, replace = TRUE))) %>% \n  mutate(the_mean = mean(the_sample)) %>% \n  ggplot(aes(sample = the_mean)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](matched-pairs-sign_files/figure-html/haschin-1.png){width=672}\n:::\n:::\n\n(Code note: you can do anything with the result of a simulation, and you can use anything that might need to be normal as input to a normal quantile plot. Now that we have the normal quantile plot as a tool, we can use it wherever it might be helpful.)\n\nThis is actually not nearly as bad as I was expecting. Even a sample size of 10 is providing some help. The bootstrapped sampling distribution is somewhat left-skewed, which is not a surprise given the two low outliers. However, it is rather close to normal, suggesting that the $t$-test is not as bad as we thought.\n\n(I did 10,000 simulations because I was having trouble seeing how non-normal it was. With this many, I can be pretty sure that this distribution is somewhat left-skewed.)\n\n\n$\\blacksquare$\n\n\n\n\n\n\n\n## French teachers\n\n Twenty high-school French teachers attended a summer institute to improve their French skills. At the beginning of their session, each teacher took a listening test (to test their understanding of spoken French). After 4 weeks of immersion in French, each teacher took a similar listening test again. (The actual French spoken in the two tests was different, so simply taking the first test should not improve the score in the second one; the tests were otherwise similar.) The maximum score on each test was 36, and a higher score is better. The data are [here](http://ritsokiguess.site/datafiles/frenchtest.txt). (Right-click on the link, select \"copy link address\", and then paste that URL into R Studio.) The data values are separated by *tabs*.\n\nThe data file has three columns:\n\n- an identification for each teacher\n- the teacher's score in the first test\n- the teacher's score in the second test\n\n\n\n(a) Read in and display (some of) the data.\n\nSolution\n\n\nSeparated by tabs means `read_tsv`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/frenchtest.txt\"\nfrench <- read_tsv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 20 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\ndbl (3): id, pre, post\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nfrench\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"pre\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"post\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"32\",\"3\":\"34\"},{\"1\":\"2\",\"2\":\"31\",\"3\":\"31\"},{\"1\":\"3\",\"2\":\"29\",\"3\":\"35\"},{\"1\":\"4\",\"2\":\"10\",\"3\":\"16\"},{\"1\":\"5\",\"2\":\"30\",\"3\":\"33\"},{\"1\":\"6\",\"2\":\"33\",\"3\":\"36\"},{\"1\":\"7\",\"2\":\"22\",\"3\":\"24\"},{\"1\":\"8\",\"2\":\"25\",\"3\":\"28\"},{\"1\":\"9\",\"2\":\"32\",\"3\":\"26\"},{\"1\":\"10\",\"2\":\"20\",\"3\":\"26\"},{\"1\":\"11\",\"2\":\"30\",\"3\":\"36\"},{\"1\":\"12\",\"2\":\"20\",\"3\":\"26\"},{\"1\":\"13\",\"2\":\"24\",\"3\":\"27\"},{\"1\":\"14\",\"2\":\"24\",\"3\":\"24\"},{\"1\":\"15\",\"2\":\"31\",\"3\":\"32\"},{\"1\":\"16\",\"2\":\"30\",\"3\":\"31\"},{\"1\":\"17\",\"2\":\"15\",\"3\":\"15\"},{\"1\":\"18\",\"2\":\"32\",\"3\":\"34\"},{\"1\":\"19\",\"2\":\"23\",\"3\":\"26\"},{\"1\":\"20\",\"2\":\"23\",\"3\":\"26\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nAs promised. The score on the first test is called `pre` and on the second is called `post`.\n\n\n$\\blacksquare$\n\n\n(b) Explain briefly why this is a matched-pairs study. \n\nSolution\n\n\nThere are two measurements for each teacher, or, the 20 `pre` measurements and the 20 `post` measurements are paired up, namely, the ones that come from the same teacher. Or, if it were two independent samples, our 40 measurements would come from 40 different teachers, but there are only 20 teachers, so the 40 measurements must be paired up.\n\n\n$\\blacksquare$\n\n\n(c) Run a suitable matched-pairs $t$-test to see whether the teachers' scores have on average *improved* over the four weeks.\n\nSolution\n\n\nSeeing whether the scores have improved implies a *one*-sided test that `post` is bigger than `pre`. There are three ways you might do that, any of which is good. Remember that if you are running a test with `paired = TRUE`, the alternative is relative to the column that is *input first*, not the first one in alphabetical order or anything like that:\n\n(i):\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(french, t.test(pre, post, paired = TRUE, alternative = \"less\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  pre and post\nt = -3.8649, df = 19, p-value = 0.0005216\nalternative hypothesis: true mean difference is less than 0\n95 percent confidence interval:\n      -Inf -1.381502\nsample estimates:\nmean difference \n           -2.5 \n```\n:::\n:::\n\n(ii):\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(french, t.test(post, pre, paired = T, alternative = \"greater\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  post and pre\nt = 3.8649, df = 19, p-value = 0.0005216\nalternative hypothesis: true mean difference is greater than 0\n95 percent confidence interval:\n 1.381502      Inf\nsample estimates:\nmean difference \n            2.5 \n```\n:::\n:::\n\nYour choice between these two might be influenced by whether you think `pre` comes first, or whether you think it's easier to decide how `post` compares to `pre`. It's all down to what seems natural to you. \n\n(iii) working out the differences and testing those (but look ahead in the question to see whether you need the differences for anything else: you do):\n\n::: {.cell}\n\n```{.r .cell-code}\nfrench %>% mutate(gain = post - pre) -> french1\nwith(french1, t.test(gain, mu=0, alternative = \"greater\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  gain\nt = 3.8649, df = 19, p-value = 0.0005216\nalternative hypothesis: true mean is greater than 0\n95 percent confidence interval:\n 1.381502      Inf\nsample estimates:\nmean of x \n      2.5 \n```\n:::\n:::\n\nThis last is an ordinary one-sample test, which saves you having to learn anything new, but requires you to calculate the differences first. You will need the differences for a plot anyway, so this may not be as much extra work as it appears. The right thing to do here is to *save* the data frame with the differences in it, so that you don't need to calculate them again later.\n\nA fourth alternative is to calculate the differences as `pre`  minus `post`, and then switch the `alternative` around (since if going to the French institute helps, the differences this way will be mostly *negative*):\n\n::: {.cell}\n\n```{.r .cell-code}\nfrench %>% mutate(gain = pre - post) -> french2\nwith(french2, t.test(gain, mu=0, alternative = \"less\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  gain\nt = -3.8649, df = 19, p-value = 0.0005216\nalternative hypothesis: true mean is less than 0\n95 percent confidence interval:\n      -Inf -1.381502\nsample estimates:\nmean of x \n     -2.5 \n```\n:::\n:::\n\n\n\n$\\blacksquare$\n\n\n(d) What do you conclude from your test, in the context of the data?\n\nSolution\n\n\nThe P-value of 0.0005 is much less than 0.05, so we reject the null hypothesis that the mean scores before and after are the same, in favour of the alternative that the mean score afterwards is higher. That is to say, the four-week program is helping the teachers improve their understanding of spoken French.\n\n\n$\\blacksquare$\n\n\n(e) How much is the teachers' listening skill improving, on average? Give a suitable interval to support your answer.\n\nSolution\n\n\nA 95% (or other level) confidence interval for the mean difference. A one-sided test doesn't give that, so you need to do the test again without the `alternative` (to make it two-sided), via any of the methods above, such as:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(french, t.test(post, pre, paired = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  post and pre\nt = 3.8649, df = 19, p-value = 0.001043\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 1.146117 3.853883\nsample estimates:\nmean difference \n            2.5 \n```\n:::\n:::\n\nThis says that, with 95% confidence, the mean test score afterwards is between about 1.1 and 3.9 points higher than before. So that's how much listening skill is improving on average. Give the suitably rounded interval; the test scores are whole numbers, and there are 20 differences making up the mean, so one decimal is the most you should give.\n\nIf you did it the first way:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(french, t.test(pre, post, paired = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  pre and post\nt = -3.8649, df = 19, p-value = 0.001043\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -3.853883 -1.146117\nsample estimates:\nmean difference \n           -2.5 \n```\n:::\n:::\n\nyou have given yourself a bit of work to do, because this is before minus after, so you have to strip off the minus signs and switch the numbers around. Giving the answer with the minus signs is wrong, because I didn't ask about before minus after. Disentangle it, though, and you're good.\n\n\n\n$\\blacksquare$\n\n\n(f) Make a suitable plot to assess any assumptions for this test.\n\nSolution\n\n\nThe key assumption here is that the *differences* are approximately normally distributed.\n\nFirst calculate *and save* the differences (since you will need them later for a sign test; otherwise you would have to find them again). If you found the differences to make your $t$-test, use the ones you saved there.\n\n::: {.cell}\n\n```{.r .cell-code}\nfrench %>% mutate(gain = post - pre) -> french1\n```\n:::\n\n\nAssess that with a histogram (with suitable number of bins):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(french1, aes(x=gain)) + geom_histogram(bins=6)\n```\n\n::: {.cell-output-display}\n![](matched-pairs-sign_files/figure-html/french-9-1.png){width=672}\n:::\n:::\n\nor, better, a normal quantile plot (since the normality is our immediate concern):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(french1, aes(sample=gain)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](matched-pairs-sign_files/figure-html/french-10-1.png){width=672}\n:::\n:::\n(note that the horizontal lines of points are because the test scores were whole numbers, therefore the differences between them are whole numbers also, and some of the teachers had the same difference in scores as others.)\n\n\n$\\blacksquare$\n\n\n(g) Do you trust the result of your matched-pairs $t$-test? Explain briefly. \n\nSolution\n\n\nThere are about three considerations here:\n\n- the plot shows an outlier at the low end, but no other real problems.\n- the sample size is 20, so we should get some help from the Central Limit Theorem.\n- the P-value was really small.\n\nI expect you to mention the first two of those. Make a call about whether you think that outlier is too much of a problem, given the sample size. You could, I think, go either way with this one.\n\nThe third of my points says that even if the distribution of differences is not normal enough, and so the P-value is off by a bit, it would take a lot to change it enough to stop it being significant. So I don't think we need to worry, for myself.\n\nExtra: \n\n\nWe can assess the $t$-test by obtaining a bootstrap distribution of the sample mean, by sampling from the differences with replacement:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(my_sample = list(sample(french1$gain, replace = T))) %>% \n  mutate(my_mean = mean(my_sample)) %>% \n  ggplot(aes(sample = my_mean)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](matched-pairs-sign_files/figure-html/french-12-1.png){width=672}\n:::\n:::\n\n\nThe bootstrapped sampling distribution of the sample mean difference is about as normal as you could reasonably wish for, so there was no need to worry. Only a very few of the most extreme samples were at all off the line.\n\nA histogram would be almost as good, but now that you know about the normal quantile plot, the time to use it is when you are *specifically* interested in normality, as you are here. (If you were interested in shape generally, then a histogram or, if appropriate, a boxplot, would also work.)\n\nThe code:  the first line takes 1000 bootstrap samples, and the second finds the mean of each one. Instead of saving the sample means, since I was only going to be using them once, I made them into a dataframe, and then made a normal quantile plot of them. The `enframe` creates a dataframe with a column called `value` with the means in it, which I use in the plot.\n\n\n\n$\\blacksquare$\n\n\n(h) Run a suitable sign test, and obtain a suitable (95%) confidence interval. Comment briefly on your results.\n\nSolution\n\nThis works with the differences, that you calculated for the plot, so use the data frame that you saved them in:\n\n::: {.cell}\n\n```{.r .cell-code}\nsign_test(french1, gain, 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$above_below\nbelow above \n    1    16 \n\n$p_values\n  alternative      p_value\n1       lower 0.9999923706\n2       upper 0.0001373291\n3   two-sided 0.0002746582\n```\n:::\n\n```{.r .cell-code}\nci_median(french1, gain)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.007812 3.000000\n```\n:::\n:::\n\nThe P-value is 0.00014, again very small, saying that the median difference is greater than zero, that is, that the test scores after are greater than the test scores before on average. The confidence interval is from 1 to 3 points, indicating that this is how much test scores are increasing on average.\n\nA technique thing: the first time you are going through this, you probably got to this point and realized that you were calculating the differences for the second (or third) time. This is the place to stop and think that you don't really need to do that, and to go back to the plot you did and *save* the differences after you have calculated them. Then you edit the code here to use the differences you got before and saved. It doesn't matter whether you see this the first time you do it or not, but it does matter that you see it before you hand it in. It's like editing an essay; you need to go back through work that you will be handing in and make sure you did it the best way you could.\n\n\n\n\n$\\blacksquare$\n\n\n(i) Comment briefly on the comparison between your inferences for the mean and the median. \n\nSolution\n\n\nThe upper-tail P-value is 0.0001, in the same ballpark as the $t$-test (0.0005). The 95% confidence interval for the median difference is from 1 to 3,^[I think I mentioned elsewhere that the P-value of the sign test, as it depends on the null median for a fixed data set, only changes at a data point. Therefore, the ends of a CI for the median must be data points.] again much like the $t$-interval (1.1 to 3.9). \n\nThis suggests that it doesn't matter much which test we do, and therefore that the $t$-test ought to be better because it uses the data better.^[It uses the actual data values, not just whether each one is positive or negative.] This is more evidence that the outlier didn't have that big of an effect.\n\nExtra: choosing a test on the basis of its P-value is *wrong*, because as soon as you introduce a choice on that basis, your P-value looks lower than it should; a P-value is based on you doing one test and only that one test. It is reasonable to note, as I did, that the two P-values are about the same and then choose between the tests on *some other basis*, such as that the $t$-test uses the data better.^[If the P-values had come out very different, that would be telling you that it matters which one you use, and you would need to go back and look at your plot to decide. Often, this happens when there is something wrong with the $t$-test, but not necessarily.]\n\n\n$\\blacksquare$\n\n\n\n\n",
    "supporting": [
      "matched-pairs-sign_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}