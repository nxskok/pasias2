{
  "hash": "270fdb6650d912efbf1ae7451568cf18",
  "result": {
    "engine": "knitr",
    "markdown": "# Regression with categorical variables\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Crickets revisited\n\n\n This is a continuation of the crickets problem that you\nmay have seen before (minus the data tidying).\n\nMale tree crickets produce \"mating songs\" by rubbing their wings\ntogether to produce a chirping sound. It is hypothesized that female\ntree crickets identify males of the correct species by how fast (in\nchirps per second) the male's mating song is. This is called the\n\"pulse rate\".  Some data for two species of crickets are in\n[link](http://ritsokiguess.site/datafiles/crickets2.csv) as a CSV\nfile. The columns are species (text), temperature, and pulse\nrate (numbers). This is the tidied version of the data set that the\nprevious version of this question had you create.\nThe research question is whether males\nof the different species have different average pulse rates. It is\nalso of interest to see whether temperature has an effect, and if\nso, what.\n\n\n(a) Read the data into R and display what you have.\n\n\n\n(b) Do a two-sample $t$-test to see whether the mean pulse rates\ndiffer between species. What do you conclude?\n\n\n\n(c) Can you do that two-sample $t$-test as a regression?\n\n\n\n(d) The analysis in the last part did not use temperature,\nhowever. Is it possible that temperature also has an effect? To\nassess this, draw a scatterplot of pulse rate against temperature,\nwith the points distinguished, somehow, by the species they are\nfrom.^[This was the actual reason I thought of this      question originally:    I wanted you to do this.]\n\n\n\n(e) What does the plot tell you that the $t$-test doesn't? How\nwould you describe differences in pulse rates between species now?\n\n\n\n(f) Fit a regression predicting pulse rate from species and\ntemperature. Compare the P-value for species in this regression to\nthe one from the $t$-test. What does that tell you?\n\n\n\n(g) Make suitable residual plots for the regression\n`pulse.1`. \n\n\n\n\n\n\n\n\n## Pulse rates and marching\n\n Forty students, some male and some female, measured their resting pulse rates. Then they marched in place for one minute and measured their pulse rate again. \nOur aim is to use regression to predict the pulse rate after the marching from the pulse rate before, and to see whether that is different for males and females. The data set is in [http://ritsokiguess.site/datafiles/pulsemarch.csv](http://ritsokiguess.site/datafiles/pulsemarch.csv). \n\n\n\n(a) Read in and display (some of) the data.\n\n\n\n(b) Make a suitable graph using all three variables, adding appropriate regression line(s) to the plot.\n\n\n\n(c) Explain briefly but carefully how any effects of pulse rate before on pulse rate after, and also of sex on pulse rate after, show up on your plot. (If either explanatory variable has no effect, explain how you know.)\n\n\n\n(d) Run a regression predicting pulse rate after from the other two variables. Display the output.\n\n\n\n(e) Looking at your graph, does the significance (or lack of) of each of your two explanatory variables surprise you? Explain briefly.\n\n\n\n(f) What does the numerical value of the Estimate for `Sex` in your regression output mean, in the context of this data set? Explain briefly.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n##  Crickets revisited\n\n\n This is a continuation of the crickets problem that you\nmay have seen before (minus the data tidying).\n\nMale tree crickets produce \"mating songs\" by rubbing their wings\ntogether to produce a chirping sound. It is hypothesized that female\ntree crickets identify males of the correct species by how fast (in\nchirps per second) the male's mating song is. This is called the\n\"pulse rate\".  Some data for two species of crickets are in\n[link](http://ritsokiguess.site/datafiles/crickets2.csv) as a CSV\nfile. The columns are species (text), temperature, and pulse\nrate (numbers). This is the tidied version of the data set that the\nprevious version of this question had you create.\nThe research question is whether males\nof the different species have different average pulse rates. It is\nalso of interest to see whether temperature has an effect, and if\nso, what.\n\n\n(a) Read the data into R and display what you have.\n\n\nSolution\n\n\nNothing terribly surprising here:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/crickets2.csv\"\ncrickets <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 31 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): species\ndbl (2): temperature, pulse_rate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ncrickets\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"species\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"temperature\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"pulse_rate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"exclamationis\",\"2\":\"20.8\",\"3\":\"67.9\"},{\"1\":\"exclamationis\",\"2\":\"20.8\",\"3\":\"65.1\"},{\"1\":\"exclamationis\",\"2\":\"24.0\",\"3\":\"77.3\"},{\"1\":\"exclamationis\",\"2\":\"24.0\",\"3\":\"78.7\"},{\"1\":\"exclamationis\",\"2\":\"24.0\",\"3\":\"79.4\"},{\"1\":\"exclamationis\",\"2\":\"24.0\",\"3\":\"80.4\"},{\"1\":\"exclamationis\",\"2\":\"26.2\",\"3\":\"85.8\"},{\"1\":\"exclamationis\",\"2\":\"26.2\",\"3\":\"86.6\"},{\"1\":\"exclamationis\",\"2\":\"26.2\",\"3\":\"87.5\"},{\"1\":\"exclamationis\",\"2\":\"26.2\",\"3\":\"89.1\"},{\"1\":\"exclamationis\",\"2\":\"28.4\",\"3\":\"98.6\"},{\"1\":\"exclamationis\",\"2\":\"29.0\",\"3\":\"100.8\"},{\"1\":\"exclamationis\",\"2\":\"30.4\",\"3\":\"99.3\"},{\"1\":\"exclamationis\",\"2\":\"30.4\",\"3\":\"101.7\"},{\"1\":\"niveus\",\"2\":\"17.2\",\"3\":\"44.3\"},{\"1\":\"niveus\",\"2\":\"18.3\",\"3\":\"47.2\"},{\"1\":\"niveus\",\"2\":\"18.3\",\"3\":\"47.6\"},{\"1\":\"niveus\",\"2\":\"18.3\",\"3\":\"49.6\"},{\"1\":\"niveus\",\"2\":\"18.9\",\"3\":\"50.3\"},{\"1\":\"niveus\",\"2\":\"18.9\",\"3\":\"51.8\"},{\"1\":\"niveus\",\"2\":\"20.4\",\"3\":\"60.0\"},{\"1\":\"niveus\",\"2\":\"21.0\",\"3\":\"58.5\"},{\"1\":\"niveus\",\"2\":\"21.0\",\"3\":\"58.9\"},{\"1\":\"niveus\",\"2\":\"22.1\",\"3\":\"60.7\"},{\"1\":\"niveus\",\"2\":\"23.5\",\"3\":\"69.8\"},{\"1\":\"niveus\",\"2\":\"24.2\",\"3\":\"70.9\"},{\"1\":\"niveus\",\"2\":\"25.9\",\"3\":\"76.2\"},{\"1\":\"niveus\",\"2\":\"26.5\",\"3\":\"76.1\"},{\"1\":\"niveus\",\"2\":\"26.5\",\"3\":\"77.0\"},{\"1\":\"niveus\",\"2\":\"26.5\",\"3\":\"77.7\"},{\"1\":\"niveus\",\"2\":\"28.6\",\"3\":\"84.7\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\n31 crickets, which is what I remember. What species are there?\n\n::: {.cell}\n\n```{.r .cell-code}\ncrickets %>% count(species)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"species\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"exclamationis\",\"2\":\"14\"},{\"1\":\"niveus\",\"2\":\"17\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nThat looks good. We proceed.\n\n$\\blacksquare$\n\n(b) Do a two-sample $t$-test to see whether the mean pulse rates\ndiffer between species. What do you conclude?\n\n\nSolution\n\n\nDrag your mind way back to this:\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(pulse_rate ~ species, data = crickets)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  pulse_rate by species\nt = 5.2236, df = 28.719, p-value = 1.401e-05\nalternative hypothesis: true difference in means between group exclamationis and group niveus is not equal to 0\n95 percent confidence interval:\n 14.08583 32.22677\nsample estimates:\nmean in group exclamationis        mean in group niveus \n                   85.58571                    62.42941 \n```\n\n\n:::\n:::\n\n \n\nThere is strong evidence of a difference in means (a P-value around\n0.00001), and the confidence interval says that the mean chirp rate is\nhigher for *exclamationis*. That is, not just for the crickets\nthat were observed here, but for *all* crickets of these two\nspecies. \n      \n$\\blacksquare$\n\n(c) Can you do that two-sample $t$-test as a regression?\n\n\nSolution\n\n\nHang onto the \"pulse rate depends on species\" idea and try\nthat in `lm`:\n\n::: {.cell}\n\n```{.r .cell-code}\npulse.0 <- lm(pulse_rate ~ species, data = crickets)\nsummary(pulse.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = pulse_rate ~ species, data = crickets)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-20.486  -9.458  -1.729  13.342  22.271 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     85.586      3.316  25.807  < 2e-16 ***\nspeciesniveus  -23.156      4.478  -5.171 1.58e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.41 on 29 degrees of freedom\nMultiple R-squared:  0.4797,\tAdjusted R-squared:  0.4617 \nF-statistic: 26.74 on 1 and 29 DF,  p-value: 1.579e-05\n```\n\n\n:::\n:::\n\n         \n\nI had to use \"model 0\" for this since I already have a\n`pulse.1` below and I didn't want to go down and renumber\neverything. \n\nLook along the `speciesniveus` line. Ignoring the fact that it\nis negative, the $t$-statistic is almost the same as before (5.17 vs.\\\n5.22) and so is the P-value ($1.4 \\times 10^{-5}$ vs.\\ $1.6 \\times\n10^{-5}$). \n\nWhy aren't they exactly the same? Regression is assuming equal\nvariances everywhere (that is, within the two `species`), and\nbefore, we did the Welch-Satterthwaite test that does not assume equal\nvariances. What if we do the pooled $t$-test instead?\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(pulse_rate ~ species, data = crickets, var.equal = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  pulse_rate by species\nt = 5.1706, df = 29, p-value = 1.579e-05\nalternative hypothesis: true difference in means between group exclamationis and group niveus is not equal to 0\n95 percent confidence interval:\n 13.99690 32.31571\nsample estimates:\nmean in group exclamationis        mean in group niveus \n                   85.58571                    62.42941 \n```\n\n\n:::\n:::\n\n \n\nNow the regression and the $t$-test *do* give exactly the same\nanswers. We'll think about that equal-spreads assumption again later.\n\n$\\blacksquare$\n\n(d) The analysis in the last part did not use temperature,\nhowever. Is it possible that temperature also has an effect? To\nassess this, draw a scatterplot of pulse rate against temperature,\nwith the points distinguished, somehow, by the species they are\nfrom.^[This was the actual reason I thought of this      question originally:    I wanted you to do this.]\n\n\nSolution\n\n\nOne of the wonderful things about `ggplot` is that doing\nthe obvious thing works:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(crickets, aes(x = temperature, y = pulse_rate, colour = species)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/crickets-b-6-1.png){width=672}\n:::\n:::\n\n       \n    \n$\\blacksquare$\n\n(e) What does the plot tell you that the $t$-test doesn't? How\nwould you describe differences in pulse rates between species now?\n\n\nSolution\n\n\nThe plot tells you that (for both species) as temperature goes\nup, pulse rate goes up as well. *Allowing for that*, the\ndifference in pulse rates between the two species is even\nclearer than it was before. To see an example, pick a\ntemperature, and note that the mean pulse rate at that\ntemperature seems to be at least 10 higher for\n*exclamationis*, with a high degree of consistency.\nThe $t$-test mixed up all the pulse rates at all the different\ntemperatures. Even though the conclusion was clear enough, it\ncould be clearer if we incorporated temperature into the analysis.\nThere was also a potential source of unfairness in that the\n*exclamationis* crickets tended to be observed at higher\ntemperatures than *niveus* crickets; since pulse rates\nincrease with temperature, the apparent difference in pulse\nrates between the species might have been explainable by one\nspecies being observed mainly in higher temperatures. This was\n*utterly invisible* to us when we did the $t$-test, but it\nshows the importance of accounting for all the relevant\nvariables when you do your analysis.^[And it shows the        value of looking at relevant plots.] If the species had been\nobserved at opposite temperatures, we might have\nconcluded^[Mistakenly.] \nthat *niveus* have the\nhigher pulse rates on average. I come back to this later when I\ndiscuss the confidence interval for species difference that\ncomes out of the regression model with temperature.\n      \n$\\blacksquare$\n\n(f) Fit a regression predicting pulse rate from species and\ntemperature. Compare the P-value for species in this regression to\nthe one from the $t$-test. What does that tell you?\n\n\nSolution\n\n\nThis is actually a so-called \"analysis of covariance model\",\nwhich properly belongs in D29, but it's really just a regression:\n\n::: {.cell}\n\n```{.r .cell-code}\npulse.1 <- lm(pulse_rate ~ species + temperature, data = crickets)\nsummary(pulse.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = pulse_rate ~ species + temperature, data = crickets)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0128 -1.1296 -0.3912  0.9650  3.7800 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    -7.21091    2.55094  -2.827  0.00858 ** \nspeciesniveus -10.06529    0.73526 -13.689 6.27e-14 ***\ntemperature     3.60275    0.09729  37.032  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.786 on 28 degrees of freedom\nMultiple R-squared:  0.9896,\tAdjusted R-squared:  0.9888 \nF-statistic:  1331 on 2 and 28 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n \n\nThe P-value for species is now $6.27\\times 10^{-14}$ or\n0.00000000000006, which is even less than the P-value of 0.00001 that\ncame out of the $t$-test. That is to say, when you know temperature,\nyou can be even more sure of your conclusion that there is a\ndifference between the species.\n\nThe R-squared for this regression is almost 99\\%, which says that if\nyou know both temperature and species, you can predict the pulse rate\nalmost exactly.\n\nIn the regression output, the slope for species is about $-10$. It is\nlabelled `speciesniveus`. Since species is categorical,\n`lm` uses the first category, *exclamationis*, as the\nbaseline and expresses each other species relative to that. Since the\nslope is about $-10$, it says that at any given temperature, the mean\npulse rate for *niveus* is about 10 less than for\n*exclamationis*. This is pretty much what the scatterplot told\nus.\n\nWe can go a little further here:\n\n::: {.cell}\n\n```{.r .cell-code}\nconfint(pulse.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                   2.5 %    97.5 %\n(Intercept)   -12.436265 -1.985547\nspeciesniveus -11.571408 -8.559175\ntemperature     3.403467  3.802038\n```\n\n\n:::\n:::\n\n \n\nThe second line says that the pulse rate for *niveus* is\nbetween about 8.5 and 11.5 less than for *exclamationis*, at\nany given temperature (comparing the two species at the same\ntemperature as each other, but that temperature could be\nanything). This is a lot shorter than the CI that came out of the\n$t$-test, that went from 14 to 32. This is because we are now\naccounting for temperature, which also makes a difference. (In the\n$t$-test, the temperatures were all mixed up). What we also see is\nthat the $t$-interval is shifted up compared to the one from the\nregression. This is because the $t$-interval conflates^[Mixes up.] \ntwo things: the *exclamationis* crickets do have a\nhigher pulse rate, but they were also observed at higher temperatures,\nwhich makes it look as if their pulse rates are more\nhigher^[This is actually grammatically correct.] than they\nreally are, when you account for temperature.\n\nThis particular model constrains the slope with temperature to be the\nsame for both species (just the intercepts differ). If you want to\nallow the slopes to differ between species, you add an interaction\nbetween temperature and species:\n\n::: {.cell}\n\n```{.r .cell-code}\npulse.2 <- lm(pulse_rate ~ species * temperature, data = crickets)\nsummary(pulse.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = pulse_rate ~ species * temperature, data = crickets)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7031 -1.3417 -0.1235  0.8100  3.6330 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               -11.0408     4.1515  -2.659    0.013 *  \nspeciesniveus              -4.3484     4.9617  -0.876    0.389    \ntemperature                 3.7514     0.1601  23.429   <2e-16 ***\nspeciesniveus:temperature  -0.2340     0.2009  -1.165    0.254    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.775 on 27 degrees of freedom\nMultiple R-squared:  0.9901,\tAdjusted R-squared:  0.989 \nF-statistic: 898.9 on 3 and 27 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n \n\nTo see whether adding the interaction term added anything to the\nprediction,^[Though it's hard to imagine being able to improve on an R-squared of 99%.] \ncompare the model with and without using `anova`:\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(pulse.1, pulse.2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Res.Df\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"RSS\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Df\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Sum of Sq\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"28\",\"2\":\"89.34987\",\"3\":\"NA\",\"4\":\"NA\",\"5\":\"NA\",\"6\":\"NA\",\"_rn_\":\"1\"},{\"1\":\"27\",\"2\":\"85.07409\",\"3\":\"1\",\"4\":\"4.275779\",\"5\":\"1.357006\",\"6\":\"0.2542464\",\"_rn_\":\"2\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nThere's no significant improvement by adding the interaction, so\nthere's no evidence that having different slopes for each species is\nnecessary. This is the same interpretation as any `anova` for\ncomparing two regressions: the two models are not significantly\ndifferent in fit, so go with the simpler one, that is, the one without\nthe interaction.\n\nNote that `anova` gave the same P-value as did the\n$t$-test for the slope coefficient for the interaction in\n`summary`, 0.254 in both cases. This is because there were only\ntwo species and therefore only one slope coefficient was required to\ndistinguish them. If there had been three species, we would have had\nto look at the `anova` output to hunt for a difference among\nspecies, since there would have been two slope coefficients, each with\nits own P-value.^[This wouldn't have told us about the overall  effect of species.] \n\nIf you haven't seen interactions before, don't worry about this. The\nidea behind it is that we are testing whether we needed lines with\ndifferent slopes and we concluded that we don't. Don't worry so much\nabout the mechanism behind `pulse.2`; just worry about how it\nsomehow provides a way of modelling two different slopes, one for each\nspecies, which we can then test to see whether it helps.\n\nThe upshot is that we do not need different slopes; the model\n`pulse.1` with the same slope for each species describes what\nis going on.\n\n`ggplot` makes it almost laughably easy to add regression lines\nfor each species to our plot, thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(crickets, aes(x = temperature, y = pulse_rate, colour = species)) +\n  geom_point() + geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/crickets-b-11-1.png){width=672}\n:::\n:::\n\n \n\nThe lines are almost exactly parallel, so having the same slope for\neach species makes perfect sense.\n      \n$\\blacksquare$\n\n(g) Make suitable residual plots for the regression\n`pulse.1`. \n\n\nSolution\n\n\nFirst, the plot of residuals against fitted values (after all,\nit *is* a regression):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pulse.1, aes(x = .fitted, y = .resid)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/crickets-b-12-1.png){width=672}\n:::\n:::\n\n         \n\nThis looks nice and random.\n\nNow, we plot the residuals against the explanatory variables. There\nare two, temperature and species, but the latter is categorical. We'll\nhave some extra issues around species, but before we get to that, we\nhave to remember that the data and the output from the regression are\nin different places when we plot them. There are different ways to get\naround that. Perhaps the simplest is to use `pulse.1` as our\n\"default\" data frame and then get `temperature` from the\nright place:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pulse.1, aes(x = crickets$temperature, y = .resid)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/crickets-b-13-1.png){width=672}\n:::\n:::\n\n \n\nI don't see anything untoward there.\n\nSpecies. We want to compare the residuals for the two species, which\nis categorical. Since the residuals are quantitative, this suggests a\nboxplot. Remembering to get species from the right place again, that\ngoes like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pulse.1, aes(x = crickets$species, y = .resid)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/crickets-b-14-1.png){width=672}\n:::\n:::\n\n \n\nFor the residuals, the median should be zero within each group, and\nthe two groups should be approximately normal with mean 0 and about\nthe same spread. Same spread looks OK, since the boxes are almost\nexactly the same height, but the normality is not quite there, since\nboth distributions are a little bit skewed to the right. That would\nalso explain why the median residual in each group is a little bit\nless than zero, because the mathematics requires the overall\n*mean* residual to be zero, and the right-skewness would make the\nmean higher than the median.\n\nIs that non-normality really problematic? Well, I could look at the\nnormal quantile plot of all the residuals together:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(pulse.1, aes(sample = .resid)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/crickets-b-15-1.png){width=672}\n:::\n:::\n\n \n\nThere's a little weirdness at the top, and a tiny indication of a\ncurve (that would suggest a little right-skewedness), but not really\nmuch to worry about. If that third-highest residual were a bit\nlower (say, 3 rather than 3.5) and maybe if the lowest residual was a\nbit lower, I don't think we'd have anything to complain about at all.\n\nSo, I'm not worried.\n\n$\\blacksquare$\n\n\n\n\n\n\n## Pulse rates and marching\n\n Forty students, some male and some female, measured their resting pulse rates. Then they marched in place for one minute and measured their pulse rate again. \nOur aim is to use regression to predict the pulse rate after the marching from the pulse rate before, and to see whether that is different for males and females. The data set is in [http://ritsokiguess.site/datafiles/pulsemarch.csv](http://ritsokiguess.site/datafiles/pulsemarch.csv). \n\n\n\n(a) Read in and display (some of) the data.\n\nSolution\n\n\nAs usual:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/pulsemarch.csv\"\nmarch <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 40 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Sex\ndbl (2): Before, After\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nmarch\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Sex\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Before\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"After\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Female\",\"2\":\"72\",\"3\":\"84\"},{\"1\":\"Male\",\"2\":\"60\",\"3\":\"72\"},{\"1\":\"Female\",\"2\":\"68\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"70\",\"3\":\"72\"},{\"1\":\"Male\",\"2\":\"68\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"61\",\"3\":\"75\"},{\"1\":\"Male\",\"2\":\"80\",\"3\":\"84\"},{\"1\":\"Male\",\"2\":\"72\",\"3\":\"76\"},{\"1\":\"Female\",\"2\":\"64\",\"3\":\"80\"},{\"1\":\"Female\",\"2\":\"62\",\"3\":\"92\"},{\"1\":\"Male\",\"2\":\"60\",\"3\":\"76\"},{\"1\":\"Female\",\"2\":\"96\",\"3\":\"100\"},{\"1\":\"Female\",\"2\":\"64\",\"3\":\"72\"},{\"1\":\"Female\",\"2\":\"76\",\"3\":\"88\"},{\"1\":\"Male\",\"2\":\"55\",\"3\":\"64\"},{\"1\":\"Male\",\"2\":\"60\",\"3\":\"68\"},{\"1\":\"Female\",\"2\":\"46\",\"3\":\"64\"},{\"1\":\"Female\",\"2\":\"56\",\"3\":\"64\"},{\"1\":\"Male\",\"2\":\"88\",\"3\":\"100\"},{\"1\":\"Male\",\"2\":\"80\",\"3\":\"88\"},{\"1\":\"Male\",\"2\":\"66\",\"3\":\"68\"},{\"1\":\"Female\",\"2\":\"80\",\"3\":\"104\"},{\"1\":\"Male\",\"2\":\"68\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"80\",\"3\":\"88\"},{\"1\":\"Male\",\"2\":\"76\",\"3\":\"84\"},{\"1\":\"Female\",\"2\":\"70\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"59\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"68\",\"3\":\"76\"},{\"1\":\"Female\",\"2\":\"64\",\"3\":\"68\"},{\"1\":\"Male\",\"2\":\"74\",\"3\":\"84\"},{\"1\":\"Male\",\"2\":\"84\",\"3\":\"88\"},{\"1\":\"Male\",\"2\":\"72\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"60\",\"3\":\"72\"},{\"1\":\"Male\",\"2\":\"75\",\"3\":\"88\"},{\"1\":\"Male\",\"2\":\"76\",\"3\":\"72\"},{\"1\":\"Female\",\"2\":\"76\",\"3\":\"96\"},{\"1\":\"Female\",\"2\":\"64\",\"3\":\"68\"},{\"1\":\"Female\",\"2\":\"64\",\"3\":\"68\"},{\"1\":\"Male\",\"2\":\"60\",\"3\":\"60\"},{\"1\":\"Female\",\"2\":\"76\",\"3\":\"104\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n$\\blacksquare$\n\n\n(b) Make a suitable graph using all three variables, adding appropriate regression line(s) to the plot.\n\nSolution\n\n\nTwo quantitative and one categorical says scatterplot, with colour distinguishing the categories (two here). `geom_smooth` adds a regression line to the plot for each `Sex`, which is what we want. I used `se=F` to remove the grey envelopes from the plot (because I thought they confused the issue):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(march, aes(x=Before, y=After, colour=Sex)) + geom_point() + \ngeom_smooth(method = \"lm\", se=F)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/fus-1.png){width=672}\n:::\n:::\n\nHaving only one regression line is not so good because that only shows that pulse rate after goes up with pulse rate before, but not if and how the sexes differ.\n\nExtra: I took a shortcut of the process here, to make the question shorter. In practice, what you'd do is to put smooth trends on the plot first:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(march, aes(x=Before, y=After, colour=Sex)) + geom_point() + \ngeom_smooth(se=F)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/hearter-1.png){width=672}\n:::\n:::\n\nThe red trend looks curved, but if you look carefully, pretty much all of^[My mind just jumped to a former German soccer player by the name of Klaus Allofs.] the evidence for the curve comes from that point on the right with pulse rate before over 90 and pulse rate after around 100. If it weren't for that, the red trend would be pretty close to linear. As you'll recall, a decision about the kind of trend based on *one* observation is a pretty flimsy decision.\n\n*Then*, having seen that the trends are not obviously curved, you would draw the plot with the straight lines. (Fitting separate *curves* is a whole different story that I didn't want to get into.)\n\n\n$\\blacksquare$\n\n\n(c) Explain briefly but carefully how any effects of pulse rate before on pulse rate after, and also of sex on pulse rate after, show up on your plot. (If either explanatory variable has no effect, explain how you know.)\n\nSolution\n\n\nThere is an upward trend, so\nif the pulse rate before is higher, so is the pulse rate after. This is true for both males and females. (Or, holding `Sex` fixed, that is, comparing two people of the same sex.)\n\nThe red line is always above the  blue line, so at any given `Before` pulse rate, the `After` pulse rate for a female is predicted to be higher than that for a male.\n\nNote that you have to be careful: when talking about the effect of each explanatory variable, you have to *hold the other one constant* (in general, hold all the other ones constant). If you can word that in a way that makes sense in the context of the data you are looking at, so much the better.\n\n\n$\\blacksquare$\n\n\n(d) Run a regression predicting pulse rate after from the other two variables. Display the output.\n\nSolution\n\n\nThus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmarch.1 <- lm(After~Before+Sex, data=march)\nsummary(march.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = After ~ Before + Sex, data = march)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.8653  -4.6319  -0.4271   3.3856  16.0047 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  19.8003     7.9217   2.499   0.0170 *  \nBefore        0.9064     0.1127   8.046  1.2e-09 ***\nSexMale      -4.8191     2.2358  -2.155   0.0377 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.918 on 37 degrees of freedom\nMultiple R-squared:  0.6468,\tAdjusted R-squared:  0.6277 \nF-statistic: 33.87 on 2 and 37 DF,  p-value: 4.355e-09\n```\n\n\n:::\n:::\n\nExtra: if you want \"all the other variables except the response\" as explanatory, there is also this shortcut:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarch.1a <- lm(After~., data=march)\nsummary(march.1a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = After ~ ., data = march)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.8653  -4.6319  -0.4271   3.3856  16.0047 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  19.8003     7.9217   2.499   0.0170 *  \nSexMale      -4.8191     2.2358  -2.155   0.0377 *  \nBefore        0.9064     0.1127   8.046  1.2e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.918 on 37 degrees of freedom\nMultiple R-squared:  0.6468,\tAdjusted R-squared:  0.6277 \nF-statistic: 33.87 on 2 and 37 DF,  p-value: 4.355e-09\n```\n\n\n:::\n:::\n\n\n\n$\\blacksquare$\n\n\n(e) Looking at your graph, does the significance (or lack of) of each of your two explanatory variables surprise you? Explain briefly.\n\nSolution\n\n\nWe noted a clear upward trend before, for both sexes, so there is no surprise that the `Before` pulse rate is significant.\n\nThe red dots (females) on the graph seemed to be on average above the blue ones (males), at least for similar before pulse rates. (This is not completely convincing, so you are entitled to be surprised also; note that the P-value, while significant, is not *that* small).\n\nExtra: comparing the *lines* is less convincing, because how do we get a feel for whether these lines are more different than chance? One deceiving way to (fail to) get a feel for this is to re-draw our plot but with the grey envelopes:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(march, aes(x=Before, y=After, colour=Sex)) + geom_point() + \ngeom_smooth(method = \"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/buttin-1.png){width=672}\n:::\n:::\n\nThe grey envelopes overlap substantially, which would make you think the lines are *not* significantly different. But, this is not the right way to compare the lines. It is a similar problem to that of comparing two *means*  (that we would normally do with a two-sample test of some kind) by working out the two *one*-sample confidence intervals, and seeing whether they overlap. If they *do not*, then you can be sure that the means differ, but if they do overlap, then you cannot say anything about whether the means differ: maybe they do, maybe they don't. This one is analogous; the grey envelopes overlap, so maybe the lines differ, maybe they don't. Looking at the grey envelopes in this case gives you *no* insight about whether males and females differ.\n\n[Here](https://www.cscu.cornell.edu/news/statnews/stnews73.pdf) is a short discussion of this issue (in the context of comparing two means).\n\n\n\n\n$\\blacksquare$\n\n\n(f) What does the numerical value of the Estimate for `Sex` in your regression output mean, in the context of this data set? Explain briefly.\n\nSolution\n\n\nThe estimate is labelled `SexMale`, and its value is $-4.8$.\n\n`Sex` is a categorical variable, so it has a baseline category, which is the first one, `Female`. The Estimate `SexMale` shows how males compare to the baseline (females), at a fixed `Before` pulse rate.\nThis value is $-4.8$, so, at any `Before` pulse rate, the male `After` pulse rate is predicted to be 4.8 *less* than the female one.\n\nI think you have to mention the value $-4.8$, so that you can talk intelligently about what it means for these data.\n\nExtra: the implication of our model is that the predicted difference is the *same* all the way along. You might have your doubts about that; you might think the lines are closer together on the left and further apart on the right. Another way to think about this is whether the lines are *parallel*: that is, whether they have the same slope. I'm inclined to think they do; the data points are fairly scattered, and I think the slopes would have to be a lot more different to be significantly different. But you don't have to take my word for it: we can test this by adding an **interaction term** to the model. You might have seen this in ANOVA, where you are assessing the effect of one factor at different levels of the other. This is more or less the same idea. Note the `*` rather than the `+` in the model formula:^[To be precise, the * means \"the main effects and the interaction together\"; if you want to talk about just the interaction term, you denote it by `:`; note the `Before:SexMale` term in the summary table.]\n\n::: {.cell}\n\n```{.r .cell-code}\nmarch.2 <- lm(After~Before*Sex, data=march)\nsummary(march.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = After ~ Before * Sex, data = march)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.2831  -4.3638  -0.3965   3.4077  16.6188 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     13.4390    11.1416   1.206    0.236    \nBefore           0.9991     0.1604   6.230 3.43e-07 ***\nSexMale          7.9470    15.8095   0.503    0.618    \nBefore:SexMale  -0.1846     0.2263  -0.816    0.420    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.949 on 36 degrees of freedom\nMultiple R-squared:  0.6532,\tAdjusted R-squared:  0.6243 \nF-statistic:  22.6 on 3 and 36 DF,  p-value: 2.11e-08\n```\n\n\n:::\n:::\n\nThe `Before:SexMale` term tests the interaction, and you see it is nowhere near significant. There is no justification for having lines with different slopes for males and females.\n\nWe were lucky here in that `Sex` has only two levels, so looking at the `summary` gave us what we wanted. If we had had an `Other` category for `Sex`, for people who don't identify with either male or female, there would be two Estimates in the `summary` table, one comparing Male with Female, and one comparing Other with Female.^[Female is the baseline, so everything gets compared with that, whether you like it or not.]\nBut maybe the significant difference is Male vs. Other, and we would never see it. \n\nTo look for *any* effect of a categorical variable, the right way is to use `drop1`, to see which variables, including categorical ones, can be removed as a whole, thus:^[The `test` piece says to do an $F$-test, which is different from without the quotes, which would mean not to do any tests, `F` without quotes meaning `FALSE`.]\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(march.2, test=\"F\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Sum of Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"RSS\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"NA\",\"3\":\"1738.512\",\"4\":\"158.8762\",\"5\":\"NA\",\"6\":\"NA\",\"_rn_\":\"<none>\"},{\"1\":\"1\",\"2\":\"32.13734\",\"3\":\"1770.649\",\"4\":\"157.6089\",\"5\":\"0.6654795\",\"6\":\"0.4199971\",\"_rn_\":\"Before:Sex\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nThis *only* lists things that can be removed, in this case the interaction. It is not significant, so out it comes (resulting in our model `march.1`):\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(march.1, test=\"F\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Sum of Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"RSS\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"NA\",\"3\":\"1770.649\",\"4\":\"157.6089\",\"5\":\"NA\",\"6\":\"NA\",\"_rn_\":\"<none>\"},{\"1\":\"1\",\"2\":\"3097.976\",\"3\":\"4868.625\",\"4\":\"196.0675\",\"5\":\"64.736188\",\"6\":\"1.203225e-09\",\"_rn_\":\"Before\"},{\"1\":\"1\",\"2\":\"222.337\",\"3\":\"1992.986\",\"4\":\"160.3404\",\"5\":\"4.646017\",\"6\":\"3.770029e-02\",\"_rn_\":\"Sex\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nBoth remaining explanatory variables are significant, so we need to keep them both. \n\nOur categorical explanatory variable has only two levels, so `drop1` and `summary` give the exact same P-values.\n\nExtra 2:\n\nLet's go back and look at our data set again:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarch\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Sex\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Before\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"After\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Female\",\"2\":\"72\",\"3\":\"84\"},{\"1\":\"Male\",\"2\":\"60\",\"3\":\"72\"},{\"1\":\"Female\",\"2\":\"68\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"70\",\"3\":\"72\"},{\"1\":\"Male\",\"2\":\"68\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"61\",\"3\":\"75\"},{\"1\":\"Male\",\"2\":\"80\",\"3\":\"84\"},{\"1\":\"Male\",\"2\":\"72\",\"3\":\"76\"},{\"1\":\"Female\",\"2\":\"64\",\"3\":\"80\"},{\"1\":\"Female\",\"2\":\"62\",\"3\":\"92\"},{\"1\":\"Male\",\"2\":\"60\",\"3\":\"76\"},{\"1\":\"Female\",\"2\":\"96\",\"3\":\"100\"},{\"1\":\"Female\",\"2\":\"64\",\"3\":\"72\"},{\"1\":\"Female\",\"2\":\"76\",\"3\":\"88\"},{\"1\":\"Male\",\"2\":\"55\",\"3\":\"64\"},{\"1\":\"Male\",\"2\":\"60\",\"3\":\"68\"},{\"1\":\"Female\",\"2\":\"46\",\"3\":\"64\"},{\"1\":\"Female\",\"2\":\"56\",\"3\":\"64\"},{\"1\":\"Male\",\"2\":\"88\",\"3\":\"100\"},{\"1\":\"Male\",\"2\":\"80\",\"3\":\"88\"},{\"1\":\"Male\",\"2\":\"66\",\"3\":\"68\"},{\"1\":\"Female\",\"2\":\"80\",\"3\":\"104\"},{\"1\":\"Male\",\"2\":\"68\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"80\",\"3\":\"88\"},{\"1\":\"Male\",\"2\":\"76\",\"3\":\"84\"},{\"1\":\"Female\",\"2\":\"70\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"59\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"68\",\"3\":\"76\"},{\"1\":\"Female\",\"2\":\"64\",\"3\":\"68\"},{\"1\":\"Male\",\"2\":\"74\",\"3\":\"84\"},{\"1\":\"Male\",\"2\":\"84\",\"3\":\"88\"},{\"1\":\"Male\",\"2\":\"72\",\"3\":\"80\"},{\"1\":\"Male\",\"2\":\"60\",\"3\":\"72\"},{\"1\":\"Male\",\"2\":\"75\",\"3\":\"88\"},{\"1\":\"Male\",\"2\":\"76\",\"3\":\"72\"},{\"1\":\"Female\",\"2\":\"76\",\"3\":\"96\"},{\"1\":\"Female\",\"2\":\"64\",\"3\":\"68\"},{\"1\":\"Female\",\"2\":\"64\",\"3\":\"68\"},{\"1\":\"Male\",\"2\":\"60\",\"3\":\"60\"},{\"1\":\"Female\",\"2\":\"76\",\"3\":\"104\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nYou might have been thinking, when we started, that these are before and after measurements *on the same people*, and so what we have here is matched pairs. So we do, but it's not the kind of matched pairs we are accustomed to. Let's begin by taking differences, getting rid of the `Before` and `After` columns, and see what we have left:\n\n::: {.cell}\n\n```{.r .cell-code}\nmarch %>% \nmutate(difference=After-Before) %>% \nselect(-After, -Before) -> march_paired\nmarch_paired\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Sex\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"difference\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Female\",\"2\":\"12\"},{\"1\":\"Male\",\"2\":\"12\"},{\"1\":\"Female\",\"2\":\"12\"},{\"1\":\"Male\",\"2\":\"2\"},{\"1\":\"Male\",\"2\":\"12\"},{\"1\":\"Male\",\"2\":\"14\"},{\"1\":\"Male\",\"2\":\"4\"},{\"1\":\"Male\",\"2\":\"4\"},{\"1\":\"Female\",\"2\":\"16\"},{\"1\":\"Female\",\"2\":\"30\"},{\"1\":\"Male\",\"2\":\"16\"},{\"1\":\"Female\",\"2\":\"4\"},{\"1\":\"Female\",\"2\":\"8\"},{\"1\":\"Female\",\"2\":\"12\"},{\"1\":\"Male\",\"2\":\"9\"},{\"1\":\"Male\",\"2\":\"8\"},{\"1\":\"Female\",\"2\":\"18\"},{\"1\":\"Female\",\"2\":\"8\"},{\"1\":\"Male\",\"2\":\"12\"},{\"1\":\"Male\",\"2\":\"8\"},{\"1\":\"Male\",\"2\":\"2\"},{\"1\":\"Female\",\"2\":\"24\"},{\"1\":\"Male\",\"2\":\"12\"},{\"1\":\"Male\",\"2\":\"8\"},{\"1\":\"Male\",\"2\":\"8\"},{\"1\":\"Female\",\"2\":\"10\"},{\"1\":\"Male\",\"2\":\"21\"},{\"1\":\"Male\",\"2\":\"8\"},{\"1\":\"Female\",\"2\":\"4\"},{\"1\":\"Male\",\"2\":\"10\"},{\"1\":\"Male\",\"2\":\"4\"},{\"1\":\"Male\",\"2\":\"8\"},{\"1\":\"Male\",\"2\":\"12\"},{\"1\":\"Male\",\"2\":\"13\"},{\"1\":\"Male\",\"2\":\"-4\"},{\"1\":\"Female\",\"2\":\"20\"},{\"1\":\"Female\",\"2\":\"4\"},{\"1\":\"Female\",\"2\":\"4\"},{\"1\":\"Male\",\"2\":\"0\"},{\"1\":\"Female\",\"2\":\"28\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nIn matched pairs, we are used to having *one* column of differences, and we test that for a mean or median of zero, to express no difference between before and after (or whatever it was). But now, we have an extra column `Sex`. We are not interested here in whether the differences average out to zero;^[I think it's a given that pulse rates will be higher after exercise than before.] we care more about whether the differences differ (!) between males and females. That is to say, we have a two-sample matched pairs test!\n\nAt this point, your head ought to be hurting!\n\nHowever, at this point what we are saying is that *if* you believe that the difference is a good way to summarize the effect of the exercise, then we have one measurement for each person, independent because different people's measurements will be independent. It doesn't matter where they came from. We have measurements on two groups, so some kind of two-sample test will be good. Which kind? Let's look at a graph, a good one now being a boxplot:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(march_paired, aes(x=Sex, y=difference)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/fridingen-1.png){width=672}\n:::\n:::\n\nOr, if you like, a facetted normal quantile plot:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(march_paired, aes(sample=difference)) +\nstat_qq() + stat_qq_line() +\nfacet_wrap(~Sex)\n```\n\n::: {.cell-output-display}\n![](regression-categorical_files/figure-html/brugg-1.png){width=672}\n:::\n:::\n\n\nIt seems to me that these are normal enough for a $t$-test, given the sample sizes (feel free to disagree):\n\n::: {.cell}\n\n```{.r .cell-code}\nmarch_paired %>% count(Sex)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Sex\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Female\",\"2\":\"16\"},{\"1\":\"Male\",\"2\":\"24\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nThe spreads look a bit different, so I think I would prefer the Welch test here:\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(difference~Sex, data=march_paired)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  difference by Sex\nt = 2.0307, df = 23.296, p-value = 0.05386\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -0.08848652  9.92181986\nsample estimates:\nmean in group Female   mean in group Male \n           13.375000             8.458333 \n```\n\n\n:::\n:::\n\nThis time, there is not quite a significant difference between males and females. (The P-value is just the other side of 0.05.) Though the conclusion is different, the P-values are fairly similar.\n\nWhich test is better? I think treating it as matched pairs is assuming that the differences after minus before are the things to be looking at. This assumes that the after measurements are the before measurement plus a something that depends on treatment, but *not* on the before measurement. This would fail, for example, if all the after measurements are two times the before ones (so that the difference would be bigger if the before score was bigger).\nThe regression approach is more flexible, because *any* linear relationship is taken care of. A matched-pairs model of this kind is a special case of the regression model but with the slope set to be 1. In our regression, the slope is less than 1, but not by much. \n\n\n$\\blacksquare$\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "regression-categorical_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}