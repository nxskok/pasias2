{
  "hash": "2349c145a61310462635c7a78c632bbb",
  "result": {
    "markdown": "# Analysis of variance revisited\n\nPackages for this chapter:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(car)\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Acid rain\n\n\n One of the first noticeable effects of climate change was\n\"acid rain\". This is formed by the water vapour in clouds combining\nwith nitrous oxide and sulfur dioxide, which come from coal and oil\nproduction. How does the acidity of rain affect the acidity of the\nsoil on which it falls? (This will have an effect on the kind of\nplants that can be grown in that soil.) Acidity is measured using the\npH scale, where a pH of 7 is chemically neutral, a number less than 7\nis acidic, and a number greater than 7 is alkaline.\n\nAn experiment was conducted at the Florida Institute of Food and\nAgricultural Sciences, to determine how acidity of rain affects soil\nacidity. Experimental plots were irrigated with rainwater that was\nprepared to have one of two different pH levels, 3.7 and 4.5. The\nacidity of the soil was then measured at three different depths,\n0--15, 15--30, and 30--46 centimetres. This was done on three\ndifferent dates, in April and June 1991. The data are in\n[link](http://ritsokiguess.site/datafiles/acidrain.csv).\n\n\n\n(a) Read in and display the data.\n\n\n(b) Draw a grouped boxplot to show how soil acidity depends on\nthe pH of the rain and the soil depth. (The first time you do this\nyou might not get the boxplot you want. How can you fix that?)\n\n\n(c) What does your grouped boxplot say about likely\ninteractions? Explain briefly.\n\n\n(d) Fit an ANOVA with interaction. What do you conclude from\nit? You may want to create a column that is the factor version of\n`rain_pH` first.\n\n\n\n\n\n##  Treating hay fever\n\n\n Hay fever is an allergic reaction to things like grasses or\npollen which can make it unpleasant to go outside when the weather is\nat its best.  A research lab is developing a new compound to relieve\nsevere cases of hay fever. There were two active ingredients, labelled\nA and B, with each one having three levels, low, medium and\nhigh. There were thus $3\\times 3=9$ treatment combinations. 36\nsubjects were available, and these were randomly assigned to\ncombinations of levels of factor A and factor B, so that each\ncombination was tested on 4 people. The response variable was the\nnumber of hours of relief from symptoms (so a higher value is\nbetter). The data are in\n[link](http://ritsokiguess.site/datafiles/hayfever.txt).\n\n\n\n(a) Read the data and display its structure. Verify that you\nhave what you were expecting.\n\n\n(b) Calculate the mean hours of relief for each combination of\nlevels of the two active ingredients. Save your results in a data\nframe and display that.\n\n\n(c) Make an interaction plot, showing how the mean pain relief depends on the combination of levels of A and B. It is probably easiest to use the data frame you obtained in the previous part.\n\n\n(d) What do you conclude from your interaction plot? Explain briefly.\n\n\n(e) Run an analysis of variance with interaction. What do you conclude?\n\n\n(f) Analyze the simple effects of B when A is\n`medium`. (This means doing an appropriate `aov` and\nan appropriate Tukey, if warranted.)\n\n\n(g) Analyze the simple effects of B when A is `high`.\n\n\n\n\n\n\n##  Focused comparisons of the effect of caffeine\n\n\n \nDoes caffeine help students do better on a certain test? To\nfind out, 36 students were randomly allocated to three groups (12 in\neach group).  Each student received a fixed number of cups of coffee\nwhile they were studying, but the students didn't know whether they\nwere receiving all full-strength coffee (\"high\"), all decaf coffee\n(\"low\") or a 50-50 mixture of the two (\"moderate\"). For each\nsubject, their group was recorded as well as their score on the\ntest. The data are in\n[link](http://ritsokiguess.site/datafiles/caffeine.csv), as a\n`.csv` file.\n\nThis time we look at\ncontrasts. Suppose I knew ahead of time\nthat I wanted to compare moderate caffeine with high, and any\ncaffeine with none. (In the latter case, we're comparing \n\"no caffeine\" against the average of the other two groups.)\n\nIn the previous go-through of the caffeine data, we\ndiscovered that `amount` was actually text rather than a\nfactor, but we also discovered that it *didn't matter*. Here it\ndoes matter, so the first thing we have to do is to re-do the\n`pivot_longer`, creating a factor version of `amount`.\n\n\n\n(a) Read in the data again, from\n[link](http://ritsokiguess.site/datafiles/caffeine.csv), and\ndisplay it. This is the untidy format, so name it appropriately:\n\n\n\n(b) Copy your `pivot_longer` from before, only this time add\n`names_ptypes = list(amount=factor())` to the end of it. Take a look at the\nresults. What has changed from before?\n\n\n\n(c) Using the newly tidied caffeine data, run the ANOVA \n*as a  regression* (that is, using `lm`). Look at the\n`summary` of the output. What do you see?\n\n\n\n(d) Obtain the different values of `amount`, in the order\nthat R has them.\n\n\n\n(e) Create a contrast that compares High with Moderate, ignoring\nNone. That is, create a vector whose length is the same as the\nnumber of levels of `amount`, and which has a 1 to represent\nHigh and a $-1$ to represent Moderate. \n\n\n\n(f) Create a contrast that compares \"any caffeine\" against\n\"none\" by comparing None against the average of Moderate and High.\n\n\n\n(g) Verify that your two contrasts are orthogonal.\n\n\n\n(h) Arrange your contrasts as columns of a matrix (using\n`cbind`), and say that you want to use these as contrasts for\n`amount` (in data frame `caffeine` or whatever you\ncalled it).\n\n\n\n(i) Fit the ANOVA as an `lm`, and look at the\n`summary`. What do you conclude about your contrasts?\n\n\n\n(j) What happens if you try to use high caffeine vs.\\ moderate\ncaffeine and moderate vs.\\ none as your two contrasts?\n\n\n\n\n\n\n\n##  Who studies the most outside class?\n\n\n A social scientist wanted to see how many hours students\n studied outside of class. She took a random sample of 75 students\n from three different majors: math, social science and English, and\n recorded the number of weekly outside-class study hours for each\n student. The data can be found at\n [link](http://ritsokiguess.site/datafiles/studyhours.txt). The\n social scientist had two research questions: whether math students study\n more outside of class than the other students, and whether English and\n social science students study different amounts of time outside class.\n\n\n(a) Explain briefly why contrasts would be a better idea here\nthan ANOVA with Tukey.\n\n\n\n(b) Read in the data and make side-by-side boxplots of study\nhours by major. What do the boxplots suggest about the comparisons\nthat the researcher wants to make?\n\n\n\n(c) Set up contrasts for each of the researcher's research\nquestions, bearing in mind the levels of `major` and the\norder in which they come. (For the `Math` contrast, you want\nMath against the average of the other two.)\n\n\n\n(d) Verify that your two contrasts are orthogonal.\n\n\n\n(e) Create a matrix of contrasts (using `cbind`) and let\n`lm` know that these are contrasts for `major`, in\ndata frame `studyhours` (or whatever you called it).\n\n\n\n(f) Fit the model using `lm`. What do you conclude about\nyour contrasts?\n\n\n\n(g) Are you surprised by the significance or non-significance you\nfound in the previous part? Explain briefly.\n\n\n \n\n\n\n##  Mental context\n\n\n It is believed that being in the same mental context for\nlearning and for testing leads to better test scores. An experiment\nwas carried out to test this. During the learning phase, subjects\nlearned a list of 80 words in a room painted orange and decorated with\nposters, paintings and other paraphernalia.^[This is a fancy  word for *stuff*.] A memory test was given to all subjects\nimmediately after they had learned the words, to give the impression\nthat the experiment was over. (The results of this test were\ndiscarded.) One day later, subjects were unexpectedly re-tested under\ndifferent experimental conditions and asked to write down all the\nwords of the original list that they could remember. The re-test took\nplace in five different conditions, which subjects were randomly\nallocated to one of:\n\n\n\n* Same context: in the original orange-painted room.\n\n* Different context: in a very different room, painted grey and\nlocated in a different part of campus.\n\n* Imaginary context: in the grey room, but subjects are asked to\nremember the orange room in which they took the original test. To\nhelp them with this, the experimenter begins by asking them several\nquestions about the orange room and the objects in it.\n\n* Photographed context: in the grey room, but subjects are shown\nphotographs of the orange room.\n\n* Placebo context: in the grey room, with subjects first being\nasked to recall their living room.\n\n\nIn each case, the response variable was the number of words on the\noriginal list successfully recalled by each subject.\n\n50 subjects in total completed the experiment, 10 under each of the 5\nconditions. \n\nThe researchers had four research hypotheses to test with the data:\n\n\n\n* Groups where the context matches (is the same, or is simulated\nby imagining or photograph) will perform better than groups with\ndifferent or placebo contexts.\n\n* The group with the same context will differ from the group with\nimaginary or photographed contexts.\n\n\n* The imaginary-context group will differ from the\nphotographed-context group.\n\n* The different-context group will differ from the placebo-context group.\n\n\nThe research hypotheses are (as is usual) written as\n*alternative* hypotheses. We can rewrite them as null\nhypotheses, with some extra wording to facilitate converting them\ninto contrasts, like this:\n\n\n* The mean of the `same`, `imaginary` and\n`photograph` groups (group means) is equal to the mean of the\n`different` and `placebo` groups (group means).\n\n* The mean of the `imaginary` and `photograph`\ngroups is equal to the (mean of the) `same` group.\n\n* The `imaginary` and the `photograph` groups will\nhave the same mean.\n\n* The `different` and the `placebo` groups will\nhave the same mean.\n\nThe data are in\n[link](http://ritsokiguess.site/datafiles/smith.txt) (the\noriginal researcher's name was Smith). \n\n\n(a) Read in the data and verify that you have a column called\n`context` that is text and a column called\n`words` that is a (whole) number.\n\n\n\n(b) Turn `context` into a `factor`, within the\ndata frame. (We are going to be doing contrasts). Display how the\ndata frame now looks.\n\n\n\n(c) What are the names of the five contexts in the data set\n(just display them),\nand what order are they in?\n\n\n\n(d) Write each of the four research hypotheses (in the\nnull-hypothesis versions) as R vectors that can be used to make\ncontrasts. (This will mean getting the contexts in the right\norder. If you get stuck, do the last two first, since they're\neasiest. The first one is actually the hardest.)\n\n\n\n(e) Pick two of your contrasts (doesn't matter which two) and\ndemonstrate that they are orthogonal.\n\n\n\n(f) Collect your contrasts together into a matrix, and\ntell `lm` that these are the contrasts for `context`.\n\n\n\n(g) Fit a model with `lm`, and display the results.\n\n\n\n(h) For each of the original research hypotheses, what do you\ninfer about them?\n\n\n\n\n\n\n\n\n\n##  Trying on shirts\n\n\n Does it make a difference if you see somebody else trying on\na shirt before you do, and if so, does it matter what kind of person\nit is? \n\nAn experiment was carried out in a university bookstore, with\nstudents who wanted to try on a shirt serving as (unsuspecting)\nexperimental subjects. When a student wanted to try on a shirt, the\nsales associate told them that there was only one shirt left, and it\nwas being tried on by an \"other customer\". This \"other customer\"\nwas actually a \"confederate\" of the experimenter (that means, they\nwere pretending to be a real customer but were actually part of the\nexperiment). The \"other customer\" was always female: either an\nattractive well-dressed model, or an average-looking student wearing\njeans. The \"other customer\" would come out of the\ndressing room and hand the shirt to the sales associate, who would\ngive it to the student who wanted to try it on. When the student had\ntried on the shirt, they were asked to rate it on a 7-point scale (on\nfive different dimensions, and those five scores were then\naveraged). Does a student's evaluation depend on whether the student\nwas male or female, and whether the \"other customer\" was a model or\na student? There was also a control group, where the student was\nhanded the shirt directly  by the sales associate, without the \n\"other customer\" being involved at all. \n\nThere were thus five treatments:\nmale students who saw a model, male students who saw a student, female\nstudents who saw a model, female students who saw a student, and the\ncontrol group. There were 25 students in each treatment group.\n\nThe data from this experiment can be found at\n[link](http://ritsokiguess.site/datafiles/shirts.csv).\n\n\n\n(a) Read in and display the data. How many observations do you\nhave, and is that what you should have?\n\n\n(b) Turn `treatment` into a `factor` in your data\nframe. (You can use the same name as the text `treatment`\nthat you read in from the file.)\n\n\n(c) List the treatments in the order that they are in within\nyour `factor`. (There are lots of ways to do this; any one of\nthem except for `distinct` is good.)\n\n\n(d) <a name=\"part:mean-eval\">*</a> \nObtain a table of mean evaluation scores for each treatment group.\n  \n\n\n(e) The experimenters wanted to compare four specific things in\ntheir analysis:\n\n\n* evaluation scores between male students who saw a (female) model and\nmale students who saw a (female) student\n\n* evaluation scores between female students who saw a (female)\nmodel and female students who saw a (female) student\n\n* evaluation scores for male and for female students (overall)\n\n* evaluation scores for the (average of the) four genuine\ntreatments and for the control group\n\nCreate contrasts, with suitable names, using vectors with\nappropriate values.\n  \n\n\n(f) Pick two of your contrasts (doesn't matter which two) and\ndemonstrate that they are orthogonal.\n  \n\n\n(g) Collect all your contrasts together into a matrix and\ndeclare that they are contrasts for `treatment` within your\ndata frame (whatever you called it).\n  \n\n\n(h) Predict evaluation score from \ntreatment *as a  regression*, and display the results.\n  \n\n\n(i) For each of your contrasts, assess whether or not it is\nsignificant, and explain briefly what that means in the context of the\ndata. If a contrast is significant, use your answer to\npart (<a href=\"#part:mean-eval\">here</a>) to help in your interpretation. \n    \n\n\n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n##  Acid rain\n\n\n One of the first noticeable effects of climate change was\n\"acid rain\". This is formed by the water vapour in clouds combining\nwith nitrous oxide and sulfur dioxide, which come from coal and oil\nproduction. How does the acidity of rain affect the acidity of the\nsoil on which it falls? (This will have an effect on the kind of\nplants that can be grown in that soil.) Acidity is measured using the\npH scale, where a pH of 7 is chemically neutral, a number less than 7\nis acidic, and a number greater than 7 is alkaline.\n\nAn experiment was conducted at the Florida Institute of Food and\nAgricultural Sciences, to determine how acidity of rain affects soil\nacidity. Experimental plots were irrigated with rainwater that was\nprepared to have one of two different pH levels, 3.7 and 4.5. The\nacidity of the soil was then measured at three different depths,\n0--15, 15--30, and 30--46 centimetres. This was done on three\ndifferent dates, in April and June 1991. The data are in\n[link](http://ritsokiguess.site/datafiles/acidrain.csv).\n\n\n\n(a) Read in and display the data.\n\nSolution\n\n\nThis time, it's a `.csv`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/acidrain.csv\"\nacidrain <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 18 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): soil_depth\ndbl  (2): rain_pH, soil_acidity\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nacidrain\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"soil_depth\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"date\"],\"name\":[2],\"type\":[\"date\"],\"align\":[\"right\"]},{\"label\":[\"rain_pH\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"soil_acidity\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0-15\",\"2\":\"1991-04-03\",\"3\":\"3.7\",\"4\":\"5.33\"},{\"1\":\"0-15\",\"2\":\"1991-04-03\",\"3\":\"4.5\",\"4\":\"5.33\"},{\"1\":\"0-15\",\"2\":\"1991-06-16\",\"3\":\"3.7\",\"4\":\"5.47\"},{\"1\":\"0-15\",\"2\":\"1991-06-16\",\"3\":\"4.5\",\"4\":\"5.47\"},{\"1\":\"0-15\",\"2\":\"1991-06-30\",\"3\":\"3.7\",\"4\":\"5.20\"},{\"1\":\"0-15\",\"2\":\"1991-06-30\",\"3\":\"4.5\",\"4\":\"5.13\"},{\"1\":\"15-30\",\"2\":\"1991-04-03\",\"3\":\"3.7\",\"4\":\"5.27\"},{\"1\":\"15-30\",\"2\":\"1991-04-03\",\"3\":\"4.5\",\"4\":\"5.03\"},{\"1\":\"15-30\",\"2\":\"1991-06-16\",\"3\":\"3.7\",\"4\":\"5.50\"},{\"1\":\"15-30\",\"2\":\"1991-06-16\",\"3\":\"4.5\",\"4\":\"5.53\"},{\"1\":\"15-30\",\"2\":\"1991-06-30\",\"3\":\"3.7\",\"4\":\"5.33\"},{\"1\":\"15-30\",\"2\":\"1991-06-30\",\"3\":\"4.5\",\"4\":\"5.20\"},{\"1\":\"30-46\",\"2\":\"1991-04-03\",\"3\":\"3.7\",\"4\":\"5.37\"},{\"1\":\"30-46\",\"2\":\"1991-04-03\",\"3\":\"4.5\",\"4\":\"5.40\"},{\"1\":\"30-46\",\"2\":\"1991-06-16\",\"3\":\"3.7\",\"4\":\"5.80\"},{\"1\":\"30-46\",\"2\":\"1991-06-16\",\"3\":\"4.5\",\"4\":\"5.60\"},{\"1\":\"30-46\",\"2\":\"1991-06-30\",\"3\":\"3.7\",\"4\":\"5.33\"},{\"1\":\"30-46\",\"2\":\"1991-06-30\",\"3\":\"4.5\",\"4\":\"5.17\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nThere are 4 columns, soil depth, date, pH of the rain that was\napplied (all explanatory) and soil acidity, the response. You'll note\nthat we have one soil acidity value per combination of the other\nthings (it was a designed experiment).\n\nWe're going to ignore the date for now, treating the observations on\ndifferent dates as replicates.\n\n$\\blacksquare$\n\n(b) Draw a grouped boxplot to show how soil acidity depends on\nthe pH of the rain and the soil depth. (The first time you do this\nyou might not get the boxplot you want. How can you fix that?)\n\nSolution\n\n\nThe problem is likely to be that either your `x` or your\n`fill` for your boxplot is numerical (`rain_pH` is\n`dbl`) rather than the categorical variable you need.\nTry to use one of the explanatory variables as `x` and the other\none as `fill` (or `colour`):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(acidrain, aes(x = rain_pH, y = soil_acidity, fill = soil_depth)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-html/acidrain-2-1.png){width=672}\n:::\n:::\n\n     \n\nThat looks as if it worked, but it didn't. See the boxplot below for\nhow it's supposed to be.  I need `x` for the boxplot needs to\nbe categorical. The easiest way to make it such is to wrap it in\n`factor`:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(acidrain, aes(x = factor(rain_pH), y = soil_acidity, fill = soil_depth)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-html/acidrain-3-1.png){width=672}\n:::\n:::\n\n     \n\nEven though `soil_depth` looks like numbers, the printout of\nthe data frame reveals that it is text, so that is OK.\n\nIf you prefer, exchange `x` and `fill`:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(acidrain, aes(fill = factor(rain_pH), y = soil_acidity, x = soil_depth)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-html/acidrain-4-1.png){width=672}\n:::\n:::\n\n     \n$\\blacksquare$\n\n(c) What does your grouped boxplot say about likely\ninteractions? Explain briefly.\n\nSolution\n\n\nThink about the effect of one of your explanatory variables, for\neach level of the other. For example, in the last plot, the effect\nof the rain pH pm on the soil acidity is very small at the largest\nand smallest depths, but at the middle soil depth 15--30, the\naverage (median) soil acidity is a lot less when the rain pH is\n*higher* (which seems odd to me). The effect of rain pH being\ndifferent according to soil pH is what suggests an interaction\neffect. \nAnother way of thinking about this is imagining what an\ninteraction plot would look like. This would be a trace going\nthrough the middle (strictly, mean rather than median) of each set\nof boxplots of one colour. In the last boxplot, the red trace\nwould go close to straight across, while the blue one would dip in\nthe middle. Not parallel, so suggesting an interaction.\nEither approach is good.\n\n$\\blacksquare$\n\n(d) Fit an ANOVA with interaction. What do you conclude from\nit? You may want to create a column that is the factor version of\n`rain_pH` first.\n\nSolution\n\n\nFollowing my own hint:\n\n::: {.cell}\n\n```{.r .cell-code}\nacidrain <- acidrain %>% mutate(frph = factor(rain_pH))\nsoil.1 <- aov(soil_acidity ~ frph * soil_depth, data = acidrain)\nsummary(soil.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                Df Sum Sq Mean Sq F value Pr(>F)\nfrph             1 0.0304 0.03042   0.759  0.401\nsoil_depth       2 0.0671 0.03357   0.838  0.457\nfrph:soil_depth  2 0.0078 0.00391   0.097  0.908\nResiduals       12 0.4810 0.04008               \n```\n:::\n:::\n\n \n\nThe interaction is nowhere near significant, perhaps surprisingly. But\nbear in mind that there are only 18 observations in total, so each box\non the boxplot is based on *three* observations only. So the\ninteraction would have to be a lot bigger to be significant.\n\nThe usual procedure after finding a non-significant\ninteraction is to take it out:\n\n::: {.cell}\n\n```{.r .cell-code}\nsoil.2 <- update(soil.1, . ~ . - frph:soil_depth)\nsummary(soil.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value Pr(>F)\nfrph         1 0.0304 0.03042   0.871  0.366\nsoil_depth   2 0.0671 0.03357   0.962  0.406\nResiduals   14 0.4888 0.03492               \n```\n:::\n:::\n\n \n\nThe P-values have come down a bit (the result of gaining two df for\nerror while the error SS only got a tiny bit bigger), but not nearly\nenough to be significant.\n\n\n$\\blacksquare$\n\n\n\n\n##  Treating hay fever\n\n\n Hay fever is an allergic reaction to things like grasses or\npollen which can make it unpleasant to go outside when the weather is\nat its best.  A research lab is developing a new compound to relieve\nsevere cases of hay fever. There were two active ingredients, labelled\nA and B, with each one having three levels, low, medium and\nhigh. There were thus $3\\times 3=9$ treatment combinations. 36\nsubjects were available, and these were randomly assigned to\ncombinations of levels of factor A and factor B, so that each\ncombination was tested on 4 people. The response variable was the\nnumber of hours of relief from symptoms (so a higher value is\nbetter). The data are in\n[link](http://ritsokiguess.site/datafiles/hayfever.txt).\n\n\n\n(a) Read the data and display its structure. Verify that you\nhave what you were expecting.\n\nSolution\n\n\nAligned columns separated by spaces, so `read_table`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/hayfever.txt\"\nhayfever <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  relief = col_double(),\n  a = col_character(),\n  b = col_character(),\n  replicate = col_double()\n)\n```\n:::\n\n```{.r .cell-code}\nhayfever\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"relief\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"a\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"b\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"replicate\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2.4\",\"2\":\"low\",\"3\":\"low\",\"4\":\"1\"},{\"1\":\"2.7\",\"2\":\"low\",\"3\":\"low\",\"4\":\"2\"},{\"1\":\"2.3\",\"2\":\"low\",\"3\":\"low\",\"4\":\"3\"},{\"1\":\"2.5\",\"2\":\"low\",\"3\":\"low\",\"4\":\"4\"},{\"1\":\"4.6\",\"2\":\"low\",\"3\":\"medium\",\"4\":\"1\"},{\"1\":\"4.2\",\"2\":\"low\",\"3\":\"medium\",\"4\":\"2\"},{\"1\":\"4.9\",\"2\":\"low\",\"3\":\"medium\",\"4\":\"3\"},{\"1\":\"4.7\",\"2\":\"low\",\"3\":\"medium\",\"4\":\"4\"},{\"1\":\"4.8\",\"2\":\"low\",\"3\":\"high\",\"4\":\"1\"},{\"1\":\"4.5\",\"2\":\"low\",\"3\":\"high\",\"4\":\"2\"},{\"1\":\"4.4\",\"2\":\"low\",\"3\":\"high\",\"4\":\"3\"},{\"1\":\"4.6\",\"2\":\"low\",\"3\":\"high\",\"4\":\"4\"},{\"1\":\"5.8\",\"2\":\"medium\",\"3\":\"low\",\"4\":\"1\"},{\"1\":\"5.2\",\"2\":\"medium\",\"3\":\"low\",\"4\":\"2\"},{\"1\":\"5.5\",\"2\":\"medium\",\"3\":\"low\",\"4\":\"3\"},{\"1\":\"5.3\",\"2\":\"medium\",\"3\":\"low\",\"4\":\"4\"},{\"1\":\"8.9\",\"2\":\"medium\",\"3\":\"medium\",\"4\":\"1\"},{\"1\":\"9.1\",\"2\":\"medium\",\"3\":\"medium\",\"4\":\"2\"},{\"1\":\"8.7\",\"2\":\"medium\",\"3\":\"medium\",\"4\":\"3\"},{\"1\":\"9.0\",\"2\":\"medium\",\"3\":\"medium\",\"4\":\"4\"},{\"1\":\"9.1\",\"2\":\"medium\",\"3\":\"high\",\"4\":\"1\"},{\"1\":\"9.3\",\"2\":\"medium\",\"3\":\"high\",\"4\":\"2\"},{\"1\":\"8.7\",\"2\":\"medium\",\"3\":\"high\",\"4\":\"3\"},{\"1\":\"9.4\",\"2\":\"medium\",\"3\":\"high\",\"4\":\"4\"},{\"1\":\"6.1\",\"2\":\"high\",\"3\":\"low\",\"4\":\"1\"},{\"1\":\"5.7\",\"2\":\"high\",\"3\":\"low\",\"4\":\"2\"},{\"1\":\"5.9\",\"2\":\"high\",\"3\":\"low\",\"4\":\"3\"},{\"1\":\"6.2\",\"2\":\"high\",\"3\":\"low\",\"4\":\"4\"},{\"1\":\"9.9\",\"2\":\"high\",\"3\":\"medium\",\"4\":\"1\"},{\"1\":\"10.5\",\"2\":\"high\",\"3\":\"medium\",\"4\":\"2\"},{\"1\":\"10.6\",\"2\":\"high\",\"3\":\"medium\",\"4\":\"3\"},{\"1\":\"10.1\",\"2\":\"high\",\"3\":\"medium\",\"4\":\"4\"},{\"1\":\"13.5\",\"2\":\"high\",\"3\":\"high\",\"4\":\"1\"},{\"1\":\"13.0\",\"2\":\"high\",\"3\":\"high\",\"4\":\"2\"},{\"1\":\"13.3\",\"2\":\"high\",\"3\":\"high\",\"4\":\"3\"},{\"1\":\"13.2\",\"2\":\"high\",\"3\":\"high\",\"4\":\"4\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n     \n\nI have 36 observations (patients). There are two categorical columns\n`a` and `b` corresponding to the two active ingredients,\nand they each seem to have levels low, medium and high.^[It's important to be clear about the distinction between a categorical variable, that lives in a data frame column, and its levels, the values that appear in the column. This is especially important if you're trying to decide whether a data frame is tidy, since typically an untidy data frame will have factor levels as column names rather than the factor itself, and you need to be able to tell the difference.]\n\nThe `replicate` column labels each observation *within*\nits A-B combination, so that each treatment combination was indeed\nreplicated four times. We won't be using this column in our analysis;\nI think it's a refugee from the original untidy format the data was in\nbefore it came to you.\n\n$\\blacksquare$\n\n(b) Calculate the mean hours of relief for each combination of\nlevels of the two active ingredients. Save your results in a data\nframe and display that.\n\nSolution\n\n\nThis is a group-by and summarize, but there are two active ingredients and they *both* have to go in the group-by:\n\n::: {.cell}\n\n```{.r .cell-code}\nhayfever %>%\n  group_by(a, b) %>%\n  summarize(m = mean(relief)) -> d\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'a'. You can override using the `.groups`\nargument.\n```\n:::\n\n```{.r .cell-code}\nd\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"a\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"b\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"m\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"high\",\"2\":\"high\",\"3\":\"13.250\"},{\"1\":\"high\",\"2\":\"low\",\"3\":\"5.975\"},{\"1\":\"high\",\"2\":\"medium\",\"3\":\"10.275\"},{\"1\":\"low\",\"2\":\"high\",\"3\":\"4.575\"},{\"1\":\"low\",\"2\":\"low\",\"3\":\"2.475\"},{\"1\":\"low\",\"2\":\"medium\",\"3\":\"4.600\"},{\"1\":\"medium\",\"2\":\"high\",\"3\":\"9.125\"},{\"1\":\"medium\",\"2\":\"low\",\"3\":\"5.450\"},{\"1\":\"medium\",\"2\":\"medium\",\"3\":\"8.925\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nI'm using my usual name `d` for a temporary data frame. I could\nhave put brackets around my whole pipeline to display its result, but\nI still need to save the data frame `d` to use in a moment.\n\nThese levels are in the wrong logical order, but they are in the right order in the original data frame, so we can use `fct_inorder` first, thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nhayfever %>%\n  mutate(a = fct_inorder(a), b = fct_inorder(b)) %>%\n  group_by(a, b) %>%\n  summarize(m = mean(relief)) -> d2\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'a'. You can override using the `.groups`\nargument.\n```\n:::\n\n```{.r .cell-code}\nd2\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"a\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"b\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"m\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"low\",\"2\":\"low\",\"3\":\"2.475\"},{\"1\":\"low\",\"2\":\"medium\",\"3\":\"4.600\"},{\"1\":\"low\",\"2\":\"high\",\"3\":\"4.575\"},{\"1\":\"medium\",\"2\":\"low\",\"3\":\"5.450\"},{\"1\":\"medium\",\"2\":\"medium\",\"3\":\"8.925\"},{\"1\":\"medium\",\"2\":\"high\",\"3\":\"9.125\"},{\"1\":\"high\",\"2\":\"low\",\"3\":\"5.975\"},{\"1\":\"high\",\"2\":\"medium\",\"3\":\"10.275\"},{\"1\":\"high\",\"2\":\"high\",\"3\":\"13.250\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n$\\blacksquare$\n\n(c) Make an interaction plot, showing how the mean pain relief depends on the combination of levels of A and B. It is probably easiest to use the data frame you obtained in the previous part.\n\nSolution\n\n\nMy column of mean relief values is called `m`. Use whatever\nname you gave it.  I'm going to use my proper-order data frame for\nthis:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d2, aes(x = a, y = m, colour = b, group = b)) +\n  geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-html/zellerin-1.png){width=672}\n:::\n:::\n\n     \nOr, you probably had this:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d, aes(x = a, y = m, colour = b, group = b)) +\n  geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-html/bapplin-1.png){width=672}\n:::\n:::\n\n     \n\nSince `a` and `b` both have three levels, you could just as well use them the other way around:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d2, aes(x = b, y = m, colour = a, group = a)) +\n  geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-html/vonmengen-1.png){width=672}\n:::\n:::\n\n \n\nThe plot looks different depending on how you draw it, but the\nconclusion from it (below) will be the same.\n\n$\\blacksquare$\n\n(d) What do you conclude from your interaction plot? Explain briefly.\n\nSolution\n\n\nThe three lines are not particularly close to being parallel, so I\nwould expect to see an interaction between the two active\ningredients (that is, the number of hours of pain relief depends\non the combination of the two of them).\n\nExtra: It is always a judgment call to decide whether the lines\nare \"approximately parallel\" or not. It depends on how much\nvariability there is in the data, which the interaction plot\ndoesn't show. Another idea is to add the data to the interaction\nplot, colour-coded in the same way. I would do this by taking out\nthe `geom_point` for the means and add one instead for the\ndata, taken from the original data frame:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d2, aes(x = a, y = m, colour = b, group = b)) +\n  geom_line() +\n  geom_point(data = hayfever, aes(y = relief))\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-html/swaub-1.png){width=672}\n:::\n:::\n\n     \n\nTechnique: for that last `geom_point`, put in anything that\nchanges: a new data frame, and a new `y` for the plot, but the\n`x` and `colour` and `group` are the same as they\nwere before, so I don't need to specify them.\n\nThe points are *very* close to the lines, so there is almost no\nresidual variability. This makes it more convincing that the\ninteraction is real and will be significant.\n\n$\\blacksquare$\n\n(e) Run an analysis of variance with interaction. What do you conclude?\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhayfever.1 <- aov(relief ~ a * b, data = hayfever)\nsummary(hayfever.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value Pr(>F)    \na            2 220.02  110.01  1827.9 <2e-16 ***\nb            2 123.66   61.83  1027.3 <2e-16 ***\na:b          4  29.42    7.36   122.2 <2e-16 ***\nResiduals   27   1.63    0.06                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n     \n\nThe interaction is (strongly) significant. The hours of relief depend on the combination of levels of the active ingredients A and B.\n\nDon't try to interpret the main effects of A and B from here. That's what simple effects are for, coming up.\n\n$\\blacksquare$\n\n(f) Analyze the simple effects of B when A is\n`medium`. (This means doing an appropriate `aov` and\nan appropriate Tukey, if warranted.)\n\nSolution\n\n\nFirst, we pull out only the data where A is `medium`, and then we do a one-way analysis of B on that data. This is the slick way, though you can certainly save the result of `filter` first:\n\n::: {.cell}\n\n```{.r .cell-code}\nhayfever %>%\n  filter(a == \"medium\") %>%\n  aov(relief ~ b, data = .) -> simple_medium\nsummary(simple_medium)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nb            2  34.16  17.081   262.8 1.04e-08 ***\nResiduals    9   0.59   0.065                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n     \n\nThere is definitely some effect of ingredient B when A is medium. What\nis it? Tukey will tell us:\n\n::: {.cell}\n\n```{.r .cell-code}\nTukeyHSD(simple_medium)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = relief ~ b, data = .)\n\n$b\n              diff       lwr       upr     p adj\nlow-high    -3.675 -4.178336 -3.171664 0.0000000\nmedium-high -0.200 -0.703336  0.303336 0.5323662\nmedium-low   3.475  2.971664  3.978336 0.0000000\n```\n:::\n:::\n\n \n\nThere is no difference between medium and high (levels of B), but both of these are better in terms of relief than low is.\n\n$\\blacksquare$\n\n(g) Analyze the simple effects of B when A is `high`.\n\nSolution\n\n\nSame idea: pull out only the data where A is `high`, do a one-way analysis of B, and do Tukey if needed:\n\n::: {.cell}\n\n```{.r .cell-code}\nhayfever %>%\n  filter(a == \"high\") %>%\n  aov(relief ~ b, data = .) -> simple_high\nsummary(simple_high)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nb            2 107.02   53.51     796 7.49e-11 ***\nResiduals    9   0.61    0.07                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nTukeyHSD(simple_high)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = relief ~ b, data = .)\n\n$b\n              diff       lwr       upr p adj\nlow-high    -7.275 -7.786868 -6.763132 0e+00\nmedium-high -2.975 -3.486868 -2.463132 2e-07\nmedium-low   4.300  3.788132  4.811868 0e+00\n```\n:::\n:::\n\n     \n\nWhen A is high, there is definitely an effect of B again, but this\ntime high (for B) is better than medium is better than low. (All the\nP-values in Tukey are very small.)\n\nYou could guess this from the interaction plot as well (whichever one\nyou came up with): when A is high, it is better for B to be high as\nwell, but when A is medium or low, there is not much difference\nbetween B being medium or high.\n\nExtra: here, the effect of B is different, depending on what A is. This is\nwhat a significant interaction *means*. If there were no\nsignificant interaction, the effect of B would always be the same, no\nmatter what A was.\n\n$\\blacksquare$\n\n\n\n\n\n##  Focused comparisons of the effect of caffeine\n\n\n \nDoes caffeine help students do better on a certain test? To\nfind out, 36 students were randomly allocated to three groups (12 in\neach group).  Each student received a fixed number of cups of coffee\nwhile they were studying, but the students didn't know whether they\nwere receiving all full-strength coffee (\"high\"), all decaf coffee\n(\"low\") or a 50-50 mixture of the two (\"moderate\"). For each\nsubject, their group was recorded as well as their score on the\ntest. The data are in\n[link](http://ritsokiguess.site/datafiles/caffeine.csv), as a\n`.csv` file.\n\nThis time we look at\ncontrasts. Suppose I knew ahead of time\nthat I wanted to compare moderate caffeine with high, and any\ncaffeine with none. (In the latter case, we're comparing \n\"no caffeine\" against the average of the other two groups.)\n\nIn the previous go-through of the caffeine data, we\ndiscovered that `amount` was actually text rather than a\nfactor, but we also discovered that it *didn't matter*. Here it\ndoes matter, so the first thing we have to do is to re-do the\n`pivot_longer`, creating a factor version of `amount`.\n\n\n\n(a) Read in the data again, from\n[link](http://ritsokiguess.site/datafiles/caffeine.csv), and\ndisplay it. This is the untidy format, so name it appropriately:\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://individual.utoronto.ca/kbutler/stad29/caffeine.csv\"\ncaffeine.untidy <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 12 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): Sub, High, Moderate, None\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\ncaffeine.untidy\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Sub\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"High\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Moderate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"None\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"72\",\"3\":\"68\",\"4\":\"68\"},{\"1\":\"2\",\"2\":\"65\",\"3\":\"80\",\"4\":\"74\"},{\"1\":\"3\",\"2\":\"68\",\"3\":\"64\",\"4\":\"59\"},{\"1\":\"4\",\"2\":\"83\",\"3\":\"65\",\"4\":\"61\"},{\"1\":\"5\",\"2\":\"79\",\"3\":\"69\",\"4\":\"65\"},{\"1\":\"6\",\"2\":\"92\",\"3\":\"79\",\"4\":\"72\"},{\"1\":\"7\",\"2\":\"69\",\"3\":\"80\",\"4\":\"80\"},{\"1\":\"8\",\"2\":\"74\",\"3\":\"63\",\"4\":\"58\"},{\"1\":\"9\",\"2\":\"78\",\"3\":\"69\",\"4\":\"65\"},{\"1\":\"10\",\"2\":\"83\",\"3\":\"70\",\"4\":\"60\"},{\"1\":\"11\",\"2\":\"88\",\"3\":\"83\",\"4\":\"78\"},{\"1\":\"12\",\"2\":\"71\",\"3\":\"75\",\"4\":\"75\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nOne caffeine level per column, rather than a column of caffeine\nlevels, so untidy.\n\n\n$\\blacksquare$\n\n(b) Copy your `pivot_longer` from before, only this time add\n`names_ptypes = list(amount=factor())` to the end of it. Take a look at the\nresults. What has changed from before?\n\n\nSolution\n\n\nWe'll save into `caffeine` again:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine.untidy %>%\n  pivot_longer(-Sub, names_to=\"amount\", values_to=\"score\", \n               names_ptypes = list(amount=factor())) -> caffeine\ncaffeine\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Sub\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"amount\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"score\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"High\",\"3\":\"72\"},{\"1\":\"1\",\"2\":\"Moderate\",\"3\":\"68\"},{\"1\":\"1\",\"2\":\"None\",\"3\":\"68\"},{\"1\":\"2\",\"2\":\"High\",\"3\":\"65\"},{\"1\":\"2\",\"2\":\"Moderate\",\"3\":\"80\"},{\"1\":\"2\",\"2\":\"None\",\"3\":\"74\"},{\"1\":\"3\",\"2\":\"High\",\"3\":\"68\"},{\"1\":\"3\",\"2\":\"Moderate\",\"3\":\"64\"},{\"1\":\"3\",\"2\":\"None\",\"3\":\"59\"},{\"1\":\"4\",\"2\":\"High\",\"3\":\"83\"},{\"1\":\"4\",\"2\":\"Moderate\",\"3\":\"65\"},{\"1\":\"4\",\"2\":\"None\",\"3\":\"61\"},{\"1\":\"5\",\"2\":\"High\",\"3\":\"79\"},{\"1\":\"5\",\"2\":\"Moderate\",\"3\":\"69\"},{\"1\":\"5\",\"2\":\"None\",\"3\":\"65\"},{\"1\":\"6\",\"2\":\"High\",\"3\":\"92\"},{\"1\":\"6\",\"2\":\"Moderate\",\"3\":\"79\"},{\"1\":\"6\",\"2\":\"None\",\"3\":\"72\"},{\"1\":\"7\",\"2\":\"High\",\"3\":\"69\"},{\"1\":\"7\",\"2\":\"Moderate\",\"3\":\"80\"},{\"1\":\"7\",\"2\":\"None\",\"3\":\"80\"},{\"1\":\"8\",\"2\":\"High\",\"3\":\"74\"},{\"1\":\"8\",\"2\":\"Moderate\",\"3\":\"63\"},{\"1\":\"8\",\"2\":\"None\",\"3\":\"58\"},{\"1\":\"9\",\"2\":\"High\",\"3\":\"78\"},{\"1\":\"9\",\"2\":\"Moderate\",\"3\":\"69\"},{\"1\":\"9\",\"2\":\"None\",\"3\":\"65\"},{\"1\":\"10\",\"2\":\"High\",\"3\":\"83\"},{\"1\":\"10\",\"2\":\"Moderate\",\"3\":\"70\"},{\"1\":\"10\",\"2\":\"None\",\"3\":\"60\"},{\"1\":\"11\",\"2\":\"High\",\"3\":\"88\"},{\"1\":\"11\",\"2\":\"Moderate\",\"3\":\"83\"},{\"1\":\"11\",\"2\":\"None\",\"3\":\"78\"},{\"1\":\"12\",\"2\":\"High\",\"3\":\"71\"},{\"1\":\"12\",\"2\":\"Moderate\",\"3\":\"75\"},{\"1\":\"12\",\"2\":\"None\",\"3\":\"75\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nThe variable created for the \"names\" is now a\n`factor`: it was text before. Maybe we should have made it a\nfactor before (it wouldn't have done any harm), but we got away with\nnot doing so.\n\n\n$\\blacksquare$\n\n(c) Using the newly tidied caffeine data, run the ANOVA \n*as a  regression* (that is, using `lm`). Look at the\n`summary` of the output. What do you see?\n\n\nSolution\n\n\nExtra: I'm going to run the ANOVA the \"old way\" first, so that we can\ncompare results. You don't need to do this:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine.old <- aov(score ~ amount, data = caffeine)\nsummary(caffeine.old)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value Pr(>F)  \namount       2  477.7  238.86   3.986 0.0281 *\nResiduals   33 1977.5   59.92                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nTukeyHSD(caffeine.old)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = score ~ amount, data = caffeine)\n\n$amount\n                   diff       lwr       upr     p adj\nModerate-High -4.750000 -12.50468  3.004679 0.3025693\nNone-High     -8.916667 -16.67135 -1.161987 0.0213422\nNone-Moderate -4.166667 -11.92135  3.588013 0.3952176\n```\n:::\n:::\n\n       \n\nEnd of digression.\n\n\nNow we'll do it using `lm`, with contrasts later, and see how\nthings change:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine.2 <- lm(score ~ amount, data = caffeine)\nsummary(caffeine.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = score ~ amount, data = caffeine)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.833  -6.958  -2.458   6.354  15.167 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      76.833      2.235  34.383  < 2e-16 ***\namountModerate   -4.750      3.160  -1.503  0.14234    \namountNone       -8.917      3.160  -2.821  0.00803 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.741 on 33 degrees of freedom\nMultiple R-squared:  0.1946,\tAdjusted R-squared:  0.1458 \nF-statistic: 3.986 on 2 and 33 DF,  p-value: 0.02815\n```\n:::\n:::\n\n       \nLook at the slopes. They are `amount` followed by one of the\namounts of caffeine. R is using \"high\" as a baseline  (that's the\nfirst level alphabetically), so the\n`amountModerate` line is testing high vs.\\ moderate: high is\n*not* significantly higher, in terms of test scores, than\nmoderate. That's one of the things I wanted to test. What about the\ncoefficient for `amountNone`? That's none vs.\\ *high*,\nsince high was the baseline. This is, as we saw from Tukey,\nsignificant. But it is not what I said we wanted to test. \n\nExtra: in case you're curious, you can also get the regular analysis of\nvariance table as below. `anova` is multi-talented:\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(caffeine.2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Sum Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Mean Sq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2\",\"2\":\"477.7222\",\"3\":\"238.86111\",\"4\":\"3.986051\",\"5\":\"0.02814646\",\"_rn_\":\"amount\"},{\"1\":\"33\",\"2\":\"1977.5000\",\"3\":\"59.92424\",\"4\":\"NA\",\"5\":\"NA\",\"_rn_\":\"Residuals\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nThe problem is that you can't naturally do Tukey this way, which is\noften what you want to do next. That's why we used `aov` before.\n\nSince we have a regression model (albeit a peculiar one), we can test\nwhether we should remove `amount` (that is, whether it has any\nimpact on test scores) this way too:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(caffeine.2, test = \"F\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Sum of Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"RSS\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"NA\",\"3\":\"1977.500\",\"4\":\"150.2185\",\"5\":\"NA\",\"6\":\"NA\",\"_rn_\":\"<none>\"},{\"1\":\"2\",\"2\":\"477.7222\",\"3\":\"2455.222\",\"4\":\"154.0083\",\"5\":\"3.986051\",\"6\":\"0.02814646\",\"_rn_\":\"amount\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nSame conclusion: there is some effect of caffeine level on test score.\n\n\n$\\blacksquare$\n\n(d) Obtain the different values of `amount`, in the order\nthat R has them.\n\n\nSolution\n\n\nCount them, or find the distinct ones:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine %>% group_by(amount) %>% summarize(count = n())\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"amount\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"count\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"High\",\"2\":\"12\"},{\"1\":\"Moderate\",\"2\":\"12\"},{\"1\":\"None\",\"2\":\"12\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nor there is this shortcut to the above:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine %>% count(amount)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"amount\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"High\",\"2\":\"12\"},{\"1\":\"Moderate\",\"2\":\"12\"},{\"1\":\"None\",\"2\":\"12\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nOr\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine %>% distinct(amount)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"amount\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"High\"},{\"1\":\"Moderate\"},{\"1\":\"None\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nsince we didn't really need to know how many of each there were.\n\nThese would all have worked if `amount` had been text rather a\nfactor. If you have a genuine `factor`, you can also ask for\nits `levels`:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(caffeine, levels(amount))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"High\"     \"Moderate\" \"None\"    \n```\n:::\n:::\n\n \n\nor `summary` will count them up and list them:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine %>% select(amount) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      amount  \n High    :12  \n Moderate:12  \n None    :12  \n```\n:::\n:::\n\n \n\nThis last won't work if you have a categorical-variable-as-text. It\nhas to be a genuine factor for it to work.\n\nThe categories are High, Moderate and None in that order.  For working\nwith contrasts, we need to have the thing we're making contrasts for\n(see below) as a `factor`, otherwise it won't work.\n\n\n$\\blacksquare$\n\n(e) Create a contrast that compares High with Moderate, ignoring\nNone. That is, create a vector whose length is the same as the\nnumber of levels of `amount`, and which has a 1 to represent\nHigh and a $-1$ to represent Moderate. \n\n\nSolution\n\n\nPut a 0 in for None:\n\n::: {.cell}\n\n```{.r .cell-code}\nc.hm <- c(1, -1, 0)\n```\n:::\n\n       \n\nHaving the 1 and the $-1$ the other way around would also have been fine.\n\n\n$\\blacksquare$\n\n(f) Create a contrast that compares \"any caffeine\" against\n\"none\" by comparing None against the average of Moderate and High.\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc.any <- c(-0.5, -0.5, 1)\n```\n:::\n\n \nNote that both our contrasts have coefficients that add up to zero, as\nthey must:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c.hm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n\n```{.r .cell-code}\nsum(c.any)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n \n\n\n$\\blacksquare$\n\n(g) Verify that your two contrasts are orthogonal.\n\n\nSolution\n\n\nMultiply them together and check that what you get adds up to zero:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c.hm * c.any)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n \n\nZero, so orthogonal. You can check that writing `c.any` as\n`c(-1,-1,2)` would also work (and still be orthogonal with\n`c.hm`), and so would writing it as `c(1,1,-2)`. \n\n\n$\\blacksquare$\n\n(h) Arrange your contrasts as columns of a matrix (using\n`cbind`), and say that you want to use these as contrasts for\n`amount` (in data frame `caffeine` or whatever you\ncalled it).\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c.hm, c.any)\ncontrasts(caffeine$amount) <- m\n```\n:::\n\n \n\n\n$\\blacksquare$\n\n(i) Fit the ANOVA as an `lm`, and look at the\n`summary`. What do you conclude about your contrasts?\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncaff.3 <- lm(score ~ amount, data = caffeine)\nsummary(caff.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = score ~ amount, data = caffeine)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.833  -6.958  -2.458   6.354  15.167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   72.278      1.290  56.022   <2e-16 ***\namountc.hm     2.375      1.580   1.503   0.1423    \namountc.any   -4.361      1.825  -2.390   0.0227 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.741 on 33 degrees of freedom\nMultiple R-squared:  0.1946,\tAdjusted R-squared:  0.1458 \nF-statistic: 3.986 on 2 and 33 DF,  p-value: 0.02815\n```\n:::\n:::\n\n \n\n`c.hm` was the contrast between high and moderate\ncaffeine. This is not significant (P-value 0.142), which is the same\nconclusion as Tukey, but the P-value here is quite a bit lower (and\nthus closer to being significant). There's a reason for that: here we\nare focusing in on the two contrasts that we really wanted to test,\nand ignoring the $F$-test and the Tukey that tell us stuff that we\ndon't care about. By focusing our comparison, we get a better\n(smaller) P-value.\n\n`c.any` was none vs.\\ average of any\ncaffeine. This one is significant, with a P-value of 0.023. So this\ncontrast tells us that having any caffeine is better than having none.\n\n\n$\\blacksquare$\n\n(j) What happens if you try to use high caffeine vs.\\ moderate\ncaffeine and moderate vs.\\ none as your two contrasts?\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc.hm <- c(1, -1, 0)\nc.mn <- c(0, 1, -1)\n```\n:::\n\n \n\nSo far so good: the coefficients add up to zero and they reflect the\nright comparisons. But now:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c.hm * c.mn)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1\n```\n:::\n:::\n\n \n\nThis does *not* add up to zero, so these two contrasts are not\northogonal, and we can't do what we just did. R will give us an answer\nif we try it, but it'll be the *wrong* answer.^[Software like SAS, for example, has a way of making non-orthogonal contrasts orthogonal in a way that the user doesn't have to worry about, but in R, you are closer to the ground, so to speak, and you have to make it happen yourself.]\n\nThe best\ndescription I have seen of what to do here is by David Howell,^[Howell is the author of a famous text on Statistics in Psychology.] at\n[link](https://www.uvm.edu/~dhowell/StatPages/More_Stuff/R/AnovaOneway.html)\n(at the bottom).\nLet\nme try to follow his method. \n\nFirst we need a vector that is all 1's, which I have called\n`c0` below. Since each of our contrasts `c.hm` and\n`c.mn` have 3 things in them (3 groups), we need to add a\n\"dummy\" 3rd contrast to give us a $3\\times 3$ array of numbers:^[Which we are going to invert, as a matrix. But I get ahead of myself.]\n\n::: {.cell}\n\n```{.r .cell-code}\nc0 <- rep(1, 3)\nm <- cbind(c0, c.hm, c.mn)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     c0 c.hm c.mn\n[1,]  1    1    0\n[2,]  1   -1    1\n[3,]  1    0   -1\n```\n:::\n:::\n\n \n\nThis is what Howell calls an \"augmented\" matrix of contrasts, since\nit has our two contrasts as the second and third columns, plus\nthe extra dummy one. Next we invert this matrix of contrasts,\nwhich we can do because it's square. `t(m)` means \n\"take the matrix transpose of `m`\", if you're trying to keep up at the\nback, and `solve` finds a matrix inverse:\n\n::: {.cell}\n\n```{.r .cell-code}\nminv <- solve(t(m))\n```\n:::\n\n \n\nand then we remove the first column, which represents the contrast\nthat we didn't want anyway (what Howell calls \"deaugmenting\"):^[We are working with R matrices here rather than data frames, so we access elements, rows and columns using the square bracket notation: inside the square brackets, we put first the numbers of the rows we want, then a comma, then the numbers of the columns. There are two special pieces of notation, both of which I use here: leaving the row or column slot blank means all the rows or all the columns, and using a negative row or column number means all the rows or columns except the one(s) named. Thus my notation here is all the rows, and all the columns except for the first one. You can access data frames this way too, but the Tidyverse makes it much easier.]\n\n::: {.cell}\n\n```{.r .cell-code}\nm.contr <- minv[, -1]\nm.contr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           c.hm       c.mn\n[1,]  0.6666667  0.3333333\n[2,] -0.3333333  0.3333333\n[3,] -0.3333333 -0.6666667\n```\n:::\n\n```{.r .cell-code}\ncontrasts(caffeine$amount) <- m.contr\n```\n:::\n\n \n\nThe columns of `m.contr` are our new \ncontrasts. Note that they appear to be something else: high vs.\\ the\naverage of moderate and none, and none vs.\\ the average of moderate\nand high. They are actually\n*not* orthogonal, but if Howell is to be trusted,^[I think Howell is famous enough to be\ntrusted.] they can be\nused to test what we want. \nNow fit the model again:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaff.4 <- lm(score ~ amount, data = caffeine)\nsummary(caff.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = score ~ amount, data = caffeine)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.833  -6.958  -2.458   6.354  15.167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   72.278      1.290  56.022   <2e-16 ***\namountc.hm     4.750      3.160   1.503    0.142    \namountc.mn     4.167      3.160   1.318    0.196    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.741 on 33 degrees of freedom\nMultiple R-squared:  0.1946,\tAdjusted R-squared:  0.1458 \nF-statistic: 3.986 on 2 and 33 DF,  p-value: 0.02815\n```\n:::\n:::\n\n \n\nThe rows `amountc.hm` and `amountc.mn` are the proper tests\nfor our contrasts `c.hm` and `c.mn`. \n`c.hm` is not significant (P-value 0.14) and\n`c.mn` is not significant either\n(P-value 0.20). This is the same significance as from Tukey, but note\nthat the P-values for the non-significant tests are much lower than\nthe corresponding ones from Tukey, once again because we have focused\non just these comparisons, and not on any others. We decided ahead of\ntime to test just these, and gave ourselves the best chance of finding\nsignificance that we could.\n\n$\\blacksquare$\n\n\n\n\n\n##  Who studies the most outside class?\n\n\n A social scientist wanted to see how many hours students\n studied outside of class. She took a random sample of 75 students\n from three different majors: math, social science and English, and\n recorded the number of weekly outside-class study hours for each\n student. The data can be found at\n [link](http://ritsokiguess.site/datafiles/studyhours.txt). The\n social scientist had two research questions: whether math students study\n more outside of class than the other students, and whether English and\n social science students study different amounts of time outside class.\n\n\n(a) Explain briefly why contrasts would be a better idea here\nthan ANOVA with Tukey.\n\n\nSolution\n\n\nThe researcher is not interested in all the comparisons between\nthe groups, but rather in two specific ones (as detailed in the\nquestion). So we should focus our attention on those\ncomparisons. This is what contrasts are for.\n\n$\\blacksquare$\n\n(b) Read in the data and make side-by-side boxplots of study\nhours by major. What do the boxplots suggest about the comparisons\nthat the researcher wants to make?\n\n\nSolution\n\n\nSeparated by one space. There appear to be some strange quotes\nin there, but we'll ignore those and see whether they cause any\ntrouble: \n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/studyhours.txt\"\nstudyhours <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 75 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (1): major\ndbl (2): id, hours\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nstudyhours\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"major\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"hours\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"math\",\"3\":\"15\"},{\"1\":\"2\",\"2\":\"math\",\"3\":\"20\"},{\"1\":\"3\",\"2\":\"math\",\"3\":\"14\"},{\"1\":\"4\",\"2\":\"math\",\"3\":\"15\"},{\"1\":\"5\",\"2\":\"math\",\"3\":\"14\"},{\"1\":\"6\",\"2\":\"math\",\"3\":\"10\"},{\"1\":\"7\",\"2\":\"math\",\"3\":\"12\"},{\"1\":\"8\",\"2\":\"math\",\"3\":\"9\"},{\"1\":\"9\",\"2\":\"math\",\"3\":\"10\"},{\"1\":\"10\",\"2\":\"math\",\"3\":\"11\"},{\"1\":\"11\",\"2\":\"math\",\"3\":\"9\"},{\"1\":\"12\",\"2\":\"math\",\"3\":\"8\"},{\"1\":\"13\",\"2\":\"math\",\"3\":\"8\"},{\"1\":\"14\",\"2\":\"math\",\"3\":\"10\"},{\"1\":\"15\",\"2\":\"math\",\"3\":\"8\"},{\"1\":\"16\",\"2\":\"math\",\"3\":\"7\"},{\"1\":\"17\",\"2\":\"math\",\"3\":\"7\"},{\"1\":\"18\",\"2\":\"math\",\"3\":\"5\"},{\"1\":\"19\",\"2\":\"math\",\"3\":\"5\"},{\"1\":\"20\",\"2\":\"math\",\"3\":\"5\"},{\"1\":\"21\",\"2\":\"math\",\"3\":\"15\"},{\"1\":\"22\",\"2\":\"math\",\"3\":\"6\"},{\"1\":\"23\",\"2\":\"math\",\"3\":\"5\"},{\"1\":\"24\",\"2\":\"math\",\"3\":\"3\"},{\"1\":\"25\",\"2\":\"math\",\"3\":\"5\"},{\"1\":\"26\",\"2\":\"socsci\",\"3\":\"10\"},{\"1\":\"27\",\"2\":\"socsci\",\"3\":\"12\"},{\"1\":\"28\",\"2\":\"socsci\",\"3\":\"8\"},{\"1\":\"29\",\"2\":\"socsci\",\"3\":\"7\"},{\"1\":\"30\",\"2\":\"socsci\",\"3\":\"7\"},{\"1\":\"31\",\"2\":\"socsci\",\"3\":\"10\"},{\"1\":\"32\",\"2\":\"socsci\",\"3\":\"6\"},{\"1\":\"33\",\"2\":\"socsci\",\"3\":\"8\"},{\"1\":\"34\",\"2\":\"socsci\",\"3\":\"5\"},{\"1\":\"35\",\"2\":\"socsci\",\"3\":\"4\"},{\"1\":\"36\",\"2\":\"socsci\",\"3\":\"4\"},{\"1\":\"37\",\"2\":\"socsci\",\"3\":\"4\"},{\"1\":\"38\",\"2\":\"socsci\",\"3\":\"8\"},{\"1\":\"39\",\"2\":\"socsci\",\"3\":\"3\"},{\"1\":\"40\",\"2\":\"socsci\",\"3\":\"5\"},{\"1\":\"41\",\"2\":\"socsci\",\"3\":\"7\"},{\"1\":\"42\",\"2\":\"socsci\",\"3\":\"6\"},{\"1\":\"43\",\"2\":\"socsci\",\"3\":\"3\"},{\"1\":\"44\",\"2\":\"socsci\",\"3\":\"3\"},{\"1\":\"45\",\"2\":\"socsci\",\"3\":\"3\"},{\"1\":\"46\",\"2\":\"socsci\",\"3\":\"2\"},{\"1\":\"47\",\"2\":\"socsci\",\"3\":\"2\"},{\"1\":\"48\",\"2\":\"socsci\",\"3\":\"1\"},{\"1\":\"49\",\"2\":\"socsci\",\"3\":\"5\"},{\"1\":\"50\",\"2\":\"socsci\",\"3\":\"4\"},{\"1\":\"51\",\"2\":\"english\",\"3\":\"14\"},{\"1\":\"52\",\"2\":\"english\",\"3\":\"12\"},{\"1\":\"53\",\"2\":\"english\",\"3\":\"12\"},{\"1\":\"54\",\"2\":\"english\",\"3\":\"10\"},{\"1\":\"55\",\"2\":\"english\",\"3\":\"10\"},{\"1\":\"56\",\"2\":\"english\",\"3\":\"10\"},{\"1\":\"57\",\"2\":\"english\",\"3\":\"8\"},{\"1\":\"58\",\"2\":\"english\",\"3\":\"8\"},{\"1\":\"59\",\"2\":\"english\",\"3\":\"5\"},{\"1\":\"60\",\"2\":\"english\",\"3\":\"7\"},{\"1\":\"61\",\"2\":\"english\",\"3\":\"6\"},{\"1\":\"62\",\"2\":\"english\",\"3\":\"4\"},{\"1\":\"63\",\"2\":\"english\",\"3\":\"6\"},{\"1\":\"64\",\"2\":\"english\",\"3\":\"5\"},{\"1\":\"65\",\"2\":\"english\",\"3\":\"5\"},{\"1\":\"66\",\"2\":\"english\",\"3\":\"4\"},{\"1\":\"67\",\"2\":\"english\",\"3\":\"8\"},{\"1\":\"68\",\"2\":\"english\",\"3\":\"9\"},{\"1\":\"69\",\"2\":\"english\",\"3\":\"10\"},{\"1\":\"70\",\"2\":\"english\",\"3\":\"4\"},{\"1\":\"71\",\"2\":\"english\",\"3\":\"3\"},{\"1\":\"72\",\"2\":\"english\",\"3\":\"3\"},{\"1\":\"73\",\"2\":\"english\",\"3\":\"3\"},{\"1\":\"74\",\"2\":\"english\",\"3\":\"6\"},{\"1\":\"75\",\"2\":\"english\",\"3\":\"4\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n        \n\nSo far so good. 75 students, in tidy format.\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(studyhours, aes(x = major, y = hours)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-html/studyhours-2-1.png){width=672}\n:::\n:::\n\n \n\nThis suggests that the math students study more than the others, but\nthe English and social science students study about the same amount.\n\nI see some rather consistent right-skewness here (but no outliers). We\nhave 25 observations in each group, a decent amount of data, so I'm\nnot too worried, but a transformation could be a good idea, something\nlike square root, perhaps. The spreads are not that unequal, but it\n*is* true that the Math students have both the largest median\n*and* the largest spread, and the social science students are the\nlowest on both.\n\nExtra: Box-Cox also works on ANOVA-type data, since that is an `lm`\nkind of model:\n\n::: {.cell}\n\n```{.r .cell-code}\nboxcox(hours ~ major, data = studyhours)\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-html/studyhours-3-1.png){width=672}\n:::\n:::\n\n \n\nThis suggests that some kind of transformation would be a good idea\n(no transformation, power 1, is not supported by the data). My guess\nof 0.5 is not bad; that, or something a bit less like 0.25 (fourth\nroot) would be good. Even log is supportable. But we'll proceed\nwithout transformation in this question to give you some practice with\ncontrasts. Despite appearances, I do (sometimes) like to make things\nnot so complicated!\n\n$\\blacksquare$\n\n(c) Set up contrasts for each of the researcher's research\nquestions, bearing in mind the levels of `major` and the\norder in which they come. (For the `Math` contrast, you want\nMath against the average of the other two.)\n\n\nSolution\n\n\nWe need to know what the categories of `major` are, so that\nwe can set up the contrasts correctly, so let's start with that:\n\n::: {.cell}\n\n```{.r .cell-code}\nstudyhours %>% select(major) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    major          \n Length:75         \n Class :character  \n Mode  :character  \n```\n:::\n:::\n\n \n\nOh. Yeah. We never turned `major` into a factor. We'd better do\nthat, and then try again:\n\n::: {.cell}\n\n```{.r .cell-code}\nstudyhours <- studyhours %>% mutate(major = factor(major))\nstudyhours %>% select(major) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     major   \n english:25  \n math   :25  \n socsci :25  \n```\n:::\n:::\n\n \n\nIn alphabetical order.\n\nAll right, contrasts. The English vs.\\ social science one is easier,\nso we'll do that first. Just set it up with a 1 for one of them and a\n$-1$ for the other and 0 for math, in the right order according to\nwhat the levels are, viz:\n\n::: {.cell}\n\n```{.r .cell-code}\nc.eng.socsci <- c(1, 0, -1)\n```\n:::\n\n \n\nOr `c(-1,0,1)` would be just as good.\n\nThe other one is a bit trickier, because you want math against the\naverage of the others, like\n$$\\mbox{math}-(\\mbox{English}+\\mbox{socsci})/2.$$ \nThis translates into contrast-ese like this, making sure to get Math\nin the middle where it belongs:^[As I failed to do the first time.]\n\n::: {.cell}\n\n```{.r .cell-code}\nc.math.others <- c(-0.5, 1, -0.5)\n```\n:::\n\n \n\nThe coefficients have to add up to zero, so I have to have two halves\nto balance my one 1. Or I can use two $-1$s and a 2.\n\n$\\blacksquare$\n\n(d) Verify that your two contrasts are orthogonal.\n\n\nSolution\n\n\nMultiply them together (elementwise, which is how R does it)\nand show that what you get adds up to zero:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c.eng.socsci * c.math.others)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n \n\nZero. Orthogonal.\n\nSo we are safely in \"familiar\" territory, not in the \nhere-be-dragons^[On ancient maps, people didn't know what was  in certain parts of the world, because no-one had ever explored  them, so they wrote on the map \"here be dragons\".] land of\nnon-orthogonal contrasts.\n\n$\\blacksquare$\n\n(e) Create a matrix of contrasts (using `cbind`) and let\n`lm` know that these are contrasts for `major`, in\ndata frame `studyhours` (or whatever you called it).\n\n\nSolution\n\n\nSo, like the example in lecture (where the\n`contrasts(model)` was admittedly rather confusing):\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c.math.others, c.eng.socsci)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     c.math.others c.eng.socsci\n[1,]          -0.5            1\n[2,]           1.0            0\n[3,]          -0.5           -1\n```\n:::\n\n```{.r .cell-code}\ncontrasts(studyhours$major) <- m\n```\n:::\n\n        \n\n$\\blacksquare$\n\n(f) Fit the model using `lm`. What do you conclude about\nyour contrasts?\n\n\nSolution\n\n\nPretend the ANOVA is a regression (though you can fit ANOVAs\neither way: we just used `aov` before because we were\ngoing to follow up with Tukey):\n\n::: {.cell}\n\n```{.r .cell-code}\nstudyhours.1 <- lm(hours ~ major, data = studyhours)\nsummary(studyhours.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = hours ~ major, data = studyhours)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6.44  -2.48  -0.48   2.52  10.56 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          7.3200     0.3980  18.392  < 2e-16 ***\nmajorc.math.others   2.1200     0.5628   3.767 0.000335 ***\nmajorc.eng.socsci    0.7800     0.4874   1.600 0.113936    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.447 on 72 degrees of freedom\nMultiple R-squared:  0.1887,\tAdjusted R-squared:  0.1662 \nF-statistic: 8.374 on 2 and 72 DF,  p-value: 0.0005375\n```\n:::\n:::\n\n        \n\nThere is a seriously significant difference between the math students\nand the others. There is not, however, any kind of difference between\nthe mean study hours of the English and social science students. \n\n$\\blacksquare$\n\n(g) Are you surprised by the significance or non-significance you\nfound in the previous part? Explain briefly.\n\n\nSolution\n\n\nGo back and compare with the  boxplots. The math students\nstudied noticeably more than the others, so it is not\nsurprising that this difference came out significant. The\nmedian study times for the English and social science students\nwere similar, so it is not at all surprising that this difference\nfailed to be significant.\n\nWhen you set up contrasts, *these* are the tests you are\ninterested in, so there is no reason for following up with\nTukey or anything else. But you have to be able to say ahead of\ntime which contrasts you want to test. This is in\ncontrast^[In contrast. Get it? No? Well, never mind then.] to Tukey, where you don't have to decide\nwhich comparisons interest you until right at the end.\n\nAnother question you might have had is \n\"how many contrasts can I do\"? To answer this, go back and look at the ANOVA table. If\nyou run an ANOVA using `lm`, you get the ANOVA table by\npassing the fitted model object into `anova` rather than\n`summary`:^[`anova` is one of R's  multi-purpose tools; what it does depends on what you feed it.]\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(studyhours.1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Sum Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Mean Sq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2\",\"2\":\"198.96\",\"3\":\"99.48\",\"4\":\"8.373737\",\"5\":\"0.0005374694\",\"_rn_\":\"major\"},{\"1\":\"72\",\"2\":\"855.36\",\"3\":\"11.88\",\"4\":\"NA\",\"5\":\"NA\",\"_rn_\":\"Residuals\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n        \n\nTwo degrees of freedom for `major`, so we can do 2\ncontrasts. (The example in class had four models of chainsaw, so 3 df\nfor model, so 3 contrasts possible.) What if we don't use all those\ncontrasts up? Try it and see:\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c.math.others)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     c.math.others\n[1,]          -0.5\n[2,]           1.0\n[3,]          -0.5\n```\n:::\n\n```{.r .cell-code}\ncontrasts(studyhours$major) <- m\nstudyhours.2 <- lm(hours ~ major, data = studyhours)\nsummary(studyhours.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = hours ~ major, data = studyhours)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6.44  -2.48  -0.48   2.52  10.56 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          7.3200     0.3980  18.392  < 2e-16 ***\nmajorc.math.others   2.1200     0.5628   3.767 0.000335 ***\nmajor               -1.1031     0.6893  -1.600 0.113936    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.447 on 72 degrees of freedom\nMultiple R-squared:  0.1887,\tAdjusted R-squared:  0.1662 \nF-statistic: 8.374 on 2 and 72 DF,  p-value: 0.0005375\n```\n:::\n:::\n\n\n\nThe two P-values are identical, but the second one is not now\nidentified with any contrast (so we just ignore it). If we were only\ninterested in how math students compared with the rest, we could test\nit this way.\n\nOr, we could relabel the students as \"math\" and \"other\" and just\ndo a two-sample $t$-test. To do this, we need to delve into\n`forcats` (which is a part of the `tidyverse`). It deals\nwith categorical variables which are genuine factors, which we haven't\nhad much cause to do so far. But now we do. What we want to do is to\n*recode* the levels of `major`, which is done by\n`fct_recode`:\n\n::: {.cell}\n\n```{.r .cell-code}\nstudyhoursx <- studyhours %>%\n  mutate(mathrest = fct_recode(major,\n    \"rest\" = \"english\",\n    \"rest\" = \"socsci\"\n  ))\nstudyhoursx %>% count(mathrest)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mathrest\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"rest\",\"2\":\"50\"},{\"1\":\"math\",\"2\":\"25\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nThe way `fct_recode` works is that you first give a factor,\nhere `major`, then you define a list of new levels in terms of\nthe old ones. We want a student whose major is either English or\nSocial Science to end up in the new not-math group that we'll call\n`rest`, so we need two lines inside `fct_recode`, one\nthat says that the new `rest` group includes the old\n`english` majors, and another that says that `rest` also\nincludes the old `socsci` majors. Any levels not mentioned\n(here `math`) are left unchanged.\n\nI did this wrong the first time: I got the things before and after the\n`=` in `fct_recode` the wrong way around.\n\nThe last line is to check that the result makes sense. I previously\nhad 25 students in each major. Now I have 25 students for whom\n`mathrest` is `math` (the math majors) and $50=25+25$\nstudents for whom `mathrest` is `rest` (everyone else). \n\nNow, the $t$-test.\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(hours ~ mathrest, data = studyhoursx, var.equal = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  hours by mathrest\nt = -3.7269, df = 73, p-value = 0.0003796\nalternative hypothesis: true difference in means between group rest and group math is not equal to 0\n95 percent confidence interval:\n -4.880528 -1.479472\nsample estimates:\nmean in group rest mean in group math \n              6.26               9.44 \n```\n:::\n:::\n\n \n\nThis is very close to, but not the same as, the test with the contrasts,\nbecause we are not quite testing the same thing. Here, we are\ncomparing the mean of the math students to the mean of everyone else,\nthrown together into one big bag, but with the contrasts, we are\ncomparing the mean of the math students with the *average of the\nmeans* of the other two groups, treating them as different. (Not\nclear? Well, it's not that clear to me either.)\n\nThat business with the `var.equal=T`? This is doing a pooled\n$t$-test. I did that here because the ANOVA is assuming equal spreads\nwithin the groups (which is what a pooled $t$-test does) and I thought\nI should do my best to be consistent. A pooled $t$-test is really a\ntwo-group one-way ANOVA, or at least it is if it is done two-sided.\n\n$\\blacksquare$\n \n\n\n\n##  Mental context\n\n\n It is believed that being in the same mental context for\nlearning and for testing leads to better test scores. An experiment\nwas carried out to test this. During the learning phase, subjects\nlearned a list of 80 words in a room painted orange and decorated with\nposters, paintings and other paraphernalia.^[This is a fancy  word for *stuff*.] A memory test was given to all subjects\nimmediately after they had learned the words, to give the impression\nthat the experiment was over. (The results of this test were\ndiscarded.) One day later, subjects were unexpectedly re-tested under\ndifferent experimental conditions and asked to write down all the\nwords of the original list that they could remember. The re-test took\nplace in five different conditions, which subjects were randomly\nallocated to one of:\n\n\n\n* Same context: in the original orange-painted room.\n\n* Different context: in a very different room, painted grey and\nlocated in a different part of campus.\n\n* Imaginary context: in the grey room, but subjects are asked to\nremember the orange room in which they took the original test. To\nhelp them with this, the experimenter begins by asking them several\nquestions about the orange room and the objects in it.\n\n* Photographed context: in the grey room, but subjects are shown\nphotographs of the orange room.\n\n* Placebo context: in the grey room, with subjects first being\nasked to recall their living room.\n\n\nIn each case, the response variable was the number of words on the\noriginal list successfully recalled by each subject.\n\n50 subjects in total completed the experiment, 10 under each of the 5\nconditions. \n\nThe researchers had four research hypotheses to test with the data:\n\n\n\n* Groups where the context matches (is the same, or is simulated\nby imagining or photograph) will perform better than groups with\ndifferent or placebo contexts.\n\n* The group with the same context will differ from the group with\nimaginary or photographed contexts.\n\n\n* The imaginary-context group will differ from the\nphotographed-context group.\n\n* The different-context group will differ from the placebo-context group.\n\n\nThe research hypotheses are (as is usual) written as\n*alternative* hypotheses. We can rewrite them as null\nhypotheses, with some extra wording to facilitate converting them\ninto contrasts, like this:\n\n\n* The mean of the `same`, `imaginary` and\n`photograph` groups (group means) is equal to the mean of the\n`different` and `placebo` groups (group means).\n\n* The mean of the `imaginary` and `photograph`\ngroups is equal to the (mean of the) `same` group.\n\n* The `imaginary` and the `photograph` groups will\nhave the same mean.\n\n* The `different` and the `placebo` groups will\nhave the same mean.\n\nThe data are in\n[link](http://ritsokiguess.site/datafiles/smith.txt) (the\noriginal researcher's name was Smith). \n\n\n(a) Read in the data and verify that you have a column called\n`context` that is text and a column called\n`words` that is a (whole) number.\n\n\nSolution\n\n\nThe usual thing --- read in the data appropriately and look at the\ndata frame you got:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/smith.txt\"\nsmith <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 50 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (1): context\ndbl (2): id, words\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nsmith\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"context\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"words\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"same\",\"3\":\"25\"},{\"1\":\"2\",\"2\":\"same\",\"3\":\"26\"},{\"1\":\"3\",\"2\":\"same\",\"3\":\"17\"},{\"1\":\"4\",\"2\":\"same\",\"3\":\"15\"},{\"1\":\"5\",\"2\":\"same\",\"3\":\"14\"},{\"1\":\"6\",\"2\":\"same\",\"3\":\"17\"},{\"1\":\"7\",\"2\":\"same\",\"3\":\"14\"},{\"1\":\"8\",\"2\":\"same\",\"3\":\"20\"},{\"1\":\"9\",\"2\":\"same\",\"3\":\"11\"},{\"1\":\"10\",\"2\":\"same\",\"3\":\"21\"},{\"1\":\"11\",\"2\":\"different\",\"3\":\"11\"},{\"1\":\"12\",\"2\":\"different\",\"3\":\"21\"},{\"1\":\"13\",\"2\":\"different\",\"3\":\"9\"},{\"1\":\"14\",\"2\":\"different\",\"3\":\"6\"},{\"1\":\"15\",\"2\":\"different\",\"3\":\"7\"},{\"1\":\"16\",\"2\":\"different\",\"3\":\"14\"},{\"1\":\"17\",\"2\":\"different\",\"3\":\"12\"},{\"1\":\"18\",\"2\":\"different\",\"3\":\"4\"},{\"1\":\"19\",\"2\":\"different\",\"3\":\"7\"},{\"1\":\"20\",\"2\":\"different\",\"3\":\"19\"},{\"1\":\"21\",\"2\":\"imaginary\",\"3\":\"14\"},{\"1\":\"22\",\"2\":\"imaginary\",\"3\":\"15\"},{\"1\":\"23\",\"2\":\"imaginary\",\"3\":\"29\"},{\"1\":\"24\",\"2\":\"imaginary\",\"3\":\"10\"},{\"1\":\"25\",\"2\":\"imaginary\",\"3\":\"12\"},{\"1\":\"26\",\"2\":\"imaginary\",\"3\":\"22\"},{\"1\":\"27\",\"2\":\"imaginary\",\"3\":\"14\"},{\"1\":\"28\",\"2\":\"imaginary\",\"3\":\"24\"},{\"1\":\"29\",\"2\":\"imaginary\",\"3\":\"22\"},{\"1\":\"30\",\"2\":\"imaginary\",\"3\":\"12\"},{\"1\":\"31\",\"2\":\"photograph\",\"3\":\"11\"},{\"1\":\"32\",\"2\":\"photograph\",\"3\":\"15\"},{\"1\":\"33\",\"2\":\"photograph\",\"3\":\"23\"},{\"1\":\"34\",\"2\":\"photograph\",\"3\":\"21\"},{\"1\":\"35\",\"2\":\"photograph\",\"3\":\"18\"},{\"1\":\"36\",\"2\":\"photograph\",\"3\":\"24\"},{\"1\":\"37\",\"2\":\"photograph\",\"3\":\"14\"},{\"1\":\"38\",\"2\":\"photograph\",\"3\":\"27\"},{\"1\":\"39\",\"2\":\"photograph\",\"3\":\"12\"},{\"1\":\"40\",\"2\":\"photograph\",\"3\":\"11\"},{\"1\":\"41\",\"2\":\"placebo\",\"3\":\"8\"},{\"1\":\"42\",\"2\":\"placebo\",\"3\":\"20\"},{\"1\":\"43\",\"2\":\"placebo\",\"3\":\"10\"},{\"1\":\"44\",\"2\":\"placebo\",\"3\":\"7\"},{\"1\":\"45\",\"2\":\"placebo\",\"3\":\"15\"},{\"1\":\"46\",\"2\":\"placebo\",\"3\":\"7\"},{\"1\":\"47\",\"2\":\"placebo\",\"3\":\"1\"},{\"1\":\"48\",\"2\":\"placebo\",\"3\":\"17\"},{\"1\":\"49\",\"2\":\"placebo\",\"3\":\"11\"},{\"1\":\"50\",\"2\":\"placebo\",\"3\":\"4\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n       \n\n`dbl` actually means \"decimal number\", but these look like whole numbers, so I think we are good.\n      \n$\\blacksquare$\n\n(b) Turn `context` into a `factor`, within the\ndata frame. (We are going to be doing contrasts). Display how the\ndata frame now looks.\n\n\nSolution\n\n\nUse `mutate` and assign everything back to what it was\nbefore:\n\n::: {.cell}\n\n```{.r .cell-code}\nsmith <- smith %>% mutate(context = factor(context))\nsmith\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"context\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"words\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"same\",\"3\":\"25\"},{\"1\":\"2\",\"2\":\"same\",\"3\":\"26\"},{\"1\":\"3\",\"2\":\"same\",\"3\":\"17\"},{\"1\":\"4\",\"2\":\"same\",\"3\":\"15\"},{\"1\":\"5\",\"2\":\"same\",\"3\":\"14\"},{\"1\":\"6\",\"2\":\"same\",\"3\":\"17\"},{\"1\":\"7\",\"2\":\"same\",\"3\":\"14\"},{\"1\":\"8\",\"2\":\"same\",\"3\":\"20\"},{\"1\":\"9\",\"2\":\"same\",\"3\":\"11\"},{\"1\":\"10\",\"2\":\"same\",\"3\":\"21\"},{\"1\":\"11\",\"2\":\"different\",\"3\":\"11\"},{\"1\":\"12\",\"2\":\"different\",\"3\":\"21\"},{\"1\":\"13\",\"2\":\"different\",\"3\":\"9\"},{\"1\":\"14\",\"2\":\"different\",\"3\":\"6\"},{\"1\":\"15\",\"2\":\"different\",\"3\":\"7\"},{\"1\":\"16\",\"2\":\"different\",\"3\":\"14\"},{\"1\":\"17\",\"2\":\"different\",\"3\":\"12\"},{\"1\":\"18\",\"2\":\"different\",\"3\":\"4\"},{\"1\":\"19\",\"2\":\"different\",\"3\":\"7\"},{\"1\":\"20\",\"2\":\"different\",\"3\":\"19\"},{\"1\":\"21\",\"2\":\"imaginary\",\"3\":\"14\"},{\"1\":\"22\",\"2\":\"imaginary\",\"3\":\"15\"},{\"1\":\"23\",\"2\":\"imaginary\",\"3\":\"29\"},{\"1\":\"24\",\"2\":\"imaginary\",\"3\":\"10\"},{\"1\":\"25\",\"2\":\"imaginary\",\"3\":\"12\"},{\"1\":\"26\",\"2\":\"imaginary\",\"3\":\"22\"},{\"1\":\"27\",\"2\":\"imaginary\",\"3\":\"14\"},{\"1\":\"28\",\"2\":\"imaginary\",\"3\":\"24\"},{\"1\":\"29\",\"2\":\"imaginary\",\"3\":\"22\"},{\"1\":\"30\",\"2\":\"imaginary\",\"3\":\"12\"},{\"1\":\"31\",\"2\":\"photograph\",\"3\":\"11\"},{\"1\":\"32\",\"2\":\"photograph\",\"3\":\"15\"},{\"1\":\"33\",\"2\":\"photograph\",\"3\":\"23\"},{\"1\":\"34\",\"2\":\"photograph\",\"3\":\"21\"},{\"1\":\"35\",\"2\":\"photograph\",\"3\":\"18\"},{\"1\":\"36\",\"2\":\"photograph\",\"3\":\"24\"},{\"1\":\"37\",\"2\":\"photograph\",\"3\":\"14\"},{\"1\":\"38\",\"2\":\"photograph\",\"3\":\"27\"},{\"1\":\"39\",\"2\":\"photograph\",\"3\":\"12\"},{\"1\":\"40\",\"2\":\"photograph\",\"3\":\"11\"},{\"1\":\"41\",\"2\":\"placebo\",\"3\":\"8\"},{\"1\":\"42\",\"2\":\"placebo\",\"3\":\"20\"},{\"1\":\"43\",\"2\":\"placebo\",\"3\":\"10\"},{\"1\":\"44\",\"2\":\"placebo\",\"3\":\"7\"},{\"1\":\"45\",\"2\":\"placebo\",\"3\":\"15\"},{\"1\":\"46\",\"2\":\"placebo\",\"3\":\"7\"},{\"1\":\"47\",\"2\":\"placebo\",\"3\":\"1\"},{\"1\":\"48\",\"2\":\"placebo\",\"3\":\"17\"},{\"1\":\"49\",\"2\":\"placebo\",\"3\":\"11\"},{\"1\":\"50\",\"2\":\"placebo\",\"3\":\"4\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n    \n\nNote that `context` is now labelled as the factor that we made.\n\n$\\blacksquare$\n\n(c) What are the names of the five contexts in the data set\n(just display them),\nand what order are they in?\n\n\nSolution\n\n\nYou have lots of choices now, since `context` is a factor\n(and can also be treated as text). \nThe most obvious factor-based way is this:\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(smith$context)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"different\"  \"imaginary\"  \"photograph\" \"placebo\"    \"same\"      \n```\n:::\n:::\n\n       \n\nor use `summary`:\n\n::: {.cell}\n\n```{.r .cell-code}\nsmith %>% select(context) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       context  \n different :10  \n imaginary :10  \n photograph:10  \n placebo   :10  \n same      :10  \n```\n:::\n:::\n\n \n\nOr treat `context` as text, such as this way:\n\n::: {.cell}\n\n```{.r .cell-code}\nsmith %>% count(context)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"context\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"different\",\"2\":\"10\"},{\"1\":\"imaginary\",\"2\":\"10\"},{\"1\":\"photograph\",\"2\":\"10\"},{\"1\":\"placebo\",\"2\":\"10\"},{\"1\":\"same\",\"2\":\"10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n       \n\nThese all display the contexts in alphabetical order.\n\nOr display the distinct values:\n\n::: {.cell}\n\n```{.r .cell-code}\nsmith %>% distinct(context)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"context\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"same\"},{\"1\":\"different\"},{\"1\":\"imaginary\"},{\"1\":\"photograph\"},{\"1\":\"placebo\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nor, without using the `tidyverse`,\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(smith$context)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] same       different  imaginary  photograph placebo   \nLevels: different imaginary photograph placebo same\n```\n:::\n:::\n\n \nThese two *don't* display things in alphabetical order, because\nthey display things as they appear in the file. This is not the order\nwe want, though the second way *does* display the `Levels`\nin the right order.\n      \n\n$\\blacksquare$\n\n(d) Write each of the four research hypotheses (in the\nnull-hypothesis versions) as R vectors that can be used to make\ncontrasts. (This will mean getting the contexts in the right\norder. If you get stuck, do the last two first, since they're\neasiest. The first one is actually the hardest.)\n\n\nSolution\n\n\nAll right, let's go from the bottom:\n\n\n* Different and placebo have same means. These are 1st and 4th.\n\n::: {.cell}\n\n```{.r .cell-code}\nc4 <- c(1, 0, 0, -1, 0)\n```\n:::\n\n         \n\n* Imaginary and photograph have same means. 2nd and 3rd:\n\n::: {.cell}\n\n```{.r .cell-code}\nc3 <- c(0, 1, -1, 0, 0)\n```\n:::\n\n   \n\n\n* Imaginary and photograph together same as `same`. This\ntime we have two means being compared with one, so we need to give\nthe two means half weight. 2nd and 3rd against 5th:\n\n::: {.cell}\n\n```{.r .cell-code}\nc2 <- c(0, 1 / 2, 1 / 2, 0, -1)\n```\n:::\n\n   \n\n\n* (Same and imaginary and photograph) vs.\\ (different or placebo):\n2nd, 3rd and 5th with weight $1/3$ (three of them) against 1st and\n4th with weight $1/2$ (2 of them):\n\n::: {.cell}\n\n```{.r .cell-code}\nc1 <- c(-1 / 2, 1 / 3, 1 / 3, -1 / 2, 1 / 3)\n```\n:::\n\n   \n\nVariations: you can switch the sign on everything within a\ncontrast (since it doesn't matter which is plus and which is\nminus). You can also multiply through by anything to get rid of\nthe fractions, for example these:\n\n::: {.cell}\n\n```{.r .cell-code}\nc2 <- c(0, 1, 1, 0, -2)\nc1 <- c(-3, 2, 2, -3, 2)\n```\n:::\n\n       \n\nAll that matters is that the coefficients add up to zero, and that they are the right size and sign relative to each other.\n      \n\n$\\blacksquare$\n\n(e) Pick two of your contrasts (doesn't matter which two) and\ndemonstrate that they are orthogonal.\n\n\nSolution\n\n\nMultiply your chosen contrasts together elementwise, and show\nthat the results add to zero, eg. by showing the whole thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nc1 * c2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  0.0000000  0.1666667  0.1666667  0.0000000 -0.3333333\n```\n:::\n:::\n\n    \nwhich adds to zero because it is $2/6$ minus $1/3$,\nor by explicitly summing the elementwise product:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c1 * c3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n \n\nAny pair is good.\n      \n\n$\\blacksquare$\n\n(f) Collect your contrasts together into a matrix, and\ntell `lm` that these are the contrasts for `context`.\n\n\nSolution\n\n\nThis:\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c1, c2, c3, c4)\ncontrasts(smith$context) <- m\n```\n:::\n\n       \n\nSlipping off into another aside, you might have been wondering whether\nthere was a way to test \n*all* the contrasts for orthogonality at once. There is, and it\ndepends on the rules for matrix multiplication. We want to test all\nthe *columns* of `m` for orthogonality, but matrix\nmultiplication works by combining a *row* with a column. No\nmatter, *transposing* a matrix interchanges rows and columns, so\nthat in math, we want to look at the matrix $M^T M$. In R,\n`%*%` means \"matrix multiply\".^[In R, percents around something mean that it is a special version of that something. Hence the notation for matrix-multiply and the pipe symbol. A regular * when used for multiplying matrices in R will multiply them element by element.] Thus,\n\n::: {.cell}\n\n```{.r .cell-code}\nt(m) %*% m\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          c1  c2 c3 c4\nc1 0.8333333 0.0  0  0\nc2 0.0000000 1.5  0  0\nc3 0.0000000 0.0  2  0\nc4 0.0000000 0.0  0  2\n```\n:::\n:::\n\n \nThis matrix-multiplies the transpose of `m` by `m`\nitself. There are numbers down the top-left to bottom-right diagonal,\nbut don't worry about these, since a contrast doesn't have to be\northogonal with itself. The thing to note is that \n*all the other  elements* of this matrix are \n*zero*: that means that each of\nthe four contrasts is orthogonal to each of the other three.\n      \n\n$\\blacksquare$\n\n(g) Fit a model with `lm`, and display the results.\n\n\nSolution\n\n\nWe're past the hard part:\n\n::: {.cell}\n\n```{.r .cell-code}\nsmith.1 <- lm(words ~ context, data = smith)\nsummary(smith.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = words ~ context, data = smith)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n  -9.0   -4.0   -1.5    4.6   11.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  14.8000     0.8129  18.207  < 2e-16 ***\ncontextc1     8.6000     1.9912   4.319 8.52e-05 ***\ncontextc2    -0.3333     1.4841  -0.225    0.823    \ncontextc3    -0.1000     1.2853  -0.078    0.938    \ncontextc4     0.5000     1.2853   0.389    0.699    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.748 on 45 degrees of freedom\nMultiple R-squared:  0.2954,\tAdjusted R-squared:  0.2327 \nF-statistic: 4.715 on 4 and 45 DF,  p-value: 0.002902\n```\n:::\n:::\n\n       \n      \n\n$\\blacksquare$\n\n(h) For each of the original research hypotheses, what do you\ninfer about them?\n\n\nSolution\n\n\nEven though I generated the contrasts backwards, I maintained\nthe numbering so that they refer to the original numbered\nhypotheses. You might have named them something more mnemonic;\nthat works too, and is quite possibly better.\nAnyway:\n\n\n* Matching context better than non-matching context:\nstrongly significant (P-value 0.000085). (Strictly, this is a\ntwo-sided test, but the way I constructed the contrast, this\nshould be significantly *positive* if the research\nhypothesis is true, and it is.)\n\n* Same context *not* different from\nimaginary/photographed context (P-value 0.823)\n\n* Imaginary context *not* different from photographed context (P-value 0.938).\n\n* Different context *not* different from placebo\ncontext (P-value 0.699). \n\n\nI wanted you to match up the research hypotheses with the\nP-values, as above, and state a conclusion about each one. If\nyou do that, I am happy.\n\nTaking this back to the original research, I think the\nfirst hypothesis was the most immediately important of the four:\nwe were able to show that having (or faking up) the original\nroom helped with recall. After that, it didn't matter how it was\ndone: being in the original room was not different from\nimagining the original room (by thinking about it or seeing a\nphoto of it). Failing to recall the original room was equally\nbad, whether the subjects were in a different room and not asked\nto think about the original orange room, or whether they were\nliterally asked to think about another room entirely.\n\nContrasts enabled us to tackle this problem and gain a very clear\nconclusion: recalling the original orange room is helpful, but\nit doesn't matter how you do it.\n\nHow big of a difference does thinking about the orange room\nmake? You can use the 2 SE thing to get a 95\\% confidence interval:\nthe difference in the (mean of the) recall-orange-room means and\nthe (mean of the) don't-recall means is between about 4.6 and\n12.6 words (out of 80). I leave it for you to decide whether\nthat is practically important as well as being statistically significant.\n\n$\\blacksquare$\n\n\n\n\n\n\n\n##  Trying on shirts\n\n\n Does it make a difference if you see somebody else trying on\na shirt before you do, and if so, does it matter what kind of person\nit is? \n\nAn experiment was carried out in a university bookstore, with\nstudents who wanted to try on a shirt serving as (unsuspecting)\nexperimental subjects. When a student wanted to try on a shirt, the\nsales associate told them that there was only one shirt left, and it\nwas being tried on by an \"other customer\". This \"other customer\"\nwas actually a \"confederate\" of the experimenter (that means, they\nwere pretending to be a real customer but were actually part of the\nexperiment). The \"other customer\" was always female: either an\nattractive well-dressed model, or an average-looking student wearing\njeans. The \"other customer\" would come out of the\ndressing room and hand the shirt to the sales associate, who would\ngive it to the student who wanted to try it on. When the student had\ntried on the shirt, they were asked to rate it on a 7-point scale (on\nfive different dimensions, and those five scores were then\naveraged). Does a student's evaluation depend on whether the student\nwas male or female, and whether the \"other customer\" was a model or\na student? There was also a control group, where the student was\nhanded the shirt directly  by the sales associate, without the \n\"other customer\" being involved at all. \n\nThere were thus five treatments:\nmale students who saw a model, male students who saw a student, female\nstudents who saw a model, female students who saw a student, and the\ncontrol group. There were 25 students in each treatment group.\n\nThe data from this experiment can be found at\n[link](http://ritsokiguess.site/datafiles/shirts.csv).\n\n\n\n(a) Read in and display the data. How many observations do you\nhave, and is that what you should have?\n\nSolution\n\n\n`read_csv`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/shirts.csv\"\nshirts <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 125 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): treatment\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nshirts\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"treatment\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"score\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"male_seeing_model\",\"2\":\"6.8\"},{\"1\":\"male_seeing_model\",\"2\":\"4.7\"},{\"1\":\"male_seeing_model\",\"2\":\"5.1\"},{\"1\":\"male_seeing_model\",\"2\":\"4.7\"},{\"1\":\"male_seeing_model\",\"2\":\"5.5\"},{\"1\":\"male_seeing_model\",\"2\":\"6.0\"},{\"1\":\"male_seeing_model\",\"2\":\"4.4\"},{\"1\":\"male_seeing_model\",\"2\":\"6.0\"},{\"1\":\"male_seeing_model\",\"2\":\"5.3\"},{\"1\":\"male_seeing_model\",\"2\":\"6.3\"},{\"1\":\"male_seeing_model\",\"2\":\"3.9\"},{\"1\":\"male_seeing_model\",\"2\":\"4.3\"},{\"1\":\"male_seeing_model\",\"2\":\"6.4\"},{\"1\":\"male_seeing_model\",\"2\":\"6.1\"},{\"1\":\"male_seeing_model\",\"2\":\"4.7\"},{\"1\":\"male_seeing_model\",\"2\":\"5.4\"},{\"1\":\"male_seeing_model\",\"2\":\"6.7\"},{\"1\":\"male_seeing_model\",\"2\":\"5.2\"},{\"1\":\"male_seeing_model\",\"2\":\"5.6\"},{\"1\":\"male_seeing_model\",\"2\":\"3.8\"},{\"1\":\"male_seeing_model\",\"2\":\"6.3\"},{\"1\":\"male_seeing_model\",\"2\":\"5.8\"},{\"1\":\"male_seeing_model\",\"2\":\"6.2\"},{\"1\":\"male_seeing_model\",\"2\":\"4.6\"},{\"1\":\"male_seeing_model\",\"2\":\"5.6\"},{\"1\":\"male_seeing_student\",\"2\":\"4.2\"},{\"1\":\"male_seeing_student\",\"2\":\"4.1\"},{\"1\":\"male_seeing_student\",\"2\":\"3.4\"},{\"1\":\"male_seeing_student\",\"2\":\"3.1\"},{\"1\":\"male_seeing_student\",\"2\":\"1.9\"},{\"1\":\"male_seeing_student\",\"2\":\"3.3\"},{\"1\":\"male_seeing_student\",\"2\":\"2.5\"},{\"1\":\"male_seeing_student\",\"2\":\"5.0\"},{\"1\":\"male_seeing_student\",\"2\":\"2.3\"},{\"1\":\"male_seeing_student\",\"2\":\"4.9\"},{\"1\":\"male_seeing_student\",\"2\":\"5.1\"},{\"1\":\"male_seeing_student\",\"2\":\"4.8\"},{\"1\":\"male_seeing_student\",\"2\":\"5.1\"},{\"1\":\"male_seeing_student\",\"2\":\"2.6\"},{\"1\":\"male_seeing_student\",\"2\":\"3.8\"},{\"1\":\"male_seeing_student\",\"2\":\"3.1\"},{\"1\":\"male_seeing_student\",\"2\":\"2.5\"},{\"1\":\"male_seeing_student\",\"2\":\"0.7\"},{\"1\":\"male_seeing_student\",\"2\":\"1.9\"},{\"1\":\"male_seeing_student\",\"2\":\"3.9\"},{\"1\":\"male_seeing_student\",\"2\":\"2.1\"},{\"1\":\"male_seeing_student\",\"2\":\"3.2\"},{\"1\":\"male_seeing_student\",\"2\":\"3.6\"},{\"1\":\"male_seeing_student\",\"2\":\"0.8\"},{\"1\":\"male_seeing_student\",\"2\":\"3.4\"},{\"1\":\"female_seeing_model\",\"2\":\"4.9\"},{\"1\":\"female_seeing_model\",\"2\":\"3.0\"},{\"1\":\"female_seeing_model\",\"2\":\"3.7\"},{\"1\":\"female_seeing_model\",\"2\":\"3.7\"},{\"1\":\"female_seeing_model\",\"2\":\"4.1\"},{\"1\":\"female_seeing_model\",\"2\":\"3.3\"},{\"1\":\"female_seeing_model\",\"2\":\"4.0\"},{\"1\":\"female_seeing_model\",\"2\":\"4.4\"},{\"1\":\"female_seeing_model\",\"2\":\"4.2\"},{\"1\":\"female_seeing_model\",\"2\":\"0.9\"},{\"1\":\"female_seeing_model\",\"2\":\"3.7\"},{\"1\":\"female_seeing_model\",\"2\":\"4.2\"},{\"1\":\"female_seeing_model\",\"2\":\"5.1\"},{\"1\":\"female_seeing_model\",\"2\":\"4.1\"},{\"1\":\"female_seeing_model\",\"2\":\"3.8\"},{\"1\":\"female_seeing_model\",\"2\":\"1.9\"},{\"1\":\"female_seeing_model\",\"2\":\"7.6\"},{\"1\":\"female_seeing_model\",\"2\":\"4.8\"},{\"1\":\"female_seeing_model\",\"2\":\"3.3\"},{\"1\":\"female_seeing_model\",\"2\":\"5.7\"},{\"1\":\"female_seeing_model\",\"2\":\"3.5\"},{\"1\":\"female_seeing_model\",\"2\":\"4.6\"},{\"1\":\"female_seeing_model\",\"2\":\"4.6\"},{\"1\":\"female_seeing_model\",\"2\":\"4.9\"},{\"1\":\"female_seeing_model\",\"2\":\"3.7\"},{\"1\":\"female_seeing_student\",\"2\":\"5.7\"},{\"1\":\"female_seeing_student\",\"2\":\"1.4\"},{\"1\":\"female_seeing_student\",\"2\":\"3.2\"},{\"1\":\"female_seeing_student\",\"2\":\"3.3\"},{\"1\":\"female_seeing_student\",\"2\":\"4.2\"},{\"1\":\"female_seeing_student\",\"2\":\"6.5\"},{\"1\":\"female_seeing_student\",\"2\":\"2.3\"},{\"1\":\"female_seeing_student\",\"2\":\"6.6\"},{\"1\":\"female_seeing_student\",\"2\":\"4.2\"},{\"1\":\"female_seeing_student\",\"2\":\"2.6\"},{\"1\":\"female_seeing_student\",\"2\":\"4.7\"},{\"1\":\"female_seeing_student\",\"2\":\"2.6\"},{\"1\":\"female_seeing_student\",\"2\":\"1.8\"},{\"1\":\"female_seeing_student\",\"2\":\"2.6\"},{\"1\":\"female_seeing_student\",\"2\":\"4.4\"},{\"1\":\"female_seeing_student\",\"2\":\"0.9\"},{\"1\":\"female_seeing_student\",\"2\":\"-0.5\"},{\"1\":\"female_seeing_student\",\"2\":\"2.4\"},{\"1\":\"female_seeing_student\",\"2\":\"4.3\"},{\"1\":\"female_seeing_student\",\"2\":\"7.0\"},{\"1\":\"female_seeing_student\",\"2\":\"4.2\"},{\"1\":\"female_seeing_student\",\"2\":\"1.1\"},{\"1\":\"female_seeing_student\",\"2\":\"2.9\"},{\"1\":\"female_seeing_student\",\"2\":\"3.9\"},{\"1\":\"female_seeing_student\",\"2\":\"1.7\"},{\"1\":\"control\",\"2\":\"1.1\"},{\"1\":\"control\",\"2\":\"3.3\"},{\"1\":\"control\",\"2\":\"5.1\"},{\"1\":\"control\",\"2\":\"4.3\"},{\"1\":\"control\",\"2\":\"4.3\"},{\"1\":\"control\",\"2\":\"5.7\"},{\"1\":\"control\",\"2\":\"4.9\"},{\"1\":\"control\",\"2\":\"5.0\"},{\"1\":\"control\",\"2\":\"3.8\"},{\"1\":\"control\",\"2\":\"5.9\"},{\"1\":\"control\",\"2\":\"3.5\"},{\"1\":\"control\",\"2\":\"6.5\"},{\"1\":\"control\",\"2\":\"3.6\"},{\"1\":\"control\",\"2\":\"3.6\"},{\"1\":\"control\",\"2\":\"1.0\"},{\"1\":\"control\",\"2\":\"5.1\"},{\"1\":\"control\",\"2\":\"3.7\"},{\"1\":\"control\",\"2\":\"4.6\"},{\"1\":\"control\",\"2\":\"5.1\"},{\"1\":\"control\",\"2\":\"4.3\"},{\"1\":\"control\",\"2\":\"3.0\"},{\"1\":\"control\",\"2\":\"3.1\"},{\"1\":\"control\",\"2\":\"2.3\"},{\"1\":\"control\",\"2\":\"1.9\"},{\"1\":\"control\",\"2\":\"6.1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n     \n\nThere were 5 treatment groups with 25 students in each, so there\nshould be, and are, $5 \\times 25=125$ observations.\n\n$\\blacksquare$\n\n(b) Turn `treatment` into a `factor` in your data\nframe. (You can use the same name as the text `treatment`\nthat you read in from the file.)\n\nSolution\n\n\nThus:\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts <- shirts %>% mutate(treatment = factor(treatment))\n```\n:::\n\n     \n\nand for checking:\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"treatment\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"score\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"male_seeing_model\",\"2\":\"6.8\"},{\"1\":\"male_seeing_model\",\"2\":\"4.7\"},{\"1\":\"male_seeing_model\",\"2\":\"5.1\"},{\"1\":\"male_seeing_model\",\"2\":\"4.7\"},{\"1\":\"male_seeing_model\",\"2\":\"5.5\"},{\"1\":\"male_seeing_model\",\"2\":\"6.0\"},{\"1\":\"male_seeing_model\",\"2\":\"4.4\"},{\"1\":\"male_seeing_model\",\"2\":\"6.0\"},{\"1\":\"male_seeing_model\",\"2\":\"5.3\"},{\"1\":\"male_seeing_model\",\"2\":\"6.3\"},{\"1\":\"male_seeing_model\",\"2\":\"3.9\"},{\"1\":\"male_seeing_model\",\"2\":\"4.3\"},{\"1\":\"male_seeing_model\",\"2\":\"6.4\"},{\"1\":\"male_seeing_model\",\"2\":\"6.1\"},{\"1\":\"male_seeing_model\",\"2\":\"4.7\"},{\"1\":\"male_seeing_model\",\"2\":\"5.4\"},{\"1\":\"male_seeing_model\",\"2\":\"6.7\"},{\"1\":\"male_seeing_model\",\"2\":\"5.2\"},{\"1\":\"male_seeing_model\",\"2\":\"5.6\"},{\"1\":\"male_seeing_model\",\"2\":\"3.8\"},{\"1\":\"male_seeing_model\",\"2\":\"6.3\"},{\"1\":\"male_seeing_model\",\"2\":\"5.8\"},{\"1\":\"male_seeing_model\",\"2\":\"6.2\"},{\"1\":\"male_seeing_model\",\"2\":\"4.6\"},{\"1\":\"male_seeing_model\",\"2\":\"5.6\"},{\"1\":\"male_seeing_student\",\"2\":\"4.2\"},{\"1\":\"male_seeing_student\",\"2\":\"4.1\"},{\"1\":\"male_seeing_student\",\"2\":\"3.4\"},{\"1\":\"male_seeing_student\",\"2\":\"3.1\"},{\"1\":\"male_seeing_student\",\"2\":\"1.9\"},{\"1\":\"male_seeing_student\",\"2\":\"3.3\"},{\"1\":\"male_seeing_student\",\"2\":\"2.5\"},{\"1\":\"male_seeing_student\",\"2\":\"5.0\"},{\"1\":\"male_seeing_student\",\"2\":\"2.3\"},{\"1\":\"male_seeing_student\",\"2\":\"4.9\"},{\"1\":\"male_seeing_student\",\"2\":\"5.1\"},{\"1\":\"male_seeing_student\",\"2\":\"4.8\"},{\"1\":\"male_seeing_student\",\"2\":\"5.1\"},{\"1\":\"male_seeing_student\",\"2\":\"2.6\"},{\"1\":\"male_seeing_student\",\"2\":\"3.8\"},{\"1\":\"male_seeing_student\",\"2\":\"3.1\"},{\"1\":\"male_seeing_student\",\"2\":\"2.5\"},{\"1\":\"male_seeing_student\",\"2\":\"0.7\"},{\"1\":\"male_seeing_student\",\"2\":\"1.9\"},{\"1\":\"male_seeing_student\",\"2\":\"3.9\"},{\"1\":\"male_seeing_student\",\"2\":\"2.1\"},{\"1\":\"male_seeing_student\",\"2\":\"3.2\"},{\"1\":\"male_seeing_student\",\"2\":\"3.6\"},{\"1\":\"male_seeing_student\",\"2\":\"0.8\"},{\"1\":\"male_seeing_student\",\"2\":\"3.4\"},{\"1\":\"female_seeing_model\",\"2\":\"4.9\"},{\"1\":\"female_seeing_model\",\"2\":\"3.0\"},{\"1\":\"female_seeing_model\",\"2\":\"3.7\"},{\"1\":\"female_seeing_model\",\"2\":\"3.7\"},{\"1\":\"female_seeing_model\",\"2\":\"4.1\"},{\"1\":\"female_seeing_model\",\"2\":\"3.3\"},{\"1\":\"female_seeing_model\",\"2\":\"4.0\"},{\"1\":\"female_seeing_model\",\"2\":\"4.4\"},{\"1\":\"female_seeing_model\",\"2\":\"4.2\"},{\"1\":\"female_seeing_model\",\"2\":\"0.9\"},{\"1\":\"female_seeing_model\",\"2\":\"3.7\"},{\"1\":\"female_seeing_model\",\"2\":\"4.2\"},{\"1\":\"female_seeing_model\",\"2\":\"5.1\"},{\"1\":\"female_seeing_model\",\"2\":\"4.1\"},{\"1\":\"female_seeing_model\",\"2\":\"3.8\"},{\"1\":\"female_seeing_model\",\"2\":\"1.9\"},{\"1\":\"female_seeing_model\",\"2\":\"7.6\"},{\"1\":\"female_seeing_model\",\"2\":\"4.8\"},{\"1\":\"female_seeing_model\",\"2\":\"3.3\"},{\"1\":\"female_seeing_model\",\"2\":\"5.7\"},{\"1\":\"female_seeing_model\",\"2\":\"3.5\"},{\"1\":\"female_seeing_model\",\"2\":\"4.6\"},{\"1\":\"female_seeing_model\",\"2\":\"4.6\"},{\"1\":\"female_seeing_model\",\"2\":\"4.9\"},{\"1\":\"female_seeing_model\",\"2\":\"3.7\"},{\"1\":\"female_seeing_student\",\"2\":\"5.7\"},{\"1\":\"female_seeing_student\",\"2\":\"1.4\"},{\"1\":\"female_seeing_student\",\"2\":\"3.2\"},{\"1\":\"female_seeing_student\",\"2\":\"3.3\"},{\"1\":\"female_seeing_student\",\"2\":\"4.2\"},{\"1\":\"female_seeing_student\",\"2\":\"6.5\"},{\"1\":\"female_seeing_student\",\"2\":\"2.3\"},{\"1\":\"female_seeing_student\",\"2\":\"6.6\"},{\"1\":\"female_seeing_student\",\"2\":\"4.2\"},{\"1\":\"female_seeing_student\",\"2\":\"2.6\"},{\"1\":\"female_seeing_student\",\"2\":\"4.7\"},{\"1\":\"female_seeing_student\",\"2\":\"2.6\"},{\"1\":\"female_seeing_student\",\"2\":\"1.8\"},{\"1\":\"female_seeing_student\",\"2\":\"2.6\"},{\"1\":\"female_seeing_student\",\"2\":\"4.4\"},{\"1\":\"female_seeing_student\",\"2\":\"0.9\"},{\"1\":\"female_seeing_student\",\"2\":\"-0.5\"},{\"1\":\"female_seeing_student\",\"2\":\"2.4\"},{\"1\":\"female_seeing_student\",\"2\":\"4.3\"},{\"1\":\"female_seeing_student\",\"2\":\"7.0\"},{\"1\":\"female_seeing_student\",\"2\":\"4.2\"},{\"1\":\"female_seeing_student\",\"2\":\"1.1\"},{\"1\":\"female_seeing_student\",\"2\":\"2.9\"},{\"1\":\"female_seeing_student\",\"2\":\"3.9\"},{\"1\":\"female_seeing_student\",\"2\":\"1.7\"},{\"1\":\"control\",\"2\":\"1.1\"},{\"1\":\"control\",\"2\":\"3.3\"},{\"1\":\"control\",\"2\":\"5.1\"},{\"1\":\"control\",\"2\":\"4.3\"},{\"1\":\"control\",\"2\":\"4.3\"},{\"1\":\"control\",\"2\":\"5.7\"},{\"1\":\"control\",\"2\":\"4.9\"},{\"1\":\"control\",\"2\":\"5.0\"},{\"1\":\"control\",\"2\":\"3.8\"},{\"1\":\"control\",\"2\":\"5.9\"},{\"1\":\"control\",\"2\":\"3.5\"},{\"1\":\"control\",\"2\":\"6.5\"},{\"1\":\"control\",\"2\":\"3.6\"},{\"1\":\"control\",\"2\":\"3.6\"},{\"1\":\"control\",\"2\":\"1.0\"},{\"1\":\"control\",\"2\":\"5.1\"},{\"1\":\"control\",\"2\":\"3.7\"},{\"1\":\"control\",\"2\":\"4.6\"},{\"1\":\"control\",\"2\":\"5.1\"},{\"1\":\"control\",\"2\":\"4.3\"},{\"1\":\"control\",\"2\":\"3.0\"},{\"1\":\"control\",\"2\":\"3.1\"},{\"1\":\"control\",\"2\":\"2.3\"},{\"1\":\"control\",\"2\":\"1.9\"},{\"1\":\"control\",\"2\":\"6.1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nsee that `treatment` is now definitely a factor rather than a\ncategorical variable represented as a piece of text.\n\n$\\blacksquare$\n\n(c) List the treatments in the order that they are in within\nyour `factor`. (There are lots of ways to do this; any one of\nthem except for `distinct` is good.)\n\nSolution\n\n\nThis is the most direct:\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(shirts$treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"control\"               \"female_seeing_model\"   \"female_seeing_student\"\n[4] \"male_seeing_model\"     \"male_seeing_student\"  \n```\n:::\n:::\n\n     \n\nor you can do one of the `tidyverse`-style ways, such as\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts %>% count(treatment)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"treatment\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"control\",\"2\":\"25\"},{\"1\":\"female_seeing_model\",\"2\":\"25\"},{\"1\":\"female_seeing_student\",\"2\":\"25\"},{\"1\":\"male_seeing_model\",\"2\":\"25\"},{\"1\":\"male_seeing_student\",\"2\":\"25\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nor\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts %>% distinct(treatment)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"treatment\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"male_seeing_model\"},{\"1\":\"male_seeing_student\"},{\"1\":\"female_seeing_model\"},{\"1\":\"female_seeing_student\"},{\"1\":\"control\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nexcept that `distinct` shows you the values in the order that\nthey appear in the data file, which is *not* the order that they\nappear in the factor. So that's why I asked you not to do it that way.\n\nAlphabetical order,  is the moral of the story.\n\nExtra: you can make them appear in the order they appear in the data,\nif you want to (and if you know what you are doing):\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts %>% mutate(trt2 = fct_inorder(treatment)) -> d\nlevels(d$trt2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"male_seeing_model\"     \"male_seeing_student\"   \"female_seeing_model\"  \n[4] \"female_seeing_student\" \"control\"              \n```\n:::\n:::\n\n \n\n`fct_inorder` *creates* a factor whose levels are in the\norder that they appeared in the data. If this is what you want, you\ncan go ahead and do this, and use this order when you create your\ncontrasts. It will work, and it will be good even though your\ncontrasts will look different from mine.\n\n$\\blacksquare$\n\n(d) <a name=\"part:mean-eval\">*</a> \nObtain a table of mean evaluation scores for each treatment group.\n  \n\nSolution\n\n\nWe will use this later when assessing the significance of the\ncontrasts. It's the usual group-by and summarize:\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts %>%\n  group_by(treatment) %>%\n  summarize(m = mean(score))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"treatment\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"m\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"control\",\"2\":\"4.032\"},{\"1\":\"female_seeing_model\",\"2\":\"4.068\"},{\"1\":\"female_seeing_student\",\"2\":\"3.360\"},{\"1\":\"male_seeing_model\",\"2\":\"5.416\"},{\"1\":\"male_seeing_student\",\"2\":\"3.252\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n     \n\nExtra: how does this come out if you have your factor levels in a\nnon-alphabetical order?\n\n::: {.cell}\n\n```{.r .cell-code}\nd %>% group_by(trt2) %>% summarize(m = mean(score))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"trt2\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"m\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"male_seeing_model\",\"2\":\"5.416\"},{\"1\":\"male_seeing_student\",\"2\":\"3.252\"},{\"1\":\"female_seeing_model\",\"2\":\"4.068\"},{\"1\":\"female_seeing_student\",\"2\":\"3.360\"},{\"1\":\"control\",\"2\":\"4.032\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nAh, it respects the order of the levels of the factor: that is to say,\nthe treatment groups appear here in the order that they were in the\ndata, because the factor `trt2` was created to make that\nhappen.\n\n`forcats` has other tools to re-order the levels of a factor,\nlump factor levels together to make a category \"other\", and so\non. These also work if you start with a categorical variable as text:\nit *creates* a factor with those properties.\n  \n$\\blacksquare$\n\n(e) The experimenters wanted to compare four specific things in\ntheir analysis:\n\n\n* evaluation scores between male students who saw a (female) model and\nmale students who saw a (female) student\n\n* evaluation scores between female students who saw a (female)\nmodel and female students who saw a (female) student\n\n* evaluation scores for male and for female students (overall)\n\n* evaluation scores for the (average of the) four genuine\ntreatments and for the control group\n\nCreate contrasts, with suitable names, using vectors with\nappropriate values.\n  \n\nSolution\n\n\nThese, in that order, are comparisons of treatments 4 and 5:\n\n::: {.cell}\n\n```{.r .cell-code}\nc_mms <- c(0, 0, 0, 1, -1)\n```\n:::\n\n   \n\ntreatments 2 and 3:\n\n::: {.cell}\n\n```{.r .cell-code}\nc_fms <- c(0, 1, -1, 0, 0)\n```\n:::\n\n \n\n(in these two the 1 and $-1$ can also be the other way around)\n\nthe average of 2 and 3 vs.\\ the average of 4 and 5:\n\n::: {.cell}\n\n```{.r .cell-code}\nc_mf <- c(0, 0.5, 0.5, -0.5, -0.5)\n```\n:::\n\n \n\nor you can use 1 and $-1$ instead of the 0.5s, or you can switch the\nsigns around. I like the 0.5 values to remind me it's an average of\ntwo means.\n\nFinally\n\n::: {.cell}\n\n```{.r .cell-code}\nc_tc <- c(1, -0.25, -0.25, -0.25, -0.25)\n```\n:::\n\n \n\nor multiply through by 4 to get rid of the fractions, or have the\nnegative sign on the first one and positive signs on the others.\n\nI tried to give the contrasts mnemonic but short names, so that I\nwould remember which was which.\n  \n$\\blacksquare$\n\n(f) Pick two of your contrasts (doesn't matter which two) and\ndemonstrate that they are orthogonal.\n  \n\nSolution\n\n\nMultiply them together (elementwise, which is what `*`\ndoes) and add them up, showing that you get zero, for example:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c_mf * c_tc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n     \n\nCheck (mops brow).\n  \n$\\blacksquare$\n\n(g) Collect all your contrasts together into a matrix and\ndeclare that they are contrasts for `treatment` within your\ndata frame (whatever you called it).\n  \n\nSolution\n\n\nI called my data frame `shirts`, so I need to do this:\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c_mms, c_fms, c_mf, c_tc)\ncontrasts(shirts$treatment) <- m\n```\n:::\n\n       \n\nThere's no output here; we'll see in a moment whether it worked.\n\nExtra: once you've created the matrix `m`, it gives you a\nsecond way to test the contrasts for orthogonality, all at once:\n\n::: {.cell}\n\n```{.r .cell-code}\nt(m) %*% m\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      c_mms c_fms c_mf c_tc\nc_mms     2     0    0 0.00\nc_fms     0     2    0 0.00\nc_mf      0     0    1 0.00\nc_tc      0     0    0 1.25\n```\n:::\n:::\n\n \n\nThis matrix-multiplies the transpose of `m` by `m`, so\nit's testing each column of `m` to see whether it's orthogonal\nto each other column. The columns don't have to be orthogonal to\nthemselves, hence the non-zeros down the diagonal, but all the\noff-diagonal entries are zero. Hence each contrast is orthogonal to\neach other contrast.\n\nOr even:\n\n::: {.cell}\n\n```{.r .cell-code}\nz <- t(m) %*% m\nall(z[row(z) != col(z)] == 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n \n\nThat says (a little breathlessly) that it is true that all the\nelements of $M^TM$ that are off the diagonal are zero.^[The thing inside the square brackets says only to look at the elements of $M^TM$ whose row number and whose column number are different; it is perhaps easier to reason that elements of a matrix whose row number and column number are the *same* are *on* the diagonal, for example the element in row 2, column 2.]\n  \n$\\blacksquare$\n\n(h) Predict evaluation score from \ntreatment *as a  regression*, and display the results.\n  \n\nSolution\n\n\nOnce you have everything set up, it's just a matter of going\nthrough the process:\n\n::: {.cell}\n\n```{.r .cell-code}\nscore.1 <- lm(score ~ treatment, data = shirts)\nsummary(score.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = score ~ treatment, data = shirts)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.860 -0.760  0.032  0.840  3.640 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      4.0256     0.1231  32.705  < 2e-16 ***\ntreatmentc_mms   1.0820     0.1946   5.560 1.66e-07 ***\ntreatmentc_fms   0.3540     0.1946   1.819   0.0714 .  \ntreatmentc_mf   -0.6200     0.2752  -2.253   0.0261 *  \ntreatmentc_tc    0.0064     0.2462   0.026   0.9793    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.376 on 120 degrees of freedom\nMultiple R-squared:  0.2467,\tAdjusted R-squared:  0.2216 \nF-statistic: 9.823 on 4 and 120 DF,  p-value: 6.576e-07\n```\n:::\n:::\n\n       \n\nNote how the contrasts have appeared as \"slopes\" in our\nregression. (If this didn't happen for you, go back and check what you\ndid. Probably something gave you an error before, in that case.)\n\nYour slopes can differ in terms of sign and possibly value from mine,\nbut the $t$-statistics and P-values should be the same as mine.\n  \n$\\blacksquare$\n\n(i) For each of your contrasts, assess whether or not it is\nsignificant, and explain briefly what that means in the context of the\ndata. If a contrast is significant, use your answer to\npart (<a href=\"#part:mean-eval\">here</a>) to help in your interpretation. \n    \n\nSolution\n\n\nI'll take my four contrasts as they appear in the output from `lm`:\n\n\n* Comparing the male students who saw the model with those\nwho saw the student: this is strongly significant, and the\ntable of means shows that the males who saw the model rated\nthe shirt significantly *higher* than those who saw the\n\"average-looking\" female student.\n\n* Comparing the female students who saw the model with\nthose who saw the student: this difference is not quite\nsignificant, so we conclude that it didn't matter who the\nfemale students saw coming out of the dressing room.\n\n* There is a significant difference between the average\nevaluation score that males gave to the shirt and that\nfemales did. The table of means reveals that the male\naverage was higher, mostly because males *really* liked\nthe shirt when they thought the model had been wearing it!\n\n* There is no significant difference overall between\ntreatment and control groups in terms of average\nscore. (This is mostly because the treatment groups differ\namong themselves, with the scores for students who saw the\nmodel being higher and those for students who saw the female\nstudent being lower than for the control group.)\n\nIt is enough, on the non-significant ones, to say what it is\nthat the contrast is testing, and then to note that it is not\nsignificant. On the significant ones, I want you to say what\nis higher than what.\nYou can also get these conclusions from the `lm`\noutput, but it requires a bit more care:\n\n\n* I set up `c_mms` with the score for the students\nwho had seen the model as plus and those who saw the student\nas minus. My slope here is positive, so the score for\nmale students who saw the model is higher.\n\n* My slope for `c_fms` is also positive, and I set\nthis one up the same way with model as positive and student\nas negative, so the female students rated the shirt higher\n(but not significantly higher) when they saw the model.\n\n* My `c_mf` slope is significantly negative. I set\nup this contrast with females as plus and males as minus, so\nthis means males gave a significantly *higher* score on\naverage (for reasons discussed above).\n\n* The last slope is very close to 0, consistent with there\nbeing no difference (on average) between treatment and control.\n\nPerhaps the story to get from this analysis is that male\nstudents are *such* suckers!\n    \n$\\blacksquare$\n\n\n\n\n",
    "supporting": [
      "anova-revisited_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}