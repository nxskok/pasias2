{
  "hash": "2349c145a61310462635c7a78c632bbb",
  "result": {
    "engine": "knitr",
    "markdown": "# Analysis of variance revisited\n\nPackages for this chapter:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(car)\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Acid rain\n\n\n One of the first noticeable effects of climate change was\n\"acid rain\". This is formed by the water vapour in clouds combining\nwith nitrous oxide and sulfur dioxide, which come from coal and oil\nproduction. How does the acidity of rain affect the acidity of the\nsoil on which it falls? (This will have an effect on the kind of\nplants that can be grown in that soil.) Acidity is measured using the\npH scale, where a pH of 7 is chemically neutral, a number less than 7\nis acidic, and a number greater than 7 is alkaline.\n\nAn experiment was conducted at the Florida Institute of Food and\nAgricultural Sciences, to determine how acidity of rain affects soil\nacidity. Experimental plots were irrigated with rainwater that was\nprepared to have one of two different pH levels, 3.7 and 4.5. The\nacidity of the soil was then measured at three different depths,\n0--15, 15--30, and 30--46 centimetres. This was done on three\ndifferent dates, in April and June 1991. The data are in\n[link](http://ritsokiguess.site/datafiles/acidrain.csv).\n\n\n\n(a) Read in and display the data.\n\n\n(b) Draw a grouped boxplot to show how soil acidity depends on\nthe pH of the rain and the soil depth. (The first time you do this\nyou might not get the boxplot you want. How can you fix that?)\n\n\n(c) What does your grouped boxplot say about likely\ninteractions? Explain briefly.\n\n\n(d) Fit an ANOVA with interaction. What do you conclude from\nit? You may want to create a column that is the factor version of\n`rain_pH` first.\n\n\n\n\n\n##  Treating hay fever\n\n\n Hay fever is an allergic reaction to things like grasses or\npollen which can make it unpleasant to go outside when the weather is\nat its best.  A research lab is developing a new compound to relieve\nsevere cases of hay fever. There were two active ingredients, labelled\nA and B, with each one having three levels, low, medium and\nhigh. There were thus $3\\times 3=9$ treatment combinations. 36\nsubjects were available, and these were randomly assigned to\ncombinations of levels of factor A and factor B, so that each\ncombination was tested on 4 people. The response variable was the\nnumber of hours of relief from symptoms (so a higher value is\nbetter). The data are in\n[link](http://ritsokiguess.site/datafiles/hayfever.txt).\n\n\n\n(a) Read the data and display its structure. Verify that you\nhave what you were expecting.\n\n\n(b) Calculate the mean hours of relief for each combination of\nlevels of the two active ingredients. Save your results in a data\nframe and display that.\n\n\n(c) Make an interaction plot, showing how the mean pain relief depends on the combination of levels of A and B. It is probably easiest to use the data frame you obtained in the previous part.\n\n\n(d) What do you conclude from your interaction plot? Explain briefly.\n\n\n(e) Run an analysis of variance with interaction. What do you conclude?\n\n\n(f) Analyze the simple effects of B when A is\n`medium`. (This means doing an appropriate `aov` and\nan appropriate Tukey, if warranted.)\n\n\n(g) Analyze the simple effects of B when A is `high`.\n\n\n\n\n\n\n##  Focused comparisons of the effect of caffeine\n\n\n \nDoes caffeine help students do better on a certain test? To\nfind out, 36 students were randomly allocated to three groups (12 in\neach group).  Each student received a fixed number of cups of coffee\nwhile they were studying, but the students didn't know whether they\nwere receiving all full-strength coffee (\"high\"), all decaf coffee\n(\"low\") or a 50-50 mixture of the two (\"moderate\"). For each\nsubject, their group was recorded as well as their score on the\ntest. The data are in\n[link](http://ritsokiguess.site/datafiles/caffeine.csv), as a\n`.csv` file.\n\nThis time we look at\ncontrasts. Suppose I knew ahead of time\nthat I wanted to compare moderate caffeine with high, and any\ncaffeine with none. (In the latter case, we're comparing \n\"no caffeine\" against the average of the other two groups.)\n\nIn the previous go-through of the caffeine data, we\ndiscovered that `amount` was actually text rather than a\nfactor, but we also discovered that it *didn't matter*. Here it\ndoes matter, so the first thing we have to do is to re-do the\n`pivot_longer`, creating a factor version of `amount`.\n\n\n\n(a) Read in the data again, from\n[link](http://ritsokiguess.site/datafiles/caffeine.csv), and\ndisplay it. This is the untidy format, so name it appropriately:\n\n\n\n(b) Copy your `pivot_longer` from before, only this time add\n`names_ptypes = list(amount=factor())` to the end of it. Take a look at the\nresults. What has changed from before?\n\n\n\n(c) Using the newly tidied caffeine data, run the ANOVA \n*as a  regression* (that is, using `lm`). Look at the\n`summary` of the output. What do you see?\n\n\n\n(d) Obtain the different values of `amount`, in the order\nthat R has them.\n\n\n\n(e) Create a contrast that compares High with Moderate, ignoring\nNone. That is, create a vector whose length is the same as the\nnumber of levels of `amount`, and which has a 1 to represent\nHigh and a $-1$ to represent Moderate. \n\n\n\n(f) Create a contrast that compares \"any caffeine\" against\n\"none\" by comparing None against the average of Moderate and High.\n\n\n\n(g) Verify that your two contrasts are orthogonal.\n\n\n\n(h) Arrange your contrasts as columns of a matrix (using\n`cbind`), and say that you want to use these as contrasts for\n`amount` (in data frame `caffeine` or whatever you\ncalled it).\n\n\n\n(i) Fit the ANOVA as an `lm`, and look at the\n`summary`. What do you conclude about your contrasts?\n\n\n\n(j) What happens if you try to use high caffeine vs.\\ moderate\ncaffeine and moderate vs.\\ none as your two contrasts?\n\n\n\n\n\n\n\n##  Who studies the most outside class?\n\n\n A social scientist wanted to see how many hours students\n studied outside of class. She took a random sample of 75 students\n from three different majors: math, social science and English, and\n recorded the number of weekly outside-class study hours for each\n student. The data can be found at\n [link](http://ritsokiguess.site/datafiles/studyhours.txt). The\n social scientist had two research questions: whether math students study\n more outside of class than the other students, and whether English and\n social science students study different amounts of time outside class.\n\n\n(a) Explain briefly why contrasts would be a better idea here\nthan ANOVA with Tukey.\n\n\n\n(b) Read in the data and make side-by-side boxplots of study\nhours by major. What do the boxplots suggest about the comparisons\nthat the researcher wants to make?\n\n\n\n(c) Set up contrasts for each of the researcher's research\nquestions, bearing in mind the levels of `major` and the\norder in which they come. (For the `Math` contrast, you want\nMath against the average of the other two.)\n\n\n\n(d) Verify that your two contrasts are orthogonal.\n\n\n\n(e) Create a matrix of contrasts (using `cbind`) and let\n`lm` know that these are contrasts for `major`, in\ndata frame `studyhours` (or whatever you called it).\n\n\n\n(f) Fit the model using `lm`. What do you conclude about\nyour contrasts?\n\n\n\n(g) Are you surprised by the significance or non-significance you\nfound in the previous part? Explain briefly.\n\n\n \n\n\n\n##  Mental context\n\n\n It is believed that being in the same mental context for\nlearning and for testing leads to better test scores. An experiment\nwas carried out to test this. During the learning phase, subjects\nlearned a list of 80 words in a room painted orange and decorated with\nposters, paintings and other paraphernalia.^[This is a fancy  word for *stuff*.] A memory test was given to all subjects\nimmediately after they had learned the words, to give the impression\nthat the experiment was over. (The results of this test were\ndiscarded.) One day later, subjects were unexpectedly re-tested under\ndifferent experimental conditions and asked to write down all the\nwords of the original list that they could remember. The re-test took\nplace in five different conditions, which subjects were randomly\nallocated to one of:\n\n\n\n* Same context: in the original orange-painted room.\n\n* Different context: in a very different room, painted grey and\nlocated in a different part of campus.\n\n* Imaginary context: in the grey room, but subjects are asked to\nremember the orange room in which they took the original test. To\nhelp them with this, the experimenter begins by asking them several\nquestions about the orange room and the objects in it.\n\n* Photographed context: in the grey room, but subjects are shown\nphotographs of the orange room.\n\n* Placebo context: in the grey room, with subjects first being\nasked to recall their living room.\n\n\nIn each case, the response variable was the number of words on the\noriginal list successfully recalled by each subject.\n\n50 subjects in total completed the experiment, 10 under each of the 5\nconditions. \n\nThe researchers had four research hypotheses to test with the data:\n\n\n\n* Groups where the context matches (is the same, or is simulated\nby imagining or photograph) will perform better than groups with\ndifferent or placebo contexts.\n\n* The group with the same context will differ from the group with\nimaginary or photographed contexts.\n\n\n* The imaginary-context group will differ from the\nphotographed-context group.\n\n* The different-context group will differ from the placebo-context group.\n\n\nThe research hypotheses are (as is usual) written as\n*alternative* hypotheses. We can rewrite them as null\nhypotheses, with some extra wording to facilitate converting them\ninto contrasts, like this:\n\n\n* The mean of the `same`, `imaginary` and\n`photograph` groups (group means) is equal to the mean of the\n`different` and `placebo` groups (group means).\n\n* The mean of the `imaginary` and `photograph`\ngroups is equal to the (mean of the) `same` group.\n\n* The `imaginary` and the `photograph` groups will\nhave the same mean.\n\n* The `different` and the `placebo` groups will\nhave the same mean.\n\nThe data are in\n[link](http://ritsokiguess.site/datafiles/smith.txt) (the\noriginal researcher's name was Smith). \n\n\n(a) Read in the data and verify that you have a column called\n`context` that is text and a column called\n`words` that is a (whole) number.\n\n\n\n(b) Turn `context` into a `factor`, within the\ndata frame. (We are going to be doing contrasts). Display how the\ndata frame now looks.\n\n\n\n(c) What are the names of the five contexts in the data set\n(just display them),\nand what order are they in?\n\n\n\n(d) Write each of the four research hypotheses (in the\nnull-hypothesis versions) as R vectors that can be used to make\ncontrasts. (This will mean getting the contexts in the right\norder. If you get stuck, do the last two first, since they're\neasiest. The first one is actually the hardest.)\n\n\n\n(e) Pick two of your contrasts (doesn't matter which two) and\ndemonstrate that they are orthogonal.\n\n\n\n(f) Collect your contrasts together into a matrix, and\ntell `lm` that these are the contrasts for `context`.\n\n\n\n(g) Fit a model with `lm`, and display the results.\n\n\n\n(h) For each of the original research hypotheses, what do you\ninfer about them?\n\n\n\n\n\n\n\n\n\n##  Trying on shirts\n\n\n Does it make a difference if you see somebody else trying on\na shirt before you do, and if so, does it matter what kind of person\nit is? \n\nAn experiment was carried out in a university bookstore, with\nstudents who wanted to try on a shirt serving as (unsuspecting)\nexperimental subjects. When a student wanted to try on a shirt, the\nsales associate told them that there was only one shirt left, and it\nwas being tried on by an \"other customer\". This \"other customer\"\nwas actually a \"confederate\" of the experimenter (that means, they\nwere pretending to be a real customer but were actually part of the\nexperiment). The \"other customer\" was always female: either an\nattractive well-dressed model, or an average-looking student wearing\njeans. The \"other customer\" would come out of the\ndressing room and hand the shirt to the sales associate, who would\ngive it to the student who wanted to try it on. When the student had\ntried on the shirt, they were asked to rate it on a 7-point scale (on\nfive different dimensions, and those five scores were then\naveraged). Does a student's evaluation depend on whether the student\nwas male or female, and whether the \"other customer\" was a model or\na student? There was also a control group, where the student was\nhanded the shirt directly  by the sales associate, without the \n\"other customer\" being involved at all. \n\nThere were thus five treatments:\nmale students who saw a model, male students who saw a student, female\nstudents who saw a model, female students who saw a student, and the\ncontrol group. There were 25 students in each treatment group.\n\nThe data from this experiment can be found at\n[link](http://ritsokiguess.site/datafiles/shirts.csv).\n\n\n\n(a) Read in and display the data. How many observations do you\nhave, and is that what you should have?\n\n\n(b) Turn `treatment` into a `factor` in your data\nframe. (You can use the same name as the text `treatment`\nthat you read in from the file.)\n\n\n(c) List the treatments in the order that they are in within\nyour `factor`. (There are lots of ways to do this; any one of\nthem except for `distinct` is good.)\n\n\n(d) <a name=\"part:mean-eval\">*</a> \nObtain a table of mean evaluation scores for each treatment group.\n  \n\n\n(e) The experimenters wanted to compare four specific things in\ntheir analysis:\n\n\n* evaluation scores between male students who saw a (female) model and\nmale students who saw a (female) student\n\n* evaluation scores between female students who saw a (female)\nmodel and female students who saw a (female) student\n\n* evaluation scores for male and for female students (overall)\n\n* evaluation scores for the (average of the) four genuine\ntreatments and for the control group\n\nCreate contrasts, with suitable names, using vectors with\nappropriate values.\n  \n\n\n(f) Pick two of your contrasts (doesn't matter which two) and\ndemonstrate that they are orthogonal.\n  \n\n\n(g) Collect all your contrasts together into a matrix and\ndeclare that they are contrasts for `treatment` within your\ndata frame (whatever you called it).\n  \n\n\n(h) Predict evaluation score from \ntreatment *as a  regression*, and display the results.\n  \n\n\n(i) For each of your contrasts, assess whether or not it is\nsignificant, and explain briefly what that means in the context of the\ndata. If a contrast is significant, use your answer to\npart (<a href=\"#part:mean-eval\">here</a>) to help in your interpretation. \n    \n\n\n\n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n\n\n\n\n\n\n## Acid rain\n\nOne of the first noticeable effects of climate change was \"acid rain\".\nThis is formed by the water vapour in clouds combining with nitrous\noxide and sulfur dioxide, which come from coal and oil production. How\ndoes the acidity of rain affect the acidity of the soil on which it\nfalls? (This will have an effect on the kind of plants that can be grown\nin that soil.) Acidity is measured using the pH scale, where a pH of 7\nis chemically neutral, a number less than 7 is acidic, and a number\ngreater than 7 is alkaline.\n\nAn experiment was conducted at the Florida Institute of Food and\nAgricultural Sciences, to determine how acidity of rain affects soil\nacidity. Experimental plots were irrigated with rainwater that was\nprepared to have one of two different pH levels, 3.7 and 4.5. The\nacidity of the soil was then measured at three different depths, 0--15,\n15--30, and 30--46 centimetres. This was done on three different dates,\nin April and June 1991. The data are in\n[link](http://ritsokiguess.site/datafiles/acidrain.csv).\n\n(a) Read in and display the data.\n\nSolution\n\nThis time, it's a `.csv`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/acidrain.csv\"\nacidrain <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 18 Columns: 4\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (1): soil_depth\ndbl  (2): rain_pH, soil_acidity\ndate (1): date\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nacidrain\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 18 x 4\n   soil_depth date       rain_pH soil_acidity\n   <chr>      <date>       <dbl>        <dbl>\n 1 0-15       1991-04-03     3.7         5.33\n 2 0-15       1991-04-03     4.5         5.33\n 3 0-15       1991-06-16     3.7         5.47\n 4 0-15       1991-06-16     4.5         5.47\n 5 0-15       1991-06-30     3.7         5.2 \n 6 0-15       1991-06-30     4.5         5.13\n 7 15-30      1991-04-03     3.7         5.27\n 8 15-30      1991-04-03     4.5         5.03\n 9 15-30      1991-06-16     3.7         5.5 \n10 15-30      1991-06-16     4.5         5.53\n11 15-30      1991-06-30     3.7         5.33\n12 15-30      1991-06-30     4.5         5.2 \n13 30-46      1991-04-03     3.7         5.37\n14 30-46      1991-04-03     4.5         5.4 \n15 30-46      1991-06-16     3.7         5.8 \n16 30-46      1991-06-16     4.5         5.6 \n17 30-46      1991-06-30     3.7         5.33\n18 30-46      1991-06-30     4.5         5.17\n```\n\n\n:::\n:::\n\nThere are 4 columns, soil depth, date, pH of the rain that was applied\n(all explanatory) and soil acidity, the response. You'll note that we\nhave one soil acidity value per combination of the other things (it was\na designed experiment).\n\nWe're going to ignore the date for now, treating the observations on\ndifferent dates as replicates.\n\n$\\blacksquare$\n\n(b) Draw a grouped boxplot to show how soil acidity depends on the pH of\n    the rain and the soil depth. (The first time you do this you might\n    not get the boxplot you want. How can you fix that?)\n\nSolution\n\nThe problem is likely to be that either your `x` or your `fill` for your\nboxplot is numerical (`rain_pH` is `dbl`) rather than the categorical\nvariable you need. Try to use one of the explanatory variables as `x`\nand the other one as `fill` (or `colour`):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(acidrain, aes(x = rain_pH, y = soil_acidity, fill = soil_depth)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-pdf/acidrain-2-1.pdf){fig-pos='H'}\n:::\n:::\n\nThat looks as if it worked, but it didn't. See the boxplot below for how\nit's supposed to be. I need `x` for the boxplot needs to be categorical.\nThe easiest way to make it such is to wrap it in `factor`:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(acidrain, aes(x = factor(rain_pH), y = soil_acidity, fill = soil_depth)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-pdf/acidrain-3-1.pdf){fig-pos='H'}\n:::\n:::\n\nEven though `soil_depth` looks like numbers, the printout of the data\nframe reveals that it is text, so that is OK.\n\nIf you prefer, exchange `x` and `fill`:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(acidrain, aes(fill = factor(rain_pH), y = soil_acidity, x = soil_depth)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-pdf/acidrain-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n$\\blacksquare$\n\n(c) What does your grouped boxplot say about likely interactions?\n    Explain briefly.\n\nSolution\n\nThink about the effect of one of your explanatory variables, for each\nlevel of the other. For example, in the last plot, the effect of the\nrain pH pm on the soil acidity is very small at the largest and smallest\ndepths, but at the middle soil depth 15--30, the average (median) soil\nacidity is a lot less when the rain pH is *higher* (which seems odd to\nme). The effect of rain pH being different according to soil pH is what\nsuggests an interaction effect. Another way of thinking about this is\nimagining what an interaction plot would look like. This would be a\ntrace going through the middle (strictly, mean rather than median) of\neach set of boxplots of one colour. In the last boxplot, the red trace\nwould go close to straight across, while the blue one would dip in the\nmiddle. Not parallel, so suggesting an interaction. Either approach is\ngood.\n\n$\\blacksquare$\n\n(d) Fit an ANOVA with interaction. What do you conclude from it? You may\n    want to create a column that is the factor version of `rain_pH`\n    first.\n\nSolution\n\nFollowing my own hint:\n\n::: {.cell}\n\n```{.r .cell-code}\nacidrain <- acidrain %>% mutate(frph = factor(rain_pH))\nsoil.1 <- aov(soil_acidity ~ frph * soil_depth, data = acidrain)\nsummary(soil.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                Df Sum Sq Mean Sq F value Pr(>F)\nfrph             1 0.0304 0.03042   0.759  0.401\nsoil_depth       2 0.0671 0.03357   0.838  0.457\nfrph:soil_depth  2 0.0078 0.00391   0.097  0.908\nResiduals       12 0.4810 0.04008               \n```\n\n\n:::\n:::\n\nThe interaction is nowhere near significant, perhaps surprisingly. But\nbear in mind that there are only 18 observations in total, so each box\non the boxplot is based on *three* observations only. So the interaction\nwould have to be a lot bigger to be significant.\n\nThe usual procedure after finding a non-significant interaction is to\ntake it out:\n\n::: {.cell}\n\n```{.r .cell-code}\nsoil.2 <- update(soil.1, . ~ . - frph:soil_depth)\nsummary(soil.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value Pr(>F)\nfrph         1 0.0304 0.03042   0.871  0.366\nsoil_depth   2 0.0671 0.03357   0.962  0.406\nResiduals   14 0.4888 0.03492               \n```\n\n\n:::\n:::\n\nThe P-values have come down a bit (the result of gaining two df for\nerror while the error SS only got a tiny bit bigger), but not nearly\nenough to be significant.\n\n$\\blacksquare$\n\n\n\n\n\n\n\n\n## Treating hay fever\n\nHay fever is an allergic reaction to things like grasses or pollen which\ncan make it unpleasant to go outside when the weather is at its best. A\nresearch lab is developing a new compound to relieve severe cases of hay\nfever. There were two active ingredients, labelled A and B, with each\none having three levels, low, medium and high. There were thus\n$3\\times 3=9$ treatment combinations. 36 subjects were available, and\nthese were randomly assigned to combinations of levels of factor A and\nfactor B, so that each combination was tested on 4 people. The response\nvariable was the number of hours of relief from symptoms (so a higher\nvalue is better). The data are in\n[link](http://ritsokiguess.site/datafiles/hayfever.txt).\n\n(a) Read the data and display its structure. Verify that you have what\n    you were expecting.\n\nSolution\n\nAligned columns separated by spaces, so `read_table`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/hayfever.txt\"\nhayfever <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  relief = col_double(),\n  a = col_character(),\n  b = col_character(),\n  replicate = col_double()\n)\n```\n\n\n:::\n\n```{.r .cell-code}\nhayfever\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 36 x 4\n   relief a     b      replicate\n    <dbl> <chr> <chr>      <dbl>\n 1    2.4 low   low            1\n 2    2.7 low   low            2\n 3    2.3 low   low            3\n 4    2.5 low   low            4\n 5    4.6 low   medium         1\n 6    4.2 low   medium         2\n 7    4.9 low   medium         3\n 8    4.7 low   medium         4\n 9    4.8 low   high           1\n10    4.5 low   high           2\n# i 26 more rows\n```\n\n\n:::\n:::\n\nI have 36 observations (patients). There are two categorical columns `a`\nand `b` corresponding to the two active ingredients, and they each seem\nto have levels low, medium and high.[^_hayfever-1]\n\n[^_hayfever-1]: It's important to be clear about the distinction between\n    a categorical variable, that lives in a data frame column, and its\n    levels, the values that appear in the column. This is especially\n    important if you're trying to decide whether a data frame is tidy,\n    since typically an untidy data frame will have factor levels as\n    column names rather than the factor itself, and you need to be able\n    to tell the difference.\n\nThe `replicate` column labels each observation *within* its A-B\ncombination, so that each treatment combination was indeed replicated\nfour times. We won't be using this column in our analysis; I think it's\na refugee from the original untidy format the data was in before it came\nto you.\n\n$\\blacksquare$\n\n(b) Calculate the mean hours of relief for each combination of levels of\n    the two active ingredients. Save your results in a data frame and\n    display that.\n\nSolution\n\nThis is a group-by and summarize, but there are two active ingredients\nand they *both* have to go in the group-by:\n\n::: {.cell}\n\n```{.r .cell-code}\nhayfever %>%\n  group_by(a, b) %>%\n  summarize(m = mean(relief)) -> d\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'a'. You can override using the `.groups`\nargument.\n```\n\n\n:::\n\n```{.r .cell-code}\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9 x 3\n# Groups:   a [3]\n  a      b          m\n  <chr>  <chr>  <dbl>\n1 high   high   13.2 \n2 high   low     5.98\n3 high   medium 10.3 \n4 low    high    4.58\n5 low    low     2.48\n6 low    medium  4.6 \n7 medium high    9.12\n8 medium low     5.45\n9 medium medium  8.93\n```\n\n\n:::\n:::\n\nI'm using my usual name `d` for a temporary data frame. I could have put\nbrackets around my whole pipeline to display its result, but I still\nneed to save the data frame `d` to use in a moment.\n\nThese levels are in the wrong logical order, but they are in the right\norder in the original data frame, so we can use `fct_inorder` first,\nthus:\n\n::: {.cell}\n\n```{.r .cell-code}\nhayfever %>%\n  mutate(a = fct_inorder(a), b = fct_inorder(b)) %>%\n  group_by(a, b) %>%\n  summarize(m = mean(relief)) -> d2\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'a'. You can override using the `.groups`\nargument.\n```\n\n\n:::\n\n```{.r .cell-code}\nd2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9 x 3\n# Groups:   a [3]\n  a      b          m\n  <fct>  <fct>  <dbl>\n1 low    low     2.48\n2 low    medium  4.6 \n3 low    high    4.58\n4 medium low     5.45\n5 medium medium  8.93\n6 medium high    9.12\n7 high   low     5.98\n8 high   medium 10.3 \n9 high   high   13.2 \n```\n\n\n:::\n:::\n\n$\\blacksquare$\n\n(c) Make an interaction plot, showing how the mean pain relief depends\n    on the combination of levels of A and B. It is probably easiest to\n    use the data frame you obtained in the previous part.\n\nSolution\n\nMy column of mean relief values is called `m`. Use whatever name you\ngave it. I'm going to use my proper-order data frame for this:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d2, aes(x = a, y = m, colour = b, group = b)) +\n  geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-pdf/zellerin-1.pdf){fig-pos='H'}\n:::\n:::\n\nOr, you probably had this:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d, aes(x = a, y = m, colour = b, group = b)) +\n  geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-pdf/bapplin-1.pdf){fig-pos='H'}\n:::\n:::\n\nSince `a` and `b` both have three levels, you could just as well use\nthem the other way around:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d2, aes(x = b, y = m, colour = a, group = a)) +\n  geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-pdf/vonmengen-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe plot looks different depending on how you draw it, but the\nconclusion from it (below) will be the same.\n\n$\\blacksquare$\n\n(d) What do you conclude from your interaction plot? Explain briefly.\n\nSolution\n\nThe three lines are not particularly close to being parallel, so I would\nexpect to see an interaction between the two active ingredients (that\nis, the number of hours of pain relief depends on the combination of the\ntwo of them).\n\nExtra: It is always a judgment call to decide whether the lines are\n\"approximately parallel\" or not. It depends on how much variability\nthere is in the data, which the interaction plot doesn't show. Another\nidea is to add the data to the interaction plot, colour-coded in the\nsame way. I would do this by taking out the `geom_point` for the means\nand add one instead for the data, taken from the original data frame:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(d2, aes(x = a, y = m, colour = b, group = b)) +\n  geom_line() +\n  geom_point(data = hayfever, aes(y = relief))\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-pdf/swaub-1.pdf){fig-pos='H'}\n:::\n:::\n\nTechnique: for that last `geom_point`, put in anything that changes: a\nnew data frame, and a new `y` for the plot, but the `x` and `colour` and\n`group` are the same as they were before, so I don't need to specify\nthem.\n\nThe points are *very* close to the lines, so there is almost no residual\nvariability. This makes it more convincing that the interaction is real\nand will be significant. A grouped boxplot shows the same thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(hayfever, aes(x = fct_inorder(a), y = relief, fill = fct_inorder(b))) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-pdf/unnamed-chunk-2-1.pdf){fig-pos='H'}\n:::\n:::\n\n$\\blacksquare$\n\n(e) Run an analysis of variance with interaction. What do you conclude?\n\nSolution\n\n::: {.cell}\n\n```{.r .cell-code}\nhayfever.1 <- aov(relief ~ a * b, data = hayfever)\nsummary(hayfever.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value Pr(>F)    \na            2 220.02  110.01  1827.9 <2e-16 ***\nb            2 123.66   61.83  1027.3 <2e-16 ***\na:b          4  29.42    7.36   122.2 <2e-16 ***\nResiduals   27   1.63    0.06                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\nThe interaction is (strongly) significant. The hours of relief depend on\nthe combination of levels of the active ingredients A and B.\n\nDon't try to interpret the main effects of A and B from here. That's\nwhat simple effects are for, coming up.\n\n$\\blacksquare$\n\n(f) Analyze the simple effects of B when A is `medium`. (This means\n    doing an appropriate `aov` and an appropriate Tukey, if warranted.)\n\nSolution\n\nFirst, we pull out only the data where A is `medium`, and then we do a\none-way analysis of B on that data. This is the slick way, though you\ncan certainly save the result of `filter` first:\n\n::: {.cell}\n\n```{.r .cell-code}\nhayfever %>%\n  filter(a == \"medium\") %>%\n  aov(relief ~ b, data = .) -> simple_medium\nsummary(simple_medium)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nb            2  34.16  17.081   262.8 1.04e-08 ***\nResiduals    9   0.59   0.065                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\nThere is definitely some effect of ingredient B when A is medium. What\nis it? Tukey will tell us:\n\n::: {.cell}\n\n```{.r .cell-code}\nTukeyHSD(simple_medium)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = relief ~ b, data = .)\n\n$b\n              diff       lwr       upr     p adj\nlow-high    -3.675 -4.178336 -3.171664 0.0000000\nmedium-high -0.200 -0.703336  0.303336 0.5323662\nmedium-low   3.475  2.971664  3.978336 0.0000000\n```\n\n\n:::\n:::\n\nThere is no difference between medium and high (levels of B), but both\nof these are better in terms of relief than low is.\n\n$\\blacksquare$\n\n(g) Analyze the simple effects of B when A is `high`.\n\nSolution\n\nSame idea: pull out only the data where A is `high`, do a one-way\nanalysis of B, and do Tukey if needed:\n\n::: {.cell}\n\n```{.r .cell-code}\nhayfever %>%\n  filter(a == \"high\") %>%\n  aov(relief ~ b, data = .) -> simple_high\nsummary(simple_high)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nb            2 107.02   53.51     796 7.49e-11 ***\nResiduals    9   0.61    0.07                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nTukeyHSD(simple_high)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = relief ~ b, data = .)\n\n$b\n              diff       lwr       upr p adj\nlow-high    -7.275 -7.786868 -6.763132 0e+00\nmedium-high -2.975 -3.486868 -2.463132 2e-07\nmedium-low   4.300  3.788132  4.811868 0e+00\n```\n\n\n:::\n:::\n\nWhen A is high, there is definitely an effect of B again, but this time\nhigh (for B) is better than medium is better than low. (All the P-values\nin Tukey are very small.)\n\nYou could guess this from the interaction plot as well (whichever one\nyou came up with): when A is high, it is better for B to be high as\nwell, but when A is medium or low, there is not much difference between\nB being medium or high.\n\nExtra: here, the effect of B is different, depending on what A is. This\nis what a significant interaction *means*. If there were no significant\ninteraction, the effect of B would always be the same, no matter what A\nwas.\n\n$\\blacksquare$\n\n\n##  Focused comparisons of the effect of caffeine\n\n\n \nDoes caffeine help students do better on a certain test? To\nfind out, 36 students were randomly allocated to three groups (12 in\neach group).  Each student received a fixed number of cups of coffee\nwhile they were studying, but the students didn't know whether they\nwere receiving all full-strength coffee (\"high\"), all decaf coffee\n(\"low\") or a 50-50 mixture of the two (\"moderate\"). For each\nsubject, their group was recorded as well as their score on the\ntest. The data are in\n[link](http://ritsokiguess.site/datafiles/caffeine.csv), as a\n`.csv` file.\n\nThis time we look at\ncontrasts. Suppose I knew ahead of time\nthat I wanted to compare moderate caffeine with high, and any\ncaffeine with none. (In the latter case, we're comparing \n\"no caffeine\" against the average of the other two groups.)\n\nIn the previous go-through of the caffeine data, we\ndiscovered that `amount` was actually text rather than a\nfactor, but we also discovered that it *didn't matter*. Here it\ndoes matter, so the first thing we have to do is to re-do the\n`pivot_longer`, creating a factor version of `amount`.\n\n\n\n(a) Read in the data again, from\n[link](http://ritsokiguess.site/datafiles/caffeine.csv), and\ndisplay it. This is the untidy format, so name it appropriately:\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://individual.utoronto.ca/kbutler/stad29/caffeine.csv\"\ncaffeine.untidy <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 12 Columns: 4\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (4): Sub, High, Moderate, None\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ncaffeine.untidy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 4\n     Sub  High Moderate  None\n   <dbl> <dbl>    <dbl> <dbl>\n 1     1    72       68    68\n 2     2    65       80    74\n 3     3    68       64    59\n 4     4    83       65    61\n 5     5    79       69    65\n 6     6    92       79    72\n 7     7    69       80    80\n 8     8    74       63    58\n 9     9    78       69    65\n10    10    83       70    60\n11    11    88       83    78\n12    12    71       75    75\n```\n\n\n:::\n:::\n\n \n\nOne caffeine level per column, rather than a column of caffeine\nlevels, so untidy.\n\n\n$\\blacksquare$\n\n(b) Copy your `pivot_longer` from before, only this time add\n`names_ptypes = list(amount=factor())` to the end of it. Take a look at the\nresults. What has changed from before?\n\n\nSolution\n\n\nWe'll save into `caffeine` again:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine.untidy %>%\n  pivot_longer(-Sub, names_to=\"amount\", values_to=\"score\", \n               names_ptypes = list(amount=factor())) -> caffeine\ncaffeine\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 36 x 3\n     Sub amount   score\n   <dbl> <fct>    <dbl>\n 1     1 High        72\n 2     1 Moderate    68\n 3     1 None        68\n 4     2 High        65\n 5     2 Moderate    80\n 6     2 None        74\n 7     3 High        68\n 8     3 Moderate    64\n 9     3 None        59\n10     4 High        83\n# i 26 more rows\n```\n\n\n:::\n:::\n\n \n\nThe variable created for the \"names\" is now a\n`factor`: it was text before. Maybe we should have made it a\nfactor before (it wouldn't have done any harm), but we got away with\nnot doing so.\n\n\n$\\blacksquare$\n\n(c) Using the newly tidied caffeine data, run the ANOVA \n*as a  regression* (that is, using `lm`). Look at the\n`summary` of the output. What do you see?\n\n\nSolution\n\n\nExtra: I'm going to run the ANOVA the \"old way\" first, so that we can\ncompare results. You don't need to do this:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine.old <- aov(score ~ amount, data = caffeine)\nsummary(caffeine.old)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value Pr(>F)  \namount       2  477.7  238.86   3.986 0.0281 *\nResiduals   33 1977.5   59.92                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nTukeyHSD(caffeine.old)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = score ~ amount, data = caffeine)\n\n$amount\n                   diff       lwr       upr     p adj\nModerate-High -4.750000 -12.50468  3.004679 0.3025693\nNone-High     -8.916667 -16.67135 -1.161987 0.0213422\nNone-Moderate -4.166667 -11.92135  3.588013 0.3952176\n```\n\n\n:::\n:::\n\n       \n\nEnd of digression.\n\n\nNow we'll do it using `lm`, with contrasts later, and see how\nthings change:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine.2 <- lm(score ~ amount, data = caffeine)\nsummary(caffeine.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = score ~ amount, data = caffeine)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.833  -6.958  -2.458   6.354  15.167 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      76.833      2.235  34.383  < 2e-16 ***\namountModerate   -4.750      3.160  -1.503  0.14234    \namountNone       -8.917      3.160  -2.821  0.00803 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.741 on 33 degrees of freedom\nMultiple R-squared:  0.1946,\tAdjusted R-squared:  0.1458 \nF-statistic: 3.986 on 2 and 33 DF,  p-value: 0.02815\n```\n\n\n:::\n:::\n\n       \nLook at the slopes. They are `amount` followed by one of the\namounts of caffeine. R is using \"high\" as a baseline  (that's the\nfirst level alphabetically), so the\n`amountModerate` line is testing high vs.\\ moderate: high is\n*not* significantly higher, in terms of test scores, than\nmoderate. That's one of the things I wanted to test. What about the\ncoefficient for `amountNone`? That's none vs.\\ *high*,\nsince high was the baseline. This is, as we saw from Tukey,\nsignificant. But it is not what I said we wanted to test. \n\nExtra: in case you're curious, you can also get the regular analysis of\nvariance table as below. `anova` is multi-talented:\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(caffeine.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: score\n          Df  Sum Sq Mean Sq F value  Pr(>F)  \namount     2  477.72 238.861  3.9861 0.02815 *\nResiduals 33 1977.50  59.924                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n \n\nThe problem is that you can't naturally do Tukey this way, which is\noften what you want to do next. That's why we used `aov` before.\n\nSince we have a regression model (albeit a peculiar one), we can test\nwhether we should remove `amount` (that is, whether it has any\nimpact on test scores) this way too:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(caffeine.2, test = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSingle term deletions\n\nModel:\nscore ~ amount\n       Df Sum of Sq    RSS    AIC F value  Pr(>F)  \n<none>              1977.5 150.22                  \namount  2    477.72 2455.2 154.01  3.9861 0.02815 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n \n\nSame conclusion: there is some effect of caffeine level on test score.\n\n\n$\\blacksquare$\n\n(d) Obtain the different values of `amount`, in the order\nthat R has them.\n\n\nSolution\n\n\nCount them, or find the distinct ones:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine %>% group_by(amount) %>% summarize(count = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n  amount   count\n  <fct>    <int>\n1 High        12\n2 Moderate    12\n3 None        12\n```\n\n\n:::\n:::\n\n \n\nor there is this shortcut to the above:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine %>% count(amount)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n  amount       n\n  <fct>    <int>\n1 High        12\n2 Moderate    12\n3 None        12\n```\n\n\n:::\n:::\n\n \n\nOr\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine %>% distinct(amount)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 1\n  amount  \n  <fct>   \n1 High    \n2 Moderate\n3 None    \n```\n\n\n:::\n:::\n\n \n\nsince we didn't really need to know how many of each there were.\n\nThese would all have worked if `amount` had been text rather a\nfactor. If you have a genuine `factor`, you can also ask for\nits `levels`:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(caffeine, levels(amount))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"High\"     \"Moderate\" \"None\"    \n```\n\n\n:::\n:::\n\n \n\nor `summary` will count them up and list them:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaffeine %>% select(amount) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      amount  \n High    :12  \n Moderate:12  \n None    :12  \n```\n\n\n:::\n:::\n\n \n\nThis last won't work if you have a categorical-variable-as-text. It\nhas to be a genuine factor for it to work.\n\nThe categories are High, Moderate and None in that order.  For working\nwith contrasts, we need to have the thing we're making contrasts for\n(see below) as a `factor`, otherwise it won't work.\n\n\n$\\blacksquare$\n\n(e) Create a contrast that compares High with Moderate, ignoring\nNone. That is, create a vector whose length is the same as the\nnumber of levels of `amount`, and which has a 1 to represent\nHigh and a $-1$ to represent Moderate. \n\n\nSolution\n\n\nPut a 0 in for None:\n\n::: {.cell}\n\n```{.r .cell-code}\nc.hm <- c(1, -1, 0)\n```\n:::\n\n       \n\nHaving the 1 and the $-1$ the other way around would also have been fine.\n\n\n$\\blacksquare$\n\n(f) Create a contrast that compares \"any caffeine\" against\n\"none\" by comparing None against the average of Moderate and High.\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc.any <- c(-0.5, -0.5, 1)\n```\n:::\n\n \nNote that both our contrasts have coefficients that add up to zero, as\nthey must:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c.hm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n\n```{.r .cell-code}\nsum(c.any)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n \n\n\n$\\blacksquare$\n\n(g) Verify that your two contrasts are orthogonal.\n\n\nSolution\n\n\nMultiply them together and check that what you get adds up to zero:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c.hm * c.any)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n \n\nZero, so orthogonal. You can check that writing `c.any` as\n`c(-1,-1,2)` would also work (and still be orthogonal with\n`c.hm`), and so would writing it as `c(1,1,-2)`. \n\n\n$\\blacksquare$\n\n(h) Arrange your contrasts as columns of a matrix (using\n`cbind`), and say that you want to use these as contrasts for\n`amount` (in data frame `caffeine` or whatever you\ncalled it).\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c.hm, c.any)\ncontrasts(caffeine$amount) <- m\n```\n:::\n\n \n\n\n$\\blacksquare$\n\n(i) Fit the ANOVA as an `lm`, and look at the\n`summary`. What do you conclude about your contrasts?\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncaff.3 <- lm(score ~ amount, data = caffeine)\nsummary(caff.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = score ~ amount, data = caffeine)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.833  -6.958  -2.458   6.354  15.167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   72.278      1.290  56.022   <2e-16 ***\namountc.hm     2.375      1.580   1.503   0.1423    \namountc.any   -4.361      1.825  -2.390   0.0227 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.741 on 33 degrees of freedom\nMultiple R-squared:  0.1946,\tAdjusted R-squared:  0.1458 \nF-statistic: 3.986 on 2 and 33 DF,  p-value: 0.02815\n```\n\n\n:::\n:::\n\n \n\n`c.hm` was the contrast between high and moderate\ncaffeine. This is not significant (P-value 0.142), which is the same\nconclusion as Tukey, but the P-value here is quite a bit lower (and\nthus closer to being significant). There's a reason for that: here we\nare focusing in on the two contrasts that we really wanted to test,\nand ignoring the $F$-test and the Tukey that tell us stuff that we\ndon't care about. By focusing our comparison, we get a better\n(smaller) P-value.\n\n`c.any` was none vs.\\ average of any\ncaffeine. This one is significant, with a P-value of 0.023. So this\ncontrast tells us that having any caffeine is better than having none.\n\n\n$\\blacksquare$\n\n(j) What happens if you try to use high caffeine vs.\\ moderate\ncaffeine and moderate vs.\\ none as your two contrasts?\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc.hm <- c(1, -1, 0)\nc.mn <- c(0, 1, -1)\n```\n:::\n\n \n\nSo far so good: the coefficients add up to zero and they reflect the\nright comparisons. But now:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c.hm * c.mn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1\n```\n\n\n:::\n:::\n\n \n\nThis does *not* add up to zero, so these two contrasts are not\northogonal, and we can't do what we just did. R will give us an answer\nif we try it, but it'll be the *wrong* answer.^[Software like SAS, for example, has a way of making non-orthogonal contrasts orthogonal in a way that the user doesn't have to worry about, but in R, you are closer to the ground, so to speak, and you have to make it happen yourself.]\n\nThe best\ndescription I have seen of what to do here is by David Howell,^[Howell is the author of a famous text on Statistics in Psychology.] at\n[link](https://www.uvm.edu/~dhowell/StatPages/More_Stuff/R/AnovaOneway.html)\n(at the bottom).\nLet\nme try to follow his method. \n\nFirst we need a vector that is all 1's, which I have called\n`c0` below. Since each of our contrasts `c.hm` and\n`c.mn` have 3 things in them (3 groups), we need to add a\n\"dummy\" 3rd contrast to give us a $3\\times 3$ array of numbers:^[Which we are going to invert, as a matrix. But I get ahead of myself.]\n\n::: {.cell}\n\n```{.r .cell-code}\nc0 <- rep(1, 3)\nm <- cbind(c0, c.hm, c.mn)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     c0 c.hm c.mn\n[1,]  1    1    0\n[2,]  1   -1    1\n[3,]  1    0   -1\n```\n\n\n:::\n:::\n\n \n\nThis is what Howell calls an \"augmented\" matrix of contrasts, since\nit has our two contrasts as the second and third columns, plus\nthe extra dummy one. Next we invert this matrix of contrasts,\nwhich we can do because it's square. `t(m)` means \n\"take the matrix transpose of `m`\", if you're trying to keep up at the\nback, and `solve` finds a matrix inverse:\n\n::: {.cell}\n\n```{.r .cell-code}\nminv <- solve(t(m))\n```\n:::\n\n \n\nand then we remove the first column, which represents the contrast\nthat we didn't want anyway (what Howell calls \"deaugmenting\"):^[We are working with R matrices here rather than data frames, so we access elements, rows and columns using the square bracket notation: inside the square brackets, we put first the numbers of the rows we want, then a comma, then the numbers of the columns. There are two special pieces of notation, both of which I use here: leaving the row or column slot blank means all the rows or all the columns, and using a negative row or column number means all the rows or columns except the one(s) named. Thus my notation here is all the rows, and all the columns except for the first one. You can access data frames this way too, but the Tidyverse makes it much easier.]\n\n::: {.cell}\n\n```{.r .cell-code}\nm.contr <- minv[, -1]\nm.contr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           c.hm       c.mn\n[1,]  0.6666667  0.3333333\n[2,] -0.3333333  0.3333333\n[3,] -0.3333333 -0.6666667\n```\n\n\n:::\n\n```{.r .cell-code}\ncontrasts(caffeine$amount) <- m.contr\n```\n:::\n\n \n\nThe columns of `m.contr` are our new \ncontrasts. Note that they appear to be something else: high vs.\\ the\naverage of moderate and none, and none vs.\\ the average of moderate\nand high. They are actually\n*not* orthogonal, but if Howell is to be trusted,^[I think Howell is famous enough to be\ntrusted.] they can be\nused to test what we want. \nNow fit the model again:\n\n::: {.cell}\n\n```{.r .cell-code}\ncaff.4 <- lm(score ~ amount, data = caffeine)\nsummary(caff.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = score ~ amount, data = caffeine)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.833  -6.958  -2.458   6.354  15.167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   72.278      1.290  56.022   <2e-16 ***\namountc.hm     4.750      3.160   1.503    0.142    \namountc.mn     4.167      3.160   1.318    0.196    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.741 on 33 degrees of freedom\nMultiple R-squared:  0.1946,\tAdjusted R-squared:  0.1458 \nF-statistic: 3.986 on 2 and 33 DF,  p-value: 0.02815\n```\n\n\n:::\n:::\n\n \n\nThe rows `amountc.hm` and `amountc.mn` are the proper tests\nfor our contrasts `c.hm` and `c.mn`. \n`c.hm` is not significant (P-value 0.14) and\n`c.mn` is not significant either\n(P-value 0.20). This is the same significance as from Tukey, but note\nthat the P-values for the non-significant tests are much lower than\nthe corresponding ones from Tukey, once again because we have focused\non just these comparisons, and not on any others. We decided ahead of\ntime to test just these, and gave ourselves the best chance of finding\nsignificance that we could.\n\n$\\blacksquare$\n\n\n\n\n\n##  Who studies the most outside class?\n\n\n A social scientist wanted to see how many hours students\n studied outside of class. She took a random sample of 75 students\n from three different majors: math, social science and English, and\n recorded the number of weekly outside-class study hours for each\n student. The data can be found at\n [link](http://ritsokiguess.site/datafiles/studyhours.txt). The\n social scientist had two research questions: whether math students study\n more outside of class than the other students, and whether English and\n social science students study different amounts of time outside class.\n\n\n(a) Explain briefly why contrasts would be a better idea here\nthan ANOVA with Tukey.\n\n\nSolution\n\n\nThe researcher is not interested in all the comparisons between\nthe groups, but rather in two specific ones (as detailed in the\nquestion). So we should focus our attention on those\ncomparisons. This is what contrasts are for.\n\n$\\blacksquare$\n\n(b) Read in the data and make side-by-side boxplots of study\nhours by major. What do the boxplots suggest about the comparisons\nthat the researcher wants to make?\n\n\nSolution\n\n\nSeparated by one space. There appear to be some strange quotes\nin there, but we'll ignore those and see whether they cause any\ntrouble: \n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/studyhours.txt\"\nstudyhours <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 75 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (1): major\ndbl (2): id, hours\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nstudyhours\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 75 x 3\n      id major hours\n   <dbl> <chr> <dbl>\n 1     1 math     15\n 2     2 math     20\n 3     3 math     14\n 4     4 math     15\n 5     5 math     14\n 6     6 math     10\n 7     7 math     12\n 8     8 math      9\n 9     9 math     10\n10    10 math     11\n# i 65 more rows\n```\n\n\n:::\n:::\n\n        \n\nSo far so good. 75 students, in tidy format.\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(studyhours, aes(x = major, y = hours)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-pdf/studyhours-2-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nThis suggests that the math students study more than the others, but\nthe English and social science students study about the same amount.\n\nI see some rather consistent right-skewness here (but no outliers). We\nhave 25 observations in each group, a decent amount of data, so I'm\nnot too worried, but a transformation could be a good idea, something\nlike square root, perhaps. The spreads are not that unequal, but it\n*is* true that the Math students have both the largest median\n*and* the largest spread, and the social science students are the\nlowest on both.\n\nExtra: Box-Cox also works on ANOVA-type data, since that is an `lm`\nkind of model:\n\n::: {.cell}\n\n```{.r .cell-code}\nboxcox(hours ~ major, data = studyhours)\n```\n\n::: {.cell-output-display}\n![](anova-revisited_files/figure-pdf/studyhours-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nThis suggests that some kind of transformation would be a good idea\n(no transformation, power 1, is not supported by the data). My guess\nof 0.5 is not bad; that, or something a bit less like 0.25 (fourth\nroot) would be good. Even log is supportable. But we'll proceed\nwithout transformation in this question to give you some practice with\ncontrasts. Despite appearances, I do (sometimes) like to make things\nnot so complicated!\n\n$\\blacksquare$\n\n(c) Set up contrasts for each of the researcher's research\nquestions, bearing in mind the levels of `major` and the\norder in which they come. (For the `Math` contrast, you want\nMath against the average of the other two.)\n\n\nSolution\n\n\nWe need to know what the categories of `major` are, so that\nwe can set up the contrasts correctly, so let's start with that:\n\n::: {.cell}\n\n```{.r .cell-code}\nstudyhours %>% select(major) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    major          \n Length:75         \n Class :character  \n Mode  :character  \n```\n\n\n:::\n:::\n\n \n\nOh. Yeah. We never turned `major` into a factor. We'd better do\nthat, and then try again:\n\n::: {.cell}\n\n```{.r .cell-code}\nstudyhours <- studyhours %>% mutate(major = factor(major))\nstudyhours %>% select(major) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     major   \n english:25  \n math   :25  \n socsci :25  \n```\n\n\n:::\n:::\n\n \n\nIn alphabetical order.\n\nAll right, contrasts. The English vs.\\ social science one is easier,\nso we'll do that first. Just set it up with a 1 for one of them and a\n$-1$ for the other and 0 for math, in the right order according to\nwhat the levels are, viz:\n\n::: {.cell}\n\n```{.r .cell-code}\nc.eng.socsci <- c(1, 0, -1)\n```\n:::\n\n \n\nOr `c(-1,0,1)` would be just as good.\n\nThe other one is a bit trickier, because you want math against the\naverage of the others, like\n$$\\mbox{math}-(\\mbox{English}+\\mbox{socsci})/2.$$ \nThis translates into contrast-ese like this, making sure to get Math\nin the middle where it belongs:^[As I failed to do the first time.]\n\n::: {.cell}\n\n```{.r .cell-code}\nc.math.others <- c(-0.5, 1, -0.5)\n```\n:::\n\n \n\nThe coefficients have to add up to zero, so I have to have two halves\nto balance my one 1. Or I can use two $-1$s and a 2.\n\n$\\blacksquare$\n\n(d) Verify that your two contrasts are orthogonal.\n\n\nSolution\n\n\nMultiply them together (elementwise, which is how R does it)\nand show that what you get adds up to zero:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c.eng.socsci * c.math.others)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n \n\nZero. Orthogonal.\n\nSo we are safely in \"familiar\" territory, not in the \nhere-be-dragons^[On ancient maps, people didn't know what was  in certain parts of the world, because no-one had ever explored  them, so they wrote on the map \"here be dragons\".] land of\nnon-orthogonal contrasts.\n\n$\\blacksquare$\n\n(e) Create a matrix of contrasts (using `cbind`) and let\n`lm` know that these are contrasts for `major`, in\ndata frame `studyhours` (or whatever you called it).\n\n\nSolution\n\n\nSo, like the example in lecture (where the\n`contrasts(model)` was admittedly rather confusing):\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c.math.others, c.eng.socsci)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     c.math.others c.eng.socsci\n[1,]          -0.5            1\n[2,]           1.0            0\n[3,]          -0.5           -1\n```\n\n\n:::\n\n```{.r .cell-code}\ncontrasts(studyhours$major) <- m\n```\n:::\n\n        \n\n$\\blacksquare$\n\n(f) Fit the model using `lm`. What do you conclude about\nyour contrasts?\n\n\nSolution\n\n\nPretend the ANOVA is a regression (though you can fit ANOVAs\neither way: we just used `aov` before because we were\ngoing to follow up with Tukey):\n\n::: {.cell}\n\n```{.r .cell-code}\nstudyhours.1 <- lm(hours ~ major, data = studyhours)\nsummary(studyhours.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = hours ~ major, data = studyhours)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6.44  -2.48  -0.48   2.52  10.56 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          7.3200     0.3980  18.392  < 2e-16 ***\nmajorc.math.others   2.1200     0.5628   3.767 0.000335 ***\nmajorc.eng.socsci    0.7800     0.4874   1.600 0.113936    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.447 on 72 degrees of freedom\nMultiple R-squared:  0.1887,\tAdjusted R-squared:  0.1662 \nF-statistic: 8.374 on 2 and 72 DF,  p-value: 0.0005375\n```\n\n\n:::\n:::\n\n        \n\nThere is a seriously significant difference between the math students\nand the others. There is not, however, any kind of difference between\nthe mean study hours of the English and social science students. \n\n$\\blacksquare$\n\n(g) Are you surprised by the significance or non-significance you\nfound in the previous part? Explain briefly.\n\n\nSolution\n\n\nGo back and compare with the  boxplots. The math students\nstudied noticeably more than the others, so it is not\nsurprising that this difference came out significant. The\nmedian study times for the English and social science students\nwere similar, so it is not at all surprising that this difference\nfailed to be significant.\n\nWhen you set up contrasts, *these* are the tests you are\ninterested in, so there is no reason for following up with\nTukey or anything else. But you have to be able to say ahead of\ntime which contrasts you want to test. This is in\ncontrast^[In contrast. Get it? No? Well, never mind then.] to Tukey, where you don't have to decide\nwhich comparisons interest you until right at the end.\n\nAnother question you might have had is \n\"how many contrasts can I do\"? To answer this, go back and look at the ANOVA table. If\nyou run an ANOVA using `lm`, you get the ANOVA table by\npassing the fitted model object into `anova` rather than\n`summary`:^[`anova` is one of R's  multi-purpose tools; what it does depends on what you feed it.]\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(studyhours.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: hours\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nmajor      2 198.96   99.48  8.3737 0.0005375 ***\nResiduals 72 855.36   11.88                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n        \n\nTwo degrees of freedom for `major`, so we can do 2\ncontrasts. (The example in class had four models of chainsaw, so 3 df\nfor model, so 3 contrasts possible.) What if we don't use all those\ncontrasts up? Try it and see:\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c.math.others)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     c.math.others\n[1,]          -0.5\n[2,]           1.0\n[3,]          -0.5\n```\n\n\n:::\n\n```{.r .cell-code}\ncontrasts(studyhours$major) <- m\nstudyhours.2 <- lm(hours ~ major, data = studyhours)\nsummary(studyhours.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = hours ~ major, data = studyhours)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -6.44  -2.48  -0.48   2.52  10.56 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          7.3200     0.3980  18.392  < 2e-16 ***\nmajorc.math.others   2.1200     0.5628   3.767 0.000335 ***\nmajor               -1.1031     0.6893  -1.600 0.113936    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.447 on 72 degrees of freedom\nMultiple R-squared:  0.1887,\tAdjusted R-squared:  0.1662 \nF-statistic: 8.374 on 2 and 72 DF,  p-value: 0.0005375\n```\n\n\n:::\n:::\n\n\n\nThe two P-values are identical, but the second one is not now\nidentified with any contrast (so we just ignore it). If we were only\ninterested in how math students compared with the rest, we could test\nit this way.\n\nOr, we could relabel the students as \"math\" and \"other\" and just\ndo a two-sample $t$-test. To do this, we need to delve into\n`forcats` (which is a part of the `tidyverse`). It deals\nwith categorical variables which are genuine factors, which we haven't\nhad much cause to do so far. But now we do. What we want to do is to\n*recode* the levels of `major`, which is done by\n`fct_recode`:\n\n::: {.cell}\n\n```{.r .cell-code}\nstudyhoursx <- studyhours %>%\n  mutate(mathrest = fct_recode(major,\n    \"rest\" = \"english\",\n    \"rest\" = \"socsci\"\n  ))\nstudyhoursx %>% count(mathrest)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 2\n  mathrest     n\n  <fct>    <int>\n1 rest        50\n2 math        25\n```\n\n\n:::\n:::\n\n \n\nThe way `fct_recode` works is that you first give a factor,\nhere `major`, then you define a list of new levels in terms of\nthe old ones. We want a student whose major is either English or\nSocial Science to end up in the new not-math group that we'll call\n`rest`, so we need two lines inside `fct_recode`, one\nthat says that the new `rest` group includes the old\n`english` majors, and another that says that `rest` also\nincludes the old `socsci` majors. Any levels not mentioned\n(here `math`) are left unchanged.\n\nI did this wrong the first time: I got the things before and after the\n`=` in `fct_recode` the wrong way around.\n\nThe last line is to check that the result makes sense. I previously\nhad 25 students in each major. Now I have 25 students for whom\n`mathrest` is `math` (the math majors) and $50=25+25$\nstudents for whom `mathrest` is `rest` (everyone else). \n\nNow, the $t$-test.\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(hours ~ mathrest, data = studyhoursx, var.equal = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  hours by mathrest\nt = -3.7269, df = 73, p-value = 0.0003796\nalternative hypothesis: true difference in means between group rest and group math is not equal to 0\n95 percent confidence interval:\n -4.880528 -1.479472\nsample estimates:\nmean in group rest mean in group math \n              6.26               9.44 \n```\n\n\n:::\n:::\n\n \n\nThis is very close to, but not the same as, the test with the contrasts,\nbecause we are not quite testing the same thing. Here, we are\ncomparing the mean of the math students to the mean of everyone else,\nthrown together into one big bag, but with the contrasts, we are\ncomparing the mean of the math students with the *average of the\nmeans* of the other two groups, treating them as different. (Not\nclear? Well, it's not that clear to me either.)\n\nThat business with the `var.equal=T`? This is doing a pooled\n$t$-test. I did that here because the ANOVA is assuming equal spreads\nwithin the groups (which is what a pooled $t$-test does) and I thought\nI should do my best to be consistent. A pooled $t$-test is really a\ntwo-group one-way ANOVA, or at least it is if it is done two-sided.\n\n$\\blacksquare$\n \n\n\n\n##  Mental context\n\n\n It is believed that being in the same mental context for\nlearning and for testing leads to better test scores. An experiment\nwas carried out to test this. During the learning phase, subjects\nlearned a list of 80 words in a room painted orange and decorated with\nposters, paintings and other paraphernalia.^[This is a fancy  word for *stuff*.] A memory test was given to all subjects\nimmediately after they had learned the words, to give the impression\nthat the experiment was over. (The results of this test were\ndiscarded.) One day later, subjects were unexpectedly re-tested under\ndifferent experimental conditions and asked to write down all the\nwords of the original list that they could remember. The re-test took\nplace in five different conditions, which subjects were randomly\nallocated to one of:\n\n\n\n* Same context: in the original orange-painted room.\n\n* Different context: in a very different room, painted grey and\nlocated in a different part of campus.\n\n* Imaginary context: in the grey room, but subjects are asked to\nremember the orange room in which they took the original test. To\nhelp them with this, the experimenter begins by asking them several\nquestions about the orange room and the objects in it.\n\n* Photographed context: in the grey room, but subjects are shown\nphotographs of the orange room.\n\n* Placebo context: in the grey room, with subjects first being\nasked to recall their living room.\n\n\nIn each case, the response variable was the number of words on the\noriginal list successfully recalled by each subject.\n\n50 subjects in total completed the experiment, 10 under each of the 5\nconditions. \n\nThe researchers had four research hypotheses to test with the data:\n\n\n\n* Groups where the context matches (is the same, or is simulated\nby imagining or photograph) will perform better than groups with\ndifferent or placebo contexts.\n\n* The group with the same context will differ from the group with\nimaginary or photographed contexts.\n\n\n* The imaginary-context group will differ from the\nphotographed-context group.\n\n* The different-context group will differ from the placebo-context group.\n\n\nThe research hypotheses are (as is usual) written as\n*alternative* hypotheses. We can rewrite them as null\nhypotheses, with some extra wording to facilitate converting them\ninto contrasts, like this:\n\n\n* The mean of the `same`, `imaginary` and\n`photograph` groups (group means) is equal to the mean of the\n`different` and `placebo` groups (group means).\n\n* The mean of the `imaginary` and `photograph`\ngroups is equal to the (mean of the) `same` group.\n\n* The `imaginary` and the `photograph` groups will\nhave the same mean.\n\n* The `different` and the `placebo` groups will\nhave the same mean.\n\nThe data are in\n[link](http://ritsokiguess.site/datafiles/smith.txt) (the\noriginal researcher's name was Smith). \n\n\n(a) Read in the data and verify that you have a column called\n`context` that is text and a column called\n`words` that is a (whole) number.\n\n\nSolution\n\n\nThe usual thing --- read in the data appropriately and look at the\ndata frame you got:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/smith.txt\"\nsmith <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 50 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (1): context\ndbl (2): id, words\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nsmith\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 x 3\n      id context words\n   <dbl> <chr>   <dbl>\n 1     1 same       25\n 2     2 same       26\n 3     3 same       17\n 4     4 same       15\n 5     5 same       14\n 6     6 same       17\n 7     7 same       14\n 8     8 same       20\n 9     9 same       11\n10    10 same       21\n# i 40 more rows\n```\n\n\n:::\n:::\n\n       \n\n`dbl` actually means \"decimal number\", but these look like whole numbers, so I think we are good.\n      \n$\\blacksquare$\n\n(b) Turn `context` into a `factor`, within the\ndata frame. (We are going to be doing contrasts). Display how the\ndata frame now looks.\n\n\nSolution\n\n\nUse `mutate` and assign everything back to what it was\nbefore:\n\n::: {.cell}\n\n```{.r .cell-code}\nsmith <- smith %>% mutate(context = factor(context))\nsmith\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 x 3\n      id context words\n   <dbl> <fct>   <dbl>\n 1     1 same       25\n 2     2 same       26\n 3     3 same       17\n 4     4 same       15\n 5     5 same       14\n 6     6 same       17\n 7     7 same       14\n 8     8 same       20\n 9     9 same       11\n10    10 same       21\n# i 40 more rows\n```\n\n\n:::\n:::\n\n    \n\nNote that `context` is now labelled as the factor that we made.\n\n$\\blacksquare$\n\n(c) What are the names of the five contexts in the data set\n(just display them),\nand what order are they in?\n\n\nSolution\n\n\nYou have lots of choices now, since `context` is a factor\n(and can also be treated as text). \nThe most obvious factor-based way is this:\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(smith$context)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"different\"  \"imaginary\"  \"photograph\" \"placebo\"    \"same\"      \n```\n\n\n:::\n:::\n\n       \n\nor use `summary`:\n\n::: {.cell}\n\n```{.r .cell-code}\nsmith %>% select(context) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       context  \n different :10  \n imaginary :10  \n photograph:10  \n placebo   :10  \n same      :10  \n```\n\n\n:::\n:::\n\n \n\nOr treat `context` as text, such as this way:\n\n::: {.cell}\n\n```{.r .cell-code}\nsmith %>% count(context)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 2\n  context        n\n  <fct>      <int>\n1 different     10\n2 imaginary     10\n3 photograph    10\n4 placebo       10\n5 same          10\n```\n\n\n:::\n:::\n\n       \n\nThese all display the contexts in alphabetical order.\n\nOr display the distinct values:\n\n::: {.cell}\n\n```{.r .cell-code}\nsmith %>% distinct(context)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 1\n  context   \n  <fct>     \n1 same      \n2 different \n3 imaginary \n4 photograph\n5 placebo   \n```\n\n\n:::\n:::\n\n \n\nor, without using the `tidyverse`,\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(smith$context)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] same       different  imaginary  photograph placebo   \nLevels: different imaginary photograph placebo same\n```\n\n\n:::\n:::\n\n \nThese two *don't* display things in alphabetical order, because\nthey display things as they appear in the file. This is not the order\nwe want, though the second way *does* display the `Levels`\nin the right order.\n      \n\n$\\blacksquare$\n\n(d) Write each of the four research hypotheses (in the\nnull-hypothesis versions) as R vectors that can be used to make\ncontrasts. (This will mean getting the contexts in the right\norder. If you get stuck, do the last two first, since they're\neasiest. The first one is actually the hardest.)\n\n\nSolution\n\n\nAll right, let's go from the bottom:\n\n\n* Different and placebo have same means. These are 1st and 4th.\n\n::: {.cell}\n\n```{.r .cell-code}\nc4 <- c(1, 0, 0, -1, 0)\n```\n:::\n\n         \n\n* Imaginary and photograph have same means. 2nd and 3rd:\n\n::: {.cell}\n\n```{.r .cell-code}\nc3 <- c(0, 1, -1, 0, 0)\n```\n:::\n\n   \n\n\n* Imaginary and photograph together same as `same`. This\ntime we have two means being compared with one, so we need to give\nthe two means half weight. 2nd and 3rd against 5th:\n\n::: {.cell}\n\n```{.r .cell-code}\nc2 <- c(0, 1 / 2, 1 / 2, 0, -1)\n```\n:::\n\n   \n\n\n* (Same and imaginary and photograph) vs.\\ (different or placebo):\n2nd, 3rd and 5th with weight $1/3$ (three of them) against 1st and\n4th with weight $1/2$ (2 of them):\n\n::: {.cell}\n\n```{.r .cell-code}\nc1 <- c(-1 / 2, 1 / 3, 1 / 3, -1 / 2, 1 / 3)\n```\n:::\n\n   \n\nVariations: you can switch the sign on everything within a\ncontrast (since it doesn't matter which is plus and which is\nminus). You can also multiply through by anything to get rid of\nthe fractions, for example these:\n\n::: {.cell}\n\n```{.r .cell-code}\nc2 <- c(0, 1, 1, 0, -2)\nc1 <- c(-3, 2, 2, -3, 2)\n```\n:::\n\n       \n\nAll that matters is that the coefficients add up to zero, and that they are the right size and sign relative to each other.\n      \n\n$\\blacksquare$\n\n(e) Pick two of your contrasts (doesn't matter which two) and\ndemonstrate that they are orthogonal.\n\n\nSolution\n\n\nMultiply your chosen contrasts together elementwise, and show\nthat the results add to zero, eg. by showing the whole thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nc1 * c2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  0.0000000  0.1666667  0.1666667  0.0000000 -0.3333333\n```\n\n\n:::\n:::\n\n    \nwhich adds to zero because it is $2/6$ minus $1/3$,\nor by explicitly summing the elementwise product:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c1 * c3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n \n\nAny pair is good.\n      \n\n$\\blacksquare$\n\n(f) Collect your contrasts together into a matrix, and\ntell `lm` that these are the contrasts for `context`.\n\n\nSolution\n\n\nThis:\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c1, c2, c3, c4)\ncontrasts(smith$context) <- m\n```\n:::\n\n       \n\nSlipping off into another aside, you might have been wondering whether\nthere was a way to test \n*all* the contrasts for orthogonality at once. There is, and it\ndepends on the rules for matrix multiplication. We want to test all\nthe *columns* of `m` for orthogonality, but matrix\nmultiplication works by combining a *row* with a column. No\nmatter, *transposing* a matrix interchanges rows and columns, so\nthat in math, we want to look at the matrix $M^T M$. In R,\n`%*%` means \"matrix multiply\".^[In R, percents around something mean that it is a special version of that something. Hence the notation for matrix-multiply and the pipe symbol. A regular * when used for multiplying matrices in R will multiply them element by element.] Thus,\n\n::: {.cell}\n\n```{.r .cell-code}\nt(m) %*% m\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          c1  c2 c3 c4\nc1 0.8333333 0.0  0  0\nc2 0.0000000 1.5  0  0\nc3 0.0000000 0.0  2  0\nc4 0.0000000 0.0  0  2\n```\n\n\n:::\n:::\n\n \nThis matrix-multiplies the transpose of `m` by `m`\nitself. There are numbers down the top-left to bottom-right diagonal,\nbut don't worry about these, since a contrast doesn't have to be\northogonal with itself. The thing to note is that \n*all the other  elements* of this matrix are \n*zero*: that means that each of\nthe four contrasts is orthogonal to each of the other three.\n      \n\n$\\blacksquare$\n\n(g) Fit a model with `lm`, and display the results.\n\n\nSolution\n\n\nWe're past the hard part:\n\n::: {.cell}\n\n```{.r .cell-code}\nsmith.1 <- lm(words ~ context, data = smith)\nsummary(smith.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = words ~ context, data = smith)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n  -9.0   -4.0   -1.5    4.6   11.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  14.8000     0.8129  18.207  < 2e-16 ***\ncontextc1     8.6000     1.9912   4.319 8.52e-05 ***\ncontextc2    -0.3333     1.4841  -0.225    0.823    \ncontextc3    -0.1000     1.2853  -0.078    0.938    \ncontextc4     0.5000     1.2853   0.389    0.699    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.748 on 45 degrees of freedom\nMultiple R-squared:  0.2954,\tAdjusted R-squared:  0.2327 \nF-statistic: 4.715 on 4 and 45 DF,  p-value: 0.002902\n```\n\n\n:::\n:::\n\n       \n      \n\n$\\blacksquare$\n\n(h) For each of the original research hypotheses, what do you\ninfer about them?\n\n\nSolution\n\n\nEven though I generated the contrasts backwards, I maintained\nthe numbering so that they refer to the original numbered\nhypotheses. You might have named them something more mnemonic;\nthat works too, and is quite possibly better.\nAnyway:\n\n\n* Matching context better than non-matching context:\nstrongly significant (P-value 0.000085). (Strictly, this is a\ntwo-sided test, but the way I constructed the contrast, this\nshould be significantly *positive* if the research\nhypothesis is true, and it is.)\n\n* Same context *not* different from\nimaginary/photographed context (P-value 0.823)\n\n* Imaginary context *not* different from photographed context (P-value 0.938).\n\n* Different context *not* different from placebo\ncontext (P-value 0.699). \n\n\nI wanted you to match up the research hypotheses with the\nP-values, as above, and state a conclusion about each one. If\nyou do that, I am happy.\n\nTaking this back to the original research, I think the\nfirst hypothesis was the most immediately important of the four:\nwe were able to show that having (or faking up) the original\nroom helped with recall. After that, it didn't matter how it was\ndone: being in the original room was not different from\nimagining the original room (by thinking about it or seeing a\nphoto of it). Failing to recall the original room was equally\nbad, whether the subjects were in a different room and not asked\nto think about the original orange room, or whether they were\nliterally asked to think about another room entirely.\n\nContrasts enabled us to tackle this problem and gain a very clear\nconclusion: recalling the original orange room is helpful, but\nit doesn't matter how you do it.\n\nHow big of a difference does thinking about the orange room\nmake? You can use the 2 SE thing to get a 95\\% confidence interval:\nthe difference in the (mean of the) recall-orange-room means and\nthe (mean of the) don't-recall means is between about 4.6 and\n12.6 words (out of 80). I leave it for you to decide whether\nthat is practically important as well as being statistically significant.\n\n$\\blacksquare$\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Trying on shirts\n\nDoes it make a difference if you see somebody else trying on a shirt\nbefore you do, and if so, does it matter what kind of person it is?\n\nAn experiment was carried out in a university bookstore, with students\nwho wanted to try on a shirt serving as (unsuspecting) experimental\nsubjects. When a student wanted to try on a shirt, the sales associate\ntold them that there was only one shirt left, and it was being tried on\nby an \"other customer\". This \"other customer\" was actually a\n\"confederate\" of the experimenter (that means, they were pretending to\nbe a real customer but were actually part of the experiment). The \"other\ncustomer\" was always female: either an attractive well-dressed model, or\nan average-looking student wearing jeans. The \"other customer\" would\ncome out of the dressing room and hand the shirt to the sales associate,\nwho would give it to the student who wanted to try it on. When the\nstudent had tried on the shirt, they were asked to rate it on a 7-point\nscale (on five different dimensions, and those five scores were then\naveraged). Does a student's evaluation depend on whether the student was\nmale or female, and whether the \"other customer\" was a model or a\nstudent? There was also a control group, where the student was handed\nthe shirt directly by the sales associate, without the \"other customer\"\nbeing involved at all.\n\nThere were thus five treatments: male students who saw a model, male\nstudents who saw a student, female students who saw a model, female\nstudents who saw a student, and the control group. There were 25\nstudents in each treatment group.\n\nThe data from this experiment can be found at\n[link](http://ritsokiguess.site/datafiles/shirts.csv).\n\n(a) Read in and display the data. How many observations do you have, and\n    is that what you should have?\n\nSolution\n\n`read_csv`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/shirts.csv\"\nshirts <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 125 Columns: 2\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (1): treatment\ndbl (1): score\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nshirts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 125 x 2\n   treatment         score\n   <chr>             <dbl>\n 1 male_seeing_model   6.8\n 2 male_seeing_model   4.7\n 3 male_seeing_model   5.1\n 4 male_seeing_model   4.7\n 5 male_seeing_model   5.5\n 6 male_seeing_model   6  \n 7 male_seeing_model   4.4\n 8 male_seeing_model   6  \n 9 male_seeing_model   5.3\n10 male_seeing_model   6.3\n# i 115 more rows\n```\n\n\n:::\n:::\n\nThere were 5 treatment groups with 25 students in each, so there should\nbe, and are, $5 \\times 25=125$ observations.\n\n$\\blacksquare$\n\n(b) Turn `treatment` into a `factor` in your data frame. (You can use\n    the same name as the text `treatment` that you read in from the\n    file.)\n\n    The experimenters wanted to compare four specific things in their\n    analysis:\n\n    evaluation scores between male students who saw a (female) model and\n    male students who saw a (female) student\n\n    evaluation scores between female students who saw a (female) model\n    and female students who saw a (female) student\n\n    evaluation scores for male and for female students (overall)\n\n    evaluation scores for the (average of the) four genuine treatments\n    and for the control group\n\nSolution\n\nThus:\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts <- shirts %>% mutate(treatment = factor(treatment))\n```\n:::\n\nand for checking:\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 125 x 2\n   treatment         score\n   <fct>             <dbl>\n 1 male_seeing_model   6.8\n 2 male_seeing_model   4.7\n 3 male_seeing_model   5.1\n 4 male_seeing_model   4.7\n 5 male_seeing_model   5.5\n 6 male_seeing_model   6  \n 7 male_seeing_model   4.4\n 8 male_seeing_model   6  \n 9 male_seeing_model   5.3\n10 male_seeing_model   6.3\n# i 115 more rows\n```\n\n\n:::\n:::\n\nsee that `treatment` is now definitely a factor rather than a\ncategorical variable represented as a piece of text.\n\n$\\blacksquare$\n\n(c) List the treatments in the order that they are in within your\n    `factor`. (There are lots of ways to do this; any one of them except\n    for `distinct` is good.)\n\nSolution\n\nThis is the most direct:\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(shirts$treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"control\"               \"female_seeing_model\"   \"female_seeing_student\"\n[4] \"male_seeing_model\"     \"male_seeing_student\"  \n```\n\n\n:::\n:::\n\nor you can do one of the `tidyverse`-style ways, such as\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts %>% count(treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 2\n  treatment                 n\n  <fct>                 <int>\n1 control                  25\n2 female_seeing_model      25\n3 female_seeing_student    25\n4 male_seeing_model        25\n5 male_seeing_student      25\n```\n\n\n:::\n:::\n\nor\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts %>% distinct(treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 1\n  treatment            \n  <fct>                \n1 male_seeing_model    \n2 male_seeing_student  \n3 female_seeing_model  \n4 female_seeing_student\n5 control              \n```\n\n\n:::\n:::\n\nexcept that `distinct` shows you the values in the order that they\nappear in the data file, which is *not* the order that they appear in\nthe factor. So that's why I asked you not to do it that way.\n\nAlphabetical order, is the moral of the story.\n\nExtra: you can make them appear in the order they appear in the data, if\nyou want to (and if you know what you are doing):\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts %>% mutate(trt2 = fct_inorder(treatment)) -> d\nlevels(d$trt2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"male_seeing_model\"     \"male_seeing_student\"   \"female_seeing_model\"  \n[4] \"female_seeing_student\" \"control\"              \n```\n\n\n:::\n:::\n\n`fct_inorder` *creates* a factor whose levels are in the order that they\nappeared in the data. If this is what you want, you can go ahead and do\nthis, and use this order when you create your contrasts. It will work,\nand it will be good even though your contrasts will look different from\nmine.\n\n$\\blacksquare$\n\n(d) <a name=\"part:mean-eval\">\\*</a> Obtain a table of mean evaluation\n    scores for each treatment group.\n\nSolution\n\nWe will use this later when assessing the significance of the contrasts.\nIt's the usual group-by and summarize:\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts %>%\n  group_by(treatment) %>%\n  summarize(m = mean(score))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 2\n  treatment                 m\n  <fct>                 <dbl>\n1 control                4.03\n2 female_seeing_model    4.07\n3 female_seeing_student  3.36\n4 male_seeing_model      5.42\n5 male_seeing_student    3.25\n```\n\n\n:::\n:::\n\nExtra: how does this come out if you have your factor levels in a\nnon-alphabetical order?\n\n::: {.cell}\n\n```{.r .cell-code}\nd %>% group_by(trt2) %>% summarize(m = mean(score))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 2\n  trt2                      m\n  <fct>                 <dbl>\n1 male_seeing_model      5.42\n2 male_seeing_student    3.25\n3 female_seeing_model    4.07\n4 female_seeing_student  3.36\n5 control                4.03\n```\n\n\n:::\n:::\n\nAh, it respects the order of the levels of the factor: that is to say,\nthe treatment groups appear here in the order that they were in the\ndata, because the factor `trt2` was created to make that happen.\n\n`forcats` has other tools to re-order the levels of a factor, lump\nfactor levels together to make a category \"other\", and so on. These also\nwork if you start with a categorical variable as text: it *creates* a\nfactor with those properties.\n\n$\\blacksquare$\n\n(e) The experimenters wanted to compare four specific things in their\n    analysis:\n\n-   evaluation scores between male students who saw a (female) model and\n    male students who saw a (female) student\n\n-   evaluation scores between female students who saw a (female) model\n    and female students who saw a (female) student\n\n-   evaluation scores for male and for female students (overall)\n\n-   evaluation scores for the (average of the) four genuine treatments\n    and for the control group\n\nCreate contrasts, with suitable names, using vectors with appropriate\nvalues.\n\nSolution\n\n::: {.cell}\n\n```{.r .cell-code}\nshirts %>% count(treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 2\n  treatment                 n\n  <fct>                 <int>\n1 control                  25\n2 female_seeing_model      25\n3 female_seeing_student    25\n4 male_seeing_model        25\n5 male_seeing_student      25\n```\n\n\n:::\n:::\n\nThese, in that order, are comparisons of treatments 4 and 5:\n\n::: {.cell}\n\n```{.r .cell-code}\nc_mms <- c(0, 0, 0, 1, -1)\n```\n:::\n\ntreatments 2 and 3:\n\n::: {.cell}\n\n```{.r .cell-code}\nc_fms <- c(0, 1, -1, 0, 0)\n```\n:::\n\n(in these two the 1 and $-1$ can also be the other way around)\n\nthe average of 2 and 3 vs.the average of 4 and 5:\n\n::: {.cell}\n\n```{.r .cell-code}\nc_mf <- c(0, 0.5, 0.5, -0.5, -0.5)\n```\n:::\n\nor you can use 1 and $-1$ instead of the 0.5s, or you can switch the\nsigns around. I like the 0.5 values to remind me it's an average of two\nmeans.\n\nFinally\n\n::: {.cell}\n\n```{.r .cell-code}\nc_tc <- c(1, -0.25, -0.25, -0.25, -0.25)\n```\n:::\n\nor multiply through by 4 to get rid of the fractions, or have the\nnegative sign on the first one and positive signs on the others.\n\nI tried to give the contrasts mnemonic but short names, so that I would\nremember which was which.\n\n$\\blacksquare$\n\n(f) Pick two of your contrasts (doesn't matter which two) and\n    demonstrate that they are orthogonal.\n\nSolution\n\nMultiply them together (elementwise, which is what `*` does) and add\nthem up, showing that you get zero, for example:\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(c_mf * c_tc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\nCheck (mops brow).\n\n$\\blacksquare$\n\n(g) Collect all your contrasts together into a matrix and declare that\n    they are contrasts for `treatment` within your data frame (whatever\n    you called it).\n\nSolution\n\nI called my data frame `shirts`, so I need to do this:\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- cbind(c_mms, c_fms, c_mf, c_tc)\ncontrasts(shirts$treatment) <- m\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     c_mms c_fms c_mf  c_tc\n[1,]     0     0  0.0  1.00\n[2,]     0     1  0.5 -0.25\n[3,]     0    -1  0.5 -0.25\n[4,]     1     0 -0.5 -0.25\n[5,]    -1     0 -0.5 -0.25\n```\n\n\n:::\n:::\n\nThere's no output here; we'll see in a moment whether it worked.\n\nExtra: once you've created the matrix `m`, it gives you a second way to\ntest the contrasts for orthogonality, all at once:\n\n::: {.cell}\n\n```{.r .cell-code}\nt(m) %*% m\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      c_mms c_fms c_mf c_tc\nc_mms     2     0    0 0.00\nc_fms     0     2    0 0.00\nc_mf      0     0    1 0.00\nc_tc      0     0    0 1.25\n```\n\n\n:::\n:::\n\nThis matrix-multiplies the transpose of `m` by `m`, so it's testing each\ncolumn of `m` to see whether it's orthogonal to each other column. The\ncolumns don't have to be orthogonal to themselves, hence the non-zeros\ndown the diagonal, but all the off-diagonal entries are zero. Hence each\ncontrast is orthogonal to each other contrast.\n\nOr even:\n\n::: {.cell}\n\n```{.r .cell-code}\nz <- t(m) %*% m\nall(z[row(z) != col(z)] == 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\nThat says (a little breathlessly) that it is true that all the elements\nof $M^TM$ that are off the diagonal are zero.[^_shirts-1]\n\n[^_shirts-1]: The thing inside the square brackets says only to look at\n    the elements of $M^TM$ whose row number and whose column number are\n    different; it is perhaps easier to reason that elements of a matrix\n    whose row number and column number are the *same* are *on* the\n    diagonal, for example the element in row 2, column 2.\n\n$\\blacksquare$\n\n(h) Predict evaluation score from treatment *as a regression*, and\n    display the results.\n\nSolution\n\nOnce you have everything set up, it's just a matter of going through the\nprocess:\n\n::: {.cell}\n\n```{.r .cell-code}\nscore.1 <- lm(score ~ treatment, data = shirts)\nsummary(score.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = score ~ treatment, data = shirts)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.860 -0.760  0.032  0.840  3.640 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      4.0256     0.1231  32.705  < 2e-16 ***\ntreatmentc_mms   1.0820     0.1946   5.560 1.66e-07 ***\ntreatmentc_fms   0.3540     0.1946   1.819   0.0714 .  \ntreatmentc_mf   -0.6200     0.2752  -2.253   0.0261 *  \ntreatmentc_tc    0.0064     0.2462   0.026   0.9793    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.376 on 120 degrees of freedom\nMultiple R-squared:  0.2467,\tAdjusted R-squared:  0.2216 \nF-statistic: 9.823 on 4 and 120 DF,  p-value: 6.576e-07\n```\n\n\n:::\n:::\n\nNote how the contrasts have appeared as \"slopes\" in our regression. (If\nthis didn't happen for you, go back and check what you did. Probably\nsomething gave you an error before, in that case.)\n\nYour slopes can differ in terms of sign and possibly value from mine,\nbut the $t$-statistics and P-values should be the same as mine.\n\n$\\blacksquare$\n\n(i) For each of your contrasts, assess whether or not it is significant,\n    and explain briefly what that means in the context of the data. If a\n    contrast is significant, use your answer to part\n    (<a href=\"#part:mean-eval\">here</a>) to help in your interpretation.\n\nSolution\n\nI'll take my four contrasts as they appear in the output from `lm`:\n\n-   Comparing the male students who saw the model with those who saw the\n    student: this is strongly significant, and the table of means shows\n    that the males who saw the model rated the shirt significantly\n    *higher* than those who saw the \"average-looking\" female student.\n\n-   Comparing the female students who saw the model with those who saw\n    the student: this difference is not quite significant, so we\n    conclude that it didn't matter who the female students saw coming\n    out of the dressing room.\n\n-   There is a significant difference between the average evaluation\n    score that males gave to the shirt and that females did. The table\n    of means reveals that the male average was higher, mostly because\n    males *really* liked the shirt when they thought the model had been\n    wearing it!\n\n-   There is no significant difference overall between treatment and\n    control groups in terms of average score. (This is mostly because\n    the treatment groups differ among themselves, with the scores for\n    students who saw the model being higher and those for students who\n    saw the female student being lower than for the control group.)\n\nIt is enough, on the non-significant ones, to say what it is that the\ncontrast is testing, and then to note that it is not significant. On the\nsignificant ones, I want you to say what is higher than what. You can\nalso get these conclusions from the `lm` output, but it requires a bit\nmore care:\n\n-   I set up `c_mms` with the score for the students who had seen the\n    model as plus and those who saw the student as minus. My slope here\n    is positive, so the score for male students who saw the model is\n    higher.\n\n-   My slope for `c_fms` is also positive, and I set this one up the\n    same way with model as positive and student as negative, so the\n    female students rated the shirt higher (but not significantly\n    higher) when they saw the model.\n\n-   My `c_mf` slope is significantly negative. I set up this contrast\n    with females as plus and males as minus, so this means males gave a\n    significantly *higher* score on average (for reasons discussed\n    above).\n\n-   The last slope is very close to 0, consistent with there being no\n    difference (on average) between treatment and control.\n\nPerhaps the story to get from this analysis is that male students are\n*such* suckers!\n\n$\\blacksquare$\n",
    "supporting": [
      "anova-revisited_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}