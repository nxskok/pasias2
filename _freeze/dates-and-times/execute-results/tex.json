{
  "hash": "e6bc922fb064acba50003f5c1315316a",
  "result": {
<<<<<<< HEAD
    "engine": "knitr",
    "markdown": "# Dates and times\n\nThe usual to begin with:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Growth of Mizuna lettuce seeds\n\n\n In 2010, a group of students planted some Mizuna lettuce\nseeds, and recorded how they grew. The data were saved in an Excel\nspreadsheet, which is at\n[link](http://ritsokiguess.site/datafiles/mizuna.xlsx). The columns\nare: the date, the height (in cm) of (I presume) the tallest plant,\nthe amount of water added since the previous date (ml), the\ntemperature in the container where the seedlings were growing, and any\nadditional notes that the students made (edited for length by me). The\ntop line of the data file is variable names.\n\n\n\n(a) Read the\nspreadsheet data.\n\n\n\n(b) Make a plot of `height` against your\ndates, with the points joined by lines.\n\n\n\n(c) Label each point on the plot with the\namount of water added up to that point.\n\n\n\n\n\n\n##  Types of childbirth\n\n\n Childbirths can be of two types: a\n\"vaginal\" birth in which the child is born through the mother's\n vagina in the normal fashion, and a \"cesarean section\" where a\n surgeon cuts through the wall of the mother's abdomen, and the baby\n is delivered through the incision. Cesarean births are used when\n there are difficulties in pregnancy or during childbirth that would\n make a vaginal birth too risky.\nA hospital kept track of the number of vaginal and Cesarean births\n for the twelve months of 2012. Of interest is whether the Cesarean\n rate (the ratio of Cesarean births to all births) was increasing,\n decreasing or remaining stable over that time.\nThe data may be found at\n [link](http://ritsokiguess.site/datafiles/birthtypes.txt). The\n columns are the names of the months (in 2012), the number of cesarean\n births and the number of vaginal births. (The data are not real, but\n are typical of the kind of thing you would observe.)\n\n\n(a) Read the data into R and display your data frame.\n\n\n(b) Create a column of actual dates and also a column of\ncesarean rates, as defined above. Store your new data frame in a\nvariable and display it. For the dates, assume that each date is of\nthe 1st of the month that it belongs to.\n\n\n(c) Plot the cesarean rate against time, with a smooth\ntrend. Do you see an upward trend, a downward trend, no trend, or\nsomething else?\n\n\n(d) Try to summarize the trend you just found with a\ncorrelation. What goes wrong? How can you fix it?\n\n\n\n\n\n##  Wolves and caribou\n\n\n In Denali National Park, Alaska, the size of the wolf\npopulation depends on the size of the caribou population (since\nwolves hunt and kill caribou). This is a large national park, so\ncaribou are found in very large herds, so big, in fact, that the\nwell-being of the entire herd is not threatened by wolf\nattacks.^[In fact, it is believed that wolves help keep caribou herds strong by preventing over-population: that is, the weakest caribou are the ones taken by wolves.] \nCan the size of the caribou population\nbe used to predict the size of the wolf population?\nThe data can be found at\n[link](http://ritsokiguess.site/datafiles/caribou.txt). The\ncolumns \nare: the date of the survey,^[The survey is always taken in    the fall, but the date varies.] \nthe name of the park employee in charge  of the survey, the caribou population (in hundreds) and the wolf  population (actual count).^[Counting animals in a region,    especially rare, hard-to-find animals, is a whole science in    itself. Our data are probably themselves estimates (with some    uncertainty).] \n\n\n(a) Take a look at the data file. How would you describe its\nformat? Read it into R, and check that you got something sensible.\n\n\n\n(b) Create a new data frame where the column labelled\n`date` is now a genuine R `Date`, using something\nfrom `lubridate`.\n\n\n(c) Create new columns containing the days of\nthe week and the month names for the dates.\n\n\n\n(d) Enough playing around with dates. Make a scatterplot of\ncaribou population (explanatory) against wolf population\n(response). Do you see any relationship?\n\n\n\n(e) On your plot from the previous part, label each point with\nthe year it belongs to. You can do this in two steps: first make a\nnew column containing just the years, and then use it as labels\nfor the points on the plot.\n\n\n(f) Make a plot of caribou population against time (this is done\nthe obvious way). What seems to be happening to the caribou\npopulation over time?\n\n\n\n(g) The caribou and wolf populations over time are \nreally \"time series\". \nSee if you can make a plot of *both* the\ncaribou and wolf populations against time. You can make two\n$y$-axes, one for caribou and one for wolf; this will probably\nrequire some research on your part to figure out.\n\n\n\n\n\n\n\n\n\n##  Dealing with dates in the Worcester Heart Attack study\n\n\n The Worcester Heart Attack Study is an ongoing study of\nheart attacks in the Worcester, MA area. The main purpose of the study\nis to investigate changes over time in incidence and death rates, and also\nthe use of different treatment approaches. We will be mainly using\nthis data set to investigate data handling and dealing with dates. The\ndata can be found at\n[link](http://ritsokiguess.site/datafiles/whas500.txt). \n\n\n\n(a) Read the data into R. The reading-in part is\nstraightforward, but check what type of thing each column is. Is\nthat what it should be?\n\n\n\n(b) The date columns should be R dates. They are not\nyear-month-day, so converting them via `as.Date` (which is\nwhat `read_delim` tries to do) will not work. Load the\n`lubridate` package, and create new columns in your data\nframe that are properly dates. Save your data frame, and list it to\ndemonstrate that it worked.\n\n\n\n(c) Create three new variables `diff1, diff2, diff3` that\nare the numbers of days between each of your dates, and save the\ndata frame in which they have been created. Verify that at\nleast some of them are the same as `los` and `lenfol`.\n\n\n\n(d) Construct side-by-side boxplots of the length of followup by\neach followup status. You'll need to make sure\nthat the followup status, as it gets fed into `ggplot`, is a\n`factor`, or, at least, not the number that it is now.\n\n\n\n\n\n\n## Going to sleep\n\n A student keeps track of what time they go to bed and what time they get up in the morning. They also have an app on their phone that measures the number of hours they were asleep during that time. The data for one week are in [http://ritsokiguess.site/datafiles/sleeping.csv](http://ritsokiguess.site/datafiles/sleeping.csv), in the 24-hour clock.\n\n\n\n\n(a) Read in and display the data. What type of things are each of your columns? \n\n\n\n(b) Work out the fractional number of hours that the student was in bed each of these nights. (They may not have been asleep this whole time.) Your result needs to be a *number* since we will be doing some calculations with it shortly.\n\n\n\n(c) The student is concerned with something they call \"sleep efficiency\". This is the percentage of time in bed spent sleeping. Work out the student's sleep efficiency for the seven nights in this dataframe. Which night was the student's sleep efficiency greatest?\n\n\n\n(d) Display the time spent in bed each night as a number of hours, minutes and seconds.\n\n\n\n(e) Make a graph of what time the student went to bed each night. Bear in mind that you only need the times, not the dates, and that you want a graph that is informative, showing appropriately the distribution of times the student went to bed.\n\n\n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n##  Growth of Mizuna lettuce seeds\n\n\n In 2010, a group of students planted some Mizuna lettuce\nseeds, and recorded how they grew. The data were saved in an Excel\nspreadsheet, which is at\n[link](http://ritsokiguess.site/datafiles/mizuna.xlsx). The columns\nare: the date, the height (in cm) of (I presume) the tallest plant,\nthe amount of water added since the previous date (ml), the\ntemperature in the container where the seedlings were growing, and any\nadditional notes that the students made (edited for length by me). The\ntop line of the data file is variable names.\n\n\n\n(a) Read the\nspreadsheet data.\n\n\nSolution\n\n\nThis is `read_excel` from package `readxl`. I'm\nnot sure what will happen to the dates yet. Note that this needs\na \"local\" copy of the spreadsheet (that is, you have to\ndownload it and save it on your computer, then upload it to\n`r.datatools`), possibly using `file.choose` to\nhelp R find it. I put my copy in the same project folder as I was\nworking in, so I just need the file name:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nmizuna <- read_excel(\"mizuna.xlsx\")\nmizuna\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 x 5\n   date                height water temperature notes                           \n   <dttm>               <dbl> <dbl>       <dbl> <chr>                           \n 1 2010-02-16 00:00:00    0     400        21   planted seeds; water soaked up ~\n 2 2010-02-18 00:00:00    0       0        22.5 2 of 6 seeds not appeared; soil~\n 3 2010-02-19 00:00:00    0     200        20.9 4 of 6 plants broken surface    \n 4 2010-02-22 00:00:00    3.2   100        20.8 Last seed hasnâ€™t broken surface \n 5 2010-02-23 00:00:00    4.5   100        22.9 Plants growing well.            \n 6 2010-02-25 00:00:00    6     100        21.8 Last seed sprouted; plants look~\n 7 2010-02-26 00:00:00    6.5   200        21.2 <NA>                            \n 8 2010-03-01 00:00:00    9.5   200        21.8 <NA>                            \n 9 2010-03-03 00:00:00   11.1   200        21.7 Plants needing more water       \n10 2010-03-05 00:00:00   13     250        21.9 <NA>                            \n11 2010-03-08 00:00:00   14.5   500        22.5 No water left, leaves droopy. A~\n12 2010-03-10 00:00:00   16     200        21.2 Plants green and healthy        \n13 2010-03-17 00:00:00   18.5   800        20.8 Harvest. Tips of plants turning~\n```\n\n\n:::\n:::\n\n     \n\nThe dates *did* get read properly. `dttm` is\n\"date-time\", so I guess it's allowing for the possibility that my\ndates had times attached as well. \nThe years do actually come out right.\n\n$\\blacksquare$\n\n(b) Make a plot of `height` against your\ndates, with the points joined by lines.\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mizuna, aes(x = date, y = height)) + geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/mizuna-r-2-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \n\n$\\blacksquare$\n\n(c) Label each point on the plot with the\namount of water added up to that point.\n\n\nSolution\n\n\nThis is `water` again. The way to do this is to load\n`ggrepel`, then add `geom_text_repel` to the\nplot, by adding `label=water` to the *original*\n`aes`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggrepel)\nggplot(mizuna, aes(x = date, y = height, label = water)) +\n  geom_point() + geom_line() + geom_text_repel(colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/mizuna-r-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nI made the text red, so that you can see it more easily. It \"repels\"\naway from the points, but not from the lines joining them. Which makes\nme wonder whether this would work better (I explain `alpha` afterwards):\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggrepel)\nggplot(mizuna, aes(x = date, y = height, label = water)) +\n  geom_point() + geom_line() + geom_label_repel(colour = \"red\", \n                                                alpha = 0.7)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/mizuna-r-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nThe difference between `text` and `label` is that\n`text` just uses the text of the variable to mark the point,\nwhile `label` puts that text in a box.\n\nI think it works better. You can see where the line goes (under the boxes with\nthe labels in them), but you can see the labels clearly.\n\nWhat that `alpha` does is to make the thing it's attached to\n(the labels) partly *transparent*. If you leave it out (try it),\nthe black line disappears completely under the label boxes and you\ncan't see where it goes at all. The value you give for `alpha`\nsays how transparent the thing is, from 1 (not transparent at all)\ndown to 0 (invisible). I first tried 0.3, and you could hardly see the\nboxes; then I tried 0.7 so that the boxes were a bit more\nprominent but the lines underneath were still slightly visible, and I\ndecided that this is what I liked. I think making the labels a\ndifferent colour was a good idea, since that helps to distinguish the\nnumber on the label from the line underneath.\n\nYou can apply `alpha` to pretty much any `ggplot` thing\nthat might be on top of something else, to make it possible to see\nwhat's underneath it. The commonest use for it is if you have a\nscatterplot with a lot of points; normally, you only see some of the\npoints, because the plot is then a sea of black. But if you make the\npoints partly transparent, you can see more of what's nearby that\nwould otherwise have been hidden. \n\nAt some point, I also have to show\nyou folks `jitter`, which plots in slightly different places\npoints that would otherwise overprint each other exactly, and you\nwouldn't know how many of them there were, like the outliers on the\nboxplots of German children near the new airport.\n\n$\\blacksquare$\n\n\n\n\n##  Types of childbirth\n\n\n Childbirths can be of two types: a\n\"vaginal\" birth in which the child is born through the mother's\n vagina in the normal fashion, and a \"cesarean section\" where a\n surgeon cuts through the wall of the mother's abdomen, and the baby\n is delivered through the incision. Cesarean births are used when\n there are difficulties in pregnancy or during childbirth that would\n make a vaginal birth too risky.\nA hospital kept track of the number of vaginal and Cesarean births\n for the twelve months of 2012. Of interest is whether the Cesarean\n rate (the ratio of Cesarean births to all births) was increasing,\n decreasing or remaining stable over that time.\nThe data may be found at\n [link](http://ritsokiguess.site/datafiles/birthtypes.txt). The\n columns are the names of the months (in 2012), the number of cesarean\n births and the number of vaginal births. (The data are not real, but\n are typical of the kind of thing you would observe.)\n\n\n(a) Read the data into R and display your data frame.\n\nSolution\n\n\nThis is a space-delimited text file, which means:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/birthtypes.txt\"\nbirths <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 12 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (1): month\ndbl (2): cesarean, vaginal\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nbirths\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 3\n   month cesarean vaginal\n   <chr>    <dbl>   <dbl>\n 1 Jan         11      68\n 2 Feb          9      63\n 3 Mar         10      72\n 4 Apr         18     105\n 5 May         10      90\n 6 Jun         10      92\n 7 Jul         11      78\n 8 Aug          9      83\n 9 Sep          9      90\n10 Oct         15     101\n11 Nov         12     130\n12 Dec          8     101\n```\n\n\n:::\n:::\n\n \n\nSome text and two numbers for each month. Check.\n\n$\\blacksquare$\n\n(b) Create a column of actual dates and also a column of\ncesarean rates, as defined above. Store your new data frame in a\nvariable and display it. For the dates, assume that each date is of\nthe 1st of the month that it belongs to.\n\nSolution\n\n\nThe easiest way is to use `str_c` or `paste` to\ncreate a text date with year, month and day in some order, and\nthen to use the appropriate function from `lubridate` to\nturn that into an actual `date`. If you use\n`str_c`, you (probably) need the `sep` thing to\nmake sure the values get a space between them; `paste`\ndoes this automatically. (The next question is whether\n`ymd` or whatever can cope without spaces, but I'm not\nexploring that.)\nThe cesarean rate is `cesarean` divided by\n`cesarean` plus `vaginal`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nb2 <- births %>%\n  mutate(datestr = str_c(\"2012\", month, \"1\", sep = \" \")) %>%\n  mutate(thedate = ymd(datestr)) %>%\n  mutate(cesarean_rate = cesarean / (cesarean + vaginal))\nb2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 6\n   month cesarean vaginal datestr    thedate    cesarean_rate\n   <chr>    <dbl>   <dbl> <chr>      <date>             <dbl>\n 1 Jan         11      68 2012 Jan 1 2012-01-01        0.139 \n 2 Feb          9      63 2012 Feb 1 2012-02-01        0.125 \n 3 Mar         10      72 2012 Mar 1 2012-03-01        0.122 \n 4 Apr         18     105 2012 Apr 1 2012-04-01        0.146 \n 5 May         10      90 2012 May 1 2012-05-01        0.1   \n 6 Jun         10      92 2012 Jun 1 2012-06-01        0.0980\n 7 Jul         11      78 2012 Jul 1 2012-07-01        0.124 \n 8 Aug          9      83 2012 Aug 1 2012-08-01        0.0978\n 9 Sep          9      90 2012 Sep 1 2012-09-01        0.0909\n10 Oct         15     101 2012 Oct 1 2012-10-01        0.129 \n11 Nov         12     130 2012 Nov 1 2012-11-01        0.0845\n12 Dec          8     101 2012 Dec 1 2012-12-01        0.0734\n```\n\n\n:::\n:::\n\n        \n\nIf you don't like that, create columns that contain 2012 and 1 all\nthe way down. If you set a column name equal to a single value, that\nsingle value gets repeated the right number of times:^[This is  an example of R's so-called \"recycling rules\".]\n\n::: {.cell}\n\n```{.r .cell-code}\nbirths %>% mutate(year = 2012, day = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 5\n   month cesarean vaginal  year   day\n   <chr>    <dbl>   <dbl> <dbl> <dbl>\n 1 Jan         11      68  2012     1\n 2 Feb          9      63  2012     1\n 3 Mar         10      72  2012     1\n 4 Apr         18     105  2012     1\n 5 May         10      90  2012     1\n 6 Jun         10      92  2012     1\n 7 Jul         11      78  2012     1\n 8 Aug          9      83  2012     1\n 9 Sep          9      90  2012     1\n10 Oct         15     101  2012     1\n11 Nov         12     130  2012     1\n12 Dec          8     101  2012     1\n```\n\n\n:::\n:::\n\n \n\nand then use `unite` as in class. The distinction is that\n`unite` *only* works on columns. It also \"swallows up\"\nthe columns that it is made out of; in this case, the original year,\nmonth and day disappear:\n\n::: {.cell}\n\n```{.r .cell-code}\nbirths %>%\n  mutate(year = 2012, day = 1) %>%\n  unite(datestr, year, month, day) %>%\n  mutate(thedate = ymd(datestr)) %>%\n  mutate(cesarean_rate = cesarean / (cesarean + vaginal)) -> b3\nb3 %>% mutate(the_month = month(thedate))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 6\n   datestr    cesarean vaginal thedate    cesarean_rate the_month\n   <chr>         <dbl>   <dbl> <date>             <dbl>     <dbl>\n 1 2012_Jan_1       11      68 2012-01-01        0.139          1\n 2 2012_Feb_1        9      63 2012-02-01        0.125          2\n 3 2012_Mar_1       10      72 2012-03-01        0.122          3\n 4 2012_Apr_1       18     105 2012-04-01        0.146          4\n 5 2012_May_1       10      90 2012-05-01        0.1            5\n 6 2012_Jun_1       10      92 2012-06-01        0.0980         6\n 7 2012_Jul_1       11      78 2012-07-01        0.124          7\n 8 2012_Aug_1        9      83 2012-08-01        0.0978         8\n 9 2012_Sep_1        9      90 2012-09-01        0.0909         9\n10 2012_Oct_1       15     101 2012-10-01        0.129         10\n11 2012_Nov_1       12     130 2012-11-01        0.0845        11\n12 2012_Dec_1        8     101 2012-12-01        0.0734        12\n```\n\n\n:::\n:::\n\n \n\nI don't mind which order you glue your year, month and day together,\nas long as you construct the dates with the consistent\n`lubridate` function. \n\n$\\blacksquare$\n\n(c) Plot the cesarean rate against time, with a smooth\ntrend. Do you see an upward trend, a downward trend, no trend, or\nsomething else?\n\nSolution\n\n\nThis is a scatterplot with time on the $x$ axis:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(b3, aes(x = thedate, y = cesarean_rate)) + geom_point() + geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/tann-1.pdf){fig-pos='H'}\n:::\n:::\n\n        \n\nI like this better than joining the points by lines, since we already\nhave a trend on the plot, but you can do that in some contrasting way:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(b3, aes(x = thedate, y = cesarean_rate)) + geom_point() +\n  geom_line(linetype = \"dashed\") + geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/fletzlinger-1.pdf){fig-pos='H'}\n:::\n:::\n\n \nI see a downward trend. (\"A downward trend with a wiggle\" if you\nlike.) There is a certain unevenness\nin the trend of the actual data, but the overall picture appears to be\ndownhill. \n\n$\\blacksquare$\n\n(d) Try to summarize the trend you just found with a\ncorrelation. What goes wrong? How can you fix it?\n\nSolution\n\n\nSomething like this is the obvious guess:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(b3, cor(thedate, cesarean_rate))\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in cor(thedate, cesarean_rate): 'x' must be numeric\n```\n\n\n:::\n:::\n\n \n\nThis fails because `thedate` is not of itself a number. But\nlurking in the background is how the date is actually\n*represented*: as a number of days since Jan 1, 1970. Thus,\npassing it through `as.numeric` might turn it into that:\n\n::: {.cell}\n\n```{.r .cell-code}\nb3 %>% mutate(numeric_date = as.numeric(thedate)) -> b5\nb5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 6\n   datestr    cesarean vaginal thedate    cesarean_rate numeric_date\n   <chr>         <dbl>   <dbl> <date>             <dbl>        <dbl>\n 1 2012_Jan_1       11      68 2012-01-01        0.139         15340\n 2 2012_Feb_1        9      63 2012-02-01        0.125         15371\n 3 2012_Mar_1       10      72 2012-03-01        0.122         15400\n 4 2012_Apr_1       18     105 2012-04-01        0.146         15431\n 5 2012_May_1       10      90 2012-05-01        0.1           15461\n 6 2012_Jun_1       10      92 2012-06-01        0.0980        15492\n 7 2012_Jul_1       11      78 2012-07-01        0.124         15522\n 8 2012_Aug_1        9      83 2012-08-01        0.0978        15553\n 9 2012_Sep_1        9      90 2012-09-01        0.0909        15584\n10 2012_Oct_1       15     101 2012-10-01        0.129         15614\n11 2012_Nov_1       12     130 2012-11-01        0.0845        15645\n12 2012_Dec_1        8     101 2012-12-01        0.0734        15675\n```\n\n\n:::\n:::\n\n \n\nA little mental calculation suggests that these dates in 2012 are a\nbit over 40 years, that is $40 \\times 365 \\simeq 14000$ days, since\nthe \"zero\" date of Jan 1, 1970, and so it turns out. This suggests\nthat we can calculate a correlation with the numeric dates:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(b5, cor(numeric_date, cesarean_rate))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.7091219\n```\n\n\n:::\n:::\n\n \n\nand we can make a test of the null hypothesis that the correlation is\nzero (against a two-sided alternative) thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(b5, cor.test(numeric_date, cesarean_rate))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  numeric_date and cesarean_rate\nt = -3.1804, df = 10, p-value = 0.009813\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9119078 -0.2280145\nsample estimates:\n       cor \n-0.7091219 \n```\n\n\n:::\n:::\n\n \n\nThat downward trend is more than just chance, with a P-value just\nunder 0.01. Having said that, though, if you look at the confidence\ninterval for the correlation, it includes almost all the negative\nvalues it could be, so that with only 12 observations we really know\nvery little about the correlation other than that it appears to be\nnegative. \n\nExtra: \n In practice, you would typically have a much longer time series\n of measurements than this, such as monthly measurements for\n several years. In looking at only one year, like we did here,\n we could get trapped by seasonal effects: for example, cesarean\n rates might always go down through the year and then jump up\n again in January. Looking at several years would enable us to\n disentangle seasonal effects that happen every year from\n long-term trends. (As an example of this, think of Toronto\n snowfall: there is almost always snow in the winter and there\n is never snow in the summer, a seasonal effect, but in\n assessing climate change, you want to think about long-term\n trends in snowfall, after allowing for which month you're\n looking at.)\n \n$\\blacksquare$\n\n\n\n\n##  Wolves and caribou\n\n\n In Denali National Park, Alaska, the size of the wolf\npopulation depends on the size of the caribou population (since\nwolves hunt and kill caribou). This is a large national park, so\ncaribou are found in very large herds, so big, in fact, that the\nwell-being of the entire herd is not threatened by wolf\nattacks.^[In fact, it is believed that wolves help keep caribou herds strong by preventing over-population: that is, the weakest caribou are the ones taken by wolves.] \nCan the size of the caribou population\nbe used to predict the size of the wolf population?\nThe data can be found at\n[link](http://ritsokiguess.site/datafiles/caribou.txt). The\ncolumns \nare: the date of the survey,^[The survey is always taken in    the fall, but the date varies.] \nthe name of the park employee in charge  of the survey, the caribou population (in hundreds) and the wolf  population (actual count).^[Counting animals in a region,    especially rare, hard-to-find animals, is a whole science in    itself. Our data are probably themselves estimates (with some    uncertainty).] \n\n\n(a) Take a look at the data file. How would you describe its\nformat? Read it into R, and check that you got something sensible.\n\n\nSolution\n\n\nThis looks at first sight as if it's separated by spaces, but\nmost of the data values are separated by *more than one*\nspace. If you look further, you'll see that the values are\n*lined up in columns*, with the variable names aligned at\nthe top. \n\nThis used to be exactly the kind of thing that\n`read_table` would read, but no longer. We start with the usual\n`library(tidyverse)`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nmy_url <- \"http://ritsokiguess.site/datafiles/caribou.txt\"\ndenali <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  date = col_character(),\n  name = col_character(),\n  caribou = col_character(),\n  wolf = col_character()\n)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: 7 parsing failures.\nrow col  expected    actual                                             file\n  1  -- 4 columns 5 columns 'http://ritsokiguess.site/datafiles/caribou.txt'\n  2  -- 4 columns 5 columns 'http://ritsokiguess.site/datafiles/caribou.txt'\n  3  -- 4 columns 5 columns 'http://ritsokiguess.site/datafiles/caribou.txt'\n  4  -- 4 columns 6 columns 'http://ritsokiguess.site/datafiles/caribou.txt'\n  5  -- 4 columns 5 columns 'http://ritsokiguess.site/datafiles/caribou.txt'\n... ... ......... ......... ................................................\nSee problems(...) for more details.\n```\n\n\n:::\n\n```{.r .cell-code}\ndenali\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 4\n  date       name       caribou wolf \n  <chr>      <chr>      <chr>   <chr>\n1 09/01/1995 David      S.      30   \n2 09/24/1996 Youngjin   K.      34   \n3 10/03/1997 Srinivasan M.      27   \n4 09/15/1998 Lee        Anne    J.   \n5 09/08/1999 Stephanie  T.      17   \n6 09/03/2000 Angus      Mc      D.   \n7 10/06/2001 David      S.      20   \n```\n\n\n:::\n:::\n\nThe spaces within the names have spilled into the next column, so that the dates and first names are (mostly) correct, but the initials should stay with the names.\n\nThe right thing now is `read_fwf`, where `fwf` stands for \"fixed-width format\"\n\n::: {.cell}\n\n```{.r .cell-code}\ndl_file <- \"caribou.txt\"\ndownload.file(my_url, dl_file)\nread_fwf(dl_file)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 8 Columns: 4\n-- Column specification --------------------------------------------------------\n\nchr (4): X1, X2, X3, X4\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 x 4\n  X1         X2            X3      X4   \n  <chr>      <chr>         <chr>   <chr>\n1 date       name          caribou wolf \n2 09/01/1995 David S.      30      66   \n3 09/24/1996 Youngjin K.   34      79   \n4 10/03/1997 Srinivasan M. 27      70   \n5 09/15/1998 Lee Anne J.   25      60   \n6 09/08/1999 Stephanie T.  17      48   \n7 09/03/2000 Angus Mc D.   23      55   \n8 10/06/2001 David S.      20      60   \n```\n\n\n:::\n:::\n\nThat's much closer, but it thought the column names were part of the data. We seem to need to enter them specifically:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_cols <- c(\"date\", \"name\", \"caribou\", \"wolf\")\ndenali <- read_fwf(dl_file, fwf_empty(dl_file, col_names = my_cols), skip = 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 7 Columns: 4\n-- Column specification --------------------------------------------------------\n\nchr (2): date, name\ndbl (2): caribou, wolf\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\ndenali\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 4\n  date       name          caribou  wolf\n  <chr>      <chr>           <dbl> <dbl>\n1 09/01/1995 David S.           30    66\n2 09/24/1996 Youngjin K.        34    79\n3 10/03/1997 Srinivasan M.      27    70\n4 09/15/1998 Lee Anne J.        25    60\n5 09/08/1999 Stephanie T.       17    48\n6 09/03/2000 Angus Mc D.        23    55\n7 10/06/2001 David S.           20    60\n```\n\n\n:::\n:::\n\nand that's worked. The `fwf_empty` says to guess where the columns are based on where there are spaces all the way down (as `read_table` used to do), and to use the specified column names. The top line of the datafile is those column names, though, so we need to skip that row. A bit fiddly.\n\nAnyway, that (finally) worked: four columns with the right names, and the counts of\ncaribou and wolf are numbers. There are only seven years of surveys;\nin real-life data you would have more. But the point here is working\nwith dates.\n\nThe only (small) weirdness is that the\ndates are text rather than having been converted into dates. This is\nbecause they are not year-month-day, which is the only format that\ngets automatically converted into dates when read in. (You could use\n`mdy` from `lubridate` to make them dates.)\n\nExtra: you might have wondered how the names survived, even though\nthey have spaces in them, sometimes more than one. Here's how the file looks:\n\n\n```\n\ndate       name             caribou wolf\n09/01/1995 David S.         30       66\n09/24/1996 Youngjin K.      34       79\n10/03/1997 Srinivasan M.    27       70\n09/15/1998 Lee Anne J.      25       60\n09/08/1999 Stephanie T.     17       48\n09/03/2000 Angus Mc D.      23       55\n10/06/2001 David S.         20       60\n\n```\n\n\nWhat `read_table` looks for is columns that contain spaces\n*all the way down*, and separates the values there. For example,\nbetween the year of`date` and the first name in `name`\nthere is a space all the way down. After the names and before the\ncaribou counts there are several spaces, and there is one space\nbetween the words `caribou` and `wolf` in the header\nline that goes all the way down. Thus four columns, `date`,\n`name`, `caribou` and `wolf`. This means that the\nspaces within the names don't cause any problems at all, since the\nspaces aren't in the same place in *every* line.^[The only way this would fail is if *every* first name had the same number of letters in it; then the space between first name and initial of last name *would* be in the same place in every line.]\n\n$\\blacksquare$\n\n(b) Create a new data frame where the column labelled\n`date` is now a genuine R `Date`, using something\nfrom `lubridate`.\n\nSolution\n\n\nWhat you do is to look at the format of the dates as they are\nnow. They appear to be month-day-year, American\nstyle.^[Not a surprise since Denali National Park is in  Alaska.]  \nThus the function needed is `mdy`. It doesn't matter\nwhether the months are names or numbers:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>% mutate(date = mdy(date)) -> denali\ndenali\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 4\n  date       name          caribou  wolf\n  <date>     <chr>           <dbl> <dbl>\n1 1995-09-01 David S.           30    66\n2 1996-09-24 Youngjin K.        34    79\n3 1997-10-03 Srinivasan M.      27    70\n4 1998-09-15 Lee Anne J.        25    60\n5 1999-09-08 Stephanie T.       17    48\n6 2000-09-03 Angus Mc D.        23    55\n7 2001-10-06 David S.           20    60\n```\n\n\n:::\n:::\n\n     \n\nI lived on the edge and overwrote both my column and the whole data\nframe.^[It's actually not *really* living on the edge,  because if it doesn't work, you go back and read the data in from  the file again.]\n\nThe dates are displayed in ISO format, year-month-day. You see at the\ntop of the column that they now really *are* dates, not just\npieces of text that look like dates. \n\n$\\blacksquare$\n\n(c) Create new columns containing the days of\nthe week and the month names for the dates.\n\n\nSolution\n\n\nThis involves digging in the `lubridate` help to find out how to extract things from a date. It turns out that `wday` extracts the day of the week from a date, by default as a number, and `month` gets the month, also by default as a number:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>% mutate(mon = month(date), wd = wday(date))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 6\n  date       name          caribou  wolf   mon    wd\n  <date>     <chr>           <dbl> <dbl> <dbl> <dbl>\n1 1995-09-01 David S.           30    66     9     6\n2 1996-09-24 Youngjin K.        34    79     9     3\n3 1997-10-03 Srinivasan M.      27    70    10     6\n4 1998-09-15 Lee Anne J.        25    60     9     3\n5 1999-09-08 Stephanie T.       17    48     9     4\n6 2000-09-03 Angus Mc D.        23    55     9     1\n7 2001-10-06 David S.           20    60    10     7\n```\n\n\n:::\n:::\n\n     \n\nThis is not what we wanted, though; we wanted the names of the months\nand of the days. To fix that, add `label=T` to both functions:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>% mutate(mon = month(date, label = T), wd = wday(date, label = T))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 6\n  date       name          caribou  wolf mon   wd   \n  <date>     <chr>           <dbl> <dbl> <ord> <ord>\n1 1995-09-01 David S.           30    66 Sep   Fri  \n2 1996-09-24 Youngjin K.        34    79 Sep   Tue  \n3 1997-10-03 Srinivasan M.      27    70 Oct   Fri  \n4 1998-09-15 Lee Anne J.        25    60 Sep   Tue  \n5 1999-09-08 Stephanie T.       17    48 Sep   Wed  \n6 2000-09-03 Angus Mc D.        23    55 Sep   Sun  \n7 2001-10-06 David S.           20    60 Oct   Sat  \n```\n\n\n:::\n:::\n\n \nand that cracks it.\n\nNo need to save this data frame anywhere, since we're not using any of\nthis later.\n\nExtra: the `ord` means \"ordered factor\", which makes sense\nsince these are categorical variables with a natural order. This means\nthat you could do something like counting the number of surveys in\neach month like this:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>%\n  mutate(mon = month(date, label = T), wd = wday(date, label = T)) %>%\n  count(mon)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 2\n  mon       n\n  <ord> <int>\n1 Sep       5\n2 Oct       2\n```\n\n\n:::\n:::\n\n \n      \n$\\blacksquare$\n\n(d) Enough playing around with dates. Make a scatterplot of\ncaribou population (explanatory) against wolf population\n(response). Do you see any relationship?\n\n\nSolution\n\n\nNothing terribly surprising here:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = caribou, y = wolf)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \nIf you like, add a smooth trend to it:^[This wiggles more than  I would like, with such a small number of observations. Try putting  something like `span=2` in the smooth to make it less wiggly.]\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = caribou, y = wolf)) + geom_point() + geom_smooth(se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-7-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \n\nThis is an upward trend: when one population is large, the other one\nis large too. This is typical for predator-prey relationships: when\nthere is more to eat (more caribou) the wolf population goes up, and\nwhen less, it goes down. \n      \n$\\blacksquare$\n\n(e) On your plot from the previous part, label each point with\nthe year it belongs to. You can do this in two steps: first make a\nnew column containing just the years, and then use it as labels\nfor the points on the plot.\n\nSolution\n\n\nI'm going to use `geom_text_repel` for the labels from package\n`ggrepel`. The year values are gotten using the\n`lubridate` function `year`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>%\n  mutate(year = year(date)) %>%\n  ggplot(aes(x = caribou, y = wolf, label = year)) + geom_point() + geom_text_repel()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-8-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nI thought about joining up the points in year order. This is actually\n*not* `geom_line` as you would have guessed, since what that\ndoes is to join points in the order of the variable on the\n$x$-axis.^[I have to say that I didn't know that until just now.]\nTo join points in the order that they are in the data (what we want\nhere, because the points are in time order in the data), use instead \n`geom_path`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>%\n  mutate(year = year(date)) %>%\n  ggplot(aes(x = caribou, y = wolf, label = year)) + geom_point() +\n  geom_text_repel() + geom_path()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-9-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nIn 1996, both populations were large, and both showed a steady decline\nuntil 1999. In 2000 and 2001, both populations seemed to be on the way\nup again, and you can imagine that in a couple of years, things would\ngo back to about where they were in 1995.\n\n$\\blacksquare$\n\n(f) Make a plot of caribou population against time (this is done\nthe obvious way). What seems to be happening to the caribou\npopulation over time?\n\n\nSolution\n\n\nMake a scatterplot, with the survey date as explanatory\nvariable, and caribou population as response (since time always\ngoes on the $x$-axis):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou)) + geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-10-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nI used an ordinary `geom_line` this time, to connect neighbouring\nyears, as is often done with a time series. The overall trend is\ndownward, though the 1999 value might be a low from which the\npopulation is recovering.\n      \n$\\blacksquare$\n\n(g) The caribou and wolf populations over time are \nreally \"time series\". \nSee if you can make a plot of *both* the\ncaribou and wolf populations against time. You can make two\n$y$-axes, one for caribou and one for wolf; this will probably\nrequire some research on your part to figure out.\n\n\nSolution\n\n\nThe obvious starting point is to note that both the\n`caribou` and `wolf` columns are animal\npopulations, just of different animals. One way of plotting both\npopulations is to `pivot_longer` them up into one longer column, and\nthen plot them against time, with the two animals distinguished\nby colour:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>%\n  pivot_longer(caribou:wolf, names_to=\"animal\", values_to=\"population\") %>%\n  ggplot(aes(x = date, y = population, colour = animal)) +\n  geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \nThis is not quite the story, though, because the caribou and wolf\npopulations are on different scales. The caribou population is\nnumbered in hundreds, while the wolf population is an actual count. \n\nThe surveys are late in the year, so the one that is nearly in 1996 is\nactually the 1995 survey.\n\nWhat would be nice would be to have a secondary $y$-axis, so that\nthere were two $y$-scales, one for each animal. This is very easy to\nmanipulate, though (you can change either scale and get a very\ndifferent-looking graph), so we ought to be careful.\n\nAll right, so let's put the caribou on the left:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou)) + geom_line()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nOr we can add a `colour` aesthetic to distinguish the caribou\nfrom the wolf populations, that we're going to add in a moment. This looks rather odd at first:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou, colour = \"caribou\")) + geom_line()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-13-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nNow we think about adding the wolf numbers. This is done by adding a\nsecond `geom_line`, overriding the `y` and the\n`colour` to specify that this is wolf now:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou, colour = \"caribou\")) +\n  geom_line() +\n  geom_line(aes(y = wolf, colour = \"wolf\"))\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-14-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nWhat has happened is that we get lines of different colour for each\nanimal, with a legend. So far so good. The problem is that the wolf\nnumbers are about 2.5 times bigger than the caribou\nnumbers,^[Which means, if you stop to think about it, that  there are *actually* about 40 times more caribou than wolves.]\nso that\nwe don't get a good sense of how they go up and down together. If we\ndivided the wolf numbers by 2.5, we would see this better:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou, colour = \"caribou\")) +\n  geom_line() +\n  geom_line(aes(y = wolf / 2.5, colour = \"wolf\"))\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-15-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nNow we get to the secondary $y$-axis. We want to label this\n`wolf` and have it reflect that we actually made the graph by\ndividing the wolf values by 2.5:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou, colour = \"caribou\")) +\n  geom_line() +\n  geom_line(aes(y = wolf / 2.5, colour = \"wolf\")) +\n  scale_y_continuous(sec.axis = sec_axis(~ . * 2.5, name = \"wolf\"))\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-16-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nWoo, and, very possibly, hoo. I got most of these ideas from\n[link](https://rpubs.com/MarkusLoew/226759). \n\nNow we see how the populations vary over time, and also that they vary\ntogether. \n\nThis is about the only double-$y$-axis setup that I like, with scales\nchosen so that both the series vary about the same amount. By\n\"discreetly\" changing the wolf scale, you could make it look as if\none population was much bigger than the other, or varied much more\nthan the other. Lies and statistics.\n\nIn my opinion, too many people just plot series against time, possibly\nwith a second $y$-axis.^[And all too often with Excel (spit).]\nVariables that vary together, like the wolf\nand caribou populations here, ought to be plotted *against each\nother* on a scatterplot, possibly with the time points labelled.\n\nThe ambitious among you may like to compare the graphs here with\nother predator-prey relationships. If you are of a mathematical bent,\nyou might look into the Lotka-Volterra equations, which is a system of\ntwo differential equations describing how changes in one population\ncause changes in the other population.\n\n$\\blacksquare$\n\n\n\n\n\n\n\n##  Dealing with dates in the Worcester Heart Attack study\n\n\n The Worcester Heart Attack Study is an ongoing study of\nheart attacks in the Worcester, MA area. The main purpose of the study\nis to investigate changes over time in incidence and death rates, and also\nthe use of different treatment approaches. We will be mainly using\nthis data set to investigate data handling and dealing with dates. The\ndata can be found at\n[link](http://ritsokiguess.site/datafiles/whas500.txt). \n\n\n\n(a) Read the data into R. The reading-in part is\nstraightforward, but check what type of thing each column is. Is\nthat what it should be?\n\n\nSolution\n\n\nThis is `read_delim`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/whas500.txt\"\nwhas <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 500 Columns: 22\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr  (3): admitdate, disdate, fdate\ndbl (19): id, age, gender, hr, sysbp, diasbp, bmi, cvd, afb, sho, chf, av3, ...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nwhas\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 500 x 22\n      id   age gender    hr sysbp diasbp   bmi   cvd   afb   sho   chf   av3\n   <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1    83      0    89   152     78  25.5     1     1     0     0     0\n 2     2    49      0    84   120     60  24.0     1     0     0     0     0\n 3     3    70      1    83   147     88  22.1     0     0     0     0     0\n 4     4    70      0    65   123     76  26.6     1     0     0     1     0\n 5     5    70      0    63   135     85  24.4     1     0     0     0     0\n 6     6    70      0    76    83     54  23.2     1     0     0     0     1\n 7     7    57      0    73   191    116  39.5     1     0     0     0     0\n 8     8    55      0    91   147     95  27.1     1     0     0     0     0\n 9     9    88      1    63   209    100  27.4     1     0     0     1     0\n10    10    54      0   104   166    106  25.5     1     0     0     0     0\n# i 490 more rows\n# i 10 more variables: miord <dbl>, mitype <dbl>, year <dbl>, admitdate <chr>,\n#   disdate <chr>, fdate <chr>, los <dbl>, dstat <dbl>, lenfol <dbl>,\n#   fstat <dbl>\n```\n\n\n:::\n:::\n\n   \n\nTo see what type everything is, note that when you display a\n`tibble`, the type of all the columns on the screen is\ndisplayed at the top. Click the little right-arrow to see more columns\nand to check their type.\n\nAll the numbers are properly integer (`int`) or decimal\n(`dbl`) numbers, but the date columns are `chr` or\ntext. This means that they haven't been read as `Date`s\n(because they were not in year-month-day order).  \n\n$\\blacksquare$\n\n(b) The date columns should be R dates. They are not\nyear-month-day, so converting them via `as.Date` (which is\nwhat `read_delim` tries to do) will not work. Load the\n`lubridate` package, and create new columns in your data\nframe that are properly dates. Save your data frame, and list it to\ndemonstrate that it worked.\n\n\nSolution\n\n\nYou can load `lubridate` first, but there is no need since it is now part of the `tidyverse`.\n\n\nThese dates are day-month-year, so we need `dmy` from\n`lubridate`: \n\n::: {.cell}\n\n```{.r .cell-code}\nwhas %>% mutate(\n  admit = dmy(admitdate),\n  dis = dmy(disdate),\n  f = dmy(fdate)\n) -> whas2\nglimpse(whas2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 500\nColumns: 25\n$ id        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1~\n$ age       <dbl> 83, 49, 70, 70, 70, 70, 57, 55, 88, 54, 48, 75, 48, 54, 67, ~\n$ gender    <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, ~\n$ hr        <dbl> 89, 84, 83, 65, 63, 76, 73, 91, 63, 104, 95, 154, 85, 95, 93~\n$ sysbp     <dbl> 152, 120, 147, 123, 135, 83, 191, 147, 209, 166, 160, 193, 1~\n$ diasbp    <dbl> 78, 60, 88, 76, 85, 54, 116, 95, 100, 106, 110, 123, 80, 65,~\n$ bmi       <dbl> 25.54051, 24.02398, 22.14290, 26.63187, 24.41255, 23.24236, ~\n$ cvd       <dbl> 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, ~\n$ afb       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ~\n$ sho       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ chf       <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ~\n$ av3       <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ~\n$ miord     <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, ~\n$ mitype    <dbl> 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ~\n$ year      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ admitdate <chr> \"13-01-1997\", \"19-01-1997\", \"01-01-1997\", \"17-02-1997\", \"01-~\n$ disdate   <chr> \"18-01-1997\", \"24-01-1997\", \"06-01-1997\", \"27-02-1997\", \"07-~\n$ fdate     <chr> \"31-12-2002\", \"31-12-2002\", \"31-12-2002\", \"11-12-1997\", \"31-~\n$ los       <dbl> 5, 5, 5, 10, 6, 1, 5, 4, 4, 5, 5, 10, 7, 21, 4, 1, 13, 14, 6~\n$ dstat     <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ lenfol    <dbl> 2178, 2172, 2190, 297, 2131, 1, 2122, 1496, 920, 2175, 2173,~\n$ fstat     <dbl> 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ~\n$ admit     <date> 1997-01-13, 1997-01-19, 1997-01-01, 1997-02-17, 1997-03-01,~\n$ dis       <date> 1997-01-18, 1997-01-24, 1997-01-06, 1997-02-27, 1997-03-07,~\n$ f         <date> 2002-12-31, 2002-12-31, 2002-12-31, 1997-12-11, 2002-12-31,~\n```\n\n\n:::\n:::\n\n \n\nThere are a lot of columns, so I used `glimpse`.  The three new\nvariables we created are at the end of the list. They are correctly\n`Date`s, and they have the right values, the ones we can see at\nleast. \n\nThe indentation is up to you. I think it's nice to make the\ncreations of the three new variables line up. You can also make the\nopening and closing brackets on the long `mutate` aligned, or\nyou can do as I have done here and put two closing brackets on the\nend. The rationale for this is that each of the variable definition\nlines in the `mutate` ends either with a comma or an extra\nclosing bracket, the latter being on the last line. Your choice here is\na matter of taste or (in your working life) the coding norms of the\nteam you're working with.\n\nExtra: you may have been offended by the repetition above. It so happens that\nthese columns' names all end in `date` and they are the only\nones that do, so we can use a \"select helper\" to select only them,\nand then submit all of them to a `mutate` via `across`,\nwhich goes like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas %>% mutate(across(ends_with(\"date\"), \\(date) dmy(date))) %>% glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 500\nColumns: 22\n$ id        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1~\n$ age       <dbl> 83, 49, 70, 70, 70, 70, 57, 55, 88, 54, 48, 75, 48, 54, 67, ~\n$ gender    <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, ~\n$ hr        <dbl> 89, 84, 83, 65, 63, 76, 73, 91, 63, 104, 95, 154, 85, 95, 93~\n$ sysbp     <dbl> 152, 120, 147, 123, 135, 83, 191, 147, 209, 166, 160, 193, 1~\n$ diasbp    <dbl> 78, 60, 88, 76, 85, 54, 116, 95, 100, 106, 110, 123, 80, 65,~\n$ bmi       <dbl> 25.54051, 24.02398, 22.14290, 26.63187, 24.41255, 23.24236, ~\n$ cvd       <dbl> 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, ~\n$ afb       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ~\n$ sho       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ chf       <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ~\n$ av3       <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ~\n$ miord     <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, ~\n$ mitype    <dbl> 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ~\n$ year      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ admitdate <date> 1997-01-13, 1997-01-19, 1997-01-01, 1997-02-17, 1997-03-01,~\n$ disdate   <date> 1997-01-18, 1997-01-24, 1997-01-06, 1997-02-27, 1997-03-07,~\n$ fdate     <date> 2002-12-31, 2002-12-31, 2002-12-31, 1997-12-11, 2002-12-31,~\n$ los       <dbl> 5, 5, 5, 10, 6, 1, 5, 4, 4, 5, 5, 10, 7, 21, 4, 1, 13, 14, 6~\n$ dstat     <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ lenfol    <dbl> 2178, 2172, 2190, 297, 2131, 1, 2122, 1496, 920, 2175, 2173,~\n$ fstat     <dbl> 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ~\n```\n\n\n:::\n:::\n\n \n\nOne line, as you see, not three. The English-language version of this reads \"for each of the columns whose\nname ends with `date`, work out `dmy` of it\", that is to say, convert it into a date.\nWe can use any of the\nselect-helpers in this, including listing the column numbers or\nnames; in this case our date variables all ended with\n`date`. \n\nThis overwrites the original date columns (you can see that they are now `date`s), but you can give them new names thus. This is inside the `across` inside the `mutate`, so it needs two close-brackets after (the probable reason for the error if you get one):\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas %>% mutate(across(ends_with(\"date\"), \\(date) dmy(date), \n                       .names = \"{.col}_d\")) %>% glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 500\nColumns: 25\n$ id          <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,~\n$ age         <dbl> 83, 49, 70, 70, 70, 70, 57, 55, 88, 54, 48, 75, 48, 54, 67~\n$ gender      <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0~\n$ hr          <dbl> 89, 84, 83, 65, 63, 76, 73, 91, 63, 104, 95, 154, 85, 95, ~\n$ sysbp       <dbl> 152, 120, 147, 123, 135, 83, 191, 147, 209, 166, 160, 193,~\n$ diasbp      <dbl> 78, 60, 88, 76, 85, 54, 116, 95, 100, 106, 110, 123, 80, 6~\n$ bmi         <dbl> 25.54051, 24.02398, 22.14290, 26.63187, 24.41255, 23.24236~\n$ cvd         <dbl> 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1~\n$ afb         <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0~\n$ sho         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ chf         <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1~\n$ av3         <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1~\n$ miord       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0~\n$ mitype      <dbl> 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1~\n$ year        <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n$ admitdate   <chr> \"13-01-1997\", \"19-01-1997\", \"01-01-1997\", \"17-02-1997\", \"0~\n$ disdate     <chr> \"18-01-1997\", \"24-01-1997\", \"06-01-1997\", \"27-02-1997\", \"0~\n$ fdate       <chr> \"31-12-2002\", \"31-12-2002\", \"31-12-2002\", \"11-12-1997\", \"3~\n$ los         <dbl> 5, 5, 5, 10, 6, 1, 5, 4, 4, 5, 5, 10, 7, 21, 4, 1, 13, 14,~\n$ dstat       <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ lenfol      <dbl> 2178, 2172, 2190, 297, 2131, 1, 2122, 1496, 920, 2175, 217~\n$ fstat       <dbl> 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1~\n$ admitdate_d <date> 1997-01-13, 1997-01-19, 1997-01-01, 1997-02-17, 1997-03-0~\n$ disdate_d   <date> 1997-01-18, 1997-01-24, 1997-01-06, 1997-02-27, 1997-03-0~\n$ fdate_d     <date> 2002-12-31, 2002-12-31, 2002-12-31, 1997-12-11, 2002-12-3~\n```\n\n\n:::\n:::\n\nThe three columns on the end are the new actual-dates we created. To give them new names, use `.names` inside `across`, and in *that* is a recipe that says how to make the new names. `{.col}` means the name the column had before, and the `_d` after that means to add that to the old name to make the new one.\n\n$\\blacksquare$\n\n(c) Create three new variables `diff1, diff2, diff3` that\nare the numbers of days between each of your dates, and save the\ndata frame in which they have been created. Verify that at\nleast some of them are the same as `los` and `lenfol`.\n\n\nSolution\n\n\nI don't know\nwhat R's internal storage is for dates (it might be seconds or\nmilliseconds or anything, not necessarily days),\nso subtracting them requires care; you have to divide by the\nlength of a day (in whatever units), thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 <- whas2 %>% mutate(\n  diff1 = (dis - admit) / ddays(1),\n  diff2 = (f - admit) / ddays(1),\n  diff3 = (f - dis) / ddays(1)\n)\nglimpse(whas3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 500\nColumns: 28\n$ id        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1~\n$ age       <dbl> 83, 49, 70, 70, 70, 70, 57, 55, 88, 54, 48, 75, 48, 54, 67, ~\n$ gender    <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, ~\n$ hr        <dbl> 89, 84, 83, 65, 63, 76, 73, 91, 63, 104, 95, 154, 85, 95, 93~\n$ sysbp     <dbl> 152, 120, 147, 123, 135, 83, 191, 147, 209, 166, 160, 193, 1~\n$ diasbp    <dbl> 78, 60, 88, 76, 85, 54, 116, 95, 100, 106, 110, 123, 80, 65,~\n$ bmi       <dbl> 25.54051, 24.02398, 22.14290, 26.63187, 24.41255, 23.24236, ~\n$ cvd       <dbl> 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, ~\n$ afb       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ~\n$ sho       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ chf       <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ~\n$ av3       <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ~\n$ miord     <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, ~\n$ mitype    <dbl> 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ~\n$ year      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ admitdate <chr> \"13-01-1997\", \"19-01-1997\", \"01-01-1997\", \"17-02-1997\", \"01-~\n$ disdate   <chr> \"18-01-1997\", \"24-01-1997\", \"06-01-1997\", \"27-02-1997\", \"07-~\n$ fdate     <chr> \"31-12-2002\", \"31-12-2002\", \"31-12-2002\", \"11-12-1997\", \"31-~\n$ los       <dbl> 5, 5, 5, 10, 6, 1, 5, 4, 4, 5, 5, 10, 7, 21, 4, 1, 13, 14, 6~\n$ dstat     <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ lenfol    <dbl> 2178, 2172, 2190, 297, 2131, 1, 2122, 1496, 920, 2175, 2173,~\n$ fstat     <dbl> 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ~\n$ admit     <date> 1997-01-13, 1997-01-19, 1997-01-01, 1997-02-17, 1997-03-01,~\n$ dis       <date> 1997-01-18, 1997-01-24, 1997-01-06, 1997-02-27, 1997-03-07,~\n$ f         <date> 2002-12-31, 2002-12-31, 2002-12-31, 1997-12-11, 2002-12-31,~\n$ diff1     <dbl> 5, 5, 5, 10, 6, 1, 5, 4, 4, 5, 5, 10, 7, 21, 4, 1, 13, 14, 6~\n$ diff2     <dbl> 2178, 2172, 2190, 297, 2131, 1, 2122, 1496, 920, 2175, 2173,~\n$ diff3     <dbl> 2173, 2167, 2185, 287, 2125, 0, 2117, 1492, 916, 2170, 2168,~\n```\n\n\n:::\n:::\n\n       \n\nThe extra `d` on the front of `ddays` indicates that\nthese are what is known to `lubridate` as \"durations\": a\nperiod of time 1 day long that could be any day (as opposed to \n\"June 1, 1970\" which is 1 day long, but tied to a particular day). \n\n`los` should be the number of days in hospital, what I\ncalculated as `diff1`, and `lenfol` should be the time\nfrom being admitted to last followup, which is my `diff2`. My\noutput from `glimpse` confirms that. \n\nExtra: of course, checking that the first few values match is a nice\nconfirmation, but is not actually a *proof*. For that, we should\ncompare all 500 values, and it would be best to do it in such a way\nthat R is comparing all 500 values for us, since it would be a lot\nmore reliable than the human eye. R has a function `all.equal`\nwhich does exactly that. By way of warmup:\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 1:4\ny <- 1:4\nz <- c(1, 2, 3, 5)\nall.equal(x, y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nall.equal(x, z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Mean relative difference: 0.25\"\n```\n\n\n:::\n:::\n\n \n\nI thought the second one was just going to say `FALSE`, but it\ngave us a message instead, saying how close `x` and `z`\nwere on average, so that we could decide whether they were close\nenough to call equal, or, as in this case, not.\n\nAnyway:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(whas3, all.equal(lenfol, diff2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nwith(whas3, all.equal(los, diff1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n \n\nso they really are all equal, all 500 of them.^[The computer  scientists among you will note that I shouldn't have done this,  because `diff1` through `diff3` are double-precision  decimal numbers, so I should have tested their equality with  `lenfol` and `los` by working out the absolute  differences and testing whether they were all *small*. On  consulting the help for `all.equal`, though, I find that it  *does* work properly, because it actually tests whether the  things being compared differ by less than a quantity  `tolerance` which defaults to 0.000000015, and if  they  do it calls them equal. This is all tied in with the difference  between integers and decimal numbers as they are represented on a  computer: exactly and approximately, respectively. A  double-precision number has about 16 significant digits of accuracy;  equal things won't have all 16 digits equal, most likely, but they  would be expected to have at least 8 of those digits the  same. CSCA08 stuff, I imagine. This is where you can casually toss  around terms like \"machine epsilon\". Oh! I just realized  something. You know how very very small P-values are shown in R as  *<2.2e-16*? *That's* the machine epsilon. Anything smaller than that is  indistinguishable from zero, and you can't have a P-value be  *exactly* zero. The default `tolerance` I mentioned  above is the square root of this, which is normally used for such  things.]\n\n$\\blacksquare$\n\n(d) Construct side-by-side boxplots of the length of followup by\neach followup status. You'll need to make sure\nthat the followup status, as it gets fed into `ggplot`, is a\n`factor`, or, at least, not the number that it is now.\n\n\nSolution\n\n\nThe easiest way to make a factor is to wrap `fstat`, which\nis a numeric 0 or 1, in `factor()`:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(whas3, aes(x = factor(fstat), y = lenfol)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-9-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \n\nOr create a factor version of `fstat` first:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 %>%\n  mutate(ffstat = factor(fstat)) %>%\n  ggplot(aes(x = ffstat, y = lenfol)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-10-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nI think the second way looks better, because you\nget a cleaner $x$-axis on your plot. But if you're doing this for\nexploration, rather than as something that's going to appear in a\nreport for your boss, the first way is fine.\n\n`ggplot` also treats text stuff as categorical where needed, so\nthis also works:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 %>%\n  mutate(cfstat = as.character(fstat)) %>%\n  ggplot(aes(x = cfstat, y = lenfol)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n Extra: this is an example of what's called \"survival data\": the purpose of the study was to see what affected how long a person survived after a heart attack. Each patient was followed up for the number of days in `lenfol`, but followup could have stopped for two (or more) reasons: the patient died (indicated by `fstat` being 1), or something else happened to them (`fstat` is 0), such as moving away from where the study was conducted, getting another disease, the funding for this study running out, or simply losing touch with the people doing the study. Such a patient is called \"lost to followup\" or \"censored\", and all we know about their survival is that they were still alive when last seen, but we don't know how long they lived after that.\n \nFor example:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas %>% select(id, lenfol, fstat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 500 x 3\n      id lenfol fstat\n   <dbl>  <dbl> <dbl>\n 1     1   2178     0\n 2     2   2172     0\n 3     3   2190     0\n 4     4    297     1\n 5     5   2131     0\n 6     6      1     1\n 7     7   2122     0\n 8     8   1496     1\n 9     9    920     1\n10    10   2175     0\n# i 490 more rows\n```\n\n\n:::\n:::\n\nThe patient with id 4 died after 297 days, but patients 1 through 3 lived for over 2000 days and were still alive when last seen. My guess for patients 1 through 3 is that the study ended and they were still alive:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas %>% summarize(maxfol = max(lenfol)/365.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 1\n  maxfol\n   <dbl>\n1   6.46\n```\n\n\n:::\n:::\n\nThe longest time anyone was followed up was six and a half years. Studies like this are funded for some number of years (say 10), and people can join after the beginning. (If they happen to join near the end, they won't get followed up for very long.)\n\nWe're not going to analyze these data, but if we were, we would want to take advantage of the information in the patient who lived for \"at least 2178 days\". Looking only at the patients who we knew to have died would be wasteful and might introduce a bias; for example, if we were comparing several treatments, and one of the treatments was so good that almost everybody on it was still alive at the end, we would want to have a strong inference that this treatment was the best.\n\nWith that in mind, let's redraw our boxplot with better labels for the followup status:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 %>% \n  mutate(followup_status = ifelse(fstat == 1, \"died\", \"censored\")) %>% \n  ggplot(aes(x = followup_status, y = lenfol)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-14-1.pdf){fig-pos='H'}\n:::\n:::\n\nNow we have a clearer sense of what is going on. Out of the patients who died, some of them survived a long time, but most of them died fairly quickly. Out of the patients who were censored, the times they were observed were all over the place, which suggests that (at least for the ones still in the study at the end) they joined the study at all kinds of different times.\n\nAnother graph that is possible here is a facetted histogram:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 %>% \n  mutate(followup_status = ifelse(fstat == 1, \"died\", \"censored\")) %>% \n  ggplot(aes(x = lenfol)) + geom_histogram(bins = 10) +\n  facet_wrap(~followup_status)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-15-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe right-skewed distribution of times to death is what we saw from the boxplot, but what is that periodic thing on the left? Let's convert the days to years and draw again:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 %>% \n  mutate(followup_status = ifelse(fstat == 1, \"died\", \"censored\")) %>% \n  mutate(followup_years = lenfol/365.25) %>% \n  ggplot(aes(x = followup_years)) + geom_histogram(bins = 20) +\n  facet_wrap(~followup_status)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-16-1.pdf){fig-pos='H'}\n:::\n:::\n\nThat's odd. On the left, it looks as if there were bursts of patients admitted to the study at around 1.5, 3.5, and 5.5 years from the end. (These are, remember, all people who survived and mostly people who survived to the end.) Not what I would have expected -- I would have expected a steady stream of patients, the heart attack victims as they happened to come in.\n\n$\\blacksquare$\n\n\n\n\n## Going to sleep\n\n A student keeps track of what time they go to bed and what time they get up in the morning. They also have an app on their phone that measures the number of hours they were asleep during that time. The data for one week are in [http://ritsokiguess.site/datafiles/sleeping.csv](http://ritsokiguess.site/datafiles/sleeping.csv), in the 24-hour clock.\n\n\n\n\n(a) Read in and display the data. What type of things are each of your columns? \n\nSolution\n\n\nThe usual, to start:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/sleeping.csv\"\nsleep <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 7 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl  (1): sleep.time\ndttm (2): bed.time, rise.time\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nsleep\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 3\n  bed.time            rise.time           sleep.time\n  <dttm>              <dttm>                   <dbl>\n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45\n```\n\n\n:::\n:::\n\nOn mine, the sleep time is an ordinary decimal number, but the two times are something called `dttm`, which I can guess means date-time. In your document, you might see\n`S3:POSIXct`, and you probably don't know what that is (although you can guess).^[Which one you see will depend on which type of output you are looking at. In your document you will probably see the POSIXCT thing, but in your HTML or PDF output it will probably say ``dttm''.]\n\nIf you search for this, you'll find some links to the help files, but a bit further down is [this](https://rstudio-pubs-static.s3.amazonaws.com/28038_1bcb9aa80ca84f27ace07d612872861a.html), which says it in a few words: \"These objects store the number of seconds (for `POSIXct`) ... since January 1st 1970 at midnight.\"^[The piece in quotes comes word-for-word from the source: it is exactly what the author said. Except that the author also talks about dates, which don't concern us here, so I removed that bit and replaced it with the three dots, called an \"ellipsis\", to show that the author said some extra stuff that I didn't quote. I checked that what remained does actually still capture what the author said. Extra-in-note: an ellipsis is not to be confused with the conic section called an ellipse, and these three dots are not to be confused with the three dots in an R function, where they mean \n\"anything else that was passed in to the function\". Both uses of the three dots capture the idea of \n\"something was missed out\".]\n\nMake the claim that the first two columns are genuine date-times, and if they are labelled `S3:POSIXct` for you, say how you know. That is to say, they may look like pieces of text laid out as date-times, but they are *actual* date-times stored internally as seconds since Jan 1 1970 and displayed nicely. Thus we *do not* need to use `ymd_hms` or anything similar to deal with them.\n\n\n$\\blacksquare$\n\n\n(b) Work out the fractional number of hours that the student was in bed each of these nights. (They may not have been asleep this whole time.) Your result needs to be a *number* since we will be doing some calculations with it shortly.\n\nSolution\n\n\nSince these are genuine date-times, you can take the difference, but the unit is not predictable. Internally, these are stored as a number of *seconds*, but it displays a \"nice\" unit:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(in_bed = rise.time - bed.time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 4\n  bed.time            rise.time           sleep.time in_bed        \n  <dttm>              <dttm>                   <dbl> <drtn>        \n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74 8.968056 hours\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92 8.720000 hours\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01 7.597222 hours\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23 7.396111 hours\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34 7.992222 hours\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42 8.162222 hours\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45 6.881111 hours\n```\n\n\n:::\n:::\n\nIn this case, we did get a number of hours, but in the next part, we are going to do a calculation like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(in_bed = rise.time - bed.time) %>% \nmutate(ratio = sleep.time / in_bed)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in `mutate()`:\ni In argument: `ratio = sleep.time/in_bed`.\nCaused by error in `/.difftime`:\n! second argument of / cannot be a \"difftime\" object\n```\n\n\n:::\n:::\n\nand this doesn't work because you can't divide a number by a time. (What would its units be?) So we have to turn `in_bed` into a number, and to do that we can divide by the number of seconds in an hour:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(in_bed = (rise.time - bed.time) / dhours(1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 4\n  bed.time            rise.time           sleep.time in_bed\n  <dttm>              <dttm>                   <dbl>  <dbl>\n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74   8.97\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92   8.72\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01   7.60\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23   7.40\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34   7.99\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42   8.16\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45   6.88\n```\n\n\n:::\n:::\n\nThis is now correctly a (decimal) number.\n\n\n$\\blacksquare$\n\n\n(c) The student is concerned with something they call \"sleep efficiency\". This is the percentage of time in bed spent sleeping. Work out the student's sleep efficiency for the seven nights in this dataframe. Which night was the student's sleep efficiency greatest?\n\nSolution\n\n\nDivide the sleep time by the in-bed time and multiply by 100. To answer the last part of the question, you might think of sorting these in descending order as well:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(in_bed = (rise.time - bed.time) / dhours(1)) %>% \nmutate(efficiency = sleep.time / in_bed * 100) %>% \narrange(desc(efficiency))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 5\n  bed.time            rise.time           sleep.time in_bed efficiency\n  <dttm>              <dttm>                   <dbl>  <dbl>      <dbl>\n1 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45   6.88       93.7\n2 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01   7.60       92.3\n3 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42   8.16       90.9\n4 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92   8.72       90.8\n5 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23   7.40       84.2\n6 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34   7.99       79.3\n7 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74   8.97       75.2\n```\n\n\n:::\n:::\n\nThe night of September 8. This was the night the student went to bed the latest, but they were asleep almost all the time they were in bed.\n\n\n$\\blacksquare$\n\n\n(d) Display the time spent in bed each night as a number of hours, minutes and seconds.\n\nSolution\n\n\nThe idea here is to display the time between going to bed and getting up as an interval, using `%--%`, and then turn that into a period:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(in_bed_hms = as.period(bed.time %--% rise.time))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 4\n  bed.time            rise.time           sleep.time in_bed_hms\n  <dttm>              <dttm>                   <dbl> <Period>  \n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74 8H 58M 5S \n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92 8H 43M 12S\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01 7H 35M 50S\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23 7H 23M 46S\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34 7H 59M 32S\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42 8H 9M 44S \n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45 6H 52M 52S\n```\n\n\n:::\n:::\n\n\n$\\blacksquare$\n\n\n(e) Make a graph of what time the student went to bed each night. Bear in mind that you only need the times, not the dates, and that you want a graph that is informative, showing appropriately the distribution of times the student went to bed.\n\nSolution\n\n\nIf you just pull out the times, some of them will be at the end of the day and some will be at the beginning. Extracting the hours, minutes and seconds is one way:^[Make sure you use \"hour\" and not \"hours\" as I did the first time. That computes the total number of hours between the zero date of Jan 1, 1970 and the time given, and so is way too large to be an answer here!]\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(h = hour(bed.time), m = minute(bed.time), s = second(bed.time))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 6\n  bed.time            rise.time           sleep.time     h     m     s\n  <dttm>              <dttm>                   <dbl> <int> <int> <dbl>\n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74    23     5    24\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92    22    51     9\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01     0     9    16\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23    23    43    31\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34     0    17    41\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42    22    42    27\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45     0    22    27\n```\n\n\n:::\n:::\n\nYou could convert these into fractional hours to make a histogram of:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(h = hour(bed.time), m = minute(bed.time), s = second(bed.time)) %>% \nmutate(bed_time_hours = h + m / 60 + s / (60*60))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 7\n  bed.time            rise.time           sleep.time     h     m     s\n  <dttm>              <dttm>                   <dbl> <int> <int> <dbl>\n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74    23     5    24\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92    22    51     9\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01     0     9    16\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23    23    43    31\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34     0    17    41\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42    22    42    27\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45     0    22    27\n# i 1 more variable: bed_time_hours <dbl>\n```\n\n\n:::\n:::\n\nbut if you make a histogram of these, this is what you get:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(h = hour(bed.time), m = minute(bed.time), s = second(bed.time)) %>% \nmutate(bed_time_hours = h + m / 60 + s / (60*60)) %>% \nggplot(aes(x = bed_time_hours)) + geom_histogram(bins = 5)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/sleeping-9-1.pdf){fig-pos='H'}\n:::\n:::\n\nbut this makes no sense because the bedtimes after midnight are on the end of the previous day, not the beginning of the next one!\n\nWith that in mind, let's move the bedtimes that are, say, before 3:00am to the end of the previous day by adding 24 to them before we make the graph:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(h = hour(bed.time), m = minute(bed.time), s = second(bed.time)) %>% \nmutate(bed_time_hours = h + m / 60 + s / (60*60)) %>% \nmutate(bed_time_hours = ifelse(bed_time_hours < 3, bed_time_hours + 24, bed_time_hours)) %>% \nggplot(aes(x = bed_time_hours)) + geom_histogram(bins = 5)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/sleeping-10-1.pdf){fig-pos='H'}\n:::\n:::\n\nThis gives a sense of where the bedtimes are. If you're used to reading the 24-hour clock, you'll know that 23 is 11:00pm, and you'll have a sense that some of the bedtimes were 11 or a bit earlier and some were around midnight. (I like the 24-hour clock.) There are only 7 observations, so the graph you get won't look very nice as a histogram, but at least this one says something about when the student went to bed, in a way that puts times just after midnight next to times just before. You should give some thought about the number of bins; with only 7 observations, even 5 bins is pushing it, but this looked nicer to me than 4 bins.\n\nIf you're more used to the 12-hour clock, you'll want to convert the times to something between 10 and 12. You can do this with an `ifelse` as above, subtracting 12 from the ones before midnight and adding 12 to the ones after. Or you can recognize this as modulo arithmetic (the clock is a classic case: what is 10:00pm plus 3 hours?) A little thought will reveal that subtracting (or adding) 12 hours and taking the result modulo 24 would do it: the pre-midnight bedtimes will get turned into a number like 10 or 11, and the post-midnight ones to 12 and a bit. R has a modulo operator, which is `%%` (cite your source: mine was [this](https://stat.ethz.ch/R-manual/R-patched/library/base/html/Arithmetic.html)):\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(h = hour(bed.time), m = minute(bed.time), s = second(bed.time)) %>% \nmutate(bed_time_hours = h + m / 60 + s / (60*60)) %>% \nmutate(bed_time_hours = (bed_time_hours - 12) %% 24) %>% \nggplot(aes(x = bed_time_hours)) + geom_histogram(bins = 5)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/sleeping-11-1.pdf){fig-pos='H'}\n:::\n:::\n\nand you might find the $x$-scale of that easier to cope with. (The bins have come out differently, for some reason.)\n\nI think the best graph uses the fact that date-times plot nicely, so if we keep them as date-times, the $x$-scale will look nice. The problem is that they are times on *different* days. What if we faked it up so that they were all on the *same* day (or, at least, consecutive days, to account for the ones after midnight)?\n\nLet's look at our dataframe again:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 3\n  bed.time            rise.time           sleep.time\n  <dttm>              <dttm>                   <dbl>\n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45\n```\n\n\n:::\n:::\n\nThe `rise.time` values are all a.m., and on consecutive days, so if we subtract consecutive numbers of days from the `bed.time`s, we'll put them all on appropriate days too:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(time_of_bed = bed.time - ddays(0:6))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 x 4\n  bed.time            rise.time           sleep.time time_of_bed        \n  <dttm>              <dttm>                   <dbl> <dttm>             \n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74 2013-09-01 23:05:24\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92 2013-09-01 22:51:09\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01 2013-09-02 00:09:16\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23 2013-09-01 23:43:31\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34 2013-09-02 00:17:41\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42 2013-09-01 22:42:27\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45 2013-09-02 00:22:27\n```\n\n\n:::\n:::\n\nThese are all around the midnight at the end of September 1, so some of them are in the early hours of September 2. Now, if we make a histogram of *those*:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(time_of_bed = bed.time - ddays(0:6)) %>% \nggplot(aes(x = time_of_bed)) + geom_histogram(bins = 5)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/sleeping-14-1.pdf){fig-pos='H'}\n:::\n:::\nNow the $x$-axis formatting looks like a time, and spills seamlessly into the next day. (There was no real range of dates, so the formatting is of the times only.)\n\nOne more embellishment, idea from [here](https://www.r-bloggers.com/2018/06/customizing-time-and-date-scales-in-ggplot2/):\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(time_of_bed = bed.time - ddays(0:6)) %>% \nggplot(aes(x = time_of_bed)) + geom_histogram(bins = 5) +\nscale_x_datetime(date_labels = \"%l:%M %p\")\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/sleeping-15-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe `scale_x` and `scale_y` functions customize the $x$ and $y$ axes respectively. Inside `date_labels` go some codes that say what time units you want to display: in this case, the 12-hour hours, the minutes, and whether the time is AM or PM. The codes come from a function called `strftime`, and a full list is [here](https://man7.org/linux/man-pages/man3/strftime.3.html). Alternatively, you can look up the help for R's function of the same name with `?strftime`.^[Confusingly, uppercase I and lowercase l not only look the same, but they also both display the 12-hour hour. The former adds a zero to the front if the hour is a single digit, and the latter does not. All the hours here have two digits, though, so it comes out the same whichever you use.]\n\n\n$\\blacksquare$\n\n\n\n\n",
=======
    "markdown": "# Dates and times\n\nThe usual to begin with:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Growth of Mizuna lettuce seeds\n\n\n In 2010, a group of students planted some Mizuna lettuce\nseeds, and recorded how they grew. The data were saved in an Excel\nspreadsheet, which is at\n[link](http://ritsokiguess.site/datafiles/mizuna.xlsx). The columns\nare: the date, the height (in cm) of (I presume) the tallest plant,\nthe amount of water added since the previous date (ml), the\ntemperature in the container where the seedlings were growing, and any\nadditional notes that the students made (edited for length by me). The\ntop line of the data file is variable names.\n\n\n\n(a) Read the\nspreadsheet data.\n\n\n\n(b) Make a plot of `height` against your\ndates, with the points joined by lines.\n\n\n\n(c) Label each point on the plot with the\namount of water added up to that point.\n\n\n\n\n\n\n##  Types of childbirth\n\n\n Childbirths can be of two types: a\n\"vaginal\" birth in which the child is born through the mother's\n vagina in the normal fashion, and a \"cesarean section\" where a\n surgeon cuts through the wall of the mother's abdomen, and the baby\n is delivered through the incision. Cesarean births are used when\n there are difficulties in pregnancy or during childbirth that would\n make a vaginal birth too risky.\nA hospital kept track of the number of vaginal and Cesarean births\n for the twelve months of 2012. Of interest is whether the Cesarean\n rate (the ratio of Cesarean births to all births) was increasing,\n decreasing or remaining stable over that time.\nThe data may be found at\n [link](http://ritsokiguess.site/datafiles/birthtypes.txt). The\n columns are the names of the months (in 2012), the number of cesarean\n births and the number of vaginal births. (The data are not real, but\n are typical of the kind of thing you would observe.)\n\n\n(a) Read the data into R and display your data frame.\n\n\n(b) Create a column of actual dates and also a column of\ncesarean rates, as defined above. Store your new data frame in a\nvariable and display it. For the dates, assume that each date is of\nthe 1st of the month that it belongs to.\n\n\n(c) Plot the cesarean rate against time, with a smooth\ntrend. Do you see an upward trend, a downward trend, no trend, or\nsomething else?\n\n\n(d) Try to summarize the trend you just found with a\ncorrelation. What goes wrong? How can you fix it?\n\n\n\n\n\n##  Wolves and caribou\n\n\n In Denali National Park, Alaska, the size of the wolf\npopulation depends on the size of the caribou population (since\nwolves hunt and kill caribou). This is a large national park, so\ncaribou are found in very large herds, so big, in fact, that the\nwell-being of the entire herd is not threatened by wolf\nattacks.^[In fact, it is believed that wolves help keep caribou herds strong by preventing over-population: that is, the weakest caribou are the ones taken by wolves.] \nCan the size of the caribou population\nbe used to predict the size of the wolf population?\nThe data can be found at\n[link](http://ritsokiguess.site/datafiles/caribou.txt). The\ncolumns \nare: the date of the survey,^[The survey is always taken in    the fall, but the date varies.] \nthe name of the park employee in charge  of the survey, the caribou population (in hundreds) and the wolf  population (actual count).^[Counting animals in a region,    especially rare, hard-to-find animals, is a whole science in    itself. Our data are probably themselves estimates (with some    uncertainty).] \n\n\n(a) Take a look at the data file. How would you describe its\nformat? Read it into R, and check that you got something sensible.\n\n\n\n(b) Create a new data frame where the column labelled\n`date` is now a genuine R `Date`, using something\nfrom `lubridate`.\n\n\n(c) Create new columns containing the days of\nthe week and the month names for the dates.\n\n\n\n(d) Enough playing around with dates. Make a scatterplot of\ncaribou population (explanatory) against wolf population\n(response). Do you see any relationship?\n\n\n\n(e) On your plot from the previous part, label each point with\nthe year it belongs to. You can do this in two steps: first make a\nnew column containing just the years, and then use it as labels\nfor the points on the plot.\n\n\n(f) Make a plot of caribou population against time (this is done\nthe obvious way). What seems to be happening to the caribou\npopulation over time?\n\n\n\n(g) The caribou and wolf populations over time are \nreally \"time series\". \nSee if you can make a plot of *both* the\ncaribou and wolf populations against time. You can make two\n$y$-axes, one for caribou and one for wolf; this will probably\nrequire some research on your part to figure out.\n\n\n\n\n\n\n\n\n\n##  Dealing with dates in the Worcester Heart Attack study\n\n\n The Worcester Heart Attack Study is an ongoing study of\nheart attacks in the Worcester, MA area. The main purpose of the study\nis to investigate changes over time in incidence and death rates, and also\nthe use of different treatment approaches. We will be mainly using\nthis data set to investigate data handling and dealing with dates. The\ndata can be found at\n[link](http://ritsokiguess.site/datafiles/whas500.txt). \n\n\n\n(a) Read the data into R. The reading-in part is\nstraightforward, but check what type of thing each column is. Is\nthat what it should be?\n\n\n\n(b) The date columns should be R dates. They are not\nyear-month-day, so converting them via `as.Date` (which is\nwhat `read_delim` tries to do) will not work. Load the\n`lubridate` package, and create new columns in your data\nframe that are properly dates. Save your data frame, and list it to\ndemonstrate that it worked.\n\n\n\n(c) Create three new variables `diff1, diff2, diff3` that\nare the numbers of days between each of your dates, and save the\ndata frame in which they have been created. Verify that at\nleast some of them are the same as `los` and `lenfol`.\n\n\n\n(d) Construct side-by-side boxplots of the length of followup by\neach followup status. You'll need to make sure\nthat the followup status, as it gets fed into `ggplot`, is a\n`factor`, or, at least, not the number that it is now.\n\n\n\n\n\n\n## Going to sleep\n\n A student keeps track of what time they go to bed and what time they get up in the morning. They also have an app on their phone that measures the number of hours they were asleep during that time. The data for one week are in [http://ritsokiguess.site/datafiles/sleeping.csv](http://ritsokiguess.site/datafiles/sleeping.csv), in the 24-hour clock.\n\n\n\n\n(a) Read in and display the data. What type of things are each of your columns? \n\n\n\n(b) Work out the fractional number of hours that the student was in bed each of these nights. (They may not have been asleep this whole time.) Your result needs to be a *number* since we will be doing some calculations with it shortly.\n\n\n\n(c) The student is concerned with something they call \"sleep efficiency\". This is the percentage of time in bed spent sleeping. Work out the student's sleep efficiency for the seven nights in this dataframe. Which night was the student's sleep efficiency greatest?\n\n\n\n(d) Display the time spent in bed each night as a number of hours, minutes and seconds.\n\n\n\n(e) Make a graph of what time the student went to bed each night. Bear in mind that you only need the times, not the dates, and that you want a graph that is informative, showing appropriately the distribution of times the student went to bed.\n\n\n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n##  Growth of Mizuna lettuce seeds\n\n\n In 2010, a group of students planted some Mizuna lettuce\nseeds, and recorded how they grew. The data were saved in an Excel\nspreadsheet, which is at\n[link](http://ritsokiguess.site/datafiles/mizuna.xlsx). The columns\nare: the date, the height (in cm) of (I presume) the tallest plant,\nthe amount of water added since the previous date (ml), the\ntemperature in the container where the seedlings were growing, and any\nadditional notes that the students made (edited for length by me). The\ntop line of the data file is variable names.\n\n\n\n(a) Read the\nspreadsheet data.\n\n\nSolution\n\n\nThis is `read_excel` from package `readxl`. I'm\nnot sure what will happen to the dates yet. Note that this needs\na \"local\" copy of the spreadsheet (that is, you have to\ndownload it and save it on your computer, then upload it to\n`r.datatools`), possibly using `file.choose` to\nhelp R find it. I put my copy in the same project folder as I was\nworking in, so I just need the file name:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nmizuna <- read_excel(\"mizuna.xlsx\")\nmizuna\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 13 x 5\n   date                height water temperature notes                           \n   <dttm>               <dbl> <dbl>       <dbl> <chr>                           \n 1 2010-02-16 00:00:00    0     400        21   planted seeds; water soaked up ~\n 2 2010-02-18 00:00:00    0       0        22.5 2 of 6 seeds not appeared; soil~\n 3 2010-02-19 00:00:00    0     200        20.9 4 of 6 plants broken surface    \n 4 2010-02-22 00:00:00    3.2   100        20.8 Last seed hasnâ€™t broken surface \n 5 2010-02-23 00:00:00    4.5   100        22.9 Plants growing well.            \n 6 2010-02-25 00:00:00    6     100        21.8 Last seed sprouted; plants look~\n 7 2010-02-26 00:00:00    6.5   200        21.2 <NA>                            \n 8 2010-03-01 00:00:00    9.5   200        21.8 <NA>                            \n 9 2010-03-03 00:00:00   11.1   200        21.7 Plants needing more water       \n10 2010-03-05 00:00:00   13     250        21.9 <NA>                            \n11 2010-03-08 00:00:00   14.5   500        22.5 No water left, leaves droopy. A~\n12 2010-03-10 00:00:00   16     200        21.2 Plants green and healthy        \n13 2010-03-17 00:00:00   18.5   800        20.8 Harvest. Tips of plants turning~\n```\n:::\n:::\n\n     \n\nThe dates *did* get read properly. `dttm` is\n\"date-time\", so I guess it's allowing for the possibility that my\ndates had times attached as well. \nThe years do actually come out right.\n\n$\\blacksquare$\n\n(b) Make a plot of `height` against your\ndates, with the points joined by lines.\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mizuna, aes(x = date, y = height)) + geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/mizuna-r-2-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \n\n$\\blacksquare$\n\n(c) Label each point on the plot with the\namount of water added up to that point.\n\n\nSolution\n\n\nThis is `water` again. The way to do this is to load\n`ggrepel`, then add `geom_text_repel` to the\nplot, by adding `label=water` to the *original*\n`aes`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggrepel)\nggplot(mizuna, aes(x = date, y = height, label = water)) +\n  geom_point() + geom_line() + geom_text_repel(colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/mizuna-r-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nI made the text red, so that you can see it more easily. It \"repels\"\naway from the points, but not from the lines joining them. Which makes\nme wonder whether this would work better (I explain `alpha` afterwards):\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggrepel)\nggplot(mizuna, aes(x = date, y = height, label = water)) +\n  geom_point() + geom_line() + geom_label_repel(colour = \"red\", \n                                                alpha = 0.7)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/mizuna-r-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nThe difference between `text` and `label` is that\n`text` just uses the text of the variable to mark the point,\nwhile `label` puts that text in a box.\n\nI think it works better. You can see where the line goes (under the boxes with\nthe labels in them), but you can see the labels clearly.\n\nWhat that `alpha` does is to make the thing it's attached to\n(the labels) partly *transparent*. If you leave it out (try it),\nthe black line disappears completely under the label boxes and you\ncan't see where it goes at all. The value you give for `alpha`\nsays how transparent the thing is, from 1 (not transparent at all)\ndown to 0 (invisible). I first tried 0.3, and you could hardly see the\nboxes; then I tried 0.7 so that the boxes were a bit more\nprominent but the lines underneath were still slightly visible, and I\ndecided that this is what I liked. I think making the labels a\ndifferent colour was a good idea, since that helps to distinguish the\nnumber on the label from the line underneath.\n\nYou can apply `alpha` to pretty much any `ggplot` thing\nthat might be on top of something else, to make it possible to see\nwhat's underneath it. The commonest use for it is if you have a\nscatterplot with a lot of points; normally, you only see some of the\npoints, because the plot is then a sea of black. But if you make the\npoints partly transparent, you can see more of what's nearby that\nwould otherwise have been hidden. \n\nAt some point, I also have to show\nyou folks `jitter`, which plots in slightly different places\npoints that would otherwise overprint each other exactly, and you\nwouldn't know how many of them there were, like the outliers on the\nboxplots of German children near the new airport.\n\n$\\blacksquare$\n\n\n\n\n##  Types of childbirth\n\n\n Childbirths can be of two types: a\n\"vaginal\" birth in which the child is born through the mother's\n vagina in the normal fashion, and a \"cesarean section\" where a\n surgeon cuts through the wall of the mother's abdomen, and the baby\n is delivered through the incision. Cesarean births are used when\n there are difficulties in pregnancy or during childbirth that would\n make a vaginal birth too risky.\nA hospital kept track of the number of vaginal and Cesarean births\n for the twelve months of 2012. Of interest is whether the Cesarean\n rate (the ratio of Cesarean births to all births) was increasing,\n decreasing or remaining stable over that time.\nThe data may be found at\n [link](http://ritsokiguess.site/datafiles/birthtypes.txt). The\n columns are the names of the months (in 2012), the number of cesarean\n births and the number of vaginal births. (The data are not real, but\n are typical of the kind of thing you would observe.)\n\n\n(a) Read the data into R and display your data frame.\n\nSolution\n\n\nThis is a space-delimited text file, which means:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/birthtypes.txt\"\nbirths <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 12 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (1): month\ndbl (2): cesarean, vaginal\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nbirths\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 x 3\n   month cesarean vaginal\n   <chr>    <dbl>   <dbl>\n 1 Jan         11      68\n 2 Feb          9      63\n 3 Mar         10      72\n 4 Apr         18     105\n 5 May         10      90\n 6 Jun         10      92\n 7 Jul         11      78\n 8 Aug          9      83\n 9 Sep          9      90\n10 Oct         15     101\n11 Nov         12     130\n12 Dec          8     101\n```\n:::\n:::\n\n \n\nSome text and two numbers for each month. Check.\n\n$\\blacksquare$\n\n(b) Create a column of actual dates and also a column of\ncesarean rates, as defined above. Store your new data frame in a\nvariable and display it. For the dates, assume that each date is of\nthe 1st of the month that it belongs to.\n\nSolution\n\n\nThe easiest way is to use `str_c` or `paste` to\ncreate a text date with year, month and day in some order, and\nthen to use the appropriate function from `lubridate` to\nturn that into an actual `date`. If you use\n`str_c`, you (probably) need the `sep` thing to\nmake sure the values get a space between them; `paste`\ndoes this automatically. (The next question is whether\n`ymd` or whatever can cope without spaces, but I'm not\nexploring that.)\nThe cesarean rate is `cesarean` divided by\n`cesarean` plus `vaginal`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\nb2 <- births %>%\n  mutate(datestr = str_c(\"2012\", month, \"1\", sep = \" \")) %>%\n  mutate(thedate = ymd(datestr)) %>%\n  mutate(cesarean_rate = cesarean / (cesarean + vaginal))\nb2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 x 6\n   month cesarean vaginal datestr    thedate    cesarean_rate\n   <chr>    <dbl>   <dbl> <chr>      <date>             <dbl>\n 1 Jan         11      68 2012 Jan 1 2012-01-01        0.139 \n 2 Feb          9      63 2012 Feb 1 2012-02-01        0.125 \n 3 Mar         10      72 2012 Mar 1 2012-03-01        0.122 \n 4 Apr         18     105 2012 Apr 1 2012-04-01        0.146 \n 5 May         10      90 2012 May 1 2012-05-01        0.1   \n 6 Jun         10      92 2012 Jun 1 2012-06-01        0.0980\n 7 Jul         11      78 2012 Jul 1 2012-07-01        0.124 \n 8 Aug          9      83 2012 Aug 1 2012-08-01        0.0978\n 9 Sep          9      90 2012 Sep 1 2012-09-01        0.0909\n10 Oct         15     101 2012 Oct 1 2012-10-01        0.129 \n11 Nov         12     130 2012 Nov 1 2012-11-01        0.0845\n12 Dec          8     101 2012 Dec 1 2012-12-01        0.0734\n```\n:::\n:::\n\n        \n\nIf you don't like that, create columns that contain 2012 and 1 all\nthe way down. If you set a column name equal to a single value, that\nsingle value gets repeated the right number of times:^[This is  an example of R's so-called \"recycling rules\".]\n\n::: {.cell}\n\n```{.r .cell-code}\nbirths %>% mutate(year = 2012, day = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 x 5\n   month cesarean vaginal  year   day\n   <chr>    <dbl>   <dbl> <dbl> <dbl>\n 1 Jan         11      68  2012     1\n 2 Feb          9      63  2012     1\n 3 Mar         10      72  2012     1\n 4 Apr         18     105  2012     1\n 5 May         10      90  2012     1\n 6 Jun         10      92  2012     1\n 7 Jul         11      78  2012     1\n 8 Aug          9      83  2012     1\n 9 Sep          9      90  2012     1\n10 Oct         15     101  2012     1\n11 Nov         12     130  2012     1\n12 Dec          8     101  2012     1\n```\n:::\n:::\n\n \n\nand then use `unite` as in class. The distinction is that\n`unite` *only* works on columns. It also \"swallows up\"\nthe columns that it is made out of; in this case, the original year,\nmonth and day disappear:\n\n::: {.cell}\n\n```{.r .cell-code}\nbirths %>%\n  mutate(year = 2012, day = 1) %>%\n  unite(datestr, year, month, day) %>%\n  mutate(thedate = ymd(datestr)) %>%\n  mutate(cesarean_rate = cesarean / (cesarean + vaginal)) -> b3\nb3 %>% mutate(the_month = month(thedate))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 x 6\n   datestr    cesarean vaginal thedate    cesarean_rate the_month\n   <chr>         <dbl>   <dbl> <date>             <dbl>     <dbl>\n 1 2012_Jan_1       11      68 2012-01-01        0.139          1\n 2 2012_Feb_1        9      63 2012-02-01        0.125          2\n 3 2012_Mar_1       10      72 2012-03-01        0.122          3\n 4 2012_Apr_1       18     105 2012-04-01        0.146          4\n 5 2012_May_1       10      90 2012-05-01        0.1            5\n 6 2012_Jun_1       10      92 2012-06-01        0.0980         6\n 7 2012_Jul_1       11      78 2012-07-01        0.124          7\n 8 2012_Aug_1        9      83 2012-08-01        0.0978         8\n 9 2012_Sep_1        9      90 2012-09-01        0.0909         9\n10 2012_Oct_1       15     101 2012-10-01        0.129         10\n11 2012_Nov_1       12     130 2012-11-01        0.0845        11\n12 2012_Dec_1        8     101 2012-12-01        0.0734        12\n```\n:::\n:::\n\n \n\nI don't mind which order you glue your year, month and day together,\nas long as you construct the dates with the consistent\n`lubridate` function. \n\n$\\blacksquare$\n\n(c) Plot the cesarean rate against time, with a smooth\ntrend. Do you see an upward trend, a downward trend, no trend, or\nsomething else?\n\nSolution\n\n\nThis is a scatterplot with time on the $x$ axis:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(b3, aes(x = thedate, y = cesarean_rate)) + geom_point() + geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/tann-1.pdf){fig-pos='H'}\n:::\n:::\n\n        \n\nI like this better than joining the points by lines, since we already\nhave a trend on the plot, but you can do that in some contrasting way:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(b3, aes(x = thedate, y = cesarean_rate)) + geom_point() +\n  geom_line(linetype = \"dashed\") + geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/fletzlinger-1.pdf){fig-pos='H'}\n:::\n:::\n\n \nI see a downward trend. (\"A downward trend with a wiggle\" if you\nlike.) There is a certain unevenness\nin the trend of the actual data, but the overall picture appears to be\ndownhill. \n\n$\\blacksquare$\n\n(d) Try to summarize the trend you just found with a\ncorrelation. What goes wrong? How can you fix it?\n\nSolution\n\n\nSomething like this is the obvious guess:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(b3, cor(thedate, cesarean_rate))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in cor(thedate, cesarean_rate): 'x' must be numeric\n```\n:::\n:::\n\n \n\nThis fails because `thedate` is not of itself a number. But\nlurking in the background is how the date is actually\n*represented*: as a number of days since Jan 1, 1970. Thus,\npassing it through `as.numeric` might turn it into that:\n\n::: {.cell}\n\n```{.r .cell-code}\nb3 %>% mutate(numeric_date = as.numeric(thedate)) -> b5\nb5\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 x 6\n   datestr    cesarean vaginal thedate    cesarean_rate numeric_date\n   <chr>         <dbl>   <dbl> <date>             <dbl>        <dbl>\n 1 2012_Jan_1       11      68 2012-01-01        0.139         15340\n 2 2012_Feb_1        9      63 2012-02-01        0.125         15371\n 3 2012_Mar_1       10      72 2012-03-01        0.122         15400\n 4 2012_Apr_1       18     105 2012-04-01        0.146         15431\n 5 2012_May_1       10      90 2012-05-01        0.1           15461\n 6 2012_Jun_1       10      92 2012-06-01        0.0980        15492\n 7 2012_Jul_1       11      78 2012-07-01        0.124         15522\n 8 2012_Aug_1        9      83 2012-08-01        0.0978        15553\n 9 2012_Sep_1        9      90 2012-09-01        0.0909        15584\n10 2012_Oct_1       15     101 2012-10-01        0.129         15614\n11 2012_Nov_1       12     130 2012-11-01        0.0845        15645\n12 2012_Dec_1        8     101 2012-12-01        0.0734        15675\n```\n:::\n:::\n\n \n\nA little mental calculation suggests that these dates in 2012 are a\nbit over 40 years, that is $40 \\times 365 \\simeq 14000$ days, since\nthe \"zero\" date of Jan 1, 1970, and so it turns out. This suggests\nthat we can calculate a correlation with the numeric dates:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(b5, cor(numeric_date, cesarean_rate))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.7091219\n```\n:::\n:::\n\n \n\nand we can make a test of the null hypothesis that the correlation is\nzero (against a two-sided alternative) thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(b5, cor.test(numeric_date, cesarean_rate))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  numeric_date and cesarean_rate\nt = -3.1804, df = 10, p-value = 0.009813\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9119078 -0.2280145\nsample estimates:\n       cor \n-0.7091219 \n```\n:::\n:::\n\n \n\nThat downward trend is more than just chance, with a P-value just\nunder 0.01. Having said that, though, if you look at the confidence\ninterval for the correlation, it includes almost all the negative\nvalues it could be, so that with only 12 observations we really know\nvery little about the correlation other than that it appears to be\nnegative. \n\nExtra: \n In practice, you would typically have a much longer time series\n of measurements than this, such as monthly measurements for\n several years. In looking at only one year, like we did here,\n we could get trapped by seasonal effects: for example, cesarean\n rates might always go down through the year and then jump up\n again in January. Looking at several years would enable us to\n disentangle seasonal effects that happen every year from\n long-term trends. (As an example of this, think of Toronto\n snowfall: there is almost always snow in the winter and there\n is never snow in the summer, a seasonal effect, but in\n assessing climate change, you want to think about long-term\n trends in snowfall, after allowing for which month you're\n looking at.)\n \n$\\blacksquare$\n\n\n\n\n##  Wolves and caribou\n\n\n In Denali National Park, Alaska, the size of the wolf\npopulation depends on the size of the caribou population (since\nwolves hunt and kill caribou). This is a large national park, so\ncaribou are found in very large herds, so big, in fact, that the\nwell-being of the entire herd is not threatened by wolf\nattacks.^[In fact, it is believed that wolves help keep caribou herds strong by preventing over-population: that is, the weakest caribou are the ones taken by wolves.] \nCan the size of the caribou population\nbe used to predict the size of the wolf population?\nThe data can be found at\n[link](http://ritsokiguess.site/datafiles/caribou.txt). The\ncolumns \nare: the date of the survey,^[The survey is always taken in    the fall, but the date varies.] \nthe name of the park employee in charge  of the survey, the caribou population (in hundreds) and the wolf  population (actual count).^[Counting animals in a region,    especially rare, hard-to-find animals, is a whole science in    itself. Our data are probably themselves estimates (with some    uncertainty).] \n\n\n(a) Take a look at the data file. How would you describe its\nformat? Read it into R, and check that you got something sensible.\n\n\nSolution\n\n\nThis looks at first sight as if it's separated by spaces, but\nmost of the data values are separated by *more than one*\nspace. If you look further, you'll see that the values are\n*lined up in columns*, with the variable names aligned at\nthe top. \n\nThis used to be exactly the kind of thing that\n`read_table` would read, but no longer. We start with the usual\n`library(tidyverse)`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nmy_url <- \"http://ritsokiguess.site/datafiles/caribou.txt\"\ndenali <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  date = col_character(),\n  name = col_character(),\n  caribou = col_character(),\n  wolf = col_character()\n)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 7 parsing failures.\nrow col  expected    actual                                             file\n  1  -- 4 columns 5 columns 'http://ritsokiguess.site/datafiles/caribou.txt'\n  2  -- 4 columns 5 columns 'http://ritsokiguess.site/datafiles/caribou.txt'\n  3  -- 4 columns 5 columns 'http://ritsokiguess.site/datafiles/caribou.txt'\n  4  -- 4 columns 6 columns 'http://ritsokiguess.site/datafiles/caribou.txt'\n  5  -- 4 columns 5 columns 'http://ritsokiguess.site/datafiles/caribou.txt'\n... ... ......... ......... ................................................\nSee problems(...) for more details.\n```\n:::\n\n```{.r .cell-code}\ndenali\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 4\n  date       name       caribou wolf \n  <chr>      <chr>      <chr>   <chr>\n1 09/01/1995 David      S.      30   \n2 09/24/1996 Youngjin   K.      34   \n3 10/03/1997 Srinivasan M.      27   \n4 09/15/1998 Lee        Anne    J.   \n5 09/08/1999 Stephanie  T.      17   \n6 09/03/2000 Angus      Mc      D.   \n7 10/06/2001 David      S.      20   \n```\n:::\n:::\n\nThe spaces within the names have spilled into the next column, so that the dates and first names are (mostly) correct, but the initials should stay with the names.\n\nThe right thing now is `read_fwf`, where `fwf` stands for \"fixed-width format\"\n\n::: {.cell}\n\n```{.r .cell-code}\ndl_file <- \"caribou.txt\"\ndownload.file(my_url, dl_file)\nread_fwf(dl_file)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 8 Columns: 4\n-- Column specification --------------------------------------------------------\n\nchr (4): X1, X2, X3, X4\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 x 4\n  X1         X2            X3      X4   \n  <chr>      <chr>         <chr>   <chr>\n1 date       name          caribou wolf \n2 09/01/1995 David S.      30      66   \n3 09/24/1996 Youngjin K.   34      79   \n4 10/03/1997 Srinivasan M. 27      70   \n5 09/15/1998 Lee Anne J.   25      60   \n6 09/08/1999 Stephanie T.  17      48   \n7 09/03/2000 Angus Mc D.   23      55   \n8 10/06/2001 David S.      20      60   \n```\n:::\n:::\n\nThat's much closer, but it thought the column names were part of the data. We seem to need to enter them specifically:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_cols <- c(\"date\", \"name\", \"caribou\", \"wolf\")\ndenali <- read_fwf(dl_file, fwf_empty(dl_file, col_names = my_cols), skip = 1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 7 Columns: 4\n-- Column specification --------------------------------------------------------\n\nchr (2): date, name\ndbl (2): caribou, wolf\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\ndenali\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 4\n  date       name          caribou  wolf\n  <chr>      <chr>           <dbl> <dbl>\n1 09/01/1995 David S.           30    66\n2 09/24/1996 Youngjin K.        34    79\n3 10/03/1997 Srinivasan M.      27    70\n4 09/15/1998 Lee Anne J.        25    60\n5 09/08/1999 Stephanie T.       17    48\n6 09/03/2000 Angus Mc D.        23    55\n7 10/06/2001 David S.           20    60\n```\n:::\n:::\n\nand that's worked. The `fwf_empty` says to guess where the columns are based on where there are spaces all the way down (as `read_table` used to do), and to use the specified column names. The top line of the datafile is those column names, though, so we need to skip that row. A bit fiddly.\n\nAnyway, that (finally) worked: four columns with the right names, and the counts of\ncaribou and wolf are numbers. There are only seven years of surveys;\nin real-life data you would have more. But the point here is working\nwith dates.\n\nThe only (small) weirdness is that the\ndates are text rather than having been converted into dates. This is\nbecause they are not year-month-day, which is the only format that\ngets automatically converted into dates when read in. (You could use\n`mdy` from `lubridate` to make them dates.)\n\nExtra: you might have wondered how the names survived, even though\nthey have spaces in them, sometimes more than one. Here's how the file looks:\n\n\n```\n\ndate       name             caribou wolf\n09/01/1995 David S.         30       66\n09/24/1996 Youngjin K.      34       79\n10/03/1997 Srinivasan M.    27       70\n09/15/1998 Lee Anne J.      25       60\n09/08/1999 Stephanie T.     17       48\n09/03/2000 Angus Mc D.      23       55\n10/06/2001 David S.         20       60\n\n```\n\n\nWhat `read_table` looks for is columns that contain spaces\n*all the way down*, and separates the values there. For example,\nbetween the year of`date` and the first name in `name`\nthere is a space all the way down. After the names and before the\ncaribou counts there are several spaces, and there is one space\nbetween the words `caribou` and `wolf` in the header\nline that goes all the way down. Thus four columns, `date`,\n`name`, `caribou` and `wolf`. This means that the\nspaces within the names don't cause any problems at all, since the\nspaces aren't in the same place in *every* line.^[The only way this would fail is if *every* first name had the same number of letters in it; then the space between first name and initial of last name *would* be in the same place in every line.]\n\n$\\blacksquare$\n\n(b) Create a new data frame where the column labelled\n`date` is now a genuine R `Date`, using something\nfrom `lubridate`.\n\nSolution\n\n\nWhat you do is to look at the format of the dates as they are\nnow. They appear to be month-day-year, American\nstyle.^[Not a surprise since Denali National Park is in  Alaska.]  \nThus the function needed is `mdy`. It doesn't matter\nwhether the months are names or numbers:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>% mutate(date = mdy(date)) -> denali\ndenali\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 4\n  date       name          caribou  wolf\n  <date>     <chr>           <dbl> <dbl>\n1 1995-09-01 David S.           30    66\n2 1996-09-24 Youngjin K.        34    79\n3 1997-10-03 Srinivasan M.      27    70\n4 1998-09-15 Lee Anne J.        25    60\n5 1999-09-08 Stephanie T.       17    48\n6 2000-09-03 Angus Mc D.        23    55\n7 2001-10-06 David S.           20    60\n```\n:::\n:::\n\n     \n\nI lived on the edge and overwrote both my column and the whole data\nframe.^[It's actually not *really* living on the edge,  because if it doesn't work, you go back and read the data in from  the file again.]\n\nThe dates are displayed in ISO format, year-month-day. You see at the\ntop of the column that they now really *are* dates, not just\npieces of text that look like dates. \n\n$\\blacksquare$\n\n(c) Create new columns containing the days of\nthe week and the month names for the dates.\n\n\nSolution\n\n\nThis involves digging in the `lubridate` help to find out how to extract things from a date. It turns out that `wday` extracts the day of the week from a date, by default as a number, and `month` gets the month, also by default as a number:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>% mutate(mon = month(date), wd = wday(date))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 6\n  date       name          caribou  wolf   mon    wd\n  <date>     <chr>           <dbl> <dbl> <dbl> <dbl>\n1 1995-09-01 David S.           30    66     9     6\n2 1996-09-24 Youngjin K.        34    79     9     3\n3 1997-10-03 Srinivasan M.      27    70    10     6\n4 1998-09-15 Lee Anne J.        25    60     9     3\n5 1999-09-08 Stephanie T.       17    48     9     4\n6 2000-09-03 Angus Mc D.        23    55     9     1\n7 2001-10-06 David S.           20    60    10     7\n```\n:::\n:::\n\n     \n\nThis is not what we wanted, though; we wanted the names of the months\nand of the days. To fix that, add `label=T` to both functions:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>% mutate(mon = month(date, label = T), wd = wday(date, label = T))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 6\n  date       name          caribou  wolf mon   wd   \n  <date>     <chr>           <dbl> <dbl> <ord> <ord>\n1 1995-09-01 David S.           30    66 Sep   Fri  \n2 1996-09-24 Youngjin K.        34    79 Sep   Tue  \n3 1997-10-03 Srinivasan M.      27    70 Oct   Fri  \n4 1998-09-15 Lee Anne J.        25    60 Sep   Tue  \n5 1999-09-08 Stephanie T.       17    48 Sep   Wed  \n6 2000-09-03 Angus Mc D.        23    55 Sep   Sun  \n7 2001-10-06 David S.           20    60 Oct   Sat  \n```\n:::\n:::\n\n \nand that cracks it.\n\nNo need to save this data frame anywhere, since we're not using any of\nthis later.\n\nExtra: the `ord` means \"ordered factor\", which makes sense\nsince these are categorical variables with a natural order. This means\nthat you could do something like counting the number of surveys in\neach month like this:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>%\n  mutate(mon = month(date, label = T), wd = wday(date, label = T)) %>%\n  count(mon)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 2\n  mon       n\n  <ord> <int>\n1 Sep       5\n2 Oct       2\n```\n:::\n:::\n\n \n      \n$\\blacksquare$\n\n(d) Enough playing around with dates. Make a scatterplot of\ncaribou population (explanatory) against wolf population\n(response). Do you see any relationship?\n\n\nSolution\n\n\nNothing terribly surprising here:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = caribou, y = wolf)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \nIf you like, add a smooth trend to it:^[This wiggles more than  I would like, with such a small number of observations. Try putting  something like `span=2` in the smooth to make it less wiggly.]\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = caribou, y = wolf)) + geom_point() + geom_smooth(se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-7-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \n\nThis is an upward trend: when one population is large, the other one\nis large too. This is typical for predator-prey relationships: when\nthere is more to eat (more caribou) the wolf population goes up, and\nwhen less, it goes down. \n      \n$\\blacksquare$\n\n(e) On your plot from the previous part, label each point with\nthe year it belongs to. You can do this in two steps: first make a\nnew column containing just the years, and then use it as labels\nfor the points on the plot.\n\nSolution\n\n\nI'm going to use `geom_text_repel` for the labels from package\n`ggrepel`. The year values are gotten using the\n`lubridate` function `year`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>%\n  mutate(year = year(date)) %>%\n  ggplot(aes(x = caribou, y = wolf, label = year)) + geom_point() + geom_text_repel()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-8-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nI thought about joining up the points in year order. This is actually\n*not* `geom_line` as you would have guessed, since what that\ndoes is to join points in the order of the variable on the\n$x$-axis.^[I have to say that I didn't know that until just now.]\nTo join points in the order that they are in the data (what we want\nhere, because the points are in time order in the data), use instead \n`geom_path`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>%\n  mutate(year = year(date)) %>%\n  ggplot(aes(x = caribou, y = wolf, label = year)) + geom_point() +\n  geom_text_repel() + geom_path()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-9-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nIn 1996, both populations were large, and both showed a steady decline\nuntil 1999. In 2000 and 2001, both populations seemed to be on the way\nup again, and you can imagine that in a couple of years, things would\ngo back to about where they were in 1995.\n\n$\\blacksquare$\n\n(f) Make a plot of caribou population against time (this is done\nthe obvious way). What seems to be happening to the caribou\npopulation over time?\n\n\nSolution\n\n\nMake a scatterplot, with the survey date as explanatory\nvariable, and caribou population as response (since time always\ngoes on the $x$-axis):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou)) + geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-10-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nI used an ordinary `geom_line` this time, to connect neighbouring\nyears, as is often done with a time series. The overall trend is\ndownward, though the 1999 value might be a low from which the\npopulation is recovering.\n      \n$\\blacksquare$\n\n(g) The caribou and wolf populations over time are \nreally \"time series\". \nSee if you can make a plot of *both* the\ncaribou and wolf populations against time. You can make two\n$y$-axes, one for caribou and one for wolf; this will probably\nrequire some research on your part to figure out.\n\n\nSolution\n\n\nThe obvious starting point is to note that both the\n`caribou` and `wolf` columns are animal\npopulations, just of different animals. One way of plotting both\npopulations is to `pivot_longer` them up into one longer column, and\nthen plot them against time, with the two animals distinguished\nby colour:\n\n::: {.cell}\n\n```{.r .cell-code}\ndenali %>%\n  pivot_longer(caribou:wolf, names_to=\"animal\", values_to=\"population\") %>%\n  ggplot(aes(x = date, y = population, colour = animal)) +\n  geom_point() + geom_line()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \nThis is not quite the story, though, because the caribou and wolf\npopulations are on different scales. The caribou population is\nnumbered in hundreds, while the wolf population is an actual count. \n\nThe surveys are late in the year, so the one that is nearly in 1996 is\nactually the 1995 survey.\n\nWhat would be nice would be to have a secondary $y$-axis, so that\nthere were two $y$-scales, one for each animal. This is very easy to\nmanipulate, though (you can change either scale and get a very\ndifferent-looking graph), so we ought to be careful.\n\nAll right, so let's put the caribou on the left:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou)) + geom_line()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nOr we can add a `colour` aesthetic to distinguish the caribou\nfrom the wolf populations, that we're going to add in a moment. This looks rather odd at first:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou, colour = \"caribou\")) + geom_line()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-13-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nNow we think about adding the wolf numbers. This is done by adding a\nsecond `geom_line`, overriding the `y` and the\n`colour` to specify that this is wolf now:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou, colour = \"caribou\")) +\n  geom_line() +\n  geom_line(aes(y = wolf, colour = \"wolf\"))\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-14-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nWhat has happened is that we get lines of different colour for each\nanimal, with a legend. So far so good. The problem is that the wolf\nnumbers are about 2.5 times bigger than the caribou\nnumbers,^[Which means, if you stop to think about it, that  there are *actually* about 40 times more caribou than wolves.]\nso that\nwe don't get a good sense of how they go up and down together. If we\ndivided the wolf numbers by 2.5, we would see this better:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou, colour = \"caribou\")) +\n  geom_line() +\n  geom_line(aes(y = wolf / 2.5, colour = \"wolf\"))\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-15-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nNow we get to the secondary $y$-axis. We want to label this\n`wolf` and have it reflect that we actually made the graph by\ndividing the wolf values by 2.5:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(denali, aes(x = date, y = caribou, colour = \"caribou\")) +\n  geom_line() +\n  geom_line(aes(y = wolf / 2.5, colour = \"wolf\")) +\n  scale_y_continuous(sec.axis = sec_axis(~ . * 2.5, name = \"wolf\"))\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/denali-r-16-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nWoo, and, very possibly, hoo. I got most of these ideas from\n[link](https://rpubs.com/MarkusLoew/226759). \n\nNow we see how the populations vary over time, and also that they vary\ntogether. \n\nThis is about the only double-$y$-axis setup that I like, with scales\nchosen so that both the series vary about the same amount. By\n\"discreetly\" changing the wolf scale, you could make it look as if\none population was much bigger than the other, or varied much more\nthan the other. Lies and statistics.\n\nIn my opinion, too many people just plot series against time, possibly\nwith a second $y$-axis.^[And all too often with Excel (spit).]\nVariables that vary together, like the wolf\nand caribou populations here, ought to be plotted *against each\nother* on a scatterplot, possibly with the time points labelled.\n\nThe ambitious among you may like to compare the graphs here with\nother predator-prey relationships. If you are of a mathematical bent,\nyou might look into the Lotka-Volterra equations, which is a system of\ntwo differential equations describing how changes in one population\ncause changes in the other population.\n\n$\\blacksquare$\n\n\n\n\n\n\n\n##  Dealing with dates in the Worcester Heart Attack study\n\n\n The Worcester Heart Attack Study is an ongoing study of\nheart attacks in the Worcester, MA area. The main purpose of the study\nis to investigate changes over time in incidence and death rates, and also\nthe use of different treatment approaches. We will be mainly using\nthis data set to investigate data handling and dealing with dates. The\ndata can be found at\n[link](http://ritsokiguess.site/datafiles/whas500.txt). \n\n\n\n(a) Read the data into R. The reading-in part is\nstraightforward, but check what type of thing each column is. Is\nthat what it should be?\n\n\nSolution\n\n\nThis is `read_delim`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/whas500.txt\"\nwhas <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 500 Columns: 22\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr  (3): admitdate, disdate, fdate\ndbl (19): id, age, gender, hr, sysbp, diasbp, bmi, cvd, afb, sho, chf, av3, ...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nwhas\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 500 x 22\n      id   age gender    hr sysbp diasbp   bmi   cvd   afb   sho   chf   av3\n   <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1    83      0    89   152     78  25.5     1     1     0     0     0\n 2     2    49      0    84   120     60  24.0     1     0     0     0     0\n 3     3    70      1    83   147     88  22.1     0     0     0     0     0\n 4     4    70      0    65   123     76  26.6     1     0     0     1     0\n 5     5    70      0    63   135     85  24.4     1     0     0     0     0\n 6     6    70      0    76    83     54  23.2     1     0     0     0     1\n 7     7    57      0    73   191    116  39.5     1     0     0     0     0\n 8     8    55      0    91   147     95  27.1     1     0     0     0     0\n 9     9    88      1    63   209    100  27.4     1     0     0     1     0\n10    10    54      0   104   166    106  25.5     1     0     0     0     0\n# i 490 more rows\n# i 10 more variables: miord <dbl>, mitype <dbl>, year <dbl>, admitdate <chr>,\n#   disdate <chr>, fdate <chr>, los <dbl>, dstat <dbl>, lenfol <dbl>,\n#   fstat <dbl>\n```\n:::\n:::\n\n   \n\nTo see what type everything is, note that when you display a\n`tibble`, the type of all the columns on the screen is\ndisplayed at the top. Click the little right-arrow to see more columns\nand to check their type.\n\nAll the numbers are properly integer (`int`) or decimal\n(`dbl`) numbers, but the date columns are `chr` or\ntext. This means that they haven't been read as `Date`s\n(because they were not in year-month-day order).  \n\n$\\blacksquare$\n\n(b) The date columns should be R dates. They are not\nyear-month-day, so converting them via `as.Date` (which is\nwhat `read_delim` tries to do) will not work. Load the\n`lubridate` package, and create new columns in your data\nframe that are properly dates. Save your data frame, and list it to\ndemonstrate that it worked.\n\n\nSolution\n\n\nYou can load `lubridate` first, but there is no need since it is now part of the `tidyverse`.\n\n\nThese dates are day-month-year, so we need `dmy` from\n`lubridate`: \n\n::: {.cell}\n\n```{.r .cell-code}\nwhas %>% mutate(\n  admit = dmy(admitdate),\n  dis = dmy(disdate),\n  f = dmy(fdate)\n) -> whas2\nglimpse(whas2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 500\nColumns: 25\n$ id        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1~\n$ age       <dbl> 83, 49, 70, 70, 70, 70, 57, 55, 88, 54, 48, 75, 48, 54, 67, ~\n$ gender    <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, ~\n$ hr        <dbl> 89, 84, 83, 65, 63, 76, 73, 91, 63, 104, 95, 154, 85, 95, 93~\n$ sysbp     <dbl> 152, 120, 147, 123, 135, 83, 191, 147, 209, 166, 160, 193, 1~\n$ diasbp    <dbl> 78, 60, 88, 76, 85, 54, 116, 95, 100, 106, 110, 123, 80, 65,~\n$ bmi       <dbl> 25.54051, 24.02398, 22.14290, 26.63187, 24.41255, 23.24236, ~\n$ cvd       <dbl> 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, ~\n$ afb       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ~\n$ sho       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ chf       <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ~\n$ av3       <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ~\n$ miord     <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, ~\n$ mitype    <dbl> 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ~\n$ year      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ admitdate <chr> \"13-01-1997\", \"19-01-1997\", \"01-01-1997\", \"17-02-1997\", \"01-~\n$ disdate   <chr> \"18-01-1997\", \"24-01-1997\", \"06-01-1997\", \"27-02-1997\", \"07-~\n$ fdate     <chr> \"31-12-2002\", \"31-12-2002\", \"31-12-2002\", \"11-12-1997\", \"31-~\n$ los       <dbl> 5, 5, 5, 10, 6, 1, 5, 4, 4, 5, 5, 10, 7, 21, 4, 1, 13, 14, 6~\n$ dstat     <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ lenfol    <dbl> 2178, 2172, 2190, 297, 2131, 1, 2122, 1496, 920, 2175, 2173,~\n$ fstat     <dbl> 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ~\n$ admit     <date> 1997-01-13, 1997-01-19, 1997-01-01, 1997-02-17, 1997-03-01,~\n$ dis       <date> 1997-01-18, 1997-01-24, 1997-01-06, 1997-02-27, 1997-03-07,~\n$ f         <date> 2002-12-31, 2002-12-31, 2002-12-31, 1997-12-11, 2002-12-31,~\n```\n:::\n:::\n\n \n\nThere are a lot of columns, so I used `glimpse`.  The three new\nvariables we created are at the end of the list. They are correctly\n`Date`s, and they have the right values, the ones we can see at\nleast. \n\nThe indentation is up to you. I think it's nice to make the\ncreations of the three new variables line up. You can also make the\nopening and closing brackets on the long `mutate` aligned, or\nyou can do as I have done here and put two closing brackets on the\nend. The rationale for this is that each of the variable definition\nlines in the `mutate` ends either with a comma or an extra\nclosing bracket, the latter being on the last line. Your choice here is\na matter of taste or (in your working life) the coding norms of the\nteam you're working with.\n\nExtra: you may have been offended by the repetition above. It so happens that\nthese columns' names all end in `date` and they are the only\nones that do, so we can use a \"select helper\" to select only them,\nand then submit all of them to a `mutate` via `across`,\nwhich goes like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas %>% mutate(across(ends_with(\"date\"), \\(date) dmy(date))) %>% glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 500\nColumns: 22\n$ id        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1~\n$ age       <dbl> 83, 49, 70, 70, 70, 70, 57, 55, 88, 54, 48, 75, 48, 54, 67, ~\n$ gender    <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, ~\n$ hr        <dbl> 89, 84, 83, 65, 63, 76, 73, 91, 63, 104, 95, 154, 85, 95, 93~\n$ sysbp     <dbl> 152, 120, 147, 123, 135, 83, 191, 147, 209, 166, 160, 193, 1~\n$ diasbp    <dbl> 78, 60, 88, 76, 85, 54, 116, 95, 100, 106, 110, 123, 80, 65,~\n$ bmi       <dbl> 25.54051, 24.02398, 22.14290, 26.63187, 24.41255, 23.24236, ~\n$ cvd       <dbl> 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, ~\n$ afb       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ~\n$ sho       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ chf       <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ~\n$ av3       <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ~\n$ miord     <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, ~\n$ mitype    <dbl> 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, ~\n$ year      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~\n$ admitdate <date> 1997-01-13, 1997-01-19, 1997-01-01, 1997-02-17, 1997-03-01,~\n$ disdate   <date> 1997-01-18, 1997-01-24, 1997-01-06, 1997-02-27, 1997-03-07,~\n$ fdate     <date> 2002-12-31, 2002-12-31, 2002-12-31, 1997-12-11, 2002-12-31,~\n$ los       <dbl> 5, 5, 5, 10, 6, 1, 5, 4, 4, 5, 5, 10, 7, 21, 4, 1, 13, 14, 6~\n$ dstat     <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ lenfol    <dbl> 2178, 2172, 2190, 297, 2131, 1, 2122, 1496, 920, 2175, 2173,~\n$ fstat     <dbl> 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, ~\n```\n:::\n:::\n\n \n\nOne line, as you see, not three. The English-language version of this reads \"for each of the columns whose\nname ends with `date`, work out `dmy` of it\", that is to say, convert it into a date.\nWe can use any of the\nselect-helpers in this, including listing the column numbers or\nnames; in this case our date variables all ended with\n`date`. \n\nThis overwrites the original date columns (you can see that they are now `date`s), but you can give them new names thus. This is inside the `across` inside the `mutate`, so it needs two close-brackets after (the probable reason for the error if you get one):\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas %>% mutate(across(ends_with(\"date\"), \\(date) dmy(date), \n                       .names = \"{.col}_d\")) %>% glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 500\nColumns: 25\n$ id          <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,~\n$ age         <dbl> 83, 49, 70, 70, 70, 70, 57, 55, 88, 54, 48, 75, 48, 54, 67~\n$ gender      <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0~\n$ hr          <dbl> 89, 84, 83, 65, 63, 76, 73, 91, 63, 104, 95, 154, 85, 95, ~\n$ sysbp       <dbl> 152, 120, 147, 123, 135, 83, 191, 147, 209, 166, 160, 193,~\n$ diasbp      <dbl> 78, 60, 88, 76, 85, 54, 116, 95, 100, 106, 110, 123, 80, 6~\n$ bmi         <dbl> 25.54051, 24.02398, 22.14290, 26.63187, 24.41255, 23.24236~\n$ cvd         <dbl> 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1~\n$ afb         <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0~\n$ sho         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ chf         <dbl> 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1~\n$ av3         <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1~\n$ miord       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0~\n$ mitype      <dbl> 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1~\n$ year        <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n$ admitdate   <chr> \"13-01-1997\", \"19-01-1997\", \"01-01-1997\", \"17-02-1997\", \"0~\n$ disdate     <chr> \"18-01-1997\", \"24-01-1997\", \"06-01-1997\", \"27-02-1997\", \"0~\n$ fdate       <chr> \"31-12-2002\", \"31-12-2002\", \"31-12-2002\", \"11-12-1997\", \"3~\n$ los         <dbl> 5, 5, 5, 10, 6, 1, 5, 4, 4, 5, 5, 10, 7, 21, 4, 1, 13, 14,~\n$ dstat       <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ lenfol      <dbl> 2178, 2172, 2190, 297, 2131, 1, 2122, 1496, 920, 2175, 217~\n$ fstat       <dbl> 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1~\n$ admitdate_d <date> 1997-01-13, 1997-01-19, 1997-01-01, 1997-02-17, 1997-03-0~\n$ disdate_d   <date> 1997-01-18, 1997-01-24, 1997-01-06, 1997-02-27, 1997-03-0~\n$ fdate_d     <date> 2002-12-31, 2002-12-31, 2002-12-31, 1997-12-11, 2002-12-3~\n```\n:::\n:::\n\nThe three columns on the end are the new actual-dates we created. To give them new names, use `.names` inside `across`, and in *that* is a recipe that says how to make the new names. `{.col}` means the name the column had before, and the `_d` after that means to add that to the old name to make the new one.\n\n$\\blacksquare$\n\n(c) Create three new variables `diff1, diff2, diff3` that\nare the numbers of days between each of your dates, and save the\ndata frame in which they have been created. Verify that at\nleast some of them are the same as `los` and `lenfol`.\n\n\nSolution\n\n\nI don't know\nwhat R's internal storage is for dates (it might be seconds or\nmilliseconds or anything, not necessarily days),\nso subtracting them requires care; you have to divide by the\nlength of a day (in whatever units), thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas2 %>% mutate(\n  diff1 = (dis - admit),\n  diff2 = (f - admit),\n  diff3 = (f - dis)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 500 x 28\n      id   age gender    hr sysbp diasbp   bmi   cvd   afb   sho   chf   av3\n   <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1    83      0    89   152     78  25.5     1     1     0     0     0\n 2     2    49      0    84   120     60  24.0     1     0     0     0     0\n 3     3    70      1    83   147     88  22.1     0     0     0     0     0\n 4     4    70      0    65   123     76  26.6     1     0     0     1     0\n 5     5    70      0    63   135     85  24.4     1     0     0     0     0\n 6     6    70      0    76    83     54  23.2     1     0     0     0     1\n 7     7    57      0    73   191    116  39.5     1     0     0     0     0\n 8     8    55      0    91   147     95  27.1     1     0     0     0     0\n 9     9    88      1    63   209    100  27.4     1     0     0     1     0\n10    10    54      0   104   166    106  25.5     1     0     0     0     0\n# i 490 more rows\n# i 16 more variables: miord <dbl>, mitype <dbl>, year <dbl>, admitdate <chr>,\n#   disdate <chr>, fdate <chr>, los <dbl>, dstat <dbl>, lenfol <dbl>,\n#   fstat <dbl>, admit <date>, dis <date>, f <date>, diff1 <drtn>,\n#   diff2 <drtn>, diff3 <drtn>\n```\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 <- whas2 %>% mutate(\n  diff1 = (dis - admit) / ddays(1),\n  diff2 = (f - admit) / ddays(1),\n  diff3 = (f - dis) / ddays(1)\n)\nwhas3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 500 x 28\n      id   age gender    hr sysbp diasbp   bmi   cvd   afb   sho   chf   av3\n   <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1    83      0    89   152     78  25.5     1     1     0     0     0\n 2     2    49      0    84   120     60  24.0     1     0     0     0     0\n 3     3    70      1    83   147     88  22.1     0     0     0     0     0\n 4     4    70      0    65   123     76  26.6     1     0     0     1     0\n 5     5    70      0    63   135     85  24.4     1     0     0     0     0\n 6     6    70      0    76    83     54  23.2     1     0     0     0     1\n 7     7    57      0    73   191    116  39.5     1     0     0     0     0\n 8     8    55      0    91   147     95  27.1     1     0     0     0     0\n 9     9    88      1    63   209    100  27.4     1     0     0     1     0\n10    10    54      0   104   166    106  25.5     1     0     0     0     0\n# i 490 more rows\n# i 16 more variables: miord <dbl>, mitype <dbl>, year <dbl>, admitdate <chr>,\n#   disdate <chr>, fdate <chr>, los <dbl>, dstat <dbl>, lenfol <dbl>,\n#   fstat <dbl>, admit <date>, dis <date>, f <date>, diff1 <dbl>, diff2 <dbl>,\n#   diff3 <dbl>\n```\n:::\n:::\n\n       \n\nThe extra `d` on the front of `ddays` indicates that\nthese are what is known to `lubridate` as \"durations\": a\nperiod of time 1 day long that could be any day (as opposed to \n\"June 1, 1970\" which is 1 day long, but tied to a particular day). \n\n`los` should be the number of days in hospital, what I\ncalculated as `diff1`, and `lenfol` should be the time\nfrom being admitted to last followup, which is my `diff2`. My\noutput from `glimpse` confirms that. \n\nExtra: of course, checking that the first few values match is a nice\nconfirmation, but is not actually a *proof*. For that, we should\ncompare all 500 values, and it would be best to do it in such a way\nthat R is comparing all 500 values for us, since it would be a lot\nmore reliable than the human eye. R has a function `all.equal`\nwhich does exactly that. By way of warmup:\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 1:4\ny <- 1:4\nz <- c(1, 2, 3, 5)\nall.equal(x, y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nall.equal(x, z)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Mean relative difference: 0.25\"\n```\n:::\n:::\n\n \n\nI thought the second one was just going to say `FALSE`, but it\ngave us a message instead, saying how close `x` and `z`\nwere on average, so that we could decide whether they were close\nenough to call equal, or, as in this case, not.\n\nAnyway:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(whas3, all.equal(lenfol, diff2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nwith(whas3, all.equal(los, diff1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n \n\nso they really are all equal, all 500 of them.^[The computer  scientists among you will note that I shouldn't have done this,  because `diff1` through `diff3` are double-precision  decimal numbers, so I should have tested their equality with  `lenfol` and `los` by working out the absolute  differences and testing whether they were all *small*. On  consulting the help for `all.equal`, though, I find that it  *does* work properly, because it actually tests whether the  things being compared differ by less than a quantity  `tolerance` which defaults to 0.000000015, and if  they  do it calls them equal. This is all tied in with the difference  between integers and decimal numbers as they are represented on a  computer: exactly and approximately, respectively. A  double-precision number has about 16 significant digits of accuracy;  equal things won't have all 16 digits equal, most likely, but they  would be expected to have at least 8 of those digits the  same. CSCA08 stuff, I imagine. This is where you can casually toss  around terms like \"machine epsilon\". Oh! I just realized  something. You know how very very small P-values are shown in R as  *<2.2e-16*? *That's* the machine epsilon. Anything smaller than that is  indistinguishable from zero, and you can't have a P-value be  *exactly* zero. The default `tolerance` I mentioned  above is the square root of this, which is normally used for such  things.]\n\n$\\blacksquare$\n\n(d) Construct side-by-side boxplots of the length of followup by\neach followup status. You'll need to make sure\nthat the followup status, as it gets fed into `ggplot`, is a\n`factor`, or, at least, not the number that it is now.\n\n\nSolution\n\n\nThe easiest way to make a factor is to wrap `fstat`, which\nis a numeric 0 or 1, in `factor()`:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(whas3, aes(x = factor(fstat), y = lenfol)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-9-1.pdf){fig-pos='H'}\n:::\n:::\n\n       \n\nOr create a factor version of `fstat` first:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 %>%\n  mutate(ffstat = factor(fstat)) %>%\n  ggplot(aes(x = ffstat, y = lenfol)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-10-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nI think the second way looks better, because you\nget a cleaner $x$-axis on your plot. But if you're doing this for\nexploration, rather than as something that's going to appear in a\nreport for your boss, the first way is fine.\n\n`ggplot` also treats text stuff as categorical where needed, so\nthis also works:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 %>%\n  mutate(cfstat = as.character(fstat)) %>%\n  ggplot(aes(x = cfstat, y = lenfol)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n Extra: this is an example of what's called \"survival data\": the purpose of the study was to see what affected how long a person survived after a heart attack. Each patient was followed up for the number of days in `lenfol`, but followup could have stopped for two (or more) reasons: the patient died (indicated by `fstat` being 1), or something else happened to them (`fstat` is 0), such as moving away from where the study was conducted, getting another disease, the funding for this study running out, or simply losing touch with the people doing the study. Such a patient is called \"lost to followup\" or \"censored\", and all we know about their survival is that they were still alive when last seen, but we don't know how long they lived after that.\n \nFor example:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas %>% select(id, lenfol, fstat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 500 x 3\n      id lenfol fstat\n   <dbl>  <dbl> <dbl>\n 1     1   2178     0\n 2     2   2172     0\n 3     3   2190     0\n 4     4    297     1\n 5     5   2131     0\n 6     6      1     1\n 7     7   2122     0\n 8     8   1496     1\n 9     9    920     1\n10    10   2175     0\n# i 490 more rows\n```\n:::\n:::\n\nThe patient with id 4 died after 297 days, but patients 1 through 3 lived for over 2000 days and were still alive when last seen. My guess for patients 1 through 3 is that the study ended and they were still alive:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas %>% summarize(maxfol = max(lenfol)/365.25)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 1\n  maxfol\n   <dbl>\n1   6.46\n```\n:::\n:::\n\nThe longest time anyone was followed up was six and a half years. Studies like this are funded for some number of years (say 10), and people can join after the beginning. (If they happen to join near the end, they won't get followed up for very long.)\n\nWe're not going to analyze these data, but if we were, we would want to take advantage of the information in the patient who lived for \"at least 2178 days\". Looking only at the patients who we knew to have died would be wasteful and might introduce a bias; for example, if we were comparing several treatments, and one of the treatments was so good that almost everybody on it was still alive at the end, we would want to have a strong inference that this treatment was the best.\n\nWith that in mind, let's redraw our boxplot with better labels for the followup status:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 %>% \n  mutate(followup_status = ifelse(fstat == 1, \"died\", \"censored\")) %>% \n  ggplot(aes(x = followup_status, y = lenfol)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-14-1.pdf){fig-pos='H'}\n:::\n:::\n\nNow we have a clearer sense of what is going on. Out of the patients who died, some of them survived a long time, but most of them died fairly quickly. Out of the patients who were censored, the times they were observed were all over the place, which suggests that (at least for the ones still in the study at the end) they joined the study at all kinds of different times.\n\nAnother graph that is possible here is a facetted histogram:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 %>% \n  mutate(followup_status = ifelse(fstat == 1, \"died\", \"censored\")) %>% \n  ggplot(aes(x = lenfol)) + geom_histogram(bins = 10) +\n  facet_wrap(~followup_status)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-15-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe right-skewed distribution of times to death is what we saw from the boxplot, but what is that periodic thing on the left? Let's convert the days to years and draw again:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas3 %>% \n  mutate(followup_status = ifelse(fstat == 1, \"died\", \"censored\")) %>% \n  mutate(followup_years = lenfol/365.25) %>% \n  ggplot(aes(x = followup_years)) + geom_histogram(bins = 20) +\n  facet_wrap(~followup_status)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/whas-16-1.pdf){fig-pos='H'}\n:::\n:::\n\nThat's odd. On the left, it looks as if there were bursts of patients admitted to the study at around 1.5, 3.5, and 5.5 years from the end. (These are, remember, all people who survived and mostly people who survived to the end.) Not what I would have expected -- I would have expected a steady stream of patients, the heart attack victims as they happened to come in.\n\n$\\blacksquare$\n\n\n\n\n## Going to sleep\n\n A student keeps track of what time they go to bed and what time they get up in the morning. They also have an app on their phone that measures the number of hours they were asleep during that time. The data for one week are in [http://ritsokiguess.site/datafiles/sleeping.csv](http://ritsokiguess.site/datafiles/sleeping.csv), in the 24-hour clock.\n\n\n\n\n(a) Read in and display the data. What type of things are each of your columns? \n\nSolution\n\n\nThe usual, to start:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/sleeping.csv\"\nsleep <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 7 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl  (1): sleep.time\ndttm (2): bed.time, rise.time\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nsleep\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 3\n  bed.time            rise.time           sleep.time\n  <dttm>              <dttm>                   <dbl>\n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45\n```\n:::\n:::\n\nOn mine, the sleep time is an ordinary decimal number, but the two times are something called `dttm`, which I can guess means date-time. In your document, you might see\n`S3:POSIXct`, and you probably don't know what that is (although you can guess).^[Which one you see will depend on which type of output you are looking at. In your document you will probably see the POSIXCT thing, but in your HTML or PDF output it will probably say ``dttm''.]\n\nIf you search for this, you'll find some links to the help files, but a bit further down is [this](https://rstudio-pubs-static.s3.amazonaws.com/28038_1bcb9aa80ca84f27ace07d612872861a.html), which says it in a few words: \"These objects store the number of seconds (for `POSIXct`) ... since January 1st 1970 at midnight.\"^[The piece in quotes comes word-for-word from the source: it is exactly what the author said. Except that the author also talks about dates, which don't concern us here, so I removed that bit and replaced it with the three dots, called an \"ellipsis\", to show that the author said some extra stuff that I didn't quote. I checked that what remained does actually still capture what the author said. Extra-in-note: an ellipsis is not to be confused with the conic section called an ellipse, and these three dots are not to be confused with the three dots in an R function, where they mean \n\"anything else that was passed in to the function\". Both uses of the three dots capture the idea of \n\"something was missed out\".]\n\nMake the claim that the first two columns are genuine date-times, and if they are labelled `S3:POSIXct` for you, say how you know. That is to say, they may look like pieces of text laid out as date-times, but they are *actual* date-times stored internally as seconds since Jan 1 1970 and displayed nicely. Thus we *do not* need to use `ymd_hms` or anything similar to deal with them.\n\n\n$\\blacksquare$\n\n\n(b) Work out the fractional number of hours that the student was in bed each of these nights. (They may not have been asleep this whole time.) Your result needs to be a *number* since we will be doing some calculations with it shortly.\n\nSolution\n\n\nSince these are genuine date-times, you can take the difference, but the unit is not predictable. Internally, these are stored as a number of *seconds*, but it displays a \"nice\" unit:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(in_bed = rise.time - bed.time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 4\n  bed.time            rise.time           sleep.time in_bed        \n  <dttm>              <dttm>                   <dbl> <drtn>        \n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74 8.968056 hours\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92 8.720000 hours\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01 7.597222 hours\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23 7.396111 hours\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34 7.992222 hours\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42 8.162222 hours\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45 6.881111 hours\n```\n:::\n:::\n\nIn this case, we did get a number of hours, but in the next part, we are going to do a calculation like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(in_bed = rise.time - bed.time) %>% \nmutate(ratio = sleep.time / in_bed)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `mutate()`:\ni In argument: `ratio = sleep.time/in_bed`.\nCaused by error in `/.difftime`:\n! second argument of / cannot be a \"difftime\" object\n```\n:::\n:::\n\nand this doesn't work because you can't divide a number by a time. (What would its units be?) So we have to turn `in_bed` into a number, and to do that we can divide by the number of seconds in an hour:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(in_bed = (rise.time - bed.time) / dhours(1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 4\n  bed.time            rise.time           sleep.time in_bed\n  <dttm>              <dttm>                   <dbl>  <dbl>\n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74   8.97\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92   8.72\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01   7.60\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23   7.40\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34   7.99\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42   8.16\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45   6.88\n```\n:::\n:::\n\nThis is now correctly a (decimal) number.\n\n\n$\\blacksquare$\n\n\n(c) The student is concerned with something they call \"sleep efficiency\". This is the percentage of time in bed spent sleeping. Work out the student's sleep efficiency for the seven nights in this dataframe. Which night was the student's sleep efficiency greatest?\n\nSolution\n\n\nDivide the sleep time by the in-bed time and multiply by 100. To answer the last part of the question, you might think of sorting these in descending order as well:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(in_bed = (rise.time - bed.time) / dhours(1)) %>% \nmutate(efficiency = sleep.time / in_bed * 100) %>% \narrange(desc(efficiency))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 5\n  bed.time            rise.time           sleep.time in_bed efficiency\n  <dttm>              <dttm>                   <dbl>  <dbl>      <dbl>\n1 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45   6.88       93.7\n2 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01   7.60       92.3\n3 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42   8.16       90.9\n4 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92   8.72       90.8\n5 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23   7.40       84.2\n6 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34   7.99       79.3\n7 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74   8.97       75.2\n```\n:::\n:::\n\nThe night of September 8. This was the night the student went to bed the latest, but they were asleep almost all the time they were in bed.\n\n\n$\\blacksquare$\n\n\n(d) Display the time spent in bed each night as a number of hours, minutes and seconds.\n\nSolution\n\n\nThe idea here is to display the time between going to bed and getting up as an interval, using `%--%`, and then turn that into a period:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(in_bed_hms = as.period(bed.time %--% rise.time))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 4\n  bed.time            rise.time           sleep.time in_bed_hms\n  <dttm>              <dttm>                   <dbl> <Period>  \n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74 8H 58M 5S \n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92 8H 43M 12S\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01 7H 35M 50S\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23 7H 23M 46S\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34 7H 59M 32S\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42 8H 9M 44S \n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45 6H 52M 52S\n```\n:::\n:::\n\n\n$\\blacksquare$\n\n\n(e) Make a graph of what time the student went to bed each night. Bear in mind that you only need the times, not the dates, and that you want a graph that is informative, showing appropriately the distribution of times the student went to bed.\n\nSolution\n\n\nIf you just pull out the times, some of them will be at the end of the day and some will be at the beginning. Extracting the hours, minutes and seconds is one way:^[Make sure you use \"hour\" and not \"hours\" as I did the first time. That computes the total number of hours between the zero date of Jan 1, 1970 and the time given, and so is way too large to be an answer here!]\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(h = hour(bed.time), m = minute(bed.time), s = second(bed.time))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 6\n  bed.time            rise.time           sleep.time     h     m     s\n  <dttm>              <dttm>                   <dbl> <int> <int> <dbl>\n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74    23     5    24\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92    22    51     9\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01     0     9    16\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23    23    43    31\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34     0    17    41\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42    22    42    27\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45     0    22    27\n```\n:::\n:::\n\nYou could convert these into fractional hours to make a histogram of:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(h = hour(bed.time), m = minute(bed.time), s = second(bed.time)) %>% \nmutate(bed_time_hours = h + m / 60 + s / (60*60))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 7\n  bed.time            rise.time           sleep.time     h     m     s\n  <dttm>              <dttm>                   <dbl> <int> <int> <dbl>\n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74    23     5    24\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92    22    51     9\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01     0     9    16\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23    23    43    31\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34     0    17    41\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42    22    42    27\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45     0    22    27\n# i 1 more variable: bed_time_hours <dbl>\n```\n:::\n:::\n\nbut if you make a histogram of these, this is what you get:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(h = hour(bed.time), m = minute(bed.time), s = second(bed.time)) %>% \nmutate(bed_time_hours = h + m / 60 + s / (60*60)) %>% \nggplot(aes(x = bed_time_hours)) + geom_histogram(bins = 5)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/sleeping-9-1.pdf){fig-pos='H'}\n:::\n:::\n\nbut this makes no sense because the bedtimes after midnight are on the end of the previous day, not the beginning of the next one!\n\nWith that in mind, let's move the bedtimes that are, say, before 3:00am to the end of the previous day by adding 24 to them before we make the graph:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(h = hour(bed.time), m = minute(bed.time), s = second(bed.time)) %>% \nmutate(bed_time_hours = h + m / 60 + s / (60*60)) %>% \nmutate(bed_time_hours = ifelse(bed_time_hours < 3, bed_time_hours + 24, bed_time_hours)) %>% \nggplot(aes(x = bed_time_hours)) + geom_histogram(bins = 5)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/sleeping-10-1.pdf){fig-pos='H'}\n:::\n:::\n\nThis gives a sense of where the bedtimes are. If you're used to reading the 24-hour clock, you'll know that 23 is 11:00pm, and you'll have a sense that some of the bedtimes were 11 or a bit earlier and some were around midnight. (I like the 24-hour clock.) There are only 7 observations, so the graph you get won't look very nice as a histogram, but at least this one says something about when the student went to bed, in a way that puts times just after midnight next to times just before. You should give some thought about the number of bins; with only 7 observations, even 5 bins is pushing it, but this looked nicer to me than 4 bins.\n\nIf you're more used to the 12-hour clock, you'll want to convert the times to something between 10 and 12. You can do this with an `ifelse` as above, subtracting 12 from the ones before midnight and adding 12 to the ones after. Or you can recognize this as modulo arithmetic (the clock is a classic case: what is 10:00pm plus 3 hours?) A little thought will reveal that subtracting (or adding) 12 hours and taking the result modulo 24 would do it: the pre-midnight bedtimes will get turned into a number like 10 or 11, and the post-midnight ones to 12 and a bit. R has a modulo operator, which is `%%` (cite your source: mine was [this](https://stat.ethz.ch/R-manual/R-patched/library/base/html/Arithmetic.html)):\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(h = hour(bed.time), m = minute(bed.time), s = second(bed.time)) %>% \nmutate(bed_time_hours = h + m / 60 + s / (60*60)) %>% \nmutate(bed_time_hours = (bed_time_hours - 12) %% 24) %>% \nggplot(aes(x = bed_time_hours)) + geom_histogram(bins = 5)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/sleeping-11-1.pdf){fig-pos='H'}\n:::\n:::\n\nand you might find the $x$-scale of that easier to cope with. (The bins have come out differently, for some reason.)\n\nI think the best graph uses the fact that date-times plot nicely, so if we keep them as date-times, the $x$-scale will look nice. The problem is that they are times on *different* days. What if we faked it up so that they were all on the *same* day (or, at least, consecutive days, to account for the ones after midnight)?\n\nLet's look at our dataframe again:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 3\n  bed.time            rise.time           sleep.time\n  <dttm>              <dttm>                   <dbl>\n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45\n```\n:::\n:::\n\nThe `rise.time` values are all a.m., and on consecutive days, so if we subtract consecutive numbers of days from the `bed.time`s, we'll put them all on appropriate days too:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(time_of_bed = bed.time - ddays(0:6))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 4\n  bed.time            rise.time           sleep.time time_of_bed        \n  <dttm>              <dttm>                   <dbl> <dttm>             \n1 2013-09-01 23:05:24 2013-09-02 08:03:29       6.74 2013-09-01 23:05:24\n2 2013-09-02 22:51:09 2013-09-03 07:34:21       7.92 2013-09-01 22:51:09\n3 2013-09-04 00:09:16 2013-09-04 07:45:06       7.01 2013-09-02 00:09:16\n4 2013-09-04 23:43:31 2013-09-05 07:07:17       6.23 2013-09-01 23:43:31\n5 2013-09-06 00:17:41 2013-09-06 08:17:13       6.34 2013-09-02 00:17:41\n6 2013-09-06 22:42:27 2013-09-07 06:52:11       7.42 2013-09-01 22:42:27\n7 2013-09-08 00:22:27 2013-09-08 07:15:19       6.45 2013-09-02 00:22:27\n```\n:::\n:::\n\nThese are all around the midnight at the end of September 1, so some of them are in the early hours of September 2. Now, if we make a histogram of *those*:\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(time_of_bed = bed.time - ddays(0:6)) %>% \nggplot(aes(x = time_of_bed)) + geom_histogram(bins = 5)\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/sleeping-14-1.pdf){fig-pos='H'}\n:::\n:::\nNow the $x$-axis formatting looks like a time, and spills seamlessly into the next day. (There was no real range of dates, so the formatting is of the times only.)\n\nOne more embellishment, idea from [here](https://www.r-bloggers.com/2018/06/customizing-time-and-date-scales-in-ggplot2/):\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% mutate(time_of_bed = bed.time - ddays(0:6)) %>% \nggplot(aes(x = time_of_bed)) + geom_histogram(bins = 5) +\nscale_x_datetime(date_labels = \"%l:%M %p\")\n```\n\n::: {.cell-output-display}\n![](dates-and-times_files/figure-pdf/sleeping-15-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe `scale_x` and `scale_y` functions customize the $x$ and $y$ axes respectively. Inside `date_labels` go some codes that say what time units you want to display: in this case, the 12-hour hours, the minutes, and whether the time is AM or PM. The codes come from a function called `strftime`, and a full list is [here](https://man7.org/linux/man-pages/man3/strftime.3.html). Alternatively, you can look up the help for R's function of the same name with `?strftime`.^[Confusingly, uppercase I and lowercase l not only look the same, but they also both display the 12-hour hour. The former adds a zero to the front if the hour is a single digit, and the latter does not. All the hours here have two digits, though, so it comes out the same whichever you use.]\n\n\n$\\blacksquare$\n\n\n\n\n",
>>>>>>> 038bb2509ac8e38facb2622be6ad3052b44aca34
    "supporting": [
      "dates-and-times_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}