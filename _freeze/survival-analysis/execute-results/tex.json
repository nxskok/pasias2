{
  "hash": "36a3931c5e43af70c59b5477da91a17c",
  "result": {
    "engine": "knitr",
    "markdown": "# Survival analysis\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survival)\nlibrary(tidyverse)\nlibrary(marginaleffects)\nlibrary(survminer)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  The Worcester survey\n\n\n The Worcester survey was a long-term study of\nall myocardial-infarction^[Heart attack.] victims admitted to hospitals in the\nWorcester, Massachusetts area.^[Worcester is pronounced, by locals, *Woo-stuh*.] \nThe data have been well studied, and can be found in\nthe file [link](http://ritsokiguess.site/datafiles/whas100.csv).\n\n\n\n(a) Read the data and\n display the first few rows of the data frame. You might get an extra\n column, which you can ignore.\nFor your information, the variables are:\n\n\n* patient ID code\n\n* admission date\n\n* date of last followup (this is the date of death if the\npatient died)\n\n* length of hospital stay (days)\n\n* followup time (days) (time between admission and last followup)\n\n* followup status: 1=dead, 0=alive\n\n* Age in years (at admission)\n\n* gender (0=male, 1=female)\n\n* body mass index (kg/m$^2$)\n\n \n\n(b) Create a suitable response variable for a Cox proportional\nhazards model for time of survival, using the followup time and\nfollowup status.\n \n\n(c) Fit a Cox proportional hazards model predicting survival time\nfrom age, gender and BMI. Obtain the `summary` (but you don't\nneed to comment on it yet).\n\n \n\n(d) Test the overall fit of the model. What does the result mean?\n \n\n(e) Can any of your explanatory variables be removed from the\nmodel? Explain briefly.\n \n\n(f) Remove your most non-significant explanatory variable from\nthe model and fit again. Take a look at the results. Are all your\nremaining explanatory variables significant? (If all your\nexplanatory variables were previously significant, you can skip this part.)\n \n\n(g) Calculate the 1st quartile, median, and 3rd quartiles of\nage and BMI. (`quantile`.) Round these off to the\nnearest whole number. (Do the rounding off yourself, though R has a\nfunction `round` that does this, which you can investigate if\nyou want.) As an alternative, you can get these by passing the whole\ndata frame, or the columns of it you want, into `summary`.\n \n\n(h) Make a data frame out of all the combinations of\nage and BMI values (that you obtained in the previous part) suitable for predicting\nwith. \n \n\n(i) Obtain predicted survival probabilities for each of the values\nin your new data frame. Use your best model. (You don't need to look\nat the results, though you can if you want to.)\n \n\n(j) Make a graph depicting the survival curves from\n`survfit` with different colours distinguishing the different\nsurvival curves.\n \n\n(k) What is the effect of age on survival? What is the effect\nof BMI on survival? Explain briefly. (You will have to disentangle\nthe meaning of the different coloured lines on the plot to do this.)\n \n\n\n\n\n\n##  Drug treatment programs\n\n\n One of the goals of drug treatment programs is to lengthen\nthe time until the patient returns to using drugs. (It is not\ngenerally possible to prevent patients from *ever* using drugs\nagain.) In one study, over 600 former drug users took part. Two\ndifferent programs, a short program and a long program, were offered\nat two different sites, labelled A and B. The data can be found in\n[link](http://ritsokiguess.site/datafiles/drugusers.txt). The\nvariables are these:\n\n\n\n* `ID`: patient ID number\n\n* `age`: patient age at enrollment into the study\n\n* `ndrugtx`: number of previous drug treatments\n\n* `treat`: 0 for short treatment program, 1 for long program\n\n* `site`: 0 for site A, 1 for site B\n\n* `time`: time until return to drug use\n\n* `censor`: whether the subject returned to drug use (1) or\nnot (0) during the follow-up period\n\n* `herco`: whether subject used heroine or cocaine in the\nlast 3 months: 1 is both, 2 is one (either heroine or cocaine), 3 is neither.\n\n\n\n(a) Read in the data and check in one way or another that you\nhave what was promised above.\n\n\n\n(b) There are some missing values in the dataframe. Demonstrate\nthis using `summary`. Pipe the dataframe into\n`drop_na` and show that they have gone. (`drop_na`\nremoves all rows that have missing values in them.)\n\n\n\n(c) Some of these variables are recorded as numbers but are\nactually categorical. Which ones? Re-define these variables in your\ndata frame so that they have sensible (text) values.\n\n\n\n(d) Create a suitable reponse variable for a Cox proportional\nhazards regression that predicts time until return to drug use from\nthe other variables.\nThis requires some care, because you need to be sure about what the\ncensoring variable actually represents and what you need it to represent.\n\n\n\n(e) Look at the first few values of your response variable. Why\nis the fifth one marked with a `+`? Explain briefly.\n\n\n\n(f) Fit a Cox proportional hazards model, predicting from all\nthe other variables (except for `row` and `ID`) that you haven't used\nyet. Display the results.\n\n\n\n(g) Find which explanatory variables can be removed at $\\alpha=0.05$\n(there should be two of them). Bear in mind that we have categorical variables, so that looking at the output from `summary` is not enough.\n\n\n\n(h) Remove *all* the non-significant explanatory variables\nand re-fit your model. By carrying out a suitable test demonstrate\nthat your smaller model is the better one.\n\n\n\n(i) <a name=\"part:posneg\">*</a> Display your better model. Are all of the\nexplanatory variables significant? Do their slope coefficients have\nsensible signs (plus or minus), based on what you know or can guess\nabout drug treatments? Explain briefly.\n\n\n\n(j) We have three variables left in our model, `age`,\n`ndrugtx` and `treat`. The quartiles of age are 27 and\n37, the quartiles of `ndrugtx` are 1 and 6, and the two\npossible values of `treat` are `short` and `long`. Create a data frame\nwith variables of these names and all possible combinations of their\nvalues (so there should be 8 rows in the resulting data\nframe). Display the resulting data frame.\n\n\n\n(k) Obtain predicted survival probabilities for each of the\nvalues of `age`, `ndrugtx` and `treat` used in\nthe previous part. You don't need to display it (we are going to\nplot it shortly). \n\n\n(l) Plot your predicted survival curves. \n\n\n\n(m) Which of your combinations of values is predicted to take\nthe longest to return to drug use? Which is predicted to take the\nshortest time? Explain briefly.\n\n\n\n(n) Are your survival curve plot and your conclusions from part\n(<a href=\"#part:posneg\">here</a>) consistent, or not? Explain briefly.\n\n\n\n\n\n\n\n\n\n##  Multiple myeloma\n\n\n Multiple myeloma is a kind of cancer. It\nforms in a plasma cell (which is a type of white blood cell). It\ncauses cancer cells to accumulate in the bone marrow, where they crowd\nout healthy blood cells. Plasma cells make antibodies (to help fight\ninfections), while the cancer cells don't: they produce abnormal\nproteins that can cause kidney problems. (This adapted from\n[link](http://www.mayoclinic.org/diseases-conditions/multiple-myeloma/basics/definition/con-20026607).)\nThe variables are:\n\n\n\n* `time`: survival time from diagnosis (months)\n\n* `vstatus`: 0=alive, 1=dead at end of study\n\n* `logbun`: log of BUN test score (BUN test is a test of\nkidney function, not to be confused with cha siu\nbao^[Barbecued pork in a bun. A staple of Chinese dim sum and  Chinese bakeries, such as Ding Dong bakery on Spadina.]).\n\n* `hgb`: hemoglobin (at diagnosis).\n\n* `platelet`: platelets: 1=normal, 0=abnormal (at\ndiagnosis).\n\n* `age` at diagnosis, in years\n\n* `logwbc`: log of WBC (white blood cell count, at\ndiagnosis)\n\n* `frac`: fractures at diagnosis (0=absent, 1=present)\n\n* `logpbm`: log of percent of plasma cells in bone marrow\n\n* `protein`: proteinuria (protein in urine) at\ndiagnosis. Most people have very little, so a larger than normal\namount indicates illness of some kind.\n\n* `scalc`: serum calcium at diagnosis.\n\n\nThe data, on 65 patients with multiple myeloma, are in\n[link](http://ritsokiguess.site/datafiles/myeloma.csv). Some of the\nvariables are logs because they could take very large values.\n\nThere are a lot of parts here, but each part is supposed to be short.\n\n\n\n(a) Read in the data and display (some of) the values. Confirm that\nyou have the right number of observations and the right variables.\n\n\n\n(b) Create a suitable response variable for a Cox\nproportional-hazards survival model, bearing in mind that the\n\"event\" here is death. Display your response variable, and explain\nbriefly what the `+` signs attached to some of the values\nmean, without using a technical term.\n\n\n\n(c) What is the technical term for those patients that have a\n`+` by their values for the response variable?\n\n\n\n(d) Fit a Cox proportional-hazards survival model predicting\nyour response variable from all the other variables (except for the\nones that you used to make the response variable). Display the\n`summary` of your model.\n\n\n\n(e) In your model, which explanatory variables have a P-value less than\n0.10? Fit a model containing only those and display the results.\n\n\n\n(f) Do a test to compare the two models that you fit. Why do \nyou prefer the second model? Explain briefly.\n\n\n\n(g) There should be two explanatory variables left in your\nmodel. These are both numerical variables. Find their first and\nthird quartiles, any way you like.\n\n\n\n(h) Create a data frame containing all possible combinations\nof the two quartiles for each of the two variables, and display the result.\n\n\n\n(i) Obtain predicted survival probabilities for each of the\ncombinations of variables you created above. You don't need to look\nat the results (they are rather long).\n\n\n\n(j) Obtain a graph of the predicted survival curves for each\ncombination of your variables.\n\n\n\n(k) Is it better to have high or low values for each of the\nvariables in your prediction? Explain briefly.\n\n\n\n\n\n\n\n\n##  Ovarian cancer\n\n\n R's `survival` package contains several data\nsets. One of these is called `ovarian`; it comes from a study\nof 26 ovarian cancer patients. The major purpose of this study was to\ncompare the effects of two treatments on survival time.\n\n\n\n(a) Obtain and display (all of) the data set. This is as simple as\nloading the package and typing the data set's name.\n\n\n(b) The columns of interest to us are:\n\n\n* `futime`: the time for which a patient was followed-up:\nthe number of days until either they died or the study ended (or\nthey withdrew from the study for some other reason).\n\n* `fustat`: follow-up status: 1 if the patient died of\novarian cancer, 0 if they were still alive when the study ended.\n\n* `age`: of patient, at diagnosis, in years\n\n* `rx`: treatment, numbered 1 or 2, but really labels for\nthe two treatments.\n\nCreate and display a suitable response variable `y` for a Cox\nproportional-hazards model.\n\n\n(c) In the display of your response variable, some values are\nmarked with a `+`. Why is that? Explain briefly. (If you use\na technical term, you should explain what it means.)\n\n\n(d) Fit a Cox proportional-hazards model for predicting\nsurvival time from age and treatment. Note that the numeric values\nfor treatment make sense only as labels for the two treatments, so\nin your model formula make treatment into a factor. Display the\nresults. \n\n\n(e) Is there a significant difference between the treatments in\nterms of their effects on survival (from ovarian cancer)?\n\n\n(f) Is there a significant effect of age? If there is, describe\nthe effect that age has on survival.\n\n\n(g) Make a martingale residual plot for this model. Do you see\nany problems? Explain briefly.\n\n\n(h) Find the quartiles of `age`, and make a data frame\ncontaining all combinations of those two ages and the two\ntreatments. Display what you have. (Feel free to copy the values by\nhand, rather than trying to save them and use them.)\n\n\n\n(i) Obtain predicted survival probabilities for each of your\nage-treatment combinations, for each of a variety of survival\ntimes. (This is only one thing, despite it sounding like a lot.)\n\n\n\n(j) Draw a plot that compares the survival probabilities at the\ndifferent times.\n\n\n\n(k) According to your plot, how would you describe the effects of\ntreatment and of age?\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n##  The Worcester survey\n\n\n The Worcester survey was a long-term study of\nall myocardial-infarction^[Heart attack.] victims admitted to hospitals in the\nWorcester, Massachusetts area.^[Worcester is pronounced, by locals, *Woo-stuh*.] \nThe data have been well studied, and can be found in\nthe file [link](http://ritsokiguess.site/datafiles/whas100.csv).\n\n\n\n(a) Read the data and\n display the first few rows of the data frame. You might get an extra\n column, which you can ignore.\nFor your information, the variables are:\n\n\n* patient ID code\n\n* admission date\n\n* date of last followup (this is the date of death if the\npatient died)\n\n* length of hospital stay (days)\n\n* followup time (days) (time between admission and last followup)\n\n* followup status: 1=dead, 0=alive\n\n* Age in years (at admission)\n\n* gender (0=male, 1=female)\n\n* body mass index (kg/m$^2$)\n\n \nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/whas100.csv\"\nwhas100 <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Missing column names filled in: 'X1' [1]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nParsed with column specification:\ncols(\n  X1 = col_double(),\n  id = col_double(),\n  admitdate = col_character(),\n  foldate = col_character(),\n  los = col_double(),\n  lenfol = col_double(),\n  fstat = col_double(),\n  age = col_double(),\n  gender = col_double(),\n  bmi = col_double()\n)\n```\n\n\n:::\n\n```{.r .cell-code}\nwhas100\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 100 x 10\n      X1    id admitdate  foldate      los lenfol fstat   age gender   bmi\n   <dbl> <dbl> <chr>      <chr>      <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl>\n 1     1     1 3/13/1995  3/19/1995      4      6     1    65      0  31.4\n 2     2     2 1/14/1995  1/23/1996      5    374     1    88      1  22.7\n 3     3     3 2/17/1995  10/4/2001      5   2421     1    77      0  27.9\n 4     4     4 4/7/1995   7/14/1995      9     98     1    81      1  21.5\n 5     5     5 2/9/1995   5/29/1998      4   1205     1    78      0  30.7\n 6     6     6 1/16/1995  9/11/2000      7   2065     1    82      1  26.5\n 7     7     7 1/17/1995  10/15/1997     3   1002     1    66      1  35.7\n 8     8     8 11/15/1994 11/24/2000    56   2201     1    81      1  28.3\n 9     9     9 8/18/1995  2/23/1996      5    189     1    76      0  27.1\n10    10    10 7/22/1995  12/31/2002     9   2719     0    40      0  21.8\n# i 90 more rows\n```\n\n\n:::\n:::\n\n     \n\nI seem to have an extra column called `X1`. This is because I\nsaved my version of the data using the old `write.csv`, which\ncomes with row names, and I forgot to\nget rid of them. These came back as an extra unnamed variable to which\n`read_delim` gave the name `X1`.\n \n$\\blacksquare$\n\n(b) Create a suitable response variable for a Cox proportional\nhazards model for time of survival, using the followup time and\nfollowup status.\n \nSolution\n\n\n`Surv`. The event here is death, so the two parts of the\nresponse variable are followup time `lenfol` and followup\nstatus, 1 being \"dead\", `fstat`:\n\n::: {.cell}\n\n```{.r .cell-code}\ny <- with(whas100, Surv(lenfol, fstat == 1))\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1]    6   374  2421    98  1205  2065  1002  2201   189  2719+ 2638+  492 \n [13]  302  2574+ 2610+ 2641+ 1669  2624  2578+ 2595+  123  2613+  774  2012 \n [25] 2573+ 1874  2631+ 1907   538   104     6  1401  2710   841   148  2137+\n [37] 2190+ 2173+  461  2114+ 2157+ 2054+ 2124+ 2137+ 2031  2003+ 2074+  274 \n [49] 1984+ 1993+ 1939+ 1172    89   128  1939+   14  1011  1497  1929+ 2084+\n [61]  107   451  2183+ 1876+  936   363  1048  1889+ 2072+ 1879+ 1870+ 1859+\n [73] 2052+ 1846+ 2061+ 1912+ 1836+  114  1557  1278  1836+ 1916+ 1934+ 1923+\n [85]   44  1922+  274  1860+ 1806  2145+  182  2013+ 2174+ 1624   187  1883+\n [97] 1577    62  1969+ 1054 \n```\n\n\n:::\n:::\n\n     \n\nJust using `fstat` alone as the second thing in `Surv`\nalso works, because anything that gives `TRUE` or 1 when the\nevent (death) occurs is equally good. (In R, `TRUE` as a number\nis 1 and `FALSE` as a number is 0.) \n\nI listed the values by way of checking. The ones with a `+` are\ncensored: that is, the patient was still alive the last time the\ndoctor saw them. Most of the censored values are longer times. Usually\nthis happens because the patient was still alive at the end of the study.\n\n \n\n$\\blacksquare$\n\n(c) Fit a Cox proportional hazards model predicting survival time\nfrom age, gender and BMI. Obtain the `summary` (but you don't\nneed to comment on it yet).\n\n \nSolution\n\n\nThis, using the `Surv` that we just created:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas100.1 <- coxph(Surv(lenfol, fstat == 1) ~ age + gender + bmi, data = whas100)\nsummary(whas100.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(lenfol, fstat == 1) ~ age + gender + bmi, \n    data = whas100)\n\n  n= 100, number of events= 51 \n\n           coef exp(coef) se(coef)      z Pr(>|z|)   \nage     0.03713   1.03783  0.01272  2.918  0.00352 **\ngender  0.14325   1.15402  0.30604  0.468  0.63973   \nbmi    -0.07083   0.93162  0.03607 -1.964  0.04956 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\nage       1.0378     0.9636    1.0123    1.0640\ngender    1.1540     0.8665    0.6334    2.1024\nbmi       0.9316     1.0734    0.8680    0.9999\n\nConcordance= 0.683  (se = 0.037 )\nLikelihood ratio test= 21.54  on 3 df,   p=8e-05\nWald test            = 19.46  on 3 df,   p=2e-04\nScore (logrank) test = 20.82  on 3 df,   p=1e-04\n```\n\n\n:::\n:::\n\n\nGender is actually categorical, but because there are only two different values (0 and 1) in the dataset, we can get away with treating it as quantitative here. (The coefficient is actually the effect on the log-hazard of being gender 1, female, rather than gender 0, male).   \n \n$\\blacksquare$\n\n(d) Test the overall fit of the model. What does the result mean?\n \nSolution\n\n\nLook at those three P-values at the bottom.  They are all small,\nso something in the model is helping to predict survival. As to\nwhat? Well, that's the next part.\n \n$\\blacksquare$\n\n(e) Can any of your explanatory variables be removed from the\nmodel? Explain briefly.\n \nSolution\n\n\n`gender` has a (very) large P-value, so that can be taken\nout of the model. The other two variables have small P-values\n(`bmi` only just under 0.05), so they need to stay.\nThe other way to think about this is `step`, or `drop1`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(whas100.1, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSingle term deletions\n\nModel:\nSurv(lenfol, fstat == 1) ~ age + gender + bmi\n       Df    AIC    LRT Pr(>Chi)   \n<none>    402.66                   \nage     1 410.25 9.5972 0.001949 **\ngender  1 400.87 0.2185 0.640218   \nbmi     1 404.60 3.9389 0.047182 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n     \n\nThis is here equivalent to^[Not exactly the same as that output, because it  is doing a test that would be the same if you had an infinitely  large sample, but is slightly different with an ordinary finite number of observations.] the output \nfrom `summary`, but where it\nscores is if you have a categorical explanatory variable like\n\"treatment\" with more than two levels: `drop1` will tell you\nabout keeping or dropping it as a whole.^[Our categorical  variable *gender* has only two levels.]\n\nIf you prefer: \n\n::: {.cell}\n\n```{.r .cell-code}\nstep(whas100.1, trace = 0, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(lenfol, fstat == 1) ~ age + bmi, data = whas100)\n\n        coef exp(coef) se(coef)      z        p\nage  0.03927   1.04005  0.01187  3.309 0.000938\nbmi -0.07116   0.93131  0.03614 -1.969 0.048952\n\nLikelihood ratio test=21.32  on 2 df, p=2.346e-05\nn= 100, number of events= 51 \n```\n\n\n:::\n:::\n\n     \n`gender` comes out, but the others stay. As usual, put\n`trace=1` or `trace=2` to get more output, which will\nlook like a sequence of `drop1`'s one after the other.\n \n$\\blacksquare$\n\n(f) Remove your most non-significant explanatory variable from\nthe model and fit again. Take a look at the results. Are all your\nremaining explanatory variables significant? (If all your\nexplanatory variables were previously significant, you can skip this part.)\n \nSolution\n\n\nSo, take out `gender`:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas100.2 <- update(whas100.1, . ~ . - gender)\nsummary(whas100.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(lenfol, fstat == 1) ~ age + bmi, data = whas100)\n\n  n= 100, number of events= 51 \n\n        coef exp(coef) se(coef)      z Pr(>|z|)    \nage  0.03927   1.04005  0.01187  3.309 0.000938 ***\nbmi -0.07116   0.93131  0.03614 -1.969 0.048952 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    exp(coef) exp(-coef) lower .95 upper .95\nage    1.0401     0.9615    1.0161    1.0645\nbmi    0.9313     1.0738    0.8676    0.9997\n\nConcordance= 0.681  (se = 0.037 )\nLikelihood ratio test= 21.32  on 2 df,   p=2e-05\nWald test            = 19  on 2 df,   p=7e-05\nScore (logrank) test = 19.99  on 2 df,   p=5e-05\n```\n\n\n:::\n:::\n\n     \n\nBoth explanatory variables are significant: `age` definitely,\n`bmi` only just. This is the same model as `step` gave me.\n \n$\\blacksquare$\n\n(g) Calculate the 1st quartile, median, and 3rd quartiles of\nage and BMI. (`quantile`.) Round these off to the\nnearest whole number. (Do the rounding off yourself, though R has a\nfunction `round` that does this, which you can investigate if\nyou want.) As an alternative, you can get these by passing the whole\ndata frame, or the columns of it you want, into `summary`.\n \nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(whas100$age)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   0%   25%   50%   75%  100% \n32.00 59.75 71.00 80.25 92.00 \n```\n\n\n:::\n\n```{.r .cell-code}\nquantile(whas100$bmi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      0%      25%      50%      75%     100% \n14.91878 23.53717 27.19158 30.34770 39.93835 \n```\n\n\n:::\n:::\n\n \n\nor\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas100 %>%\n  select(age, bmi) %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      age             bmi       \n Min.   :32.00   Min.   :14.92  \n 1st Qu.:59.75   1st Qu.:23.54  \n Median :71.00   Median :27.19  \n Mean   :68.25   Mean   :27.04  \n 3rd Qu.:80.25   3rd Qu.:30.35  \n Max.   :92.00   Max.   :39.94  \n```\n\n\n:::\n:::\n\n \nOr, pure tidyverse: summarize the two columns you want using `across`. This one is `reframe` rather than `summarize` because `quantile` returns five values (the five-number summary) rather than just one. The challenge with this kind of thing is getting the brackets right: there should be one bracket closed after `bmi` (the one  belonging to `c`), but the `across` has to include both the columns to work with *and* the thing to do with them (work out the 5-number summary of each one), so there are no more close-brackets before the `\\(x) quantile(x)` but several after: the one closing the `quantile`, the one closing the `across`, and the one closing the `reframe`. When you close a bracket, R Studio shows you the corresponding open bracket, and if you close too many, the offending one will get a red squiggly line under it:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas100 %>%\n  reframe(across(c(age, bmi), \\(x) quantile(x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 x 2\n    age   bmi\n  <dbl> <dbl>\n1  32    14.9\n2  59.8  23.5\n3  71    27.2\n4  80.2  30.3\n5  92    39.9\n```\n\n\n:::\n:::\n\nUsing whichever of this multitude of ways appeals to you:\n\n60, 71 and 80 for age, 24, 27 and 30 for BMI. \n \n$\\blacksquare$\n\n(h) Make a data frame out of all the combinations of\nage and BMI values (that you obtained in the previous part) suitable for predicting\nwith. \n \nSolution\n\n\nThe inevitable `datagrid`. This is probably quickest, with the best model being the second one:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas100.new <- datagrid(model = whas100.2, age = c(60, 71, 80), bmi = c(24, 27, 30))\nwhas100.new\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  lenfol fstat age bmi rowid\n1 1505.4     1  60  24     1\n2 1505.4     1  60  27     2\n3 1505.4     1  60  30     3\n4 1505.4     1  71  24     4\n5 1505.4     1  71  27     5\n6 1505.4     1  71  30     6\n7 1505.4     1  80  24     7\n8 1505.4     1  80  27     8\n9 1505.4     1  80  30     9\n```\n\n\n:::\n:::\n\nExtra: I set it up this way so that you would find the median and quartiles and then type the values into the `datagrid` (easier conceptually), but there is nothing stopping us doing it all in one step:\n\n::: {.cell}\n\n```{.r .cell-code}\ndatagrid(model = whas100.2, \n         age = quantile(whas100$age, c(0.25, 0.5, 0.75)),\n         bmi = quantile(whas100$bmi, c(0.25, 0.5, 0.75))) %>% \n  mutate(across(everything(), \\(x) round(x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  lenfol fstat age bmi rowid\n1   1505     1  60  24     1\n2   1505     1  60  27     2\n3   1505     1  60  30     3\n4   1505     1  71  24     4\n5   1505     1  71  27     5\n6   1505     1  71  30     6\n7   1505     1  80  24     7\n8   1505     1  80  27     8\n9   1505     1  80  30     9\n```\n\n\n:::\n:::\n\nThe last line rounds everything off to the (default) 0 decimal places. The repetitiousness of the preceding two lines makes me wonder whether I should have written a function. \n \n \n$\\blacksquare$\n\n(i) Obtain predicted survival probabilities for each of the values\nin your new data frame. Use your best model. (You don't need to look\nat the results, though you can if you want to.)\n \nSolution\n\nThis is an edited version of an old problem where the above was all you needed to do, but to use `predictions` from `marginaleffects`, you need to add a column of times as well. In this problem, the times are in `lenfol`, so we'll use the median and quartiles of those as well, rounded off. It doesn't really matter what times you use, as long as they show the passage of survival probabilities over time in some reasonable way:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(whas100$lenfol)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    0%    25%    50%    75%   100% \n   6.0  715.0 1877.5 2076.5 2719.0 \n```\n\n\n:::\n:::\n\nso say, 700, 1900, and 2100:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas100.new <- datagrid(model = whas100.2, age = c(60, 71, 80), \n                        bmi = c(24, 27, 30), lenfol = c(700, 1900, 2100))\nwhas100.new\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   fstat age bmi lenfol rowid\n1      1  60  24    700     1\n2      1  60  24   1900     2\n3      1  60  24   2100     3\n4      1  60  27    700     4\n5      1  60  27   1900     5\n6      1  60  27   2100     6\n7      1  60  30    700     7\n8      1  60  30   1900     8\n9      1  60  30   2100     9\n10     1  71  24    700    10\n11     1  71  24   1900    11\n12     1  71  24   2100    12\n13     1  71  27    700    13\n14     1  71  27   1900    14\n15     1  71  27   2100    15\n16     1  71  30    700    16\n17     1  71  30   1900    17\n18     1  71  30   2100    18\n19     1  80  24    700    19\n20     1  80  24   1900    20\n21     1  80  24   2100    21\n22     1  80  27    700    22\n23     1  80  27   1900    23\n24     1  80  27   2100    24\n25     1  80  30    700    25\n26     1  80  30   1900    26\n27     1  80  30   2100    27\n```\n\n\n:::\n:::\n\nand then\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(whas100.2, newdata = whas100.new, type = \"survival\")) %>% \n  select(age, bmi, lenfol, estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   age bmi lenfol  estimate\n1   60  24    700 0.8043183\n2   60  24   1900 0.6328498\n3   60  24   2100 0.5691106\n4   60  27    700 0.8387015\n5   60  27   1900 0.6910292\n6   60  27   2100 0.6342419\n7   60  30    700 0.8675455\n8   60  30   1900 0.7419075\n9   60  30   2100 0.6922567\n10  71  24    700 0.7150404\n11  71  24   1900 0.4942462\n12  71  24   2100 0.4196907\n13  71  27    700 0.7626626\n14  71  27   1900 0.5659476\n15  71  27   2100 0.4959217\n16  71  30    700 0.8034364\n17  71  30   1900 0.6313929\n18  71  30   2100 0.5674969\n19  80  24    700 0.6202600\n20  80  24   1900 0.3665979\n21  80  24   2100 0.2904487\n22  80  27    700 0.6799031\n23  80  27   1900 0.4445956\n24  80  27   2100 0.3683689\n25  80  30    700 0.7322435\n26  80  30   1900 0.5195608\n27  80  30   2100 0.4463297\n```\n\n\n:::\n:::\n\nThis is getting unwieldy to look at, but the hint here is that the effect of increasing  `bmi` is to *increase* the probability of survival (comparing the same age and the same `lenfol`, as in the first, fourth, and seventh rows).\n\n\n$\\blacksquare$\n\n(j) Make a graph depicting the survival curves from\n`survfit` with different colours distinguishing the different\nsurvival curves.\n \nSolution\n\nLet's do it all in one go this time:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(whas100.2, condition = c(\"lenfol\", \"age\", \"bmi\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-18-1.pdf){fig-pos='H'}\n:::\n:::\n\nThis puts time on the  $x$-axis, age as colours (it selects some values for you), and `bmi` as facets. Both `age` and `bmi` are quantitative, so there is no reason why they should be this way around rather than `bmi` first and `age` second, which would be equally good.\n\nIf you will find this a bit much to interpret, do two graphs, one for age and one  for BMI:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(whas100.2, condition = c(\"lenfol\", \"age\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-19-1.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(whas100.2, condition = c(\"lenfol\", \"bmi\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-20-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n \n$\\blacksquare$\n\n(k) What is the effect of age on survival? What is the effect\nof BMI on survival? Explain briefly. (You will have to disentangle\nthe meaning of the different coloured lines on the plot to do this.)\n \nSolution\n\n\nBear in mind that up-and-to-the-right is best for a survival\ncurve, since that means that people in the upper-right group have\na higher chance of surviving for longer.   \n\nThe best survival curve of all is the red one in the last facet. This goes with the youngest age (32), but the *highest* BMI, and therefore it is better to be younger in terms of survival (no surprise) but to have a *higher* BMI, which you might find surprising given the relationship between high BMI and obesity.\n\nIf you prefer to interpret the separate plots for age and BMI, which are respectively for an average BMI, presumably about 27 and an average age, presumably about 70: a younger age is better in terms of survival (the red curve), and a higher BMI is better for survival (the pink curve).\n\nExtra: That's the end of what I wanted you to do, but:\n\nA higher BMI is usually associated with being obese (and therefore\nunhealthy), so you'd expect the effect of BMI to be the other way\naround. According to Wikipedia\n([link](http://en.wikipedia.org/wiki/Body_mass_index)), the BMI values\nhere are \"overweight\" or close to it. Maybe being heavier helps\nthe body recover from a heart attack. \n\nLet's start with the martingale residual plot:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas100.2 %>% augment(whas100) %>% \n  ggplot(aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/worcester-15-1.pdf){fig-pos='H'}\n:::\n:::\n\n     \n\nThere is a suspicion of bendiness here, though the left side of the\ncurve is entirely because of that one positive residual on the\nleft. In any case, this suggests that nonlinearity (evidently in terms\nof BMI, since that's the relationship that currently makes no sense)\nwould be worth exploring. \n\nThus:\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas100.3 <- update(whas100.2, . ~ . + I(bmi^2))\nsummary(whas100.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(lenfol, fstat == 1) ~ age + bmi + I(bmi^2), \n    data = whas100)\n\n  n= 100, number of events= 51 \n\n              coef exp(coef)  se(coef)      z Pr(>|z|)    \nage       0.040542  1.041375  0.012035  3.369 0.000755 ***\nbmi      -0.848949  0.427864  0.231562 -3.666 0.000246 ***\nI(bmi^2)  0.014500  1.014606  0.004227  3.430 0.000603 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n         exp(coef) exp(-coef) lower .95 upper .95\nage         1.0414     0.9603    1.0171    1.0662\nbmi         0.4279     2.3372    0.2718    0.6736\nI(bmi^2)    1.0146     0.9856    1.0062    1.0230\n\nConcordance= 0.693  (se = 0.04 )\nLikelihood ratio test= 30.71  on 3 df,   p=1e-06\nWald test            = 32.56  on 3 df,   p=4e-07\nScore (logrank) test = 36.57  on 3 df,   p=6e-08\n```\n\n\n:::\n:::\n\n     \n\nAh, that seems to be it. The significant positive coefficient on\n`bmi`-squared \nmeans that the \"hazard of dying\" increases faster with increasing\n`bmi`, so there ought to be an optimal BMI beyond which\nsurvival chances decrease again. \nHave we improved the residuals by adding the squared term?\n\n::: {.cell}\n\n```{.r .cell-code}\nwhas100.3 %>% augment(whas100) %>% \n  ggplot(aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/worcester-17-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nI call those \"inconsequential wiggles\" now, so I think we are good.\nLet's explore the quadratic relationship on a graph. What matters now is how survival depends on BMI, so we can use an average age such as the one that `plot_predictions` will give us, and hence:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(whas100.3, condition = c(\"lenfol\", \"bmi\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-21-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nThis time, the blue and green survival curves are best, which go with BMI of about 30 and 27, values that are in the middle of the range. Both the low BMIs (red and yellow curves) and the highest one (pink, about 40) are associated with worse survival.\nBut it's still true\nthat having a very *low* BMI is worst, which is why our (linear)\nmodel said that having a higher BMI was better.\n\nIt would have been better to have you put a squared term in the model,\nbut the question was already long and complicated enough, and I\ndidn't want to make your lives more of a nightmare than they are\nalready becoming!\n \n$\\blacksquare$\n\n\n\n\n\n##  Drug treatment programs\n\n\n One of the goals of drug treatment programs is to lengthen\nthe time until the patient returns to using drugs. (It is not\ngenerally possible to prevent patients from *ever* using drugs\nagain.) In one study, over 600 former drug users took part. Two\ndifferent programs, a short program and a long program, were offered\nat two different sites, labelled A and B. The data can be found in\n[link](http://ritsokiguess.site/datafiles/drugusers.txt). The\nvariables are these:\n\n\n\n* `ID`: patient ID number\n\n* `age`: patient age at enrollment into the study\n\n* `ndrugtx`: number of previous drug treatments\n\n* `treat`: 0 for short treatment program, 1 for long program\n\n* `site`: 0 for site A, 1 for site B\n\n* `time`: time until return to drug use\n\n* `censor`: whether the subject returned to drug use (1) or\nnot (0) during the follow-up period\n\n* `herco`: whether subject used heroine or cocaine in the\nlast 3 months: 1 is both, 2 is one (either heroine or cocaine), 3 is neither.\n\n\n\n(a) Read in the data and check in one way or another that you\nhave what was promised above.\n\n\nSolution\n\n\nThis:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/drugusers.txt\"\ndrugusers <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nParsed with column specification:\ncols(\n  row = col_double(),\n  ID = col_double(),\n  age = col_double(),\n  ndrugtx = col_double(),\n  treat = col_double(),\n  site = col_double(),\n  time = col_double(),\n  censor = col_double(),\n  herco = col_double()\n)\n```\n\n\n:::\n\n```{.r .cell-code}\ndrugusers\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 628 x 9\n     row    ID   age ndrugtx treat  site  time censor herco\n   <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>\n 1     1     1    39       1     1     0   188      1     3\n 2     2     2    33       8     1     0    26      1     3\n 3     3     3    33       3     1     0   207      1     2\n 4     4     4    32       1     0     0   144      1     3\n 5     5     5    24       5     1     0   551      0     2\n 6     6     6    30       1     1     0    32      1     1\n 7     7     7    39      34     1     0   459      1     3\n 8     8     8    27       2     1     0    22      1     3\n 9     9     9    40       3     1     0   210      1     2\n10    10    10    36       7     1     0   184      1     2\n# i 618 more rows\n```\n\n\n:::\n:::\n\n \n\nThis shows that you have over 600 rows and the variables described.\n    \n\n$\\blacksquare$\n\n(b) There are some missing values in the dataframe. Demonstrate\nthis using `summary`. Pipe the dataframe into\n`drop_na` and show that they have gone. (`drop_na`\nremoves all rows that have missing values in them.)\n\n\nSolution\n\n\nFirst off, `summary` is a quick way to show how many missing\nvalues there are:^[It doesn't work with text columns, but it  *does* work if you temporarily turn the text columns into  factors, eg. by using `mutate` with `where`. However, we don't have any text  columns here, so what we do here is good for this data set.]\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(drugusers)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      row              ID             age           ndrugtx      \n Min.   :  1.0   Min.   :  1.0   Min.   :20.00   Min.   : 0.000  \n 1st Qu.:157.8   1st Qu.:157.8   1st Qu.:27.00   1st Qu.: 1.000  \n Median :314.5   Median :314.5   Median :32.00   Median : 3.000  \n Mean   :314.5   Mean   :314.5   Mean   :32.37   Mean   : 4.574  \n 3rd Qu.:471.2   3rd Qu.:471.2   3rd Qu.:37.00   3rd Qu.: 6.000  \n Max.   :628.0   Max.   :628.0   Max.   :56.00   Max.   :40.000  \n                                 NA's   :5       NA's   :17      \n     treat             site            time            censor      \n Min.   :0.0000   Min.   :0.000   Min.   :   2.0   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:  79.0   1st Qu.:1.0000  \n Median :0.0000   Median :0.000   Median : 166.0   Median :1.0000  \n Mean   :0.4904   Mean   :0.293   Mean   : 234.7   Mean   :0.8089  \n 3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.: 365.2   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1172.0   Max.   :1.0000  \n                                                                   \n     herco      \n Min.   :1.000  \n 1st Qu.:1.000  \n Median :2.000  \n Mean   :1.898  \n 3rd Qu.:3.000  \n Max.   :3.000  \n                \n```\n\n\n:::\n:::\n\n \n\nAge has five missing values and \"number of previous drug treatments\"\nhas seventeen.\n\nFollowing the instructions, and saving back into the original dataframe:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrugusers %>% drop_na() -> drugusers\n```\n:::\n\n \nand then\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(drugusers)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      row              ID             age           ndrugtx      \n Min.   :  1.0   Min.   :  1.0   Min.   :20.00   Min.   : 0.000  \n 1st Qu.:155.2   1st Qu.:155.2   1st Qu.:27.00   1st Qu.: 1.000  \n Median :312.5   Median :312.5   Median :32.00   Median : 3.000  \n Mean   :313.8   Mean   :313.8   Mean   :32.39   Mean   : 4.579  \n 3rd Qu.:473.8   3rd Qu.:473.8   3rd Qu.:37.00   3rd Qu.: 6.000  \n Max.   :628.0   Max.   :628.0   Max.   :56.00   Max.   :40.000  \n     treat             site             time            censor      \n Min.   :0.0000   Min.   :0.0000   Min.   :   2.0   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:  79.0   1st Qu.:1.0000  \n Median :0.0000   Median :0.0000   Median : 166.0   Median :1.0000  \n Mean   :0.4918   Mean   :0.2984   Mean   : 234.4   Mean   :0.8115  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.: 361.8   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1172.0   Max.   :1.0000  \n     herco     \n Min.   :1.00  \n 1st Qu.:1.00  \n Median :2.00  \n Mean   :1.89  \n 3rd Qu.:3.00  \n Max.   :3.00  \n```\n\n\n:::\n:::\n\n \n\nNo NA left. Gosh, as they say, that was easy.\nExtra: how many rows did we lose?\n\n::: {.cell}\n\n```{.r .cell-code}\nnrow(drugusers)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 610\n```\n\n\n:::\n:::\n\n \n\nThere were 628 rows before, so we lost 18. (There were 22 missing\nvalues, but some of them were two on one row, so we only lost 18\nrows.)\n\nThis is a very unsophisticated way of dealing with missing\nvalues. Another way is to \"impute\" them, that is, to guess what they\nwould have been, and then fill in the guessed values and use them as\nif they were the truth, for example by regressing the columns with missing values on all the others, and using the regression predictions in place of the missing values.\n\n\n$\\blacksquare$\n\n(c) Some of these variables are recorded as numbers but are\nactually categorical. Which ones? Re-define these variables in your\ndata frame so that they have sensible (text) values.\n\n\nSolution\n\n\nThese variables are actually categorical rather than quantitative:\n\n\n* `treat`\n\n* `site`\n\n* `censor`\n\n* `herco`\n\nMost of them have only two levels, so it doesn't matter whether\nwe make them categorical or leave them as numbers, but for\n`herco` it matters. Let's give them all sensible values,\nmostly with `ifelse`,^[`case_when` is much clearer than using nested `if-else`s when you have three or more categories, as for `herco`.] thus:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrugusers %>% mutate(\n  treat = ifelse(treat == 0, \"short\", \"long\"),\n  site = ifelse(site == 0, \"A\", \"B\"),\n  censor = ifelse(censor == 1, \"returned\", \"no-return\"),\n  herco = case_when(\n    herco == 1 ~ \"both\",\n    herco == 2 ~ \"one\",\n    herco == 3 ~ \"neither\"\n  )\n) -> drugusers\n```\n:::\n\n       \n\nI'm living on the edge and overwriting everything:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrugusers\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 610 x 9\n     row    ID   age ndrugtx treat site   time censor    herco  \n   <dbl> <dbl> <dbl>   <dbl> <chr> <chr> <dbl> <chr>     <chr>  \n 1     1     1    39       1 long  A       188 returned  neither\n 2     2     2    33       8 long  A        26 returned  neither\n 3     3     3    33       3 long  A       207 returned  one    \n 4     4     4    32       1 short A       144 returned  neither\n 5     5     5    24       5 long  A       551 no-return one    \n 6     6     6    30       1 long  A        32 returned  both   \n 7     7     7    39      34 long  A       459 returned  neither\n 8     8     8    27       2 long  A        22 returned  neither\n 9     9     9    40       3 long  A       210 returned  one    \n10    10    10    36       7 long  A       184 returned  one    \n# i 600 more rows\n```\n\n\n:::\n:::\n\n \n\n\n$\\blacksquare$\n\n(d) Create a suitable reponse variable for a Cox proportional\nhazards regression that predicts time until return to drug use from\nthe other variables.\nThis requires some care, because you need to be sure about what the\ncensoring variable actually represents and what you need it to represent.\n\n\nSolution\n\n\nThis is `Surv` in package `survival`. The response\nvariable needs to encode two things: the time until the event of\ninterest (return to drug use) and whether or not that event\nhappened for each patient.^[I now define the response variable right inside the `coxph`, in the same way as putting something like `log(y)` as a response in an `lm`, but I think, especially while you're getting used to the process, it's better to create the response variable first and look at it to make sure it's the right thing.]\nIn this case, that is\n`censor=\"returned\"`. \n\n::: {.cell}\n\n```{.r .cell-code}\ny <- with(drugusers, Surv(time, censor == \"returned\"))\n```\n:::\n\nSince we are doing this to test whether it is the right thing, we can save it in something outside of the dataframe, and then look at it (which we do in a moment).\n\n$\\blacksquare$\n\n(e) Look at the first few values of your response variable. Why\nis the fifth one marked with a `+`? Explain briefly.\n\n\nSolution\n\n\n`head` works as well with a vector (displaying the first\nsix values) as it does with a data frame:\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 188   26  207  144  551+  32 \n```\n\n\n:::\n:::\n\n      \n\nThe fifth value is marked with a `+` because it is a censored\nvalue: this is a patient who was never observed to go back to drug\nuse. You can tell this by looking at the `head` of the entire\ndata frame:^[Or, `slice` off the first few rows.]\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(drugusers)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 9\n    row    ID   age ndrugtx treat site   time censor    herco  \n  <dbl> <dbl> <dbl>   <dbl> <chr> <chr> <dbl> <chr>     <chr>  \n1     1     1    39       1 long  A       188 returned  neither\n2     2     2    33       8 long  A        26 returned  neither\n3     3     3    33       3 long  A       207 returned  one    \n4     4     4    32       1 short A       144 returned  neither\n5     5     5    24       5 long  A       551 no-return one    \n6     6     6    30       1 long  A        32 returned  both   \n```\n\n\n:::\n:::\n\n \n\nsince this patient has `censor=\"no-return\"`. The other ones have\n`censor=\"returned\"`; these are all \"uncensored\" in the jargon.\n\nTypically, censored values will be bigger than uncensored ones,\nbecause (in most cases) the individual will be observed until the study\nends, and studies of this kind carry on for years:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(drugusers, aes(x = censor, y = time)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/drug-treatment-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n \nYep. The smallest time for a censored observation would be an upper outlier\nif it were observed for an uncensored observation.\n\nOne nice side-effect of turning `censor` into a categorical variable is that it can now\ndistinguish groups as a boxplot requires.\n\nI discovered something rather amusing when I originally wrote this (a\nyear ago). Suppose you want to compare times for the two treatment\ngroups, and you *also* want to distinguish censored from\nnon-censored observations. Then, this works:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(drugusers, aes(x = treat, y = time, colour = censor)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/drug-treatment-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nFor each treatment, you get side-by-side boxplots of the times for\ncensored (red) and uncensored (blue) observations, and so you see for\nboth treatments (short and long) the censored times are typically\nlonger than the uncensored ones.\n\n(This you may recognize as a \"grouped boxplot\", for when we have two\ncategorical variables and one quantitative one.)\n\nI borrow this idea for two-way ANOVA (coming up later).\n    \n\n$\\blacksquare$\n\n(f) Fit a Cox proportional hazards model, predicting from all\nthe other variables (except for `row` and `ID`) that you haven't used\nyet. Display the results.\n\n\nSolution\n\nFor the thing to go on the left of the squiggle, copy the `Surv()` thing you made before and paste it in (once you have it working):\n\n::: {.cell}\n\n```{.r .cell-code}\ndrugusers.1 <- coxph(Surv(time, censor == \"returned\") ~ age + ndrugtx + treat + site + herco, data = drugusers)\nsummary(drugusers.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(time, censor == \"returned\") ~ age + ndrugtx + \n    treat + site + herco, data = drugusers)\n\n  n= 610, number of events= 495 \n\n                  coef exp(coef)  se(coef)      z Pr(>|z|)    \nage          -0.023798  0.976483  0.007561 -3.148  0.00165 ** \nndrugtx       0.034815  1.035429  0.007755  4.490 7.14e-06 ***\ntreatshort    0.254606  1.289953  0.091006  2.798  0.00515 ** \nsiteB        -0.173021  0.841120  0.102105 -1.695  0.09016 .  \nherconeither  0.125779  1.134032  0.103075  1.220  0.22236    \nhercoone      0.247318  1.280586  0.122759  2.015  0.04394 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n             exp(coef) exp(-coef) lower .95 upper .95\nage             0.9765     1.0241    0.9621    0.9911\nndrugtx         1.0354     0.9658    1.0198    1.0513\ntreatshort      1.2900     0.7752    1.0792    1.5418\nsiteB           0.8411     1.1889    0.6886    1.0275\nherconeither    1.1340     0.8818    0.9266    1.3879\nhercoone        1.2806     0.7809    1.0067    1.6289\n\nConcordance= 0.581  (se = 0.014 )\nLikelihood ratio test= 35.08  on 6 df,   p=4e-06\nWald test            = 36.96  on 6 df,   p=2e-06\nScore (logrank) test = 37.36  on 6 df,   p=1e-06\n```\n\n\n:::\n:::\n\n   \n\nAnother way to handle \n\"all the other $x$'s except `row`, `ID`, `time` and `censor`\" is this:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrugusers.1a <- coxph(y ~ . - row - ID - time - censor, data = drugusers)\ntidy(drugusers.1a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 5\n  term         estimate std.error statistic    p.value\n  <chr>           <dbl>     <dbl>     <dbl>      <dbl>\n1 age           -0.0238   0.00756     -3.15 0.00165   \n2 ndrugtx        0.0348   0.00775      4.49 0.00000714\n3 treatshort     0.255    0.0910       2.80 0.00515   \n4 siteB         -0.173    0.102       -1.69 0.0902    \n5 herconeither   0.126    0.103        1.22 0.222     \n6 hercoone       0.247    0.123        2.01 0.0439    \n```\n\n\n:::\n:::\n\n \n\nSame. I used `tidy` from `broom` to shorten the output a bit.\n    \n\n$\\blacksquare$\n\n(g) Find which explanatory variables can be removed at $\\alpha=0.05$\n(there should be two of them). Bear in mind that we have categorical variables, so that looking at the output from `summary` is not enough.\n\n\nSolution\n\n\nThe hint is meant to suggest to you that looking at `drop1` is the right way to go:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(drugusers.1, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSingle term deletions\n\nModel:\nSurv(time, censor == \"returned\") ~ age + ndrugtx + treat + site + \n    herco\n        Df    AIC     LRT  Pr(>Chi)    \n<none>     5712.2                      \nage      1 5720.3 10.0972  0.001485 ** \nndrugtx  1 5727.3 17.1446 3.464e-05 ***\ntreat    1 5718.0  7.8352  0.005124 ** \nsite     1 5713.1  2.9335  0.086760 .  \nherco    2 5712.5  4.3182  0.115427    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n       \n\nNote that `herco`, a categorical variable with three levels,\nhas 2 degrees of freedom here, since a test of \n\"no effect of `herco`\" is testing that survival is the same at \n*all three* levels of `herco`.\n\n\n$\\blacksquare$\n\n(h) Remove *all* the non-significant explanatory variables\nand re-fit your model. By carrying out a suitable test demonstrate\nthat your smaller model is the better one.\n\n\nSolution\n\n\n`site` and `herco` are the two variables to come\nout.^[The researchers were probably relieved that there        was not quite a significant effect of `site`.] I like\n`update`, but there is no\nproblem about copying-pasting your `coxph` and taking out\nwhat you no longer need.\n\n::: {.cell}\n\n```{.r .cell-code}\ndrugusers.2 <- update(drugusers.1, . ~ . - site - herco)\n```\n:::\n\n \n\nHaving fit two models, we can use `anova` to compare them. The\nright test gets done, so no need for `test=`:\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(drugusers.2, drugusers.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n Cox model: response is  Surv(time, censor == \"returned\")\n Model 1: ~ age + ndrugtx + treat\n Model 2: ~ age + ndrugtx + treat + site + herco\n   loglik  Chisq Df Pr(>|Chi|)  \n1 -2853.7                       \n2 -2850.1 7.2117  3    0.06545 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n \n\nThere is no significant difference between these two \nmodels,^[Not at the 0.05 level, anyway.] so we can go with the \nsmaller, simpler one\n(with just `age`, `ndrugtx` and `treat`).\n    \n\n$\\blacksquare$\n\n(i) <a name=\"part:posneg\">*</a> Display your better model. Are all of the\nexplanatory variables significant? Do their slope coefficients have\nsensible signs (plus or minus), based on what you know or can guess\nabout drug treatments? Explain briefly.\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(drugusers.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(time, censor == \"returned\") ~ age + ndrugtx + \n    treat, data = drugusers)\n\n  n= 610, number of events= 495 \n\n                coef exp(coef)  se(coef)      z Pr(>|z|)    \nage        -0.020801  0.979414  0.007419 -2.804  0.00505 ** \nndrugtx     0.035567  1.036207  0.007621  4.667 3.05e-06 ***\ntreatshort  0.231055  1.259929  0.090175  2.562  0.01040 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n           exp(coef) exp(-coef) lower .95 upper .95\nage           0.9794     1.0210    0.9653    0.9938\nndrugtx       1.0362     0.9651    1.0208    1.0518\ntreatshort    1.2599     0.7937    1.0558    1.5035\n\nConcordance= 0.572  (se = 0.014 )\nLikelihood ratio test= 27.87  on 3 df,   p=4e-06\nWald test            = 30.5  on 3 df,   p=1e-06\nScore (logrank) test = 30.62  on 3 df,   p=1e-06\n```\n\n\n:::\n:::\n\n       \n\nThe three remaining explanatory variables are all clearly significant:\nthe patient's age, the number of previous drug treatments, and whether\nthe treatment was short or long. This is legit (we don't need to run\n`drop1` again) because the remaining explanatory variables are\nall quantitative or have only two levels, so that the single-df tests\nin `summary` are what we need.\n\nDo their slope coefficients have sensible signs? Well, this requires\ncareful thought. A positive coefficient means that increasing that\nvariable *increases the hazard of the event*: ie., it makes the\nevent likelier to happen sooner. Here, the \"event\" is \n\"return to drug use\":\n\n\n\n* Age has a negative coefficient, so an older person is likely to take\n*longer* to return to drug use, other things being equal. This\nmakes some kind of sense, if you imagine drug use as being related to\nmaturity, or an older drug user as being more strongly committed to\n\"turning their life around\", so that a drug treatment of any kind is\ngoing to be more effective on an older patient.\n\n* The number of previous treatments has a positive coefficient, so that a\npatient who has had a lot of previous treatments is likely to go back\nto drugs sooner. Such a person might be an \"addict\" for whom\ntreatments really do not work, or might not be committed to giving up drugs.\n\n\n* `treatshort` has a positive coefficient.  This says that\nif you give a patient a short treatment, they are more likely (other\nthings being equal) to go back to drugs sooner, as compared to the\nbaseline long treatment.  That is, a longer treatment is more\neffective than a shorter one. Given a significant effect of\ntreatment length, this is the way around you would expect it to be.\n\n\n    \n\n$\\blacksquare$\n\n(j) We have three variables left in our model, `age`,\n`ndrugtx` and `treat`. The quartiles of age are 27 and\n37, the quartiles of `ndrugtx` are 1 and 6, and the two\npossible values of `treat` are `short` and `long`. The quartiles and median of the times to return are about 80, 160, and 360.\nCreate a data frame\nwith variables of these names and all possible combinations of their\nvalues (so there should be 24 rows in the resulting data\nframe). Display the resulting data frame.\n\n\nSolution\n\n\nThis data frame is going to be used for prediction, so I will\ncall it `new` and construct it in pieces as I did before\n(thus meaning that I don't have to think too hard about what I'm doing):\n\n::: {.cell}\n\n```{.r .cell-code}\nages <- c(27, 37)\nndrugtxs <- c(1, 6)\ntreats <- c(\"short\", \"long\")\ntimes <- c(80, 160, 360)\nnew <- datagrid(model = drugusers.2, age = ages, ndrugtx = ndrugtxs, treat = treats, time = times)\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     censor age ndrugtx treat time rowid\n1  returned  27       1 short   80     1\n2  returned  27       1 short  160     2\n3  returned  27       1 short  360     3\n4  returned  27       1  long   80     4\n5  returned  27       1  long  160     5\n6  returned  27       1  long  360     6\n7  returned  27       6 short   80     7\n8  returned  27       6 short  160     8\n9  returned  27       6 short  360     9\n10 returned  27       6  long   80    10\n11 returned  27       6  long  160    11\n12 returned  27       6  long  360    12\n13 returned  37       1 short   80    13\n14 returned  37       1 short  160    14\n15 returned  37       1 short  360    15\n16 returned  37       1  long   80    16\n17 returned  37       1  long  160    17\n18 returned  37       1  long  360    18\n19 returned  37       6 short   80    19\n20 returned  37       6 short  160    20\n21 returned  37       6 short  360    21\n22 returned  37       6  long   80    22\n23 returned  37       6  long  160    23\n24 returned  37       6  long  360    24\n```\n\n\n:::\n:::\n\n       \n\n24 rows as promised. Note that the predicted probabilities of returning to drug use (or not having done so yet) will depend on the timescale you are looking at: the longer you wait, the more likely the previous drug user will have gone back to using.\n    \n\n$\\blacksquare$\n\n(k) Obtain predicted survival probabilities for each of the\nvalues of `age`, `ndrugtx`,`treat`, and `time` used in\nthe previous part. Display at least some of it.\n\nSolution\n\nThis is the usual `marginaleffects` stuff. I like to limit the display to the columns of interest so that it's not too wide. Don't forget the `type` here:\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(drugusers.2, newdata = new, type = \"survival\")) %>% \n  select(age, ndrugtx, treat, time, estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   age ndrugtx treat time  estimate\n1   27       1 short   80 0.7262638\n2   27       1 short  160 0.4803012\n3   27       1 short  360 0.2154553\n4   27       1  long   80 0.7758026\n5   27       1  long  160 0.5587516\n6   27       1  long  360 0.2957254\n7   27       6 short   80 0.6824318\n8   27       6 short  160 0.4164154\n9   27       6 short  360 0.1598118\n10  27       6  long   80 0.7384032\n11  27       6  long  160 0.4989076\n12  27       6  long  360 0.2332963\n13  37       1 short   80 0.7712253\n14  37       1 short  160 0.5512218\n15  37       1 short  360 0.2874450\n16  37       1  long   80 0.8136850\n17  37       1  long  160 0.6232925\n18  37       1  long  360 0.3717555\n19  37       6 short   80 0.7332017\n20  37       6 short  160 0.4908862\n21  37       6 short  360 0.2255140\n22  37       6  long   80 0.7816790\n23  37       6  long  160 0.5685032\n24  37       6  long  360 0.3066315\n```\n\n\n:::\n:::\n\n\nMake sure that you use your best model, ie. the second one. \n\nThis gives you a vague picture of the effects of things. The probability of survival (not having gone back to using drugs) decreases over time, and you can get an idea of the effect of the explanatory variables in the model. For example, if you use the first six rows, you can see that the effect of a short treatment vs a long one is to decrease the probability of survival somewhat (that is to say, to make it a little *more* likely that the user will have gone back to using drugs), comparing the same values for age, number of previous treatments, and time.\n\n$\\blacksquare$\n\n(l) Plot your predicted survival curves to show the effect of each explanatory variable over time. This is most easily done with three separate plots.\n\n\nSolution\n\nThis is `plot_predictions`, remembering to put time first in the `condition` and to have a `type` also.\n\nEffect of age first:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(drugusers.2, condition = c(\"time\", \"age\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-46-1.pdf){fig-pos='H'}\n:::\n:::\n\nFive different ages were chosen for us. The best survival, at the top of the traces on the graph, is the purple and blue curves, which go with the oldest ages, so these are the least likely to go back to using drugs, all else equal.\n\nNumber of drug treatments:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(drugusers.2, condition = c(\"time\", \"ndrugtx\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-47-1.pdf){fig-pos='H'}\n:::\n:::\n\nLikewise, the graph shows some representative numbers of previous treatments, and the more of them there were, the worse the survival is. This is consistent with my comments on the `ndrugtx` coefficient on the `summary` output.\n\n\nTreatment:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(drugusers.2, condition = c(\"time\", \"treat\"), type = \"survival\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-48-1.pdf){fig-pos='H'}\n:::\n:::\n\nA long treatment is a bit better than a short one. (I don't know why the warning happened on  this one.)\n\nYou might be curious about what happens if you glue all *three* explanatory variables onto `condition`. If you are, try it and see:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(drugusers.2, condition = c(\"time\", \"age\", \"ndrugtx\", \"treat\"), \n                 type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-49-1.pdf){fig-pos='H'}\n:::\n:::\n\nWhat has happened here is that `plot_predictions` has used facets to accommodate the other explanatory variables, specifically `facet_grid` (rather than `facet_wrap`) because there are two additional explanatory variables, one of which is horizontal facets and the other one is vertical facets.\n\nTo assess the effect of each explanatory variable, hold the others constant. Thus:\n\n- To assess age, pick one of the ten facets and see that the highest age is best (no matter which facet you pick)\n- To assess number of previous drug treatments, pick a row and see what happens as you go to the right (the survival is worse as `ndrugtx` increases)\n- To assess short vs. long treatment, pick a column and compare the top facet with the bottom one. This is not easy to see, but survival in the top facet is better (so that the longer treatment is better).\n\nMy take is that the individual plots make it easier to assess the individual effects, but if you are willing to put in the work to assess the effects, you can make just the one graph and interpret that.\n\n$\\blacksquare$\n\n(m) Which of your combinations of values is predicted to take\nthe longest to return to drug use? Which is predicted to take the\nshortest time? Explain briefly.\n\n\nSolution\n\n\nRemember that \"up and to the right\" is the best survival\ncurve: that is, the people on this survival curve are predicted\nto take the longest to return to drug use. \n\nThis is easiest to see from my combined plot: the best survival curve of all is the top left one: age 56, no previous drug treatments, long treatment. The worst one is the bottom right one: age 20, 40 previous drug treatments, short treatment. (It's hard to see which age is worst in this graph, but you infer that the age effect is the same as on all the other facets.)\n\nFrom the individual graphs, name the best and worst values on each one, and the best and worst survival overall will come from the combinations of those. This gives the same answer as above.\n\n\"Returning to drug use\" is like \"death\" in that you want it\nto be a long time before it happens, so \"best\" is top right on\nthe plot of survival curves. In other circumstances, you might\nwant the event to happen *sooner*, in which case the\nlower-left survival curve would be the \"best\" one.\n    \n\n$\\blacksquare$\n\n(n) Are your survival curve plot and your conclusions from part\n(<a href=\"#part:posneg\">here</a>) consistent, or not? Explain briefly.\n\n\nSolution\n\n\nThe survival curves say that being older, having fewer previous\ntreatments and being on the long treatment are better in terms\nof taking longer to return to drug use. Our analysis of whether\nthe slope coefficients in `drugusers.2` were positive or\nnegative came to exactly the same conclusion. So the survival\ncurves and part (<a href=\"#part:posneg\">here</a>) are entirely consistent.\n\n    \n$\\blacksquare$\n\n\n\n\n\n\n\n##  Multiple myeloma\n\n\n Multiple myeloma is a kind of cancer. It\nforms in a plasma cell (which is a type of white blood cell). It\ncauses cancer cells to accumulate in the bone marrow, where they crowd\nout healthy blood cells. Plasma cells make antibodies (to help fight\ninfections), while the cancer cells don't: they produce abnormal\nproteins that can cause kidney problems. (This adapted from\n[link](http://www.mayoclinic.org/diseases-conditions/multiple-myeloma/basics/definition/con-20026607).)\nThe variables are:\n\n\n\n* `time`: survival time from diagnosis (months)\n\n* `vstatus`: 0=alive, 1=dead at end of study\n\n* `logbun`: log of BUN test score (BUN test is a test of\nkidney function, not to be confused with cha siu\nbao^[Barbecued pork in a bun. A staple of Chinese dim sum and  Chinese bakeries, such as Ding Dong bakery on Spadina.]).\n\n* `hgb`: hemoglobin (at diagnosis).\n\n* `platelet`: platelets: 1=normal, 0=abnormal (at\ndiagnosis).\n\n* `age` at diagnosis, in years\n\n* `logwbc`: log of WBC (white blood cell count, at\ndiagnosis)\n\n* `frac`: fractures at diagnosis (0=absent, 1=present)\n\n* `logpbm`: log of percent of plasma cells in bone marrow\n\n* `protein`: proteinuria (protein in urine) at\ndiagnosis. Most people have very little, so a larger than normal\namount indicates illness of some kind.\n\n* `scalc`: serum calcium at diagnosis.\n\n\nThe data, on 65 patients with multiple myeloma, are in\n[link](http://ritsokiguess.site/datafiles/myeloma.csv). Some of the\nvariables are logs because they could take very large values.\n\nThere are a lot of parts here, but each part is supposed to be short.\n\n\n\n(a) Read in the data and display (some of) the values. Confirm that\nyou have the right number of observations and the right variables.\n\n\nSolution\n\n\nThe usual:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/myeloma.csv\"\nmyeloma <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nParsed with column specification:\ncols(\n  time = col_double(),\n  vstatus = col_double(),\n  logbun = col_double(),\n  hgb = col_double(),\n  platelet = col_double(),\n  age = col_double(),\n  logwbc = col_double(),\n  frac = col_double(),\n  logpbm = col_double(),\n  protein = col_double(),\n  scalc = col_double()\n)\n```\n\n\n:::\n\n```{.r .cell-code}\nmyeloma\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 65 x 11\n    time vstatus logbun   hgb platelet   age logwbc  frac logpbm protein scalc\n   <dbl>   <dbl>  <dbl> <dbl>    <dbl> <dbl>  <dbl> <dbl>  <dbl>   <dbl> <dbl>\n 1  1.25       1   2.22   9.4        1    67   3.66     1   1.95      12    10\n 2  1.25       1   1.94  12          1    38   3.99     1   1.95      20    18\n 3  2          1   1.52   9.8        1    81   3.88     1   2          2    15\n 4  2          1   1.75  11.3        0    75   3.81     1   1.26       0    12\n 5  2          1   1.30   5.1        0    57   3.72     1   2          3     9\n 6  3          1   1.54   6.7        1    46   4.48     0   1.93      12    10\n 7  5          1   2.24  10.1        1    50   4.95     1   1.66       4     9\n 8  5          1   1.68   6.5        1    74   3.73     0   1.73       5     9\n 9  6          1   1.36   9          1    77   3.54     0   1.46       1     8\n10  6          1   2.11  10.2        0    70   3.54     1   1.36       1     8\n# i 55 more rows\n```\n\n\n:::\n:::\n\n     \n\n65 observations, and all the variables listed. If you want to go\nfurther (not necessary here), you can check that the variables\n`vstatus`, `platelet` and `frac` that should be\nzero and one actually *are* zero and one, at least for the values\nshown (they are), and the ages look like ages (they do).\n\nThe tidyverse also offers:\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(myeloma)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 65\nColumns: 11\n$ time     <dbl> 1.25, 1.25, 2.00, 2.00, 2.00, 3.00, 5.00, 5.00, 6.00, 6.00, 6~\n$ vstatus  <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n$ logbun   <dbl> 2.2175, 1.9395, 1.5185, 1.7482, 1.3010, 1.5441, 2.2355, 1.681~\n$ hgb      <dbl> 9.4, 12.0, 9.8, 11.3, 5.1, 6.7, 10.1, 6.5, 9.0, 10.2, 9.7, 10~\n$ platelet <dbl> 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1~\n$ age      <dbl> 67, 38, 81, 75, 57, 46, 50, 74, 77, 70, 60, 67, 48, 61, 53, 5~\n$ logwbc   <dbl> 3.6628, 3.9868, 3.8751, 3.8062, 3.7243, 4.4757, 4.9542, 3.732~\n$ frac     <dbl> 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1~\n$ logpbm   <dbl> 1.9542, 1.9542, 2.0000, 1.2553, 2.0000, 1.9345, 1.6628, 1.732~\n$ protein  <dbl> 12, 20, 2, 0, 3, 12, 4, 5, 1, 1, 0, 0, 5, 1, 1, 0, 0, 1, 1, 0~\n$ scalc    <dbl> 10, 18, 15, 12, 9, 10, 9, 9, 8, 8, 10, 8, 10, 10, 13, 12, 10,~\n```\n\n\n:::\n:::\n\n \n\nwhich gives a bit more of a picture of the values.^[Don't  confuse this with `glance` from `broom`, which gives a one-line summary of a *model*, containing things like R-squared and a test for the overall model significance.]\nOr if you were\nserious about checking, you could do\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(myeloma)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      time          vstatus           logbun            hgb      \n Min.   : 1.25   Min.   :0.0000   Min.   :0.7782   Min.   : 4.9  \n 1st Qu.: 7.00   1st Qu.:0.0000   1st Qu.:1.1461   1st Qu.: 8.8  \n Median :15.00   Median :1.0000   Median :1.3222   Median :10.2  \n Mean   :24.01   Mean   :0.7385   Mean   :1.3929   Mean   :10.2  \n 3rd Qu.:35.00   3rd Qu.:1.0000   3rd Qu.:1.5682   3rd Qu.:12.0  \n Max.   :92.00   Max.   :1.0000   Max.   :2.2355   Max.   :14.6  \n    platelet           age            logwbc           frac       \n Min.   :0.0000   Min.   :38.00   Min.   :3.362   Min.   :0.0000  \n 1st Qu.:1.0000   1st Qu.:51.00   1st Qu.:3.643   1st Qu.:1.0000  \n Median :1.0000   Median :60.00   Median :3.732   Median :1.0000  \n Mean   :0.8615   Mean   :60.15   Mean   :3.769   Mean   :0.7538  \n 3rd Qu.:1.0000   3rd Qu.:67.00   3rd Qu.:3.875   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :82.00   Max.   :4.954   Max.   :1.0000  \n     logpbm          protein           scalc      \n Min.   :0.4771   Min.   : 0.000   Min.   : 7.00  \n 1st Qu.:1.3617   1st Qu.: 0.000   1st Qu.: 9.00  \n Median :1.6232   Median : 1.000   Median :10.00  \n Mean   :1.5497   Mean   : 3.615   Mean   :10.12  \n 3rd Qu.:1.8451   3rd Qu.: 4.000   3rd Qu.:10.00  \n Max.   :2.0000   Max.   :27.000   Max.   :18.00  \n```\n\n\n:::\n:::\n\n \n\nwhich gives means and five-number summaries for each of the variables\n(the numeric ones, but they all are here, even the ones coded as 0 or\n1 that are really categorical).\n    \n\n$\\blacksquare$\n\n(b) Create a suitable response variable for a Cox\nproportional-hazards survival model, bearing in mind that the\n\"event\" here is death. Display your response variable, and explain\nbriefly what the `+` signs attached to some of the values\nmean, without using a technical term.\n\n\nSolution\n\nThis is really practice for the `Surv` that you are about to use in fitting a model, so it doesn't matter whether you save the results anywhere. \n\n\nTwo things to consider: the survival times, here\n`time`, and the indicator of the event (death), here\n`vstatus` being 1. Sometimes, though not here, the column that is `vstatus` here is used to capture various types of outcome such as \"lost to follow-up\" (meaning, we don't know what happened to this patient) or \"died of something else\", and it is then important to make sure that you know which of these outcomes is the one of interest to you.\n\n\nI've changed my mind on this over the years: putting the `Surv` right in the `coxph` (next part) is what I do now, because that plays best with `marginaleffects` (later), so for me this part is just practice at getting the `Surv` right:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(myeloma, Surv(time, vstatus == 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  1.25   1.25   2.00   2.00   2.00   3.00   5.00   5.00   6.00   6.00 \n[11]  6.00   6.00   7.00   7.00   7.00   9.00  11.00  11.00  11.00  11.00 \n[21] 11.00  13.00  14.00  15.00  16.00  16.00  17.00  17.00  18.00  19.00 \n[31] 19.00  24.00  25.00  26.00  32.00  35.00  37.00  41.00  41.00  51.00 \n[41] 52.00  54.00  58.00  66.00  67.00  88.00  89.00  92.00   4.00+  4.00+\n[51]  7.00+  7.00+  8.00+ 12.00+ 11.00+ 12.00+ 13.00+ 16.00+ 19.00+ 19.00+\n[61] 28.00+ 41.00+ 53.00+ 57.00+ 77.00+\n```\n\n\n:::\n:::\n\nThe values of that have a `+` by them go with\npatients who were never observed to die (or were still alive at the\nend of the study). There were 17 of these, listed at the end of the\ndata frame. Usually, these values of the response will be higher than\nthe others, but they weren't here. (Maybe some of these patients were\nwithdrawn from the study, or they joined it late.) \n\n$\\blacksquare$\n\n(c) What is the technical term for those patients that have a\n`+` by their values for the response variable?\n\n\nSolution\n\n\nCensored. A quick one.\nI was trying to dissuade you from using the word \"censored\" in\nthe previous part, since I wanted you to demonstrate that you\nunderstood what it *meant*. But you should know the technical\nterm as well, which is why I asked you for it here.\n\nGrading note, for when this was on an assignment: if this part and the previous one contain,\nsomewhere, the word \"censored\" *and* a clear explanation of\nwhat \"censored\" means, then I don't mind what is where.\n    \n\n$\\blacksquare$\n\n(d) Fit a Cox proportional-hazards survival model predicting\nyour response variable from all the other variables (except for the\nones that you used to make the response variable). Display the\n`summary` of your model.\n\n\nSolution\n\n\nThe obvious way to do this is to list all the other variables on\nthe right side of the squiggle, but a faster way is this:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyeloma.1 <- coxph(Surv(time, vstatus == 1) ~ ., data = myeloma)\nsummary(myeloma.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(time, vstatus == 1) ~ ., data = myeloma)\n\n  n= 65, number of events= 48 \n\n             coef exp(coef) se(coef)      z Pr(>|z|)   \nlogbun    1.85557   6.39536  0.65628  2.827  0.00469 **\nhgb      -0.12629   0.88136  0.07212 -1.751  0.07994 . \nplatelet -0.25488   0.77501  0.51194 -0.498  0.61858   \nage      -0.01306   0.98702  0.01957 -0.668  0.50439   \nlogwbc    0.35389   1.42460  0.71576  0.494  0.62101   \nfrac      0.34232   1.40821  0.40725  0.841  0.40059   \nlogpbm    0.38165   1.46470  0.48743  0.783  0.43364   \nprotein   0.01302   1.01311  0.02612  0.498  0.61817   \nscalc     0.12976   1.13856  0.10502  1.236  0.21659   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n         exp(coef) exp(-coef) lower .95 upper .95\nlogbun      6.3954     0.1564    1.7670    23.147\nhgb         0.8814     1.1346    0.7652     1.015\nplatelet    0.7750     1.2903    0.2841     2.114\nage         0.9870     1.0131    0.9499     1.026\nlogwbc      1.4246     0.7020    0.3503     5.794\nfrac        1.4082     0.7101    0.6339     3.128\nlogpbm      1.4647     0.6827    0.5634     3.808\nprotein     1.0131     0.9871    0.9625     1.066\nscalc       1.1386     0.8783    0.9268     1.399\n\nConcordance= 0.675  (se = 0.051 )\nLikelihood ratio test= 17.62  on 9 df,   p=0.04\nWald test            = 17.93  on 9 df,   p=0.04\nScore (logrank) test = 18.97  on 9 df,   p=0.03\n```\n\n\n:::\n:::\n\n     \n\nThe `.` in this model formula means \n\"all the columns in the data frame\" \n(except for those used in the response variable). I used `time` and\n`vstatus` to make the response, so I had no need to exclude them explicitly.\n\n\nThere is of course nothing wrong with typing out all the variable\nnames, except that the first time you type them out, you will likely\nmake a typo (unless you are more careful than I usually am). \n    \n\n$\\blacksquare$\n\n(e) In your model, which explanatory variables have a P-value less than\n0.10? Fit a model containing only those and display the results.\n\n\nSolution\n\n\nOnly `logbun` and `hgb`; the other P-values are\nlarger, usually much larger.\nBecause there are so many variables to remove, I am frightened\naway from `update` here (which I would normally try to use\nin this situation). I'm going to copy-and-paste my code for\n`myeloma.1` and edit it:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyeloma.2 <- coxph(Surv(time, vstatus == 1) ~ logbun + hgb, data = myeloma)\nsummary(myeloma.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(time, vstatus == 1) ~ logbun + hgb, data = myeloma)\n\n  n= 65, number of events= 48 \n\n           coef exp(coef) se(coef)      z Pr(>|z|)   \nlogbun  1.71597   5.56209  0.61855  2.774  0.00553 **\nhgb    -0.11966   0.88722  0.05742 -2.084  0.03717 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\nlogbun    5.5621     0.1798    1.6547   18.6961\nhgb       0.8872     1.1271    0.7928    0.9929\n\nConcordance= 0.675  (se = 0.043 )\nLikelihood ratio test= 12.27  on 2 df,   p=0.002\nWald test            = 12.51  on 2 df,   p=0.002\nScore (logrank) test = 13.07  on 2 df,   p=0.001\n```\n\n\n:::\n:::\n\n     \n\nThat's all I wanted, but you can note that `hgb` has become\nsignificant at $\\alpha=0.05$. I suspect it was somewhat correlated\nwith a variable that we removed, so that its value to the regression\nhas become clearer.\n    \n\n$\\blacksquare$\n\n(f) Do a test to compare the two models that you fit. Why do \nyou prefer the second model? Explain briefly.\n\n\nSolution\n\n\nComparing two models is `anova`, which also works here. The\nright `test` is `Chisq`:\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(myeloma.2, myeloma.1, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n Cox model: response is  Surv(time, vstatus == 1)\n Model 1: ~ logbun + hgb\n Model 2: ~ logbun + hgb + platelet + age + logwbc + frac + logpbm + protein + scalc\n   loglik Chisq Df Pr(>|Chi|)\n1 -148.06                    \n2 -145.39 5.347  7     0.6177\n```\n\n\n:::\n:::\n\n     \n\nThe usual logic here: this is far from significant, so the null\nhypothesis (that the two models are equally good) is not rejected, so\nwe prefer the smaller model `myeloma.2` because it is simpler.\n\n\nIn case you are curious, `step` also works on models like these:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyeloma.3 <- step(myeloma.1, direction = \"backward\", trace = 0)\nsummary(myeloma.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(time, vstatus == 1) ~ logbun + hgb, data = myeloma)\n\n  n= 65, number of events= 48 \n\n           coef exp(coef) se(coef)      z Pr(>|z|)   \nlogbun  1.71597   5.56209  0.61855  2.774  0.00553 **\nhgb    -0.11966   0.88722  0.05742 -2.084  0.03717 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\nlogbun    5.5621     0.1798    1.6547   18.6961\nhgb       0.8872     1.1271    0.7928    0.9929\n\nConcordance= 0.675  (se = 0.043 )\nLikelihood ratio test= 12.27  on 2 df,   p=0.002\nWald test            = 12.51  on 2 df,   p=0.002\nScore (logrank) test = 13.07  on 2 df,   p=0.001\n```\n\n\n:::\n:::\n\n\n\nThe same model as the one we found by brute force. You can change the\nvalue of `trace` to see the progress, but in this case it's not\nvery illuminating, since `<none>` and the variables we end up\nkeeping are always at the bottom of the list to remove.\n\n`step` is built on `add1` and `drop1`. In this\ncase, `drop1` is run repeatedly and the variable with lowest\nAIC is removed. We had all numeric variables in this one, but if our\nmodel had something categorical like `treatment` with, let's\nsay, 4 levels, `drop1` would contemplate dropping all four of\nthese in one shot, the same way it works with a categorical variable\nin a regression of any other kind.\n\n    \n\n$\\blacksquare$\n\n(g) There should be two explanatory variables left in your\nmodel. These are both numerical variables. Find their first and\nthird quartiles, any way you like.\n\n\nSolution\n\n\nThe most concise way is probably this:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(myeloma$logbun)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    0%    25%    50%    75%   100% \n0.7782 1.1461 1.3222 1.5682 2.2355 \n```\n\n\n:::\n\n```{.r .cell-code}\nquantile(myeloma$hgb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  0%  25%  50%  75% 100% \n 4.9  8.8 10.2 12.0 14.6 \n```\n\n\n:::\n:::\n\n     \n\nSo the quartiles are 1.15 and 1.57 for `logbun`, and 8.8 and\n12.0 for `hgb`.\n\nThere are (at least) three other ways to do it. This is the easiest:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(myeloma)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      time          vstatus           logbun            hgb      \n Min.   : 1.25   Min.   :0.0000   Min.   :0.7782   Min.   : 4.9  \n 1st Qu.: 7.00   1st Qu.:0.0000   1st Qu.:1.1461   1st Qu.: 8.8  \n Median :15.00   Median :1.0000   Median :1.3222   Median :10.2  \n Mean   :24.01   Mean   :0.7385   Mean   :1.3929   Mean   :10.2  \n 3rd Qu.:35.00   3rd Qu.:1.0000   3rd Qu.:1.5682   3rd Qu.:12.0  \n Max.   :92.00   Max.   :1.0000   Max.   :2.2355   Max.   :14.6  \n    platelet           age            logwbc           frac       \n Min.   :0.0000   Min.   :38.00   Min.   :3.362   Min.   :0.0000  \n 1st Qu.:1.0000   1st Qu.:51.00   1st Qu.:3.643   1st Qu.:1.0000  \n Median :1.0000   Median :60.00   Median :3.732   Median :1.0000  \n Mean   :0.8615   Mean   :60.15   Mean   :3.769   Mean   :0.7538  \n 3rd Qu.:1.0000   3rd Qu.:67.00   3rd Qu.:3.875   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :82.00   Max.   :4.954   Max.   :1.0000  \n     logpbm          protein           scalc      \n Min.   :0.4771   Min.   : 0.000   Min.   : 7.00  \n 1st Qu.:1.3617   1st Qu.: 0.000   1st Qu.: 9.00  \n Median :1.6232   Median : 1.000   Median :10.00  \n Mean   :1.5497   Mean   : 3.615   Mean   :10.12  \n 3rd Qu.:1.8451   3rd Qu.: 4.000   3rd Qu.:10.00  \n Max.   :2.0000   Max.   :27.000   Max.   :18.00  \n```\n\n\n:::\n:::\n\n \n\nfrom which you pick out the ones you need. Or, you `select` the\nones you need first:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyeloma %>% select(logbun, hgb) %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     logbun            hgb      \n Min.   :0.7782   Min.   : 4.9  \n 1st Qu.:1.1461   1st Qu.: 8.8  \n Median :1.3222   Median :10.2  \n Mean   :1.3929   Mean   :10.2  \n 3rd Qu.:1.5682   3rd Qu.:12.0  \n Max.   :2.2355   Max.   :14.6  \n```\n\n\n:::\n:::\n\n \n\nThe obvious `tidyverse` way is actually a bit\ninelegant, because you have to calculate two things for two variables:^[Because *summarize* will only allow you to have a single-number answer.] \n\n::: {.cell}\n\n```{.r .cell-code}\nmyeloma %>% summarize(\n  logbun.q1 = quantile(logbun, 0.25),\n  logbun.q3 = quantile(logbun, 0.75),\n  hgb.q1 = quantile(hgb, 0.25),\n  hgb.q3 = quantile(hgb, 0.75)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 4\n  logbun.q1 logbun.q3 hgb.q1 hgb.q3\n      <dbl>     <dbl>  <dbl>  <dbl>\n1      1.15      1.57    8.8     12\n```\n\n\n:::\n:::\n\nNext is the tidyverse-approved way to get both quartiles for both variables at once. Use `across` to select the variables to use, and then something with a squiggle and a dot to say \"do this on each of the columns selected in the `across`\". If you have a cleverer way to select those two columns without naming them, go for it. Read this in English as \"for each of the columns `logbun` and `hgb`, work out the first and third quantiles of it\", where the dot is read as \"it\". This works but is not the best way:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyeloma %>% \n  summarize(across(c(logbun, hgb), \n                   \\(x) quantile(x, c(0.25, 0.75))))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\ni Please use `reframe()` instead.\ni When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 2\n  logbun   hgb\n   <dbl> <dbl>\n1   1.15   8.8\n2   1.57  12  \n```\n\n\n:::\n:::\n\nThe warning says that `summarize` is designed for situations where the summary is a *single* number. (The people behind `summarize` have changed their mind on this; it used to work, indeed it still does work, but \"deprecated\" means \"one day it will stop working and our advice is to work out what to do now rather than later\".) Reading the warning carefully is the right way to figure out what to do. The `tidyverse` people have put a good deal of effort into making their messages readable and helpful, so the least we can do is to repay their hard work. \n\nThe message says to use `reframe` rather than `summarize`, so let's try that:\n\n::: {.cell}\n\n```{.r .cell-code}\nmyeloma %>% \n  reframe(across(c(logbun, hgb), \n                   \\(x) quantile(x, c(0.25, 0.75))))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 2\n  logbun   hgb\n   <dbl> <dbl>\n1   1.15   8.8\n2   1.57  12  \n```\n\n\n:::\n:::\n\n\nThis works without warnings. We have lost which quartile is which, but of course the lower one must be Q1 and the higher one Q3 for each variable.^[The way, as we  have seen elsewhere, is to use `tidy(quantile)` or `enframe(quantile)`, which  produce a two-column data frame with the percentiles shown.]\n    \n\n$\\blacksquare$\n\n(h) Create a data frame containing all possible combinations\nof the two quartiles for each of the two variables, and display the result.\n\n\nSolution\n\nThis is `datagrid`. My best model is the one I called `y.2` (I had to scroll back a ways to find it), so:\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- datagrid(model = myeloma.2, logbun = c(1.14561, 1.5682), hgb = c(8.8, 12.0))\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      time vstatus  logbun  hgb rowid\n1 24.00769       1 1.14561  8.8     1\n2 24.00769       1 1.14561 12.0     2\n3 24.00769       1 1.56820  8.8     3\n4 24.00769       1 1.56820 12.0     4\n```\n\n\n:::\n:::\n\n\nOr anything equivalent to that. \n\nThe place you have to get to in\nthe end is a data frame with columns called `logbun` and\n`hgb`, and the right four combinations of values. If you want\nto round the `logbun` values off more, for example to two\ndecimals, that's fine; it won't affect the graph that's coming up.\n    \nIn fact, for predictions, you also need some times to predict for. We'll use 10, 20, and 35, gluing those onto the end of the `datagrid`:\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- datagrid(model = myeloma.2, logbun = c(1.14561, 1.5682), \n                hgb = c(8.8, 12.0), time = c(10, 20, 35))\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   vstatus  logbun  hgb time rowid\n1        1 1.14561  8.8   10     1\n2        1 1.14561  8.8   20     2\n3        1 1.14561  8.8   35     3\n4        1 1.14561 12.0   10     4\n5        1 1.14561 12.0   20     5\n6        1 1.14561 12.0   35     6\n7        1 1.56820  8.8   10     7\n8        1 1.56820  8.8   20     8\n9        1 1.56820  8.8   35     9\n10       1 1.56820 12.0   10    10\n11       1 1.56820 12.0   20    11\n12       1 1.56820 12.0   35    12\n```\n\n\n:::\n:::\n\n\n$\\blacksquare$\n\n(i) Obtain predicted survival probabilities for each of the\ncombinations of variables you created above. \n\nSolution\n\nThis is `predictions` from `marginaleffects`:\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(myeloma.2, newdata = new, type = \"survival\")) %>% \n  select(logbun, hgb, time, estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    logbun  hgb time  estimate\n1  1.14561  8.8   10 0.8072949\n2  1.14561  8.8   20 0.5389476\n3  1.14561  8.8   35 0.4292788\n4  1.14561 12.0   10 0.8641883\n5  1.14561 12.0   20 0.6560706\n6  1.14561 12.0   35 0.5617943\n7  1.56820  8.8   10 0.6427128\n8  1.56820  8.8   20 0.2790169\n9  1.56820  8.8   35 0.1744171\n10 1.56820 12.0   10 0.7397640\n11 1.56820 12.0   20 0.4187878\n12 1.56820 12.0   35 0.3039940\n```\n\n\n:::\n:::\n\nDespite what it says in the original question, this is not too long to look at (the old way was). For example, increasing `hgb`  increases survival probability somewhat, if you compare the same `logbun` at the same time, and increasing `logbun` for the some `hgb` decreases survival probability by a bit more.\n\n\n$\\blacksquare$\n\n(j) Obtain a graph of the predicted survival curves for each\ncombination of your variables.\n\n\nSolution\n\nYou can do this in one shot or two, but it's `plot_predictions` either way.\n\nThe one-shot version is to put both `logbun` and `hgb` in at once (with `time` first, since the predictions depend on time which goes on the $x$-axis):\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(myeloma.2, condition = c(\"time\", \"logbun\", \"hgb\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-81-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe first thing in `condition` goes on the $x$-axis (time), the second thing is colour (the selected values of `logbun`), and the third thing is facets (the selected values of `hgb`).\n\nIf you don't like that, or don't fancy your chances of interpreting it (in a moment), do the two explanatory variables one at a time. First this:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(myeloma.2, condition = c(\"time\", \"logbun\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-82-1.pdf){fig-pos='H'}\n:::\n:::\n\nand then this:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(myeloma.2, condition = c(\"time\", \"hgb\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-83-1.pdf){fig-pos='H'}\n:::\n:::\n\nKeep the time first, to make sure it appears on the plot where it should. These two graphs leave you only one thing to compare (the colours, each time).\n\n\n\n\n$\\blacksquare$\n\n(k) Is it better to have high or low values for each of the\nvariables in your prediction? Explain briefly.\n\n\nSolution\n\n\nThe best survival curve is the top-right one in each case.\n\nOn the graph of `logbun`, this is the red curve, that goes with the *lowest* value of `logbun`.  So the lowest value on this variable is the best, and as `logbun` increases, the survival gets progressively worse. With `hgb`, it is the other way around: the lowest value is worst, and the highest value (pink curve) is the best.\n\nIf you prefer the one-shot graph with both explanatory variables on it:\n\n- to assess `logbun`, pick a facet, and see which curve is best: the red one, which goes with the *lowest* `logbun` value.\n- to assess `hgb`, cast your eye across the facets (along the first row and then the second) and see what is happening to the survival curves as you move from one facet to the next. These ones are moving up in their facet, so survival is improving as `hgb` increases (those numbers on the top of the facets are values of `hgb`).\n\nAnother way to think about this is to mentally compare all of those survival curves and ask which is the best out of all of them: the one for `logbun` 0.7782 (the smallest value), and `hgb` 14.6 (the largest value).\n\nExtra 1: the conclusions from the graphs are the same as those from the `summary` table (as they should be). The coefficient of `logbun` is 1.72, positive, so that a higher value is associated with a higher hazard of death (and thus a smaller value is better). On the other hand, the coefficient of `hgb`, -0.12, is negative, so that a higher value *decreases* the hazard of death, and is thus better. You might find it confusing that things are this way around; the story is that you have to get used to it, and one way to do that is to phrase it in terms of hazard of death (or whatever the event is), and then decide whether that is good or bad.\n\nExtra 2: for `ggplot` enthusiasts among you: when you have three variables in a `plot_predictions`, the plot uses `facet_wrap`. When you have *four* of them (as one of the plots in one of the other problems does), it uses `facet_grid`, which is the way to handle *two* extra categorical or made-categorical variables. In this case, the quantitative variables `hgb` and `logbun` have been broken up into five distinct values, although they could take any of the values in between; they have been made categorical to enable us to draw a graph.\n\nExtra 3: the model we fitted here assumes that each variable has a one-directional effect: that is, survival is better the higher the variable's value gets (`hgb`) or the lower it gets (`logbun`), but it can't change direction. You might imagine an explanatory variable that has a \"best\" value: survival improves as the value increases, until it reaches the best value, and then, as it increases further, survival gets worse again. To model something like that, you might add a squared term in the variable and see whether that is significant; if it is, the relationship is curved rather than linear. An example of a variable for which that might be true is blood pressure; it is dangerous to have a blood pressure that is too high (\"hypertension\") or one that is too low (\"hypotension\").\n\n\nExtra 4: Things that are tests, like `logbun`, are often set up so that\na high value is the abnormal one (so that an abnormal one will be easy\nto spot). Things that are measurements, like `hgb`, might have\nan ideal range, but the better value could be high or low, depending\non what is being measured.\n    \n$\\blacksquare$\n\n\n\n\n\n\n##  Ovarian cancer\n\n\n R's `survival` package contains several data\nsets. One of these is called `ovarian`; it comes from a study\nof 26 ovarian cancer patients. The major purpose of this study was to\ncompare the effects of two treatments on survival time.\n\n\n\n(a) Obtain and display (all of) the data set. This is as simple as\nloading the package and typing the data set's name.\n\nSolution\n\n\nThus. You may need to start with `library(survival)`:\n\n::: {.cell}\n\n```{.r .cell-code}\novarian\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   futime fustat     age resid.ds rx ecog.ps\n1      59      1 72.3315        2  1       1\n2     115      1 74.4932        2  1       1\n3     156      1 66.4658        2  1       2\n4     421      0 53.3644        2  2       1\n5     431      1 50.3397        2  1       1\n6     448      0 56.4301        1  1       2\n7     464      1 56.9370        2  2       2\n8     475      1 59.8548        2  2       2\n9     477      0 64.1753        2  1       1\n10    563      1 55.1781        1  2       2\n11    638      1 56.7562        1  1       2\n12    744      0 50.1096        1  2       1\n13    769      0 59.6301        2  2       2\n14    770      0 57.0521        2  2       1\n15    803      0 39.2712        1  1       1\n16    855      0 43.1233        1  1       2\n17   1040      0 38.8932        2  1       2\n18   1106      0 44.6000        1  1       1\n19   1129      0 53.9068        1  2       1\n20   1206      0 44.2055        2  2       1\n21   1227      0 59.5890        1  2       2\n22    268      1 74.5041        2  1       2\n23    329      1 43.1370        2  1       1\n24    353      1 63.2192        1  2       2\n25    365      1 64.4247        2  2       1\n26    377      0 58.3096        1  2       1\n```\n\n\n:::\n:::\n\n \n\nThere are indeed 26 rows. This is a `data.frame` rather than a\n`tibble`, so you might see the whole thing, in case you were\nexpecting something like this:\n\n::: {.cell}\n\n```{.r .cell-code}\novarian %>% as_tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 26 x 6\n   futime fustat   age resid.ds    rx ecog.ps\n    <dbl>  <dbl> <dbl>    <dbl> <dbl>   <dbl>\n 1     59      1  72.3        2     1       1\n 2    115      1  74.5        2     1       1\n 3    156      1  66.5        2     1       2\n 4    421      0  53.4        2     2       1\n 5    431      1  50.3        2     1       1\n 6    448      0  56.4        1     1       2\n 7    464      1  56.9        2     2       2\n 8    475      1  59.9        2     2       2\n 9    477      0  64.2        2     1       1\n10    563      1  55.2        1     2       2\n# i 16 more rows\n```\n\n\n:::\n:::\n\n \n\nwhich doesn't change anything in `ovarian`, but changes what\nkind of thing it is (and thus how it displays). Usually when you read\nsomething in from a file, you use something like `read_delim`\nthat makes a `tibble`, but this one wasn't read in from a\nfile. It was stored in the package as an old-fashioned\n`data.frame`, and so that's how it stays.\n\n\n\n\n$\\blacksquare$\n\n(b) The columns of interest to us are:\n\n\n* `futime`: the time for which a patient was followed-up:\nthe number of days until either they died or the study ended (or\nthey withdrew from the study for some other reason).\n\n* `fustat`: follow-up status: 1 if the patient died of\novarian cancer, 0 if they were still alive when the study ended.\n\n* `age`: of patient, at diagnosis, in years\n\n* `rx`: treatment, numbered 1 or 2, but really labels for\nthe two treatments.\n\nCreate and display a suitable response variable `y` for a Cox\nproportional-hazards model.\n\nSolution\n\nYou'll notice that `rx` (treatment) is a number, but it really should be categorical, so let's first replace it with the categorical version of itself so that we don't get in trouble later:\n\n::: {.cell}\n\n```{.r .cell-code}\novarian %>% \n  mutate(rx = factor(rx)) -> ovarian\novarian\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   futime fustat     age resid.ds rx ecog.ps\n1      59      1 72.3315        2  1       1\n2     115      1 74.4932        2  1       1\n3     156      1 66.4658        2  1       2\n4     421      0 53.3644        2  2       1\n5     431      1 50.3397        2  1       1\n6     448      0 56.4301        1  1       2\n7     464      1 56.9370        2  2       2\n8     475      1 59.8548        2  2       2\n9     477      0 64.1753        2  1       1\n10    563      1 55.1781        1  2       2\n11    638      1 56.7562        1  1       2\n12    744      0 50.1096        1  2       1\n13    769      0 59.6301        2  2       2\n14    770      0 57.0521        2  2       1\n15    803      0 39.2712        1  1       1\n16    855      0 43.1233        1  1       2\n17   1040      0 38.8932        2  1       2\n18   1106      0 44.6000        1  1       1\n19   1129      0 53.9068        1  2       1\n20   1206      0 44.2055        2  2       1\n21   1227      0 59.5890        1  2       2\n22    268      1 74.5041        2  1       2\n23    329      1 43.1370        2  1       1\n24    353      1 63.2192        1  2       2\n25    365      1 64.4247        2  2       1\n26    377      0 58.3096        1  2       1\n```\n\n\n:::\n:::\n\n\nNow, the idea is to use the appropriate one(s) of these columns in\n`Surv`. Remember that the response variable in a survival\nmodel encodes two things: the survival time, and whether or not\nthe event (here death) actually happened to that patient or not.\nI always forget whether the second thing in `Surv` has to\nbe 1 or 0 if the event happened. The help says that it needs to be\n1 or `TRUE` if the event (death) happened, which is what\n`fustat` is, so we can use it as it is:\n\n::: {.cell}\n\n```{.r .cell-code}\ny <- with(ovarian, Surv(futime, fustat))\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]   59   115   156   421+  431   448+  464   475   477+  563   638   744+\n[13]  769+  770+  803+  855+ 1040+ 1106+ 1129+ 1206+ 1227+  268   329   353 \n[25]  365   377+\n```\n\n\n:::\n:::\n\n     \n\nThis creates a separate variable `y` outside of any data\nframe. This is fine, because when we actually fit the model, we repeat the `Surv` rather than using the `y` we just made, which was only for practice.\n\n\n$\\blacksquare$\n\n(c) In the display of your response variable, some values are\nmarked with a `+`. Why is that? Explain briefly. (If you use\na technical term, you should explain what it means.)\n\nSolution\n\n\n\nThese are the censored observations. You can say this, but you\nalso need to say what that means (this is the \"technical term\"\nreferred to in the question). The observations with a `+`\nare individuals who were never observed to die, or who were still\nalive at the end of the study.\n\nI want you to demonstrate that you know what censored\n*means*, not just that you know when you have a censored\nobservation.\n\nExtra: in a study like this, patients are typically \"recruited\"\ninto the study at various different times. Patients who happened\nto be in the study near the beginning and who survived can have a\nlarge (censored) value of `y` (like those values over 1000\ndays). But a patient might join the study later on; if they\nsurvive, they might produce a censored observation with a small\nsurvival time, like the last value 377. I'm sure the doctor would\nhave liked to follow them for longer, but the funding ran out, and\nthe doctor had a paper to write. (There is *some* information\nin these small censored values, but not much, because most of the\npatients, even the ones who eventually died, survived for longer\nthan 377 days.)\n\nThe other thing that might have happened is that a patient with\nthe 377-censored value died *from something else* unrelated\nto ovarian cancer. The study is only concerned with deaths from\novarian cancer, so such a patient is treated as censored at their\ndeath time. After this point we cannot assess how long\nthis patient survived *ovarian cancer*.\n\n$\\blacksquare$\n\n(d) Fit a Cox proportional-hazards model for predicting\nsurvival time from age and treatment. Note that the numeric values\nfor treatment make sense only as labels for the two treatments, so\nin your model formula make treatment into a factor. Display the\nresults. \n\nSolution\n\n\nThe hint suggests something like this:\n\n::: {.cell}\n\n```{.r .cell-code}\ntime.1 <- coxph(Surv(futime, fustat) ~ age + rx, data = ovarian)\nsummary(time.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(futime, fustat) ~ age + rx, data = ovarian)\n\n  n= 26, number of events= 12 \n\n        coef exp(coef) se(coef)      z Pr(>|z|)   \nage  0.14733   1.15873  0.04615  3.193  0.00141 **\nrx2 -0.80397   0.44755  0.63205 -1.272  0.20337   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    exp(coef) exp(-coef) lower .95 upper .95\nage    1.1587      0.863    1.0585     1.268\nrx2    0.4475      2.234    0.1297     1.545\n\nConcordance= 0.798  (se = 0.076 )\nLikelihood ratio test= 15.89  on 2 df,   p=4e-04\nWald test            = 13.47  on 2 df,   p=0.001\nScore (logrank) test = 18.56  on 2 df,   p=9e-05\n```\n\n\n:::\n:::\n\nBecause I made `rx` categorical earlier, I have nothing extra to do here. If you didn't, you might need `factor(rx)` here and below.\n\n\n$\\blacksquare$\n\n(e) Is there a significant difference between the treatments in\nterms of their effects on survival (from ovarian cancer)?\n\nSolution\n\n\n\nLook at the P-value for my `rx2`, 0.203. This is\nnot small, so there is no evidence of a difference between\ntreatments. \n\nI got away with something here, which is that treatment is actually categorical, so I should have tested it with `drop1`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(time.1, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSingle term deletions\n\nModel:\nSurv(futime, fustat) ~ age + rx\n       Df    AIC     LRT  Pr(>Chi)    \n<none>    58.084                      \nage     1 70.918 14.8346 0.0001174 ***\nrx      1 57.676  1.5925 0.2069698    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\nThe reason it didn't matter here is that there were only two treatments, and therefore that testing the coefficient was equivalent to testing the whole categorical variable (a one degree of freedom test either way). If there had been three or more treatments, then the `summary` table would have compared each one with the baseline treatment, which is not the same as testing for *any* differences among treatments.\n\nThe P-values are very close but not identical because `drop1` is using a so-called likelihood ratio test, and `summary` is using a Wald test, and they are different. In a regular regression, these two tests are identical, but once you get away from regression, they are only \"asymptotically equivalent\", meaning that they would be identical if you had an infinitely large sample size, but for actual real sample sizes, they can be a bit different. Usually though, as here, they are not different enough to change your conclusion about significance.\n\nExtra: the reason for the odd label is that we have turned\ntreatment into a categorical variable; treatment 1 is used as the\nbaseline, and the negative slope says that the \"hazard of death\"\nis lower for treatment 2 than for treatment 1: that is, people\nsurvive longer on treatment 2, but the difference is not big\nenough to be significant (we also have a smallish sample size).\n\nSince there are only two treatments, it would in fact have been OK\nto leave them as numbers (with two numbers one unit apart, the\nslope would have been the same size as here), but I think it's a\ngood idea to treat categorical variables as categorical. My own habit\nis to use letters or something non-numerical to distinguish\ncategories. I might have used `t1` and `t2` in this\ncase, or the names of the different treatments.\n\n\n$\\blacksquare$\n\n(f) Is there a significant effect of age? If there is, describe\nthe effect that age has on survival.\n\nSolution\n\n\n\nThe P-value for age is 0.0014, small, so age definitely has a\nsignificant effect on survival. As to what kind of effect, look at\nthe slope coefficient, 0.15, positive, which means that increased\nage-at-diagnosis goes with an *increased* hazard of death, or\nthat older patients do not survive as long.\n\nI would like you to get to the plain-English words at the\nend. Part of your job as a statistician is explaining what you got\nto people who are doctors, managers, etc., who won't\nunderstand the terminology. \n\nThus, when this was on an assignment, one mark for assessing significance\nvia P-value, one for looking at the slope coefficient and noting\nthat it is positive, and one for getting to \"older patients do     not survive as long\", or \n\"older patients have a larger chance of dying sooner\". \n(Strictly, this is also \"all else equal\" as usual,\nsince survival time might also have depended on treatment, but the\npoint of this question is for you to get to \"older patients do not survive as long\".) \n\n(The interpretation of the slope may seem backwards: a positive\nslope means a *shorter* survival time for a larger age. This\nis why I talk about \"hazard of death\", since that guides us to\nthe correct interpretation.)\n\nExtra: I was curious about what would happen if I just included\n`rx` in the model:\n\n::: {.cell}\n\n```{.r .cell-code}\ntime.2 <- update(time.1, . ~ . - age)\nsummary(time.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(futime, fustat) ~ rx, data = ovarian)\n\n  n= 26, number of events= 12 \n\n       coef exp(coef) se(coef)      z Pr(>|z|)\nrx2 -0.5964    0.5508   0.5870 -1.016     0.31\n\n    exp(coef) exp(-coef) lower .95 upper .95\nrx2    0.5508      1.816    0.1743      1.74\n\nConcordance= 0.608  (se = 0.07 )\nLikelihood ratio test= 1.05  on 1 df,   p=0.3\nWald test            = 1.03  on 1 df,   p=0.3\nScore (logrank) test = 1.06  on 1 df,   p=0.3\n```\n\n\n:::\n:::\n\n     \n\nStill not significant, but this model is a *lot worse* because I\ntook out the significant `age`. What this is doing is mixing up\nall the people of different ages (and we know that age has an effect\non survival) and trying (and failing) to discern an effect of\ntreatment. \n\nWe could have been badly misled by this model if one of the treatments\nhad predominantly older patients. We know that older patients have\nworse survival, so the treatment with older patients would have looked\nworse, even if it actually wasn't. The model `time.1` which\ncontained `age` properly adjusted for the effect of age, so\nthat was the best way to see whether there was a difference between\ntreatments. \n\nWhat you often see early on in a paper on this kind of stuff is a\ngraph showing that the treatment groups are similar in terms of\nimportant things like `age`. Here, that could be a boxplot:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ovarian, aes(x = rx, y = age)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/ovarian-9-1.pdf){fig-pos='H'}\n:::\n:::\n\n 0.14733\n\nYou might need to do `factor(rx)` because `geom_boxplot`\nneeds a genuine categorical variable, not just a numerical variable\nmasquerading as one. If you just leave it as the numerical `rx`, as I\ndiscovered, you get *one* boxplot of all the ages together\nregardless of treatment. The key, for you as user of software, is not\n(necessarily) to get it right the first time, but to know what to do\nto fix up the errors you will inevitably get. If you have worked\nthrough the boxplot examples in C32 and D29, you will have enough\nexperience to remember that a boxplot has to have a categorical `x`\n(text will do, but definitely not numbers). This is why I give you so\nmany things to work through: so that you gain the experience to know\nhow to fix up problems.\n\nTreatment 1 has a larger spread of ages and treatment 2 has a low\noutlier age, but the median ages are very similar.\n\n$\\blacksquare$\n\n(g) Make a martingale residual plot for this model. Do you see\nany problems? Explain briefly.\n\nSolution\n\n\nThe plot is just the same idea as the one in the notes:\n\n::: {.cell}\n\n```{.r .cell-code}\ntime.1 %>% augment(ovarian) %>% \n  ggplot(aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/ovarian-10-1.pdf){fig-pos='H'}\n:::\n:::\n\n     \n\nMake a call about whether you think the smooth trend deviates too much\nfrom the red dotted line going across at zero. Martingale residuals\ncan get very negative (and that is OK), so that residual of $-2$ is\nnot a problem, and this is pulling the smooth trend down a bit (it's\nthe reason for the dip on the right side of the smooth trend). So I'd\ncall this OK, but you can make whatever call you like as long as it's\nsupported by what you see here.\n\nI observe that the obvious fixable thing is where you have a curve\nhere, one that looks like a parabola (at which point you add squared\nterms to your explanatory variables and see if that helps, as for\n`bmi` in one of the other problems). This one\nis too wiggly to be a parabola (it bends *twice*), and so is more\nlike a cubic than anything.\n\nThe other thing you can note is that the grey envelope is \n\"not significantly different from zero\", since 0 is clearly within the grey\nenvelope all the way across.\n\n\n\n$\\blacksquare$\n\n(h) Find the quartiles of `age`, and make a data frame\ncontaining all combinations of those two ages and the two\ntreatments. Display what you have. (Feel free to copy the values by\nhand, rather than trying to save them and use them.)\n\n\nSolution\n\n\nI imagine you can guess what we are going to be doing with these:\npredictions, so we'll call the data frame `new` when we get\nthere. \n\nQuartiles first:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(ovarian$age)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      0%      25%      50%      75%     100% \n38.89320 50.16712 56.84660 62.37810 74.50410 \n```\n\n\n:::\n:::\n\n   \n\nor, if you prefer,\n\n::: {.cell}\n\n```{.r .cell-code}\novarian %>%\n  summarize(\n    q1 = quantile(age, 0.25),\n    q3 = quantile(age, 0.75)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        q1      q3\n1 50.16712 62.3781\n```\n\n\n:::\n:::\n\n \n\nThe quartiles are 50.17 and 62.38 (rounding slightly).\n\nEither way is good. \n\nThen follow my standard procedure (or one of your own devising),\nremembering that \"treatment\" is called `rx` here:\n\n::: {.cell}\n\n```{.r .cell-code}\nages <- c(50.17, 62.38)\nrxs <- c(\"1\", \"2\")\nnew <- datagrid(model = time.1, age = ages, rx = rxs)\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    futime fustat   age rx rowid\n1 599.5385      0 50.17  1     1\n2 599.5385      0 50.17  2     2\n3 599.5385      0 62.38  1     3\n4 599.5385      0 62.38  2     4\n```\n\n\n:::\n:::\n\nThe values 1 and 2 for `rx` should be in quotes (they are levels of a categorical variable), but it seems to work all right if they are not (this might be `datagrid` being clever on our behalf).\n\nExtra: recall that actual predictions of survival probabilities also depend on time, which is in `futime` here. Let's pick about three times:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(ovarian$futime)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     0%     25%     50%     75%    100% \n  59.00  368.00  476.00  794.75 1227.00 \n```\n\n\n:::\n:::\n\n so, say, 350, 500, and 800 (rounded-off median and quartiles):\n \n::: {.cell}\n\n```{.r .cell-code}\nages <- c(50.17, 62.38)\nrxs <- c(\"1\", \"2\")\nfutimes <- c(350, 500, 800)\nnew <- datagrid(model = time.1, age = ages, rx = rxs, futime = futimes)\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   fustat   age rx futime rowid\n1       0 50.17  1    350     1\n2       0 50.17  1    500     2\n3       0 50.17  1    800     3\n4       0 50.17  2    350     4\n5       0 50.17  2    500     5\n6       0 50.17  2    800     6\n7       0 62.38  1    350     7\n8       0 62.38  1    500     8\n9       0 62.38  1    800     9\n10      0 62.38  2    350    10\n11      0 62.38  2    500    11\n12      0 62.38  2    800    12\n```\n\n\n:::\n:::\n \n\n\n$\\blacksquare$\n\n(i) Obtain predicted survival probabilities for each of your\nage-treatment combinations, for each of a variety of survival\ntimes. (This is only one thing, despite it sounding like a lot.)\n\n\nSolution\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(time.1, newdata = new, type = \"survival\")) %>% \n  select(age, rx, futime, estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     age rx futime   estimate\n1  50.17  1    350 0.93188906\n2  50.17  1    500 0.76754283\n3  50.17  1    800 0.63449640\n4  50.17  2    350 0.96892249\n5  50.17  2    500 0.88833748\n6  50.17  2    800 0.81578873\n7  62.38  1    350 0.65294390\n8  62.38  1    500 0.20216448\n9  62.38  1    800 0.06399272\n10 62.38  2    350 0.82631986\n11 62.38  2    500 0.48895633\n12 62.38  2    800 0.29220453\n```\n\n\n:::\n:::\n\n\nTo eyeball these: the effect of treatment seems to be smallish (compare rows 1 and 4, or 2 and 5, of what you see here), but the effect of age is more substantial (compare rows 1 and 7, with the same treatment but different ages, or rows 2 and 8). This matches up to what we found out about significance earlier.\n\n$\\blacksquare$\n\n(j) Draw a plot that compares the survival probabilities at the\ndifferent times.\n\n\nSolution\n\nOne plot per explanatory variable might be easier to interpret:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(time.1, condition = c(\"futime\", \"age\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-111-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nand\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(time.1, condition = c(\"futime\", \"rx\"), type = \"survival\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-112-1.pdf){fig-pos='H'}\n:::\n:::\n\nOr you could put both age and treatment on one plot. Treatment is categorical, so this might fit better on facets (ie. as the last thing in `condition`):\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(time.1, condition = c(\"futime\", \"age\", \"rx\"), type = \"survival\")\n```\n\n::: {.cell-output-display}\n![](survival-analysis_files/figure-pdf/unnamed-chunk-113-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n$\\blacksquare$\n\n(k) According to your plot(s), how would you describe the effects of\ntreatment and of age?\n\t\n\nSolution\n\nThe best survival curve is up and to the right (if we are trying to avoid an unfavourable event such as death, here). \n\n- On the plot for age, the best age is the youngest one (38.9 years old on the graph: it picked some ages for us). The envelopes for ages seem to be distinct, for the most part, so that the effect of age appears to be a real one.\n- On the plot for treatment, treatment 2 appears to be better than treatment 1, but the envelopes are indistinguishable, which is consistent with the treatment difference not being significant.\n- On the two-facet plot with both explanatory variables, the age effect is clear, with the youngest age at the top and the oldest at the bottom (so being younger is associated with better survival) in each facet. To assess the treatment effect, compare the patterns in the left and right facet: the story is very much the same, so treatment doesn't make much difference to survival.\n\nExtra: recall the output from the Cox model:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(time.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\ncoxph(formula = Surv(futime, fustat) ~ age + rx, data = ovarian)\n\n  n= 26, number of events= 12 \n\n        coef exp(coef) se(coef)      z Pr(>|z|)   \nage  0.14733   1.15873  0.04615  3.193  0.00141 **\nrx2 -0.80397   0.44755  0.63205 -1.272  0.20337   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    exp(coef) exp(-coef) lower .95 upper .95\nage    1.1587      0.863    1.0585     1.268\nrx2    0.4475      2.234    0.1297     1.545\n\nConcordance= 0.798  (se = 0.076 )\nLikelihood ratio test= 15.89  on 2 df,   p=4e-04\nWald test            = 13.47  on 2 df,   p=0.001\nScore (logrank) test = 18.56  on 2 df,   p=9e-05\n```\n\n\n:::\n:::\n\n \n\nThe slope coefficient for treatment 2 (as compared to the baseline\ntreatment 1) was $-0.83097$, *negative*, which meant that patients on\ntreatment 2 had a *lower* hazard of death than patients on\ntreatment 1: that is, that treatment 2 was better for survival than\ntreatment 1. That is what the plot said also (and the relatively small\ndifference is consistent with that difference not being significant). \n\n$\\blacksquare$\n\n",
    "supporting": [
      "survival-analysis_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}