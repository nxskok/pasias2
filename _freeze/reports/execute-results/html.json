{
  "hash": "a17dea3e1662fc75d4015a4e11041e1a",
  "result": {
    "markdown": "# Writing reports\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Atomic weight of carbon\n\n\n The atomic weight of the chemical element\ncarbon is 12. Two methods of measuring the atomic weight of samples of\ncarbon were compared. The results are shown in\n[link](http://ritsokiguess.site/datafiles/carbon.txt). The methods\nare labelled 1 and 2.  The first task is to find out whether the two\nmethods have different \"typical\" measures (mean or median, as\nappropriate) of the atomic weight of carbon.\n\nFor this question, compose a report in R Markdown.  (R Markdown is\nwhat you use in an R Notebook, but you can also have a separate R\nMarkdown document from which you can produce HTML, Word etc. output.)\nSee part (a) for how to get this started.\n\nYour report should\nread like an actual report, not just the answers to some questions\nthat I set you. To help with that, write some text that links the\nparts of the report together smoothly, so that it reads as a coherent\nwhole. The grader had 3 discretionary marks to award for the overall\nquality of your writing. The scale for this was:\n\n\n\n* 3 points: excellent writing. The report flows smoothly, is easy\nto read, and contains everything it should (and nothing it\nshouldn't).\n\n* 2 points: satisfactory writing. Not the easiest to read, but\nsays what it should, and it looks at least somewhat like a report\nrather than a string of answers to questions.\n\n* 1 point: writing that is hard to read or to understand. If you\nget this (or 0), you should consider what you need to do to improve\nwhen you write your project.\n\n* 0 points: you answered the questions, but you did almost nothing\nto make it read like a report.\n\n\n\n(a) Create a new R Markdown document. To do this, in R Studio, select File,\nNew File, R Markdown. Type the report title and your name in the\nboxes, and leave the output on the default HTML. Click OK. \n\n\n(b) Write an introduction that explains the purpose of this\nstudy and the data collected in your own words.\n\n\n\n(c) Begin an appropriately-titled new section in your report,\nread the data into R and display the results.\n\n\n\n(d) Make an appropriate plot to compare the measurements\nobtained by the two methods. You might need to do something about\nthe two methods being given as numbers even though they are really\nonly identifiers. (If you do, your report ought to say what you did\nand why.)\n\n\n\n(e) Comment briefly on what you see in your plot.\n\n\n\n(f) Carry out the most appropriate $t$-test. (You might like to\nbegin another new section in your report here.)\n\n\n\n(g) Do the most appropriate test you know that does not assume\nnormally-distributed data.\n\n\n\n(h) Discuss the results of your tests and what they say about\nthe two methods for measuring the atomic weight of carbon. If it\nseems appropriate, put the discussion into a section called\nConclusions. \n\n\n\n\n\n\n\n##  Sparrowhawks\n\n(This is a report-writing question, but it also uses some regression techniques from later in the course.)\n\n One of nature's patterns is the relationship\nbetween the percentage of adult birds in a colony that return from the\nprevious year, and the number of new adults that join the colony. Data\nfor 13 colonies of sparrowhawks can be found at\n[link](http://ritsokiguess.site/datafiles/sparrowhawk.txt). The\ncolumns are the percentage of adults returning from the previous year,\nand the number of new adults that join the colony.\n\n\n\n(a) Create a new R Markdown report, give it a suitable title, and\nask for HTML output. Answer the questions that follow in your\nreport. At any stage, you can Knit HTML\nto see how the report looks so far.\n\n\n\n(b) Read in the data and display the  first few values.  Add some text saying how many rows of data\nthere are.\n\n\n\n(c) Create a new section entitled \"Exploratory analysis\", and\ncreate a scatterplot for predicting number of new adults from the\npercentage of returning adults.  Describe what you see, adding some\nsuitable text to your report.\n\n\n\n(d) Obtain the correlation between the two variables. Is this\nconsistent with the scatterplot? Explain briefly. (The R function\nyou need is `cor`. You can feed it a data frame.)\n\n\n\n(e) Obtain the regression line for predicting the number of new\nadults from the percentage of returning adults.\n\n\n\n(f) What are the intercept and slope of your regression line? Is\nthe slope significant? What does that mean, in the context of the data?\n\n\n\n(g) Create a scatterplot of the data with the regression line on it.\n\n\n\n(h) For short-lived birds, the association between these two\nvariables is positive: changes in weather and food supply cause the\npopulations of new and returning birds to increase together. For\nlong-lived territorial birds, however, the association is negative\nbecause returning birds claim their territories in the colony and do\nnot leave room for new recruits. Which type of species is the\nsparrowhawk? Add a short Conclusions section to your report with\ndiscussion of this issue.\n\n\n\n\n\n\n\n\n## Learning to code\n\n A programming course, Comp Sci 101, can be taken either in-person, by attending a class at fixed days and times, or online, by doing sessions that can be taken at times the student chooses. The course coordinator wants to know whether students taking the course in these two different ways learn a different amount, as measured by their scores on the final exam for the course. This example comes from the before-times, so the final exam was taken in person by all students. The final exam was out of 45 marks. A total of 18 students took part in the study. Each student was allowed to choose the section they preferred. The data are in  [http://ritsokiguess.site/datafiles/proggo.csv](http://ritsokiguess.site/datafiles/proggo.csv).\n \nWrite a report of a complete and appropriate analysis of these data. Your report should include a description of the data in your own words, any necessary pre-processing steps, appropriate graphs, statistical analysis, assessment of assumptions for your preferred analysis, and a statement of conclusions. Imagine that your report will be read by the department Chair, who does not know about this study, and who still remembers some of their first-year Statistics course.\n\n(My example report is in a later chapter, the one called Learning to Code.)\n\n\n\n\n## Treating dandruff\n\n According to the [Mayo Clinic](https://www.mayoclinic.org/diseases-conditions/dandruff/symptoms-causes/syc-20353850), dandruff is \"a common condition that causes the skin on the scalp to flake. It isn't contagious or serious. But it can be embarrassing and difficult to treat.\" Shampoos often claim to be effective in treating dandruff. In a study, four shampoos were compared:\n\n- `PyrI`: 1% pyrithione zinc shampoo\n- `PyrII`: the same as `PyrI` but with instructions to shampoo two times at each wash. The labels for these are `Pyr` with a Roman numeral I or II attached.\n- `Keto`: 2% ketoconazole shampoo\n- `Placebo`: a placebo shampoo\n\nEach subject was randomly assigned to a shampoo. After six weeks of treatment, eight sections of the scalp were examined for each subject. Each section of the scalp was given a score that measured the amount of flaking on a scale of 0-10, less flaking being better. The response variable, called `Flaking`, was the sum of these eight scores, and is a whole number for each subject. \n\nThe data are in [http://ritsokiguess.site/datafiles/dandruff.txt](http://ritsokiguess.site/datafiles/dandruff.txt), \nwith the data values separated by *tabs*.\n\n\n\nYour task is to write a report on your analysis of this data set, and to make a recommendation for the best shampoo(s) out of the four studied here. The target audience for your report is the principal investigator of the study described above, who knows a lot about shampoo, but not so much about statistics. (They took a course some time ago that covered the material you've seen in this course so far, at about the level of STAB22 or STA 220.)\nSome things you might want to consider, in no particular order (you need to think about where and if to include these things):\n\n- an Introduction, written in your own words as much as possible\n- a Conclusion that summarizes what you found\n- a suitable and complete piece of statistical inference\n- a numerical summary of the data\n- graph(s) of the data\n- an assessment of the assumptions of your analysis\n- citation of external sources\n- anything else that you can make the case for including\n\nIn R Markdown (the text of an R Notebook), you can use `##` to make a heading (you can experiment with more or fewer `#` symbols).\n\nYour aim is to produce a report, suitable for the intended audience, with all the important elements and no irrelevant ones, that is well-written and easy to follow. There is credit for good writing. For this report, you should include your code in with your report. (In a real report, you would probably show the output and not the code, but we are interested in your code here as well.)\n\n(My example report is in a later chapter.)\n\n\n\n\n\nMy solutions follow. The example reports on coding and treating dandruff are separate chapters.\n\n\n\n\n##  Atomic weight of carbon\n\n\n The atomic weight of the chemical element\ncarbon is 12. Two methods of measuring the atomic weight of samples of\ncarbon were compared. The results are shown in\n[link](http://ritsokiguess.site/datafiles/carbon.txt). The methods\nare labelled 1 and 2.  The first task is to find out whether the two\nmethods have different \"typical\" measures (mean or median, as\nappropriate) of the atomic weight of carbon.\n\nFor this question, compose a report in R Markdown.  (R Markdown is\nwhat you use in an R Notebook, but you can also have a separate R\nMarkdown document from which you can produce HTML, Word etc. output.)\nSee part (a) for how to get this started.\n\nYour report should\nread like an actual report, not just the answers to some questions\nthat I set you. To help with that, write some text that links the\nparts of the report together smoothly, so that it reads as a coherent\nwhole. The grader had 3 discretionary marks to award for the overall\nquality of your writing. The scale for this was:\n\n\n\n* 3 points: excellent writing. The report flows smoothly, is easy\nto read, and contains everything it should (and nothing it\nshouldn't).\n\n* 2 points: satisfactory writing. Not the easiest to read, but\nsays what it should, and it looks at least somewhat like a report\nrather than a string of answers to questions.\n\n* 1 point: writing that is hard to read or to understand. If you\nget this (or 0), you should consider what you need to do to improve\nwhen you write your project.\n\n* 0 points: you answered the questions, but you did almost nothing\nto make it read like a report.\n\n\n\n(a) Create a new R Markdown document. To do this, in R Studio, select File,\nNew File, R Markdown. Type the report title and your name in the\nboxes, and leave the output on the default HTML. Click OK. \n\nSolution\n\n\nYou'll\nsee the title and your name in a section at the top of the document,\nand below that you'll see a template document, as you would for an R\nNotebook. The difference is that where you are used to seeing\nPreview, it now says \"knit\", but this has the same effect of\nproducing the formatted version of your report.    \n\n$\\blacksquare$\n\n(b) Write an introduction that explains the purpose of this\nstudy and the data collected in your own words.\n\n\nSolution\n\n\nSomething like this:\n\n> This study is intended to compare two different methods\n> (labelled 1 and 2) for measuring the atomic weight of carbon\n> (which is known in actual fact to be 12). Fifteen samples of\n> carbon were used; ten of these were assessed using method 1 and\n> the remaining five using method 2. The primary interest in this\n> particular study is to see whether there is a difference in the\n> mean or median atomic weight as measured by the two methods.\n\nBefore that, start a new section like this:\n`## Introduction`. \nAlso, get used to expressing your understanding in your words,\nnot mine. Using my words, in my courses, is likely to be\nworth very little.\n\n\n$\\blacksquare$\n\n(c) Begin an appropriately-titled new section in your report,\nread the data into R and display the results.\n\n\nSolution\n\n\nValues separated by spaces:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/carbon.txt\"\ncarbon <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 15 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\ndbl (2): method, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\ncarbon\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"method\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"weight\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"12.0129\"},{\"1\":\"1\",\"2\":\"12.0072\"},{\"1\":\"1\",\"2\":\"12.0064\"},{\"1\":\"1\",\"2\":\"12.0054\"},{\"1\":\"1\",\"2\":\"12.0016\"},{\"1\":\"1\",\"2\":\"11.9853\"},{\"1\":\"1\",\"2\":\"11.9949\"},{\"1\":\"1\",\"2\":\"11.9985\"},{\"1\":\"1\",\"2\":\"12.0077\"},{\"1\":\"1\",\"2\":\"12.0061\"},{\"1\":\"2\",\"2\":\"12.0318\"},{\"1\":\"2\",\"2\":\"12.0246\"},{\"1\":\"2\",\"2\":\"12.0069\"},{\"1\":\"2\",\"2\":\"12.0006\"},{\"1\":\"2\",\"2\":\"12.0075\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n     \n\nI would expect you to include, without being told to include it, some\ntext in your report indicating that you have sensible data: two\nmethods labelled 1 and 2 as promised, and a bunch^[It's  probably better in a report to use language a bit more formal than  *a bunch*. Something like *a number* would be better.] \nof atomic\nweights close to the nominal figure of 12.\n\n\n$\\blacksquare$\n\n(d) Make an appropriate plot to compare the measurements\nobtained by the two methods. You might need to do something about\nthe two methods being given as numbers even though they are really\nonly identifiers. (If you do, your report ought to say what you did\nand why.)\n\n\nSolution\n\n\nThe appropriate plot, with a categorical method and quantitative\nweight, is something like a boxplot. If you're not careful,\n`method` will get treated as a quantitative variable,\nwhich you don't want; the easiest way around that, for a boxplot\nat least, is to turn it into a factor like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(carbon, aes(x = factor(method), y = weight)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](reports_files/figure-html/seewerin-1.png){width=672}\n:::\n:::\n\n       \n\nIf you insist, you could do a faceted histogram (above and below, for preference):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(carbon, aes(x = weight)) + geom_histogram(bins = 5) +\n  facet_wrap(~method, ncol = 1)\n```\n\n::: {.cell-output-display}\n![](reports_files/figure-html/schuomarcher-1.png){width=672}\n:::\n:::\n\n \n\nThere are really not enough data values for a histogram to be of much\nhelp, so I don't like this as much. \n\nIf you are thinking ahead (we are going to be doing a $t$-test), then\nyou'll realize that normality is the kind of thing we're looking for,\nin which case normal quantile plots would be the thing. However, we\nmight have to be rather forgiving for method 2 since there are only 5\nobservations: \n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(carbon, aes(sample = weight)) +\n  stat_qq() + stat_qq_line() +\n  facet_wrap(~method)\n```\n\n::: {.cell-output-display}\n![](reports_files/figure-html/mulichs-1.png){width=672}\n:::\n:::\n\n \n\nI don't mind these coming out side by side, though I would rather have\nthem squarer.\n\nI would say, boxplots are the best, normal quantile plots are also\nacceptable, but expect to lose something for histograms because they\noffer only a rather crude comparison in this case.\n\n\n$\\blacksquare$\n\n(e) Comment briefly on what you see in your plot.\n\n\nSolution\n\n\nIn boxplots, if that's what you drew, there are several things\nthat deserve comment: the medians, the spreads and the\nshapes. The median for method 1 is a little bit lower than for\nmethod 2 (the means are probably more different, given the\nshapes of the boxes). The spread for method 2 is a lot\nbigger. (Looking forward, that suggests a Welch-Satterthwaite\nrather than a pooled test.) As for shape, the method 2\nmeasurements seem more or less symmetric (the whiskers are equal\nanyway, even if the position of the median in the box isn't),\nbut the method 1 measurements have a low outlier.\nThe histograms are hard to compare. Try to say something about\ncentre and spread and shape. I think the method 2 histogram has\na slightly higher centre and definitely bigger spread. On my\nhistogram for method 1, the distribution looks skewed left.\nIf you did normal quantile plots, say something sensible about\nnormality for each of the two methods. For method 1, I would say\nthe low value is an outlier and the rest of the values look\npretty straight. Up to you whether you think there is a curve on\nthe plot (which would indicate skewness, but then that highest\nvalue is too high: it would be bunched up with the other values\nbelow 12.01 if there were really skewness). \nFor method 2, it's really hard to say anything since there are\nonly five values. Given where the line goes, there isn't much\nyou can say to doubt normality.  Perhaps the best you can say\nhere is that in a sample of size 5, it's difficult to assess\nnormality at all.\n\n\n$\\blacksquare$\n\n(f) Carry out the most appropriate $t$-test. (You might like to\nbegin another new section in your report here.)\n\n\nSolution\n\n\nThis would be the Welch-Satterthwaite version of the two-sample\n$t$-test, since the two groups do appear to have different spreads:\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(weight ~ method, data = carbon)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  weight by method\nt = -1.817, df = 5.4808, p-value = 0.1238\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.027777288  0.004417288\nsample estimates:\nmean in group 1 mean in group 2 \n       12.00260        12.01428 \n```\n:::\n:::\n\n   \n\nImagining that this is a report that would go to your boss, you ought\nto defend your choice of the Welch-Satterthwaite test (as I did\nabove), and not just do the default $t$-test without comment.\n\nIf, in your discussion above, you thought the spreads were equal\nenough, then you should do the pooled $t$-test here, which goes like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(weight ~ method, data = carbon, var.equal = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  weight by method\nt = -2.1616, df = 13, p-value = 0.04989\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -2.335341e-02 -6.588810e-06\nsample estimates:\nmean in group 1 mean in group 2 \n       12.00260        12.01428 \n```\n:::\n:::\n\n \n\nThe point here is that you should do the right test based on your\nconclusion. Being consistent is the most important thing. (In this\ncase, note that the P-values are very different. We'll get to that\nshortly.)\n\nIf we were doing this in SAS, as we see later, we'd get a test at the\nbottom of the output that compares the two variances. I feel that it's\njust as good to eyeball the spreads and make a call about whether they\nare \"reasonably close\". Or even, to always do the\nWelch-Satterthwaite test on the basis that it is pretty good even if\nthe two populations have the same variance. (If this last point of\nview is one that you share, you ought to say something about that when\nyou do your $t$-test.)\n\nExtra: I guess this is a good place to say something about tests for comparing\nvariances, given that you might be pondering that. There are\nseveral that I can think of, that R can do, of which I mention two.\n\nThe first is the $F$-test for variances that you might have learned in\nB57 (that is the basis for the ANOVA $F$-test):\n\n::: {.cell}\n\n```{.r .cell-code}\nvar.test(weight ~ method, data = carbon)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tF test to compare two variances\n\ndata:  weight by method\nF = 0.35768, num df = 9, denom df = 4, p-value = 0.1845\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.04016811 1.68758230\nsample estimates:\nratio of variances \n         0.3576842 \n```\n:::\n:::\n\n \n\nThis, unfortunately, is rather dependent on the data in the two groups\nbeing approximately normal. Since we are talking variances rather than\nmeans, there is no Central Limit Theorem to rescue us for large\nsamples (quite aside from the fact that these samples are *not*\nlarge). Since the ANOVA $F$-test is based on the same theory, this is\nwhy normality is also more important in ANOVA than it is in a $t$-test.\n\nThe second is Levene's test. This doesn't depend on normality (at\nleast, not nearly so much), so I like it better in general:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nleveneTest(weight ~ factor(method), data = carbon)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"0.988736\",\"3\":\"0.3382002\",\"_rn_\":\"group\"},{\"1\":\"13\",\"2\":\"NA\",\"3\":\"NA\",\"_rn_\":\"\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nLevene's test takes a different approach: first the absolute\ndifferences from the group medians are calculated, and then an ANOVA\nis run on the absolute differences. If, say, one of the groups has a\nlarger spread than the other(s), its absolute differences from the\nmedian will tend to be bigger.^[The use of absolute  differences, and the median, downplays the influence of outliers. The assumption here is that the absolute differences from the medians are approximately normal, which seems a less big assumption than assuming the actual data are approximately normal.]\nAs for what we conclude here, well, neither of the variance tests show\nany significance at all, so from that point of view there is no\nevidence against using the pooled $t$-test. Having said that, the\nsamples are small, and so it would be difficult to *prove* that\nthe two methods have different variance, even if they actually\ndid.^[This is coming back to the *power* of something like Levene's test; the power of any test is not going to be very big if the sample sizes are small.]\n\nThings are never as clear-cut as you would like. In the end, it all\ncomes down to making a call and defending it.\n\n\n$\\blacksquare$\n\n(g) Do the most appropriate test you know that does not assume\nnormally-distributed data.\n\n\nSolution\n\n\nThat would be Mood's median test. Since I didn't say anything\nabout building it yourself, feel free to use `smmr`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(smmr)\nmedian_test(carbon, weight, method)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$table\n     above\ngroup above below\n    1     3     6\n    2     4     1\n\n$test\n       what      value\n1 statistic 2.80000000\n2        df 1.00000000\n3   P-value 0.09426431\n```\n:::\n:::\n\n \n\nAs an aside, if you have run into a non-parametric test such as\nMann-Whitney or Kruskal-Wallis that applies in this situation, be\ncareful about using it here, because they have additional assumptions\nthat you may not want to trust. Mann-Whitney started life as a test for\n\"equal distributions\".^[The test goes back to the 1940s.] This\nmeans that the null is equal location *and* equal spread, and if\nyou reject the null, one of those has failed. But here, we suspect that\nequal spread will fail, so that the Mann-Whitney test may end up\nrejecting *whether or not* the medians are different, so it won't\nanswer the question you want an answer to. Mood's median test doesn't\nhave that problem; all it's saying if the null is true is that the\nmedians are equal; the spreads could be anything at all.\n\nThe same kind of issues apply to the signed-rank test vs. the sign\ntest. In the case of the signed-rank test, the extra assumption is of\na symmetric distribution --- to my mind, if you don't believe\nnormality, you probably don't have much confidence in symmetry\neither. That's why I like the sign test and Mood's median test: in the\nsituation where you don't want to be dealing with assumptions, these\ntests don't make you worry about that.\n\nAnother comment that you don't need to make is based on the\nnot-quite-significance of the Mood test. The P-value is less than 0.10\nbut not less than 0.05, so it doesn't quite reach significance by the\nusual standard. But if you look up at the table, the frequencies seem\nrather unbalanced: 6 out of the remaining 9 weights in group 1 are\nbelow the overall median, but 4 out of 5 weights in group 2 are\nabove. This seems as if it ought to be significant, but bear in mind\nthat the sample sizes are small, and thus Mood's median test needs\n*very* unbalanced frequencies, which we don't quite have here.\n\n\n$\\blacksquare$\n\n(h) Discuss the results of your tests and what they say about\nthe two methods for measuring the atomic weight of carbon. If it\nseems appropriate, put the discussion into a section called\nConclusions. \n\n\nSolution\n\n\nBegin by pulling out the P-values for your preferred test(s) and\nsay what they mean. The P-value for the Welch-Satterthwaite\n$t$-test is 0.1238, which indicates no difference in mean atomic\nweights between the two methods. The Mood median test gives a\nsimilarly non-significant 0.0943, indicating no difference in\nthe *median* weights. If you think both tests are\nplausible, then give both P-values and do a compare-and-contrast\nwith them; if you think that one of the tests is clearly\npreferable, then say so (and why) and focus on that test's\nresults. \n\nIf you thought the pooled test was the right one, then you'll\nhave a bit more discussion to do, since its P-value is 0.0499,\nand at $\\alpha=0.05$ this test disagrees with the others. If you\nare comparing this test with the Mood test, you ought to make\nsome kind of reasoned recommendation about which test to\nbelieve. \n\nAs ever, be consistent in your reasoning.\n\nExtra: this dataset, where I found it, was actually being used to\nillustrate a case where the pooled and the Welch-Satterthwaite\ntests disagreed. The authors of the original paper that used\nthis dataset (a 1987 paper by Best and Rayner;^[Best, D. J., and J.  C. W. Rayner. “Welch’s Approximate Solution for the Behrens–Fisher Problem.” Technometrics 29, no. 2 (May 1, 1987): 205–10. doi:10.1080/00401706.1987.10488211. The data set is near the end.]\nthe data come from 1924!) point out that the\npooled $t$-test can be especially misleading when the smaller\nsample is also the one with the larger variance. This is what\nhappened here.\n\nIn the Best and Rayner paper, the Mood (or the Mann-Whitney) test was\nnot being considered, but I think it's good practice to draw a\npicture and make a call about which test is appropriate.\n   \n\n$\\blacksquare$\n\n\n\n\n\n##  Sparrowhawks\n\n(This is a report-writing question, but it also uses some regression techniques from later in the course.)\n\n One of nature's patterns is the relationship\nbetween the percentage of adult birds in a colony that return from the\nprevious year, and the number of new adults that join the colony. Data\nfor 13 colonies of sparrowhawks can be found at\n[link](http://ritsokiguess.site/datafiles/sparrowhawk.txt). The\ncolumns are the percentage of adults returning from the previous year,\nand the number of new adults that join the colony.\n\n\n\n(a) Create a new R Markdown report, give it a suitable title, and\nask for HTML output. Answer the questions that follow in your\nreport. At any stage, you can Knit HTML\nto see how the report looks so far.\n\n\nSolution\n\n(Note: this is the previous version of Quarto, called R Markdown. The two are fairly similar.)\n\n\nIn R Studio, select File, New File, R Markdown. Fill in the Title,\nAuthor and leave the Default Output Format at HTML. You'll see a\ntemplate report with the document info at the top. This is my document info:\n\n![](sh0.png)\n \nThis is known in the jargon as a \"YAML block\".^[YAML stands for *Yet Another Markup Language*, but we're only using it in this course as the top bit of an R Markdown document.]\nBelow that is the template R Markdown document, which you can delete now or later.\n\n$\\blacksquare$\n\n(b) Read in the data and display the  first few values.  Add some text saying how many rows of data\nthere are.\n\n\nSolution\n\n\nRead the data into a data frame. In your\nreport, add some text like \"we read in the data\", perhaps\nafter a section heading like \"The data\". Then add a *code chunk* \nby selecting Chunks and Insert Chunk, or by pressing\ncontrol-alt-I. So far you have something like this. \n\n![](sh1.png)\n\nInside the code chunk, that is, in the bit between the\nbacktick characters, put R code, just as you would type it at\nthe Console or put in an  R notebook. In this case, that would be\nthe following code, minus the message that comes out of\n`read_delim`: \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nmy_url <- \"http://ritsokiguess.site/datafiles/sparrowhawk.txt\"\nsparrowhawks <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 13 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\ndbl (2): returning, newadults\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nsparrowhawks\n```\n:::\n\n     \nFor you, it looks like this:\n\n\n![](sh2.png)\n\n\nWe don't know how many rows of data there are yet, so I've left a\n\"placeholder\" for it, when we figure it out.\nThe file is annoyingly called `sparrowhawk.txt`,\nsingular. Sorry about that. \nIf you knit this (click on \"Knit HTML\" next to the ball of wool,\nor press control-shift-K), it should run, and you'll see a viewer\npop up with the HTML output. Now you can see how many rows there\nare, and you can go back and edit the R Markdown and put in 13 in\nplace of the x's, and knit again.\nYou might be worried about how hard R is working with all this\nknitting. Don't worry about that. R can take it.\nMine looked like this:\n\n![](waluj.png)\n\nThere is a better way of adding values that come from the output,\nwhich I mention here in case you are interested (if you are not,\nfeel free to skip this). What you do is to make what is called an\n\"inline code chunk\". Where you want a number to appear in the\ntext, you have some R Markdown that looks like this:\n\n![](sh3.png)\n\nThe piece inside the backticks is the letter `r`, a space,\nand then one line of R code. The one line of code will be run, and\nall of the stuff within the backticks will be replaced in the\noutput by the result of running the R code, in this case the\nnumber 13. Typically, you are extracting a number from the data,\nlike the number of rows or a mean of something. If it's a decimal\nnumber, it will come out with a lot of decimal places unless you\nexplicitly `round` it.\nOK, let me try it: the data frame has 13\nrows altogether. I didn't type that number; it was calculated from\nthe data frame. Woo hoo!\n\n$\\blacksquare$\n\n(c) Create a new section entitled \"Exploratory analysis\", and\ncreate a scatterplot for predicting number of new adults from the\npercentage of returning adults.  Describe what you see, adding some\nsuitable text to your report.\n\n\nSolution\n\n\nThe R code you add should look like this, with the results shown\n(when you knit the report again):\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nggplot(sparrowhawks, aes(x = returning, y = newadults)) +\n  geom_point() + geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](reports_files/figure-html/sparrowhawk-2-1.png){width=672}\n:::\n:::\n\n \n\n<br>\n\nThe piece of report that I added looks like this:\n\n\n![](sh4.png)\n\n\nNote (i) that you have to do nothing special to get the plot to\nappear, and (ii) that I put \"smaller\" in italics, and you see\nhow. \n\n$\\blacksquare$\n\n(d) Obtain the correlation between the two variables. Is this\nconsistent with the scatterplot? Explain briefly. (The R function\nyou need is `cor`. You can feed it a data frame.)\n\n\nSolution\n\n\nThe appropriate R code  is this, in another code chunk:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(sparrowhawks, cor(newadults, returning))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.7484673\n```\n:::\n:::\n\n \n\nOr you can ask for the correlations of the whole data frame:\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(sparrowhawks)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           returning  newadults\nreturning  1.0000000 -0.7484673\nnewadults -0.7484673  1.0000000\n```\n:::\n:::\n\n \n\nThis latter is a \"correlation matrix\" with a correlation between each\ncolumn and each other column. Obviously the correlation between a\ncolumn and itself is 1, and that is *not* the one we want.\n\nI added this to the report (still in the Exploratory Analysis\nsection, since it seems to belong there):\n\n![](sh5.png)\n\n\n$\\blacksquare$\n\n(e) Obtain the regression line for predicting the number of new\nadults from the percentage of returning adults.\n\n\nSolution\n\n\nThis R code, in another code chunk:\n\n::: {.cell}\n\n```{.r .cell-code}\nnewadults.1 <- lm(newadults ~ returning, data = sparrowhawks)\nsummary(newadults.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = newadults ~ returning, data = sparrowhawks)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8687 -1.2532  0.0508  2.0508  5.3071 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 31.93426    4.83762   6.601 3.86e-05 ***\nreturning   -0.30402    0.08122  -3.743  0.00325 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.667 on 11 degrees of freedom\nMultiple R-squared:  0.5602,\tAdjusted R-squared:  0.5202 \nF-statistic: 14.01 on 1 and 11 DF,  p-value: 0.003248\n```\n:::\n:::\n\n \n\n$\\blacksquare$\n\n(f) What are the intercept and slope of your regression line? Is\nthe slope significant? What does that mean, in the context of the data?\n\n\nSolution\n\n\nSee the output in the previous part. That's what we need to talk about.\nI added this to the report. I thought we deserved a new section here:\n\n![](sh6.png)\n \n\n$\\blacksquare$\n\n(g) Create a scatterplot of the data with the regression line on it.\n\n\nSolution\n\n\nThis code. Using `geom_smooth` with \n`method=\"lm\"`\nwill add the regression line to the plot:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sparrowhawks, aes(x = returning, y = newadults)) +\n  geom_point() + geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](reports_files/figure-html/sparrowhawk-6-1.png){width=672}\n:::\n:::\n\n \n\nI added a bit of text to the report, which I will show in a moment.\n\n$\\blacksquare$\n\n(h) For short-lived birds, the association between these two\nvariables is positive: changes in weather and food supply cause the\npopulations of new and returning birds to increase together. For\nlong-lived territorial birds, however, the association is negative\nbecause returning birds claim their territories in the colony and do\nnot leave room for new recruits. Which type of species is the\nsparrowhawk? Add a short Conclusions section to your report with\ndiscussion of this issue.\n\n\nSolution\n\n\nMy addition to the report looks like this:\n\n\n![](sh7.png)\n\n\nI think that rounds off the report nicely.\n\n$\\blacksquare$\n\n\n\n\n",
    "supporting": [
      "reports_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}