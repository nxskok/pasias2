{
  "hash": "269bf980709dca459e9d04d071eeec20",
  "result": {
    "markdown": "# Analysis of covariance\n\nPackages for this chapter:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(car)\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Productivity and research-and-development\n\n\n An economist compiled data on productivity improvements for\na sample of companies that produce electronic equipment. The companies\nwere classified according to their expenditures on research and\ndevelopment in the last three years (classified as low, moderate,\nhigh). Productivity improvement is measured on a 0--100 scale, with\nmost values being between 0 and 10. The economist also thought that\nlast year's productivity improvement would be relevant, and so\nrecorded this as well.\n\nThe data set can be found at\n[link](http://ritsokiguess.site/datafiles/productivity.txt). \n\nFeel free to use \"R&D\" as an abbreviation for \n\"research and development\" in your answers below.\n\n\n\n(a) Read in and display at least some of the data.\n\n\n(b) Plot productivity improvement for this year against last\nyear, identifying the points by the level of\nresearch-and-development expenditure. On your plot, add regression\nlines for each expenditure group.\n\n\n(c) <a name=\"part:graph-comment\">*</a> \nLook at your graph of the previous part. Do you think that (i)\nknowing last year's productivity improvement tells you something\nabout this year's, (ii) the level of expenditure on\nresearch-and-development has an impact on this year's productivity\nimprovement, (iii) there is an interaction effect between R\\&D\nexpenditure and last year's productivity increase on this year's\nproductivity increase? In each case, explain briefly.\n\n\n(d) Fit an analysis of covariance model without interaction. Run\nthe results through `drop1` with `test=\"F\"` (the\n`F` must be in quotes). What do you conclude?\n\n\n(e) Now look at the `summary` of your analysis of\ncovariance model. Explain briefly how each of the *last three*\nnumbers in the `Estimate` column are consistent with your graph.\n\n\n(f) Add an interaction between `last` and\n`expenditure` to your analysis of covariance model. Test it\nfor significance using `drop1`. In the light of what you\nhave seen, does this surprise you? Explain briefly why you are or\nare not surprised.\n\n\n\n\n\n##  Treating leprosy\n\n\n Two drugs are being tested in the treatment of\nleprosy. These are labelled A and D. There is also a control drug,\nlabelled F. The response variable is a post-treatment score of leprosy\nbacilli (measured at six different sites on each patient). A lower\nscore is better.\n\nThus far, we have a standard one-way analysis of variance. But the\nresearchers wanted greater precision in assessing the effects (if any)\nof the drugs, so they also measured a pre-treatment score of leprosy\nbacilli. The data are in the file\n[link](http://ritsokiguess.site/datafiles/leprosy.txt). The\npre-treatment and post-treatment scores are labelled `pre` and\n`post` respectively.\n\n\n\n(a) Read in the data and check that you have apparently the\nright thing.\n::: {.cell}\n\n:::\n\n   \n \n\n(b) <a name=\"part:lepro-scatter\">*</a> Make a scatterplot of post-treatment score against\npre-treatment score, with the points for each drug drawn in a\ndifferent colour. \n \n\n(c) Does it appear that including the pre-treatment score was a\ngood idea? Explain briefly.\n \n\n(d) What about this dataset suggests that analysis of\ncovariance is a method worth trying?\n \n\n(e) Fit an analysis of covariance model to predict\npost-treatment score. Include an interaction between your\nexplanatory variables. (You don't need to look at the output from\nthe model.)\n \n\n(f) Pass your fitted model of the last part into\n`drop1`. Is\nthe interaction term significant?\n\n\n\n(g) Fit a model without the interaction. Is this a sensible thing to\ndo (in addition, that is, to the fact that I just asked you to do it)?\n\n\n\n(h) Take a look at the `summary` of your preferred\nmodel. Is there a significant effect of pre-treatment score?\nDescribe the effects of the different drugs on the post-treatment\nscore. (Don't do any tests for `drug`.) Does your comparison\nof drugs make sense?\n \n\n(i) Obtain predicted values for `post` for each of the\nthree drugs at `pre` scores 5, 12 and 20. To do this, obtain\na new data frame that has all 9 combinations of drugs and\n`pre` scores, and then feed this into `predict` using\nyour preferred model.^[Analysis of covariance is just a linear  model, so *predict* works the same here as in regression.]\n \n\n(j) Now, plot the data with the fitted lines on. \n\n\n(k) Are the lines on your plot parallel, with the same slopes? Is this what you would\nexpect? Explain briefly.\n \n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n##  Productivity and research-and-development\n\n\n An economist compiled data on productivity improvements for\na sample of companies that produce electronic equipment. The companies\nwere classified according to their expenditures on research and\ndevelopment in the last three years (classified as low, moderate,\nhigh). Productivity improvement is measured on a 0--100 scale, with\nmost values being between 0 and 10. The economist also thought that\nlast year's productivity improvement would be relevant, and so\nrecorded this as well.\n\nThe data set can be found at\n[link](http://ritsokiguess.site/datafiles/productivity.txt). \n\nFeel free to use \"R&D\" as an abbreviation for \n\"research and development\" in your answers below.\n\n\n\n(a) Read in and display at least some of the data.\n\nSolution\n\n\nThe data values are separated by one space, so let's use\n`read_delim` and display whatever displays (probably the\nfirst ten lines):\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/productivity.txt\"\nproductivity <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 27 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr (1): expenditure\ndbl (2): improvement, last\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nproductivity\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 27 x 3\n   expenditure improvement  last\n   <chr>             <dbl> <dbl>\n 1 low                 7.6   8.2\n 2 low                 8.2   7.9\n 3 low                 6.8   7  \n 4 low                 5.8   5.7\n 5 low                 6.9   7.2\n 6 low                 6.6   7  \n 7 low                 6.3   6.5\n 8 low                 7.7   7.9\n 9 low                 6     6.3\n10 moderate            6.7   8.8\n# i 17 more rows\n```\n:::\n:::\n\n   \n\nThere is a column classifying expenditure along with numerical values\nfor productivity improvement for this year and last year (labelled\n`improvement` and `last`), so it looks as if we are\ngood.\n\nYou are free to give the data frame a shorter name to make it easier\nto keep typing it!\n\nExtra: those expenditure levels (that are currently text) will get\nsorted into alphabetical order unless we stop them. They are actually\nin the right order in the data file, so maybe we should turn them into\na factor (with the levels in the right order) now:\n\n::: {.cell}\n\n```{.r .cell-code}\nproductivity %>%\n  mutate(expenditure = fct_inorder(expenditure)) -> productivity\n```\n:::\n\n \n\nIf you don't do this, your answers below will be different from\nmine. Probably not in any kind of consequential way, but different\nnonetheless.\n\n$\\blacksquare$\n\n(b) Plot productivity improvement for this year against last\nyear, identifying the points by the level of\nresearch-and-development expenditure. On your plot, add regression\nlines for each expenditure group.\n\nSolution\n\n\nTwo quantitative and one categorical variable, so plot the\ncategorical variable using colour (or `shape` etc., if you\nknow about that, but colour is the most obvious thing):\n::: {.cell}\n\n```{.r .cell-code}\nggplot(productivity, aes(x = last, y = improvement, colour = expenditure)) +\n  geom_point() + geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](ancova_files/figure-pdf/productivity-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n     \n\nThe `se=F` is optional; no problem if you don't include it. (If\nyou miss it out, you'll get those CI-of-mean-response grey envelopes\naround each line.)\n\n$\\blacksquare$\n\n(c) <a name=\"part:graph-comment\">*</a> \nLook at your graph of the previous part. Do you think that (i)\nknowing last year's productivity improvement tells you something\nabout this year's, (ii) the level of expenditure on\nresearch-and-development has an impact on this year's productivity\nimprovement, (iii) there is an interaction effect between R\\&D\nexpenditure and last year's productivity increase on this year's\nproductivity increase? In each case, explain briefly.\n\nSolution\n\n\nTaking the three things in turn:\n(i) knowing about last year's productivity increase definitely\nhelps, because the three trends definitely go up (extra: and are\npretty much linear).\n(ii) knowing about the level of expenditure helps because the\ncoloured trends are in different places (low on the\nleft and high on the right, whatever colours they are for you).\n(iii) I am guessing there is no interaction because the three\nlines look more or less parallel (a judgement call: if you think\nthat there *will* be an interaction because you think the\nlines are definitely not \"approximately parallel\" and therefore\nthere is an interaction, that's OK too).\n\n$\\blacksquare$\n\n(d) Fit an analysis of covariance model without interaction. Run\nthe results through `drop1` with `test=\"F\"` (the\n`F` must be in quotes). What do you conclude?\n\nSolution\n\n\nThis looks exactly like a regression with a categorical variable,\nand is. Just the two main effects, thus:\n::: {.cell}\n\n```{.r .cell-code}\nimprovement.1 <- lm(improvement ~ last + expenditure, data = productivity)\ndrop1(improvement.1, test = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nimprovement ~ last + expenditure\n            Df Sum of Sq     RSS     AIC F value    Pr(>F)    \n<none>                    1.3175 -73.542                      \nlast         1   14.0447 15.3622  -9.226 245.176 9.274e-14 ***\nexpenditure  2    4.1958  5.5134 -38.894  36.623 7.095e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n     \n\nBoth the P-values are small, so there is strong evidence of an effect\non this year's productivity increase of last year's productivity\nincrease and the level of R\\&D expenditure. \n\n$\\blacksquare$\n\n(e) Now look at the `summary` of your analysis of\ncovariance model. Explain briefly how each of the *last three*\nnumbers in the `Estimate` column are consistent with your graph.\n\nSolution\n\n\nTo begin:\n::: {.cell}\n\n```{.r .cell-code}\nsummary(improvement.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = improvement ~ last + expenditure, data = productivity)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.52812 -0.16385 -0.00046  0.08379  0.45730 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         -1.00804    0.50991  -1.977   0.0602 .  \nlast                 1.11417    0.07116  15.658 9.27e-14 ***\nexpendituremoderate -1.83316    0.22372  -8.194 2.84e-08 ***\nexpenditurehigh     -3.14338    0.37115  -8.469 1.59e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2393 on 23 degrees of freedom\nMultiple R-squared:  0.9629,\tAdjusted R-squared:  0.958 \nF-statistic: 198.8 on 3 and 23 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n     \n\nThe last three numbers in the Estimate column are slopes for the\nquantitative variable `last` and changes in intercept for the\nlevels of the categorical variable `expenditure`. Specifically:\n\n\n\n* the slope for `last` is positive, so if last year's\nproductivity increase is higher, this year's will be higher as well. \nThis matches\nthe upward trends within each `expenditure` group on the\ngraph.\n\n* `expenditure` is categorical, so everything is measured\nrelative to the baseline. Mine is `low`, but yours is probably `high`. \n\n* My two estimates for `expenditure` `high` and\n`moderate` are both negative, so when expenditure on R\\&D is\nhigh or moderate, the productivity increase will be lower this year\n(for the same productivity increase last year). Going back to the\ngraph, if you extend the lines for `moderate` and `high` to\na middling `last` value of something like 10, the\nproductivity increase this year will be higher when\n`expenditure` is low or moderate then when it is high, which\nis consistent with those slopes both being positive. (You don't need\nto go to this detail, but you should say something convincing from\nthe graph about how this year's productivity increase is\n*higher* if R\\&D expenditure is low or moderate compared to\nhigh.)\n\n\nExtra: the graph also indicates that the higher the\n`expenditure` on R\\&D is, the more likely last year's\nproductivity improvement will be higher also. So in practice we are\nnot likely to be comparing actual companies with different\n`expenditure` but the same `last`. Nonetheless, what I\nsaid is what those positive coefficients for `expenditure`\nactually mean. Be careful not to say that `low` is lowest\nbecause it's on the left; it's whether it's higher or lower than the\nothers *at the same value of `last`* that matters.\n\nExtra extra: I asked you to do the test from `drop1` because\nthere are three levels of `expenditure` (rather than just two),\nand the `summary` output only gives you a comparison with the\nbaseline level, rather than comparing all three\nlevels. I prefer to do the right test (using `drop1`) first,\nand then use `summary` to interpret what I have, or at least\nthe parts of it that are significant.\n\nExtra extra extra: you would (or at least I would) expect a larger\nproductivity increase to go with a *larger* expenditure on R\\&D,\nbut that's not how it worked out. This is one of those cases where all\nelse isn't really equal.\n\n$\\blacksquare$\n\n(f) Add an interaction between `last` and\n`expenditure` to your analysis of covariance model. Test it\nfor significance using `drop1`. In the light of what you\nhave seen, does this surprise you? Explain briefly why you are or\nare not surprised.\n\nSolution\n\n\nI like `update` for this (writing out the whole model is an\nalternative):\n::: {.cell}\n\n```{.r .cell-code}\nimprovement.2 <- update(improvement.1, . ~ . + last:expenditure)\ndrop1(improvement.2, test = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nimprovement ~ last + expenditure + last:expenditure\n                 Df Sum of Sq     RSS     AIC F value  Pr(>F)  \n<none>                        0.95718 -78.169                  \nlast:expenditure  2   0.36035 1.31753 -73.542   3.953 0.03491 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n     \n\nYes, I too forgot the `test=\"F\"` the first time.\n\nThe interaction term is actually significant, at least at\n$\\alpha=0.05$. This is a surprise to me, because I thought those lines\non the graph were pretty close to parallel, so I wasn't expecting to\nsee a significant interaction. (What I want from you here is to look\nback at your answer to (iii) in part (<a href=\"#part:graph-comment\">here</a>), and\nto say how this small P-value is consistent or inconsistent with\nwhatever you said there. If you said that the lines weren't parallel\nenough, then this significant interaction should *not* be a\nsurprise to you.)\n\nThat's all I'm after. I don't need you to speculate on *why* the\ntest came out significant. I will, in a moment, but you don't need to.\n\nExtra: I didn't expect the interaction to come out significant, but\nthe P-value is not nearly so small as the ones we had before. I guess\nthe explanation for this is that the data cluster pretty tightly about\nthe lines in the graph, so that even a small difference in slopes can\nbe signficant. You might argue that my red line is not *quite*\nas steep as the others, but the difference does look very small.\n\nLet's take a look at the `summary` for my interaction model:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(improvement.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = improvement ~ last + expenditure + last:expenditure, \n    data = productivity)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.32417 -0.14885 -0.02465  0.13739  0.55556 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               0.27827    0.64967   0.428  0.67278    \nlast                      0.93243    0.09124  10.220 1.32e-09 ***\nexpendituremoderate      -4.50268    1.25959  -3.575  0.00179 ** \nexpenditurehigh          -7.14795    1.91223  -3.738  0.00121 ** \nlast:expendituremoderate  0.32217    0.14243   2.262  0.03444 *  \nlast:expenditurehigh      0.40858    0.17549   2.328  0.02997 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2135 on 21 degrees of freedom\nMultiple R-squared:  0.973,\tAdjusted R-squared:  0.9666 \nF-statistic: 151.5 on 5 and 21 DF,  p-value: 9.763e-16\n```\n:::\n:::\n\n \n\nThe last two Estimates, the ones beginning with `last:`, came\nfrom the interaction. Once again `low` is my baseline. These\nsay how the *slopes* for `last` for the other groups\ndiffer from the slopes for `last` for `low`\nexpenditure. (Yes, this is confusing. Read it again until you get it.)\n\nThe biggest-size difference in slopes, about $0.40$, is between low\nexpenditure and high expenditure. This says that the line for high\nexpenditure is this much more steep than the line for low\nexpenditure. That's where the non-parallelism is on the graph, such as\nit is. A small but significant difference in slopes. You can tell that\nthe effect is small by looking in the Estimate column; those changes\nin slopes, $0.40$ and $0.32$, are the smallest things in size out of\neverything in that column.\n\nHaving seen this, you now realize that I did this question wrong (or,\nat least, I led you through it wrong). The right way to do this would\nhave been to fit the interaction model *first*, see that it is\nsignificant, and then done some predictions to assess the effects of\nthings: \n\n::: {.cell}\n\n```{.r .cell-code}\nplot_cap(improvement.2, condition = c(\"last\", \"expenditure\"))\n```\n\n::: {.cell-output-display}\n![](ancova_files/figure-pdf/unnamed-chunk-2-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe three lines are not quite parallel, and evidently non-parallel enough to be significant. (This graph does not give you any sense of how much variability there is in the *slopes*; the at-least partial non-overlapping of the confidence envelopes tells you that there is a significant effect of *expenditure*, but it doesn't tell you about the interaction.)\n\nThe effect is more or less as we described it before: as `last`\ngoes up (for fixed `expenditure`), the predicted productivity\nimprovements for this year go up, and as `expenditure` level\ngoes up, the predictions go *down*. But the rates at which they\ngo up or down are different, which is the significant interaction\ncoming into play. Having said that, they are not very different, so I\ncheated and pretended the interaction was not significant (or that I\nwas using $\\alpha=0.01$), so that you would have something easier to\ninterpret. Qualitatively, the story is the same either way, because\nthe sizes of the interaction terms are small compared to the\nothers. So, even though I cheated, you ended up with more or less the\nsame conclusions doing it the way I asked you to do it, or doing it\nthe way I just did it.\n\n$\\blacksquare$\n\n\n\n\n##  Treating leprosy\n\n\n Two drugs are being tested in the treatment of\nleprosy. These are labelled A and D. There is also a control drug,\nlabelled F. The response variable is a post-treatment score of leprosy\nbacilli (measured at six different sites on each patient). A lower\nscore is better.\n\nThus far, we have a standard one-way analysis of variance. But the\nresearchers wanted greater precision in assessing the effects (if any)\nof the drugs, so they also measured a pre-treatment score of leprosy\nbacilli. The data are in the file\n[link](http://ritsokiguess.site/datafiles/leprosy.txt). The\npre-treatment and post-treatment scores are labelled `pre` and\n`post` respectively.\n\n\n\n(a) Read in the data and check that you have apparently the\nright thing.\n\n \nSolution\n\n\nTake a look at the data file. The values have multiple spaces\nbetween them, but they are aligned with each other and the\ncolumn headings, so `read_table` is the thing:\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/leprosy.txt\"\nlepro <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  drug = col_character(),\n  pre = col_double(),\n  post = col_double()\n)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 24 parsing failures.\nrow col  expected    actual                                             file\n  1  -- 3 columns 4 columns 'http://ritsokiguess.site/datafiles/leprosy.txt'\n  2  -- 3 columns 4 columns 'http://ritsokiguess.site/datafiles/leprosy.txt'\n  3  -- 3 columns 4 columns 'http://ritsokiguess.site/datafiles/leprosy.txt'\n  4  -- 3 columns 4 columns 'http://ritsokiguess.site/datafiles/leprosy.txt'\n  5  -- 3 columns 4 columns 'http://ritsokiguess.site/datafiles/leprosy.txt'\n... ... ......... ......... ................................................\nSee problems(...) for more details.\n```\n:::\n\n```{.r .cell-code}\nlepro %>% \n  mutate(change = pre-post)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 x 4\n   drug    pre  post change\n   <chr> <dbl> <dbl>  <dbl>\n 1 A        11     6      5\n 2 A         6     4      2\n 3 D         6     0      6\n 4 D         8     4      4\n 5 F        16    13      3\n 6 F        16    12      4\n 7 A         8     0      8\n 8 A        10    13     -3\n 9 D         6     2      4\n10 D        19    14      5\n# i 20 more rows\n```\n:::\n:::\n\n \n\nCall it what you like.\n\nThat looks good, with variables of the right names. \n \n$\\blacksquare$\n\n(b) <a name=\"part:lepro-scatter\">*</a> Make a scatterplot of post-treatment score against\npre-treatment score, with the points for each drug drawn in a\ndifferent colour. \n \nSolution\n\n\nThis is the kind of thing that `ggplot` does without\nbatting an eyelid:\n::: {.cell}\n\n```{.r .cell-code}\nggplot(lepro, aes(x = pre, y = post, colour = drug)) + geom_point() + geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](ancova_files/figure-pdf/leprosy-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(lepro, aes(x = drug, y = post)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](ancova_files/figure-pdf/unnamed-chunk-3-1.pdf){fig-pos='H'}\n:::\n:::\n       \n \n$\\blacksquare$\n\n(c) Does it appear that including the pre-treatment score was a\ngood idea? Explain briefly.\n \nSolution\n\n\nThe overall trend on the scatterplot is that a higher `pre`\ntends to go with a higher `post`, regardless of drug, so\nincluding this information appears to be informative.\nI personally suspect that there's some fan-out happening on the\npre-post relationship, but I'm not planning to make you explore that.\n \n$\\blacksquare$\n\n(d) What about this dataset suggests that analysis of\ncovariance is a method worth trying?\n \nSolution\n\n\nThe key is a mixture of categorical and quantitative explanatory\nvariables. Here we have a categorical variable `drug` and a\nquantitative one `pre`. \nIf we had only one type of explanatory variable, we could do a\nregression or an ANOVA as appropriate. But we don't. In some ways,\nit's not worth making a fuss about the distinction, because\nregressions and ANOVAs are all linear models anyway. But you may\nsee the term \"analysis of covariance\", so it's worth your while\nto know what it's about. \n \n$\\blacksquare$\n\n(e) Fit an analysis of covariance model to predict\npost-treatment score. Include an interaction between your\nexplanatory variables. (You don't need to look at the output from\nthe model.)\n \nSolution\n\n\nThis is what you'd guess. `lm` handles the interaction\nproperly, even though `pre` is a  quantitative variable.\n\n::: {.cell}\n\n```{.r .cell-code}\nlepro.1 <- lm(post ~ pre * drug, data = lepro)\n```\n:::\n\n     \n\nI wanted to take a look, so I did:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lepro.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ pre * drug, data = lepro)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.225 -2.437 -0.586  1.126  8.775 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  -1.6306     2.9455  -0.554   0.5850  \npre           0.7452     0.2849   2.616   0.0152 *\ndrugD        -2.9549     4.1246  -0.716   0.4806  \ndrugF        -1.4780     5.4678  -0.270   0.7892  \npre:drugD     0.3233     0.3846   0.841   0.4089  \npre:drugF     0.4492     0.4458   1.008   0.3236  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.07 on 24 degrees of freedom\nMultiple R-squared:  0.6915,\tAdjusted R-squared:  0.6272 \nF-statistic: 10.76 on 5 and 24 DF,  p-value: 1.63e-05\n```\n:::\n:::\n\n \n\nFor testing the interaction, there are *two* slope coefficients\nthat should be zero if there is no interaction. So we have to test\nthis with `drop1`, which is next.\n \n$\\blacksquare$\n\n(f) Pass your fitted model of the last part into\n`drop1`. Is\nthe interaction term significant?\n\n\nSolution\n\n\nJust this:\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(lepro.1, test = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\npost ~ pre * drug\n         Df Sum of Sq    RSS    AIC F value Pr(>F)\n<none>                397.56 89.524               \npre:drug  2    19.645 417.20 86.971   0.593 0.5606\n```\n:::\n:::\n\n       \n\nThere is only a test for the interaction term because you can't take out the main effects until you've taken out the interaction.\n\nThe P-value for the interaction is very large (0.5606) so it is\nnowhere near significant. We can drop the interaction.\n\n\n$\\blacksquare$\n\n(g) Fit a model without the interaction. Is this a sensible thing to\ndo (in addition, that is, to the fact that I just asked you to do it)?\n\n\nSolution\n\n\nChange the `*` to a `+`:\n::: {.cell}\n\n```{.r .cell-code}\nlepro.2 <- lm(post ~ pre + drug, data = lepro)\n```\n:::\n\n     \n\nOr use `update` (not much in it, here):\n\n::: {.cell}\n\n```{.r .cell-code}\nlepro.2a <- update(lepro.1, . ~ . - pre:drug)\n```\n:::\n\n \n\nWe just said that the interaction could come out, since it wasn't\nsignificant, so this is exactly the model that we should be fitting.\n\n\n$\\blacksquare$\n\n(h) Take a look at the `summary` of your preferred\nmodel. Is there a significant effect of pre-treatment score?\nDescribe the effects of the different drugs on the post-treatment\nscore. (Don't do any tests for `drug`.) Does your comparison\nof drugs make sense?\n \nSolution\n\n\nMine was the no-interaction model `lepro.2`:\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lepro.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = post ~ pre + drug, data = lepro)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4115 -2.3891 -0.5711  1.7237  8.5885 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -3.8808     1.9862  -1.954   0.0616 .  \npre           0.9872     0.1645   6.001 2.45e-06 ***\ndrugD         0.1090     1.7951   0.061   0.9521    \ndrugF         3.4461     1.8868   1.826   0.0793 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.006 on 26 degrees of freedom\nMultiple R-squared:  0.6763,\tAdjusted R-squared:  0.6389 \nF-statistic:  18.1 on 3 and 26 DF,  p-value: 1.501e-06\n```\n:::\n:::\n\n     \n\nThe pre-treatment term is definitely significant, with a P-value of\n0.0000025. So pre-treatment score definitely has an impact on\npost-treatment score.\n\nI didn't ask you to test for significance of drugs. I just wanted you\nto assess their coefficients. Drug A is being used as the baseline, so\nits coefficient is zero. Drug D has a slightly positive coefficient\n(0.109) so its average bacilli score is slightly higher (for any\npre-treatment score) than for drug A. Drug F, which was the placebo,\nhas a slope of 3.446, so its average bacilli score is a fair bit\nhigher than for either of the other drugs. This makes sense because a\nhigher score is worse, and the two \"real\" drugs are both better than\nthe fake one.\n\nWhether there is a real drug difference, I didn't ask you to assess,\nbut you could do it by `drop1` again, this way:\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(lepro.2, test = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\npost ~ pre + drug\n       Df Sum of Sq    RSS     AIC F value    Pr(>F)    \n<none>              417.20  86.971                      \npre     1    577.90 995.10 111.049 36.0145 2.454e-06 ***\ndrug    2     68.55 485.76  87.535  2.1361    0.1384    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n \n\nThis is actually not significant.^[This is why I didn't ask you to test this, since it would have confused the story.]\nThis is one of those cases where the non-significant `drug` has\na slightly *bigger* AIC than `<none>`, so `drop1`\nconsiders it best to leave it in the model.\n \n$\\blacksquare$\n\n(i) Obtain predicted values for `post` for each of the\nthree drugs at `pre` scores 5, 12 and 20. To do this, obtain\na new data frame that has all 9 combinations of drugs and\n`pre` scores, and then feed this into `predict` using\nyour preferred model.^[Analysis of covariance is just a linear  model, so *predict* works the same here as in regression.]\n \nSolution\n\n\nFirst, make the new data frame for predicting from, using\n`crossing`. I'm doing this in small steps for clarity:\nfirst, I define all the drugs and `pre` values, and then I\nfeed them into `datagrid`:\n::: {.cell}\n\n```{.r .cell-code}\ndrugs <- c(\"A\", \"D\", \"F\")\npres <- c(5, 12, 20)\nnew <- datagrid(model = lepro.2, drug = drugs, pre = pres)\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  post drug pre\n1  7.9    A   5\n2  7.9    A  12\n3  7.9    A  20\n4  7.9    D   5\n5  7.9    D  12\n6  7.9    D  20\n7  7.9    F   5\n8  7.9    F  12\n9  7.9    F  20\n```\n:::\n:::\n\n\nNow I obtain the predictions, from my best model `lepro.2`. I\ndon't need intervals or anything like that:\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- cbind(predictions(lepro.2, newdata = new))\npreds %>% select(drug, pre, estimate, conf.low, conf.high)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  drug pre  estimate   conf.low conf.high\n1    A   5  1.055110 -1.7884966  3.898716\n2    A  12  7.965396  5.3344494 10.596343\n3    A  20 15.862867 11.6125631 20.113170\n4    D   5  1.164081 -1.7961211  4.124283\n5    D  12  8.074368  5.5092373 10.639498\n6    D  20 15.971838 11.9025779 20.041098\n7    F   5  4.501248  0.9443557  8.058140\n8    F  12 11.411535  8.9118746 13.911195\n9    F  20 19.309005 15.9320080 22.686002\n```\n:::\n:::\n\n\n \n\nI gave this a name in case I feel like using it again later.\n \n$\\blacksquare$\n\n(j) Now, plot the data with the fitted lines on. \n\nSolution\n\nThe starting point is to plot the predictions, which is `plot_cap`:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_cap(lepro.2, condition = c(\"pre\", \"drug\"))\n```\n\n::: {.cell-output-display}\n![](ancova_files/figure-pdf/unnamed-chunk-4-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe olive-coloured line is actually the red and green lines right next to each other. You can check from the previous part that the predictions for drugs A and D are very close together, with those for drug F (the placebo) being higher (worse).\n\nThis is a `ggplot`, so we can add things to it. The idea is to say that the next thing to plot comes from some other dataframe, and to specify everything we need (that is, not to inherit from the original `ggplot` that is lurking within `plot_cap`):\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_cap(lepro.2, condition = c(\"pre\", \"drug\")) +\n  geom_point(data = lepro, aes(x = pre, y = post, colour = drug), inherit.aes = FALSE)\n```\n\n::: {.cell-output-display}\n![](ancova_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-pos='H'}\n:::\n:::\n\nThere is quite a lot of variability (which is why those confidence bands are so wide), but at least some of the blue points from drug F are above the others (worse), and there is very little to choose between drugs A and D.\n\n$\\blacksquare$\n\n(k) Are the lines on your plot parallel, with the same slopes? Is this what you would\nexpect? Explain briefly.\n \nSolution\n\n\nMy lines are parallel. This is exactly what I would expect, since\nmy best model has no interaction, and the interaction is what\nwould make the lines *not* be parallel. \nIf your best model\n*did* have the interaction term still in it, your predictions\nwould have been these:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_cap(lepro.1, condition = c(\"pre\", \"drug\")) +\n  geom_point(data = lepro, aes(x = pre, y = post, colour = drug), inherit.aes = FALSE)\n```\n\n::: {.cell-output-display}\n![](ancova_files/figure-pdf/unnamed-chunk-6-1.pdf){fig-pos='H'}\n:::\n:::\n\nThere is, as you see, a\nsubstantial scatter in the points that would make it very difficult to\nprove that those three slopes are really different, even though the lines cross.\n \n$\\blacksquare$\n\n\n\n",
    "supporting": [
      "ancova_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}