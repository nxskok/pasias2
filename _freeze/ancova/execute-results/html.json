{
  "hash": "438cd76aa46aa2bb207ada9789cc37b4",
  "result": {
    "engine": "knitr",
    "markdown": "# Analysis of covariance\n\nPackages for this chapter:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(car)\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Productivity and research-and-development\n\n\n An economist compiled data on productivity improvements for\na sample of companies that produce electronic equipment. The companies\nwere classified according to their expenditures on research and\ndevelopment in the last three years (classified as low, moderate,\nhigh). Productivity improvement is measured on a 0--100 scale, with\nmost values being between 0 and 10. The economist also thought that\nlast year's productivity improvement would be relevant, and so\nrecorded this as well.\n\nThe data set can be found at\n[link](http://ritsokiguess.site/datafiles/productivity.txt). \n\nFeel free to use \"R&D\" as an abbreviation for \n\"research and development\" in your answers below.\n\n\n\n(a) Read in and display at least some of the data.\n\n\n(b) Plot productivity improvement for this year against last\nyear, identifying the points by the level of\nresearch-and-development expenditure. On your plot, add regression\nlines for each expenditure group.\n\n\n(c) <a name=\"part:graph-comment\">*</a> \nLook at your graph of the previous part. Do you think that (i)\nknowing last year's productivity improvement tells you something\nabout this year's, (ii) the level of expenditure on\nresearch-and-development has an impact on this year's productivity\nimprovement, (iii) there is an interaction effect between R\\&D\nexpenditure and last year's productivity increase on this year's\nproductivity increase? In each case, explain briefly.\n\n\n(d) Fit an analysis of covariance model without interaction. Run\nthe results through `drop1` with `test=\"F\"` (the\n`F` must be in quotes). What do you conclude?\n\n\n(e) Now look at the `summary` of your analysis of\ncovariance model. Explain briefly how each of the *last three*\nnumbers in the `Estimate` column are consistent with your graph.\n\n\n(f) Add an interaction between `last` and\n`expenditure` to your analysis of covariance model. Test it\nfor significance using `drop1`. In the light of what you\nhave seen, does this surprise you? Explain briefly why you are or\nare not surprised.\n\n\n\n\n\n##  Treating leprosy\n\n\n Two drugs are being tested in the treatment of\nleprosy. These are labelled A and D. There is also a control drug,\nlabelled F. The response variable is a post-treatment score of leprosy\nbacilli (measured at six different sites on each patient). A lower\nscore is better.\n\nThus far, we have a standard one-way analysis of variance. But the\nresearchers wanted greater precision in assessing the effects (if any)\nof the drugs, so they also measured a pre-treatment score of leprosy\nbacilli. The data are in the file\n[link](http://ritsokiguess.site/datafiles/leprosy.txt). The\npre-treatment and post-treatment scores are labelled `pre` and\n`post` respectively.\n\n\n\n(a) Read in the data and check that you have apparently the\nright thing.\n\n\n(b) <a name=\"part:lepro-scatter\">*</a> Make a scatterplot of post-treatment score against\npre-treatment score, with the points for each drug drawn in a\ndifferent colour. \n \n\n(c) Does it appear that including the pre-treatment score was a\ngood idea? Explain briefly.\n \n\n(d) What about this dataset suggests that analysis of\ncovariance is a method worth trying?\n \n\n(e) Fit an analysis of covariance model to predict\npost-treatment score. Include an interaction between your\nexplanatory variables. (You don't need to look at the output from\nthe model.)\n \n\n(f) Pass your fitted model of the last part into\n`drop1`. Is\nthe interaction term significant?\n\n\n\n(g) Fit a model without the interaction. Is this a sensible thing to\ndo (in addition, that is, to the fact that I just asked you to do it)?\n\n\n\n(h) Take a look at the `summary` of your preferred\nmodel. Is there a significant effect of pre-treatment score?\nDescribe the effects of the different drugs on the post-treatment\nscore. (Don't do any tests for `drug`.) Does your comparison\nof drugs make sense?\n \n\n(i) Obtain predicted values for `post` for each of the\nthree drugs at `pre` scores 5, 12 and 20. To do this, obtain\na new data frame that has all 9 combinations of drugs and\n`pre` scores, and then feed this into `predict` using\nyour preferred model.^[Analysis of covariance is just a linear  model, so *predict* works the same here as in regression.]\n \n\n(j) Now, plot the data with the fitted lines on. \n\n\n(k) Are the lines on your plot parallel, with the same slopes? Is this what you would\nexpect? Explain briefly.\n \n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n\n\n\n\n\n\n## Productivity and research-and-development\n\nAn economist compiled data on productivity improvements for a sample of\ncompanies that produce electronic equipment. The companies were\nclassified according to their expenditures on research and development\nin the last three years (classified as low, moderate, high).\nProductivity improvement is measured on a 0--100 scale, with most values\nbeing between 0 and 10. The economist also thought that last year's\nproductivity improvement would be relevant, and so recorded this as\nwell.\n\nThe data set can be found at\n[link](http://ritsokiguess.site/datafiles/productivity.txt).\n\nFeel free to use \"R&D\" as an abbreviation for \"research and development\"\nin your answers below.\n\n(a) Read in and display at least some of the data.\n\nSolution\n\nThe data values are separated by one space, so let's use `read_delim`\nand display whatever displays (probably the first ten lines):\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/productivity.txt\"\nproductivity <- read_delim(my_url, \" \")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 27 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (1): expenditure\ndbl (2): improvement, last\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nproductivity\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"expenditure\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"improvement\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"last\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"low\",\"2\":\"7.6\",\"3\":\"8.2\"},{\"1\":\"low\",\"2\":\"8.2\",\"3\":\"7.9\"},{\"1\":\"low\",\"2\":\"6.8\",\"3\":\"7.0\"},{\"1\":\"low\",\"2\":\"5.8\",\"3\":\"5.7\"},{\"1\":\"low\",\"2\":\"6.9\",\"3\":\"7.2\"},{\"1\":\"low\",\"2\":\"6.6\",\"3\":\"7.0\"},{\"1\":\"low\",\"2\":\"6.3\",\"3\":\"6.5\"},{\"1\":\"low\",\"2\":\"7.7\",\"3\":\"7.9\"},{\"1\":\"low\",\"2\":\"6.0\",\"3\":\"6.3\"},{\"1\":\"moderate\",\"2\":\"6.7\",\"3\":\"8.8\"},{\"1\":\"moderate\",\"2\":\"8.1\",\"3\":\"10.0\"},{\"1\":\"moderate\",\"2\":\"9.4\",\"3\":\"10.7\"},{\"1\":\"moderate\",\"2\":\"8.6\",\"3\":\"10.0\"},{\"1\":\"moderate\",\"2\":\"7.8\",\"3\":\"9.7\"},{\"1\":\"moderate\",\"2\":\"7.7\",\"3\":\"9.4\"},{\"1\":\"moderate\",\"2\":\"8.9\",\"3\":\"10.6\"},{\"1\":\"moderate\",\"2\":\"7.9\",\"3\":\"9.8\"},{\"1\":\"moderate\",\"2\":\"8.3\",\"3\":\"10.0\"},{\"1\":\"moderate\",\"2\":\"8.7\",\"3\":\"10.3\"},{\"1\":\"moderate\",\"2\":\"7.1\",\"3\":\"8.9\"},{\"1\":\"moderate\",\"2\":\"8.4\",\"3\":\"10.0\"},{\"1\":\"high\",\"2\":\"8.5\",\"3\":\"11.5\"},{\"1\":\"high\",\"2\":\"9.7\",\"3\":\"12.2\"},{\"1\":\"high\",\"2\":\"10.1\",\"3\":\"12.8\"},{\"1\":\"high\",\"2\":\"7.8\",\"3\":\"11.0\"},{\"1\":\"high\",\"2\":\"9.6\",\"3\":\"12.3\"},{\"1\":\"high\",\"2\":\"9.5\",\"3\":\"12.1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nThere is a column classifying expenditure along with numerical values\nfor productivity improvement for this year and last year (labelled\n`improvement` and `last`), so it looks as if we are good.\n\nYou are free to give the data frame a shorter name to make it easier to\nkeep typing it!\n\nExtra: those expenditure levels (that are currently text) will get\nsorted into alphabetical order unless we stop them. They are actually in\nthe right order in the data file, so maybe we should turn them into a\nfactor (with the levels in the right order) now:\n\n::: {.cell}\n\n```{.r .cell-code}\nproductivity %>%\n  mutate(expenditure = fct_inorder(expenditure)) -> productivity\n```\n:::\n\nIf you don't do this, your answers below will be different from mine.\nProbably not in any kind of consequential way, but different\nnonetheless.\n\n$\\blacksquare$\n\n(b) Plot productivity improvement for this year against last year,\n    identifying the points by the level of research-and-development\n    expenditure. On your plot, add regression lines for each expenditure\n    group.\n\nSolution\n\nTwo quantitative and one categorical variable, so plot the categorical\nvariable using colour (or `shape` etc., if you know about that, but\ncolour is the most obvious thing):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(productivity, aes(x = last, y = improvement, colour = expenditure)) +\n  geom_point() + geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ancova_files/figure-html/productivity-3-1.png){width=672}\n:::\n:::\n\nThe `se=F` is optional; no problem if you don't include it. (If you miss\nit out, you'll get those CI-of-mean-response grey envelopes around each\nline.)\n\n$\\blacksquare$\n\n(c) <a name=\"part:graph-comment\">\\*</a> Look at your graph of the\n    previous part. Do you think that (i) knowing last year's\n    productivity improvement tells you something about this year's, (ii)\n    the level of expenditure on research-and-development has an impact\n    on this year's productivity improvement, (iii) there is an\n    interaction effect between R&D expenditure and last year's\n    productivity increase on this year's productivity increase? In each\n    case, explain briefly.\n\nSolution\n\nTaking the three things in turn: (i) knowing about last year's\nproductivity increase definitely helps, because the three trends\ndefinitely go up (extra: and are pretty much linear). (ii) knowing about\nthe level of expenditure helps because the coloured trends are in\ndifferent places (low on the left and high on the right, whatever\ncolours they are for you). (iii) I am guessing there is no interaction\nbecause the three lines look more or less parallel (a judgement call: if\nyou think that there *will* be an interaction because you think the\nlines are definitely not \"approximately parallel\" and therefore there is\nan interaction, that's OK too).\n\n$\\blacksquare$\n\n(d) Fit an analysis of covariance model without interaction. Run the\n    results through `drop1` with `test=\"F\"` (the `F` must be in quotes).\n    What do you conclude?\n\nSolution\n\nThis looks exactly like a regression with a categorical variable, and\nis. Just the two main effects, thus:\n\n::: {.cell}\n\n```{.r .cell-code}\nimprovement.1 <- lm(improvement ~ last + expenditure, data = productivity)\ndrop1(improvement.1, test = \"F\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Sum of Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"RSS\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"NA\",\"3\":\"1.317535\",\"4\":\"-73.542006\",\"5\":\"NA\",\"6\":\"NA\",\"_rn_\":\"<none>\"},{\"1\":\"1\",\"2\":\"14.044687\",\"3\":\"15.362222\",\"4\":\"-9.225988\",\"5\":\"245.17589\",\"6\":\"9.273750e-14\",\"_rn_\":\"last\"},{\"1\":\"2\",\"2\":\"4.195826\",\"3\":\"5.513361\",\"4\":\"-38.893885\",\"5\":\"36.62294\",\"6\":\"7.095379e-08\",\"_rn_\":\"expenditure\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nBoth the P-values are small, so there is strong evidence of an effect on\nthis year's productivity increase of last year's productivity increase\nand the level of R&D expenditure.\n\n$\\blacksquare$\n\n(e) Now look at the `summary` of your analysis of covariance model.\n    Explain briefly how each of the *last three* numbers in the\n    `Estimate` column are consistent with your graph.\n\nSolution\n\nTo begin:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(improvement.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = improvement ~ last + expenditure, data = productivity)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.52812 -0.16385 -0.00046  0.08379  0.45730 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         -1.00804    0.50991  -1.977   0.0602 .  \nlast                 1.11417    0.07116  15.658 9.27e-14 ***\nexpendituremoderate -1.83316    0.22372  -8.194 2.84e-08 ***\nexpenditurehigh     -3.14338    0.37115  -8.469 1.59e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2393 on 23 degrees of freedom\nMultiple R-squared:  0.9629,\tAdjusted R-squared:  0.958 \nF-statistic: 198.8 on 3 and 23 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\nThe last three numbers in the Estimate column are slopes for the\nquantitative variable `last` and changes in intercept for the levels of\nthe categorical variable `expenditure`. Specifically:\n\n-   the slope for `last` is positive, so if last year's productivity\n    increase is higher, this year's will be higher as well. This matches\n    the upward trends within each `expenditure` group on the graph.\n\n-   `expenditure` is categorical, so everything is measured relative to\n    the baseline. Mine is `low`, but yours is probably `high`.\n\n-   My two estimates for `expenditure` `high` and `moderate` are both\n    negative, so when expenditure on R&D is high or moderate, the\n    productivity increase will be lower this year (for the same\n    productivity increase last year). Going back to the graph, if you\n    extend the lines for `moderate` and `high` to a middling `last`\n    value of something like 10, the productivity increase this year will\n    be higher when `expenditure` is low or moderate then when it is\n    high, which is consistent with those slopes both being positive.\n    (You don't need to go to this detail, but you should say something\n    convincing from the graph about how this year's productivity\n    increase is *higher* if R&D expenditure is low or moderate compared\n    to high.)\n\nExtra: the graph also indicates that the higher the `expenditure` on R&D\nis, the more likely last year's productivity improvement will be higher\nalso. So in practice we are not likely to be comparing actual companies\nwith different `expenditure` but the same `last`. Nonetheless, what I\nsaid is what those positive coefficients for `expenditure` actually\nmean. Be careful not to say that `low` is lowest because it's on the\nleft; it's whether it's higher or lower than the others *at the same\nvalue of `last`* that matters.\n\nExtra extra: I asked you to do the test from `drop1` because there are\nthree levels of `expenditure` (rather than just two), and the `summary`\noutput only gives you a comparison with the baseline level, rather than\ncomparing all three levels. I prefer to do the right test (using\n`drop1`) first, and then use `summary` to interpret what I have, or at\nleast the parts of it that are significant.\n\nExtra extra extra: you would (or at least I would) expect a larger\nproductivity increase to go with a *larger* expenditure on R&D, but\nthat's not how it worked out. This is one of those cases where all else\nisn't really equal.\n\n$\\blacksquare$\n\n(f) Add an interaction between `last` and `expenditure` to your analysis\n    of covariance model. Test it for significance using `drop1`. In the\n    light of what you have seen, does this surprise you? Explain briefly\n    why you are or are not surprised.\n\nSolution\n\nI like `update` for this (writing out the whole model is an\nalternative):\n\n::: {.cell}\n\n```{.r .cell-code}\nimprovement.2 <- update(improvement.1, . ~ . + last:expenditure)\ndrop1(improvement.2, test = \"F\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Sum of Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"RSS\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"NA\",\"3\":\"0.9571826\",\"4\":\"-78.16915\",\"5\":\"NA\",\"6\":\"NA\",\"_rn_\":\"<none>\"},{\"1\":\"2\",\"2\":\"0.3603524\",\"3\":\"1.3175350\",\"4\":\"-73.54201\",\"5\":\"3.952956\",\"6\":\"0.03490941\",\"_rn_\":\"last:expenditure\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nYes, I too forgot the `test=\"F\"` the first time.\n\nThe interaction term is actually significant, at least at $\\alpha=0.05$.\nThis is a surprise to me, because I thought those lines on the graph\nwere pretty close to parallel, so I wasn't expecting to see a\nsignificant interaction. (What I want from you here is to look back at\nyour answer to (iii) in part (<a href=\"#part:graph-comment\">here</a>),\nand to say how this small P-value is consistent or inconsistent with\nwhatever you said there. If you said that the lines weren't parallel\nenough, then this significant interaction should *not* be a surprise to\nyou.)\n\nThat's all I'm after. I don't need you to speculate on *why* the test\ncame out significant. I will, in a moment, but you don't need to.\n\nExtra: I didn't expect the interaction to come out significant, but the\nP-value is not nearly so small as the ones we had before. I guess the\nexplanation for this is that the data cluster pretty tightly about the\nlines in the graph, so that even a small difference in slopes can be\nsignficant. You might argue that my red line is not *quite* as steep as\nthe others, but the difference does look very small.\n\nLet's take a look at the `summary` for my interaction model:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(improvement.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = improvement ~ last + expenditure + last:expenditure, \n    data = productivity)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.32417 -0.14885 -0.02465  0.13739  0.55556 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               0.27827    0.64967   0.428  0.67278    \nlast                      0.93243    0.09124  10.220 1.32e-09 ***\nexpendituremoderate      -4.50268    1.25959  -3.575  0.00179 ** \nexpenditurehigh          -7.14795    1.91223  -3.738  0.00121 ** \nlast:expendituremoderate  0.32217    0.14243   2.262  0.03444 *  \nlast:expenditurehigh      0.40858    0.17549   2.328  0.02997 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2135 on 21 degrees of freedom\nMultiple R-squared:  0.973,\tAdjusted R-squared:  0.9666 \nF-statistic: 151.5 on 5 and 21 DF,  p-value: 9.763e-16\n```\n\n\n:::\n:::\n\nThe last two Estimates, the ones beginning with `last:`, came from the\ninteraction. Once again `low` is my baseline. These say how the *slopes*\nfor `last` for the other groups differ from the slopes for `last` for\n`low` expenditure. (Yes, this is confusing. Read it again until you get\nit.)\n\nThe biggest-size difference in slopes, about $0.40$, is between low\nexpenditure and high expenditure. This says that the line for high\nexpenditure is this much more steep than the line for low expenditure.\nThat's where the non-parallelism is on the graph, such as it is. A small\nbut significant difference in slopes. You can tell that the effect is\nsmall by looking in the Estimate column; those changes in slopes, $0.40$\nand $0.32$, are the smallest things in size out of everything in that\ncolumn.\n\nHaving seen this, you now realize that I did this question wrong (or, at\nleast, I led you through it wrong). The right way to do this would have\nbeen to fit the interaction model *first*, see that it is significant,\nand then done some predictions to assess the effects of things:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(improvement.2, condition = c(\"last\", \"expenditure\"))\n```\n\n::: {.cell-output-display}\n![](ancova_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\nThe three lines are not quite parallel, and evidently non-parallel\nenough to be significant. (This graph does not give you any sense of how\nmuch variability there is in the *slopes*; the at-least partial\nnon-overlapping of the confidence envelopes tells you that there is a\nsignificant effect of *expenditure*, but it doesn't tell you about the\ninteraction.)\n\nThe effect is more or less as we described it before: as `last` goes up\n(for fixed `expenditure`), the predicted productivity improvements for\nthis year go up, and as `expenditure` level goes up, the predictions go\n*down*. But the rates at which they go up or down are different, which\nis the significant interaction coming into play. Having said that, they\nare not very different, so I cheated and pretended the interaction was\nnot significant (or that I was using $\\alpha=0.01$), so that you would\nhave something easier to interpret. Qualitatively, the story is the same\neither way, because the sizes of the interaction terms are small\ncompared to the others. So, even though I cheated, you ended up with\nmore or less the same conclusions doing it the way I asked you to do it,\nor doing it the way I just did it.\n\n$\\blacksquare$\n\n\n##  Treating leprosy\n\n\n Two drugs are being tested in the treatment of\nleprosy. These are labelled A and D. There is also a control drug,\nlabelled F. The response variable is a post-treatment score of leprosy\nbacilli (measured at six different sites on each patient). A lower\nscore is better.\n\nThus far, we have a standard one-way analysis of variance. But the\nresearchers wanted greater precision in assessing the effects (if any)\nof the drugs, so they also measured a pre-treatment score of leprosy\nbacilli. The data are in the file\n[link](http://ritsokiguess.site/datafiles/leprosy.txt). The\npre-treatment and post-treatment scores are labelled `pre` and\n`post` respectively.\n\n\n\n(a) Read in the data and check that you have apparently the\nright thing.\n\n \nSolution\n\n\nTake a look at the data file. The values have multiple spaces\nbetween them, but they are aligned with each other and the\ncolumn headings, so `read_table` is the thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/leprosy.txt\"\nlepro <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  drug = col_character(),\n  pre = col_double(),\n  post = col_double()\n)\n```\n\n\n:::\n:::\n\n \n\nCall it what you like.\n\nThat looks good, with variables of the right names. \n \n$\\blacksquare$\n\n(b) <a name=\"part:lepro-scatter\">*</a> Make a scatterplot of post-treatment score against\npre-treatment score, with the points for each drug drawn in a\ndifferent colour. Add a linear trend for each drug.\n \nSolution\n\n\nThis is the kind of thing that `ggplot` does without\nbatting an eyelid:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(lepro, aes(x = pre, y = post, colour = drug)) + geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ancova_files/figure-html/leprosy-3-1.png){width=672}\n:::\n:::\n\n       \n \n$\\blacksquare$\n\n(c) Does it appear that including the pre-treatment score was a\ngood idea? Explain briefly.\n \nSolution\n\n\nThe overall trend on the scatterplot is that a higher `pre`\ntends to go with a higher `post`, regardless of drug, so\nincluding this information appears to be informative.\nI personally suspect that there's some fan-out happening on the\npre-post relationship, but I'm not planning to make you explore that.\n \n$\\blacksquare$\n\n(d) What about this dataset suggests that analysis of\ncovariance is a method worth trying?\n \nSolution\n\n\nThe key is a mixture of categorical and quantitative explanatory\nvariables. Here we have a categorical variable `drug` and a\nquantitative one `pre`. \nIf we had only one type of explanatory variable, we could do a\nregression or an ANOVA as appropriate. But we don't. In some ways,\nit's not worth making a fuss about the distinction, because\nregressions and ANOVAs are all linear models anyway. But you may\nsee the term \"analysis of covariance\", so it's worth your while\nto know what it's about. \n \n$\\blacksquare$\n\n(e) Fit an analysis of covariance model to predict\npost-treatment score. Include an interaction between your\nexplanatory variables. (You don't need to look at the output from\nthe model.)\n \nSolution\n\n\nThis is what you'd guess. `lm` handles the interaction\nproperly, even though `pre` is a  quantitative variable.\n\n::: {.cell}\n\n```{.r .cell-code}\nlepro.1 <- lm(post ~ pre * drug, data = lepro)\n```\n:::\n\n     \n\nI wanted to take a look, so I did:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lepro.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = post ~ pre * drug, data = lepro)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.225 -2.437 -0.586  1.126  8.775 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept)  -1.6306     2.9455  -0.554   0.5850  \npre           0.7452     0.2849   2.616   0.0152 *\ndrugD        -2.9549     4.1246  -0.716   0.4806  \ndrugF        -1.4780     5.4678  -0.270   0.7892  \npre:drugD     0.3233     0.3846   0.841   0.4089  \npre:drugF     0.4492     0.4458   1.008   0.3236  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.07 on 24 degrees of freedom\nMultiple R-squared:  0.6915,\tAdjusted R-squared:  0.6272 \nF-statistic: 10.76 on 5 and 24 DF,  p-value: 1.63e-05\n```\n\n\n:::\n:::\n\n \n\nFor testing the interaction, there are *two* slope coefficients\nthat should be zero if there is no interaction. So we have to test\nthis with `drop1`, which is next.\n \n$\\blacksquare$\n\n(f) Pass your fitted model of the last part into\n`drop1`. Is\nthe interaction term significant?\n\n\nSolution\n\n\nJust this:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(lepro.1, test = \"F\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Sum of Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"RSS\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"NA\",\"3\":\"397.5580\",\"4\":\"89.52430\",\"5\":\"NA\",\"6\":\"NA\",\"_rn_\":\"<none>\"},{\"1\":\"2\",\"2\":\"19.64465\",\"3\":\"417.2026\",\"4\":\"86.97124\",\"5\":\"0.5929594\",\"6\":\"0.5605848\",\"_rn_\":\"pre:drug\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n       \n\nThere is only a test for the interaction term because you can't take out the main effects until you've taken out the interaction.\n\nThe P-value for the interaction is very large (0.5606) so it is\nnowhere near significant. We can drop the interaction.\n\n\n$\\blacksquare$\n\n(g) Fit a model without the interaction. Is this a sensible thing to\ndo (in addition, that is, to the fact that I just asked you to do it)?\n\n\nSolution\n\n\nChange the `*` to a `+`:\n\n::: {.cell}\n\n```{.r .cell-code}\nlepro.2 <- lm(post ~ pre + drug, data = lepro)\n```\n:::\n\n     \n\nOr use `update` (not much in it, here):\n\n::: {.cell}\n\n```{.r .cell-code}\nlepro.2a <- update(lepro.1, . ~ . - pre:drug)\n```\n:::\n\n \n\nWe just said that the interaction could come out, since it wasn't\nsignificant, so this is exactly the model that we should be fitting.\n\n\n$\\blacksquare$\n\n(h) Take a look at the `summary` of your preferred\nmodel. Is there a significant effect of pre-treatment score?\nDescribe the effects of the different drugs on the post-treatment\nscore. (Don't do any tests for `drug`.) Does your comparison\nof drugs make sense?\n \nSolution\n\n\nMine was the no-interaction model `lepro.2`:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lepro.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = post ~ pre + drug, data = lepro)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4115 -2.3891 -0.5711  1.7237  8.5885 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -3.8808     1.9862  -1.954   0.0616 .  \npre           0.9872     0.1645   6.001 2.45e-06 ***\ndrugD         0.1090     1.7951   0.061   0.9521    \ndrugF         3.4461     1.8868   1.826   0.0793 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.006 on 26 degrees of freedom\nMultiple R-squared:  0.6763,\tAdjusted R-squared:  0.6389 \nF-statistic:  18.1 on 3 and 26 DF,  p-value: 1.501e-06\n```\n\n\n:::\n:::\n\n     \n\nThe pre-treatment term is definitely significant, with a P-value of\n0.0000025. So pre-treatment score definitely has an impact on\npost-treatment score.\n\nI didn't ask you to test for significance of drugs. I just wanted you\nto assess their coefficients. Drug A is being used as the baseline, so\nits coefficient is zero. Drug D has a slightly positive coefficient\n(0.109) so its average bacilli score is slightly higher (for any\npre-treatment score) than for drug A. Drug F, which was the placebo,\nhas a slope of 3.446, so its average bacilli score is a fair bit\nhigher than for either of the other drugs. This makes sense because a\nhigher score is worse, and the two \"real\" drugs are both better than\nthe fake one.\n\nWhether there is a real drug difference, I didn't ask you to assess,\nbut you could do it by `drop1` again, this way:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(lepro.2, test = \"F\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Sum of Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"RSS\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"AIC\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"NA\",\"3\":\"417.2026\",\"4\":\"86.97124\",\"5\":\"NA\",\"6\":\"NA\",\"_rn_\":\"<none>\"},{\"1\":\"1\",\"2\":\"577.89740\",\"3\":\"995.1000\",\"4\":\"111.04938\",\"5\":\"36.014475\",\"6\":\"2.454330e-06\",\"_rn_\":\"pre\"},{\"1\":\"2\",\"2\":\"68.55371\",\"3\":\"485.7563\",\"4\":\"87.53529\",\"5\":\"2.136128\",\"6\":\"1.383793e-01\",\"_rn_\":\"drug\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n \n\nThis is actually not significant.^[This is why I didn't ask you to test this, since it would have confused the story.]\nThis is one of those cases where the non-significant `drug` has\na slightly *bigger* AIC than `<none>`, so `drop1`\nconsiders it best to leave it in the model.\n \n$\\blacksquare$\n\n(i) Obtain predicted values for `post` for each of the\nthree drugs at `pre` scores 5, 12 and 20. To do this, obtain\na new data frame that has all 9 combinations of drugs and\n`pre` scores, and then feed this into `predict` using\nyour preferred model.^[Analysis of covariance is just a linear  model, so *predict* works the same here as in regression.]\n \nSolution\n\n\nFirst, make the new data frame for predicting from. I'm doing this in small steps for clarity:\nfirst, I define all the drugs and `pre` values, and then I\nfeed them into `datagrid`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndrugs <- c(\"A\", \"D\", \"F\")\npres <- c(5, 12, 20)\nnew <- datagrid(model = lepro.2, drug = drugs, pre = pres)\nnew\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"drug\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"pre\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rowid\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"A\",\"2\":\"5\",\"3\":\"1\"},{\"1\":\"A\",\"2\":\"12\",\"3\":\"2\"},{\"1\":\"A\",\"2\":\"20\",\"3\":\"3\"},{\"1\":\"D\",\"2\":\"5\",\"3\":\"4\"},{\"1\":\"D\",\"2\":\"12\",\"3\":\"5\"},{\"1\":\"D\",\"2\":\"20\",\"3\":\"6\"},{\"1\":\"F\",\"2\":\"5\",\"3\":\"7\"},{\"1\":\"F\",\"2\":\"12\",\"3\":\"8\"},{\"1\":\"F\",\"2\":\"20\",\"3\":\"9\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nNow I obtain the predictions, from my best model `lepro.2`:\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- cbind(predictions(lepro.2, newdata = new))\npreds %>% select(drug, pre, estimate, conf.low, conf.high)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"drug\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"pre\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.low\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.high\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"A\",\"2\":\"5\",\"3\":\"1.055110\",\"4\":\"-1.7884966\",\"5\":\"3.898716\"},{\"1\":\"A\",\"2\":\"12\",\"3\":\"7.965396\",\"4\":\"5.3344494\",\"5\":\"10.596343\"},{\"1\":\"A\",\"2\":\"20\",\"3\":\"15.862867\",\"4\":\"11.6125631\",\"5\":\"20.113170\"},{\"1\":\"D\",\"2\":\"5\",\"3\":\"1.164081\",\"4\":\"-1.7961210\",\"5\":\"4.124283\"},{\"1\":\"D\",\"2\":\"12\",\"3\":\"8.074368\",\"4\":\"5.5092368\",\"5\":\"10.639498\"},{\"1\":\"D\",\"2\":\"20\",\"3\":\"15.971838\",\"4\":\"11.9025776\",\"5\":\"20.041099\"},{\"1\":\"F\",\"2\":\"5\",\"3\":\"4.501248\",\"4\":\"0.9443556\",\"5\":\"8.058140\"},{\"1\":\"F\",\"2\":\"12\",\"3\":\"11.411535\",\"4\":\"8.9118746\",\"5\":\"13.911195\"},{\"1\":\"F\",\"2\":\"20\",\"3\":\"19.309005\",\"4\":\"15.9320081\",\"5\":\"22.686002\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n \n\nI gave this a name in case I feel like using it again later.\n \n$\\blacksquare$\n\n(j) Now, plot the data with the fitted lines on. \n\nSolution\n\nThe starting point is to plot the predictions, which is `plot_predictions`:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(lepro.2, condition = c(\"pre\", \"drug\"))\n```\n\n::: {.cell-output-display}\n![](ancova_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\nThe olive-coloured line is actually the red and green lines right next to each other. You can check from the previous part that the predictions for drugs A and D are very close together, with those for drug F (the placebo) being higher (worse).\n\nThis is a `ggplot`, so we can add things to it. The idea is to say that the next thing to plot comes from some other dataframe, and to specify everything we need (that is, not to inherit from the original `ggplot` that is lurking within `plot_predictions`):\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(lepro.2, condition = c(\"pre\", \"drug\")) +\n  geom_point(data = lepro, aes(x = pre, y = post, colour = drug), \n             inherit.aes = FALSE)\n```\n\n::: {.cell-output-display}\n![](ancova_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\nThere is quite a lot of variability (which is why those confidence bands are so wide), but at least some of the blue points from drug F are above the others (worse), and there is very little to choose between drugs A and D.\n\n$\\blacksquare$\n\n(k) Are the lines on your plot parallel, with the same slopes? Is this what you would\nexpect? Explain briefly.\n \nSolution\n\n\nMy lines are parallel. This is exactly what I would expect, since\nmy best model has no interaction, and the interaction is what\nwould make the lines *not* be parallel. \nIf your best model\n*did* have the interaction term still in it, your predictions\nwould have been these:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(lepro.1, condition = c(\"pre\", \"drug\")) +\n  geom_point(data = lepro, aes(x = pre, y = post, colour = drug), inherit.aes = FALSE)\n```\n\n::: {.cell-output-display}\n![](ancova_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\nThere is, as you see, a\nsubstantial scatter in the points that would make it very difficult to\nprove that those three slopes are really different, even though the lines cross.\n \n$\\blacksquare$\n\n\n\n",
    "supporting": [
      "ancova_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}