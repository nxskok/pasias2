{
  "hash": "456da2744faabd7ecdf5450b3004d27b",
  "result": {
    "markdown": "# Multidimensional Scaling\n\nPackages for this chapter:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggbiplot)\nlibrary(tidyverse)\nlibrary(ggrepel)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Making a map of Wisconsin\n\n\n The file\n[link](http://ritsokiguess.site/datafiles/wisconsin.txt) contains\nthe road distances (in miles) between 12 cities in Wisconsin and\nneighbouring states. We are going to try to reproduce a map of the\narea using multidimensional scaling.\n\n\n(a) Read in the data and create a `dist` object,\nbearing in mind that the data in the file are already\ndistances. Display your `dist` object. Probably, displaying\nthe data that you read in is a good idea also.\n \n\n(b) Obtain a vector containing the city names. (This is easy,\nand not really necessary, but it was here before when I did things\na different way.)\n \n\n(c) Run a (metric) multidimensional scaling on the data, to\nobtain a two-dimensional representation of the cities. (You\ndon't need to look at the results yet.)\n \n\n(d) Plot the results of the multidimensional scaling,\nlabelling the cities with their names. Use your judgement to\ndecide where to place the city names, and how to  make sure the\nwhole city names are shown on the map.\n \n\n(e) Are cities close together on your map also close together\nin real life? Give an example or two.\n \n\n(f) Obtain a Google (or other) map of the area containing these\ntwelve cities. (The way I expected you to do this when this was a\nhand-in problem was to take a screenshot or similar and include that\nin your document.)\n\n \n\n(g) Discuss how the map that came out of the multidimensional\nscaling corresponds to the actual (Google) map.\n\n \n\n(h) Calculate something that demonstrates that a one-dimensional\nmap of the cities is a much worse representation than the\ntwo-dimensional one that we made before. (I'm planning to get to this\nin class, but if we skip it, don't worry about this part.)\n\n \n\n\n\n\n\n##  Things that feel similar to each other\n\n\n Which objects feel similar to one another and which ones\nfeel different? Can we draw them on a \"map\"? 30\nsubjects^[Probably students in a psychology course. You know  how it goes.] were each\ngiven 17 different objects to feel, for example \"inner surface of pine  bark\", \n\"rubber eraser\" and \n\"nylon scouring pad\". The\nsubjects had to group the objects into a maximum of 8 groups such that\nthe objects within a group felt similar, and the ones in different\ngroups felt different.^[The maximum number of groups was to  ensure that each subject actually *did* group some objects  together, rather than saying that they all feel different.] A\ndissimilarity matrix was formed by counting how many subjects put each\npair of objects into *different* groups, so that the\ndissimilarity ranged from 0 (the objects were always put together in\nthe same group) to 30 (the objects were not put together into the same\ngroup by any of the subjects). \n\nThe data are in\n[link](http://ritsokiguess.site/datafiles/stimuli.txt). \n\n\n\n(a) Look at the data, and read in the file appropriately. Do you\nhave something square in shape, apart from any columns of object\nnames?  Do your columns have the same names as the objects?\n\n\n\n(b) Obtain the names of the objects. Note that they are rather\nlong. \n\n\n\n(c) Set the column names of your data frame to be your object\nnames, using `names`. Before you rush to do that, figure out\nhow many column names you need, and supply values for any extra\nones. Check that your data frame now has the right column names.\n\n\n\n(d) <a name=\"part:distances\">*</a>  \nConvert your data frame into a distance object. Take a look at the\n(rather long) result.\n\n\n\n(e) Obtain and plot a  (metric) multidimensional scaling map of\nthese data.  Label the points with the name of the\nobject they represent. (Note that\n`geom_text_repel` has an option `size` that controls\nthe size of the text.)\n\n\n\n(f) Find a pair of objects that are close together on your\nplot. Look back at your answer to part~(<a href=\"#part:distances\">here</a>): is\nthe distance between those objects small? Explain briefly.\n\n\n\n(g) Obtain a measure of goodness of fit for this\nmultidimensional scaling map.\n\n\n\n(h) Obtain a cluster analysis for the same data, using Ward's\nmethod. Obtain a dendrogram. What seems to be an appropriate number\nof clusters?  Mark them on your dendrogram too.\n\n\n\n(i) Discuss as briefly as seems reasonable whether your\nclusters tell the same story as the map that came from\nmultidimensional scaling. (There were only three marks for this, so you\ndon't need to go overboard.) Optionally, think about creating a plot\nthat will make it easier to see the correspondence between your\nclusters and the MDS map.\n\n\n\n\n\n\n\n\n\n##  Confusing letters\n\n\n Two researchers studied how often people mistook one letter\nfor another one. They did this by showing their subjects each\n(uppercase) letter for a few milliseconds only, and asking them which\nletter (out of a list) they just saw. The researchers obtain a\n\"confusion matrix\" in which, for example, the W-Q entry is the total\nof W's taken as Q and Q's taken as W. This confusion matrix is in\n[link](http://ritsokiguess.site/datafiles/letterrec.txt). Note that\nthe confusions are actually *similarities* rather than\ndissimilarities: a large number means that the two letters concerned\nare easily confused, that is, similar. Similarities can be converted\nto dissimilarities by subtracting them from a larger number than\nanything in the table (that is, subtracting from 21 is good here).\n\n\n\n(a) Read in the confusion matrix and convert it to\ndissimilarities and then to a\n`dist` object, displaying the `dist` object that you\nobtain. \n\n\n\n(b) Run a multidimensional scaling, with the default two\ndimensions, on your `dist` object, and display the\nresults. (Making a graph is coming later.)\n\n\n(c) Obtain a vector of the names of the letters that were\nconfused in this study. \n\n\n(d) Plot your multidimensional scaling map. To do this, first\ncreate a data frame containing the points you want to plot and their\nlabels, and then plot the points labelled by the right thing.\n\n\n(e) Pick a pair of letters appear close together on your\nmap. Does it make sense, from looking at these letters, that they\nwould be easy to confuse? Explain briefly.\n\n\n(f) Verify that your chosen pair of letters was often confused\nin the data.\n\n\n\n\n\n##  More beer please\n\n\n Previously, you did a cluster analysis of\nten brands of beer, as rated by 32 students. This time, we will do a\nnon-metric multidimensional scaling of those same brands of beer. The\ndata are in [link](http://ritsokiguess.site/datafiles/beer.txt).\n\n\n\n(a) Noting that we want to assess distances between brands of beer,\nread in the data and do whatever you need to do to work out\ndistances between the beers. Show your result.\n \n\n(b) Obtain a non-metric multidimensional scaling of the\nbeers. (Comment coming up in a moment.)\n \n\n(c) Obtain the `stress` value of the map, and comment on it.\n \n\n(d) Obtain a map of the beers, labelled with the names of the\nbeers. \n \n\n(e) Find a pair of beers close together on your map. Are they\nsimilar in terms of student ratings? Explain briefly.\n \n\n(f) In our cluster analysis, we found that Anchor Steam, Pete's\nWicked Ale, Guinness and Sierra Nevada were all in the same\ncluster. Would you expect them to be close together on your map? Are\nthey? Explain briefly.\n \n\n\n\n\n\n##  Feeling similar, again\n\n\n Previously, we looked at an experiment about which objects feel similar to one another and which ones feel different.\n\n30 subjects were each\ngiven 17 different objects to feel, for example \n\"inner surface of pine  bark\", \n\"rubber eraser\" and \n\"nylon scouring pad\". The\nsubjects had to group the objects into a maximum of 8 groups such that\nthe objects within a group felt similar, and the ones in different\ngroups felt different.\nA\ndissimilarity matrix was formed by counting how many subjects put each\npair of objects into *different* groups, so that the\ndissimilarity ranged from 0 (the objects were always put together in\nthe same group) to 30 (the objects were not put together into the same\ngroup by any of the subjects). \n\nThe data are in\n[link](http://ritsokiguess.site/datafiles/stimuli.txt). These have\n*no* column names.\n\nThis time we are going to try *non-metric* multidimensional\nscaling, to see whether that produces a more reasonable map. The\nreading in of the data is the same as before (so I have reduced the\nmarks given for it).\n\n\n\n(a) Obtain and display the distance matrix that you used last\ntime for these data. (I don't care whether you run all the code\nagain, or whether you just produce the matrix from where you had it\nbefore on R Studio. Correct is all I care about.)\n\n\n\n(b) Obtain a non-metric multidimensional scaling map of the\nobjects. (No plotting or comments yet.)\n\n\n\n(c) <a name=\"part:stress\">*</a> Obtain a number that says how well the map reproduces the\ndistances in the data, and comment on that number.\n\n\n\n(d) Plot the non-metric multidimensional scaling map. Label each\npoint with its (full) object name, sized suitably.\n\n\n\n(e) <a name=\"part:incons\">*</a> Find all the distances in your distance matrix that are 10\nor less (there should be three of them). Find these pairs of objects\non your map. Describe where they are on your map. Do\nthey appear to be the three closest pairs of objects?\n\n\n\n(f) Consider again your conclusions in parts (<a href=\"#part:stress\">here</a>)\nand (<a href=\"#part:incons\">here</a>). Explain briefly how they are consistent.\n\n\n\n(g) Would a three-dimensional map work better than a\ntwo-dimensional one, bearing in mind that a three-dimensional map\nwill need something like `rgl` to interpret? Calculate\nsomething that will help you decide, and explain what you think.\n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n##  Making a map of Wisconsin\n\n\n The file\n[link](http://ritsokiguess.site/datafiles/wisconsin.txt) contains\nthe road distances (in miles) between 12 cities in Wisconsin and\nneighbouring states. We are going to try to reproduce a map of the\narea using multidimensional scaling.\n\n\n(a) Read in the data and create a `dist` object,\nbearing in mind that the data in the file are already\ndistances. Display your `dist` object. Probably, displaying\nthe data that you read in is a good idea also.\n \nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/wisconsin.txt\"\nwisc <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  location = col_character(),\n  Appleton = col_double(),\n  Beloit = col_double(),\n  Fort.Atkinson = col_double(),\n  Madison = col_double(),\n  Marshfield = col_double(),\n  Milwaukee = col_double(),\n  Monroe = col_double(),\n  Superior = col_double(),\n  Wausau = col_double(),\n  Dubuque = col_double(),\n  St.Paul = col_double(),\n  Chicago = col_double()\n)\n```\n:::\n\n```{.r .cell-code}\nwisc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 x 13\n   location    Appleton Beloit Fort.Atkinson Madison Marshfield Milwaukee Monroe\n   <chr>          <dbl>  <dbl>         <dbl>   <dbl>      <dbl>     <dbl>  <dbl>\n 1 Appleton           0    130            98     102        103       100    149\n 2 Beloit           130      0            33      50        185        73     33\n 3 Fort.Atkin~       98     33             0      36        164        54     58\n 4 Madison          102     50            36       0        138        77     47\n 5 Marshfield       103    185           164     138          0       184    170\n 6 Milwaukee        100     73            54      77        184         0    107\n 7 Monroe           149     33            58      47        170       107      0\n 8 Superior         315    377           359     330        219       394    362\n 9 Wausau            91    186           166     139         45       181    186\n10 Dubuque          196     94           119      95        186       168     61\n11 St.Paul          257    304           287     258        161       322    289\n12 Chicago          186     97           113     146        276        93    130\n# i 5 more variables: Superior <dbl>, Wausau <dbl>, Dubuque <dbl>,\n#   St.Paul <dbl>, Chicago <dbl>\n```\n:::\n:::\n\n       \n\nThe first time I did this, I had a blank line on the end of the data\nfile, so I had a blank `location` and missing values for all\nthe distances for it. I tidied that up before sharing the file with\nyou, though.\n\nSo, the first column is the names of the places, which we should get\nrid of before we make a `dist` object using `as.dist`\n(since what we read in is already distances). The columns are also the\nnames  of the places, so we won't lose anything by getting rid of the\n`location` column:\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- wisc %>%\n  select(-location) %>%\n  as.dist()\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Appleton Beloit Fort.Atkinson Madison Marshfield Milwaukee Monroe\nBeloit             130                                                         \nFort.Atkinson       98     33                                                  \nMadison            102     50            36                                    \nMarshfield         103    185           164     138                            \nMilwaukee          100     73            54      77        184                 \nMonroe             149     33            58      47        170       107       \nSuperior           315    377           359     330        219       394    362\nWausau              91    186           166     139         45       181    186\nDubuque            196     94           119      95        186       168     61\nSt.Paul            257    304           287     258        161       322    289\nChicago            186     97           113     146        276        93    130\n              Superior Wausau Dubuque St.Paul\nBeloit                                       \nFort.Atkinson                                \nMadison                                      \nMarshfield                                   \nMilwaukee                                    \nMonroe                                       \nSuperior                                     \nWausau             223                       \nDubuque            351    215                \nSt.Paul            162    175     274        \nChicago            467    275     184     395\n```\n:::\n:::\n\n \n \n$\\blacksquare$\n\n(b) Obtain a vector containing the city names. (This is easy,\nand not really necessary, but it was here before when I did things\na different way.)\n \nSolution\n\n\nThe `location` column of the data frame you read in\nfrom the file:\n\n::: {.cell}\n\n```{.r .cell-code}\ncities <- wisc$location\ncities\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Appleton\"      \"Beloit\"        \"Fort.Atkinson\" \"Madison\"      \n [5] \"Marshfield\"    \"Milwaukee\"     \"Monroe\"        \"Superior\"     \n [9] \"Wausau\"        \"Dubuque\"       \"St.Paul\"       \"Chicago\"      \n```\n:::\n:::\n\n       \n \n$\\blacksquare$\n\n(c) Run a (metric) multidimensional scaling on the data, to\nobtain a two-dimensional representation of the cities. (You\ndon't need to look at the results yet.)\n \nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwisc.1 <- cmdscale(d)\n```\n:::\n\n       \n \n$\\blacksquare$\n\n(d) Plot the results of the multidimensional scaling,\nlabelling the cities with their names. Use your judgement to\ndecide where to place the city names, and how to  make sure the\nwhole city names are shown on the map.\n \nSolution\n\n\nLet's see what `wisc.1` has in it, and make a data\nframe of the right thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(wisc.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                    [,1]       [,2]\nAppleton       -13.37076  85.067148\nBeloit         -92.94157 -20.205916\nFort.Atkinson  -74.07473   4.804039\nMadison        -44.68148 -11.252521\nMarshfield      80.61250  27.097882\nMilwaukee     -102.87582  49.849552\n```\n:::\n:::\n\n         \nTwo unnamed columns (the display indicates that it's a `matrix`\nrather than a data frame). As we saw in class, if we make a data frame\nout of this, the columns will get names `X1` and\n`X2`. Those are perfectly good names for coordinates. The city\nnames on the left of `wisc.1` are actually row names rather\nthan an actual genuine column. It's probably best *not* to assume\nthat they will make it through the transition to a data frame, so\nwe'll explicitly create a column called `city` with the city\nnames (that we saved before):\n\n::: {.cell}\n\n```{.r .cell-code}\ndd <- data.frame(wisc.1, city = cities)\ndd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      X1          X2          city\nAppleton       -13.37076   85.067148      Appleton\nBeloit         -92.94157  -20.205916        Beloit\nFort.Atkinson  -74.07473    4.804039 Fort.Atkinson\nMadison        -44.68148  -11.252521       Madison\nMarshfield      80.61250   27.097882    Marshfield\nMilwaukee     -102.87582   49.849552     Milwaukee\nMonroe         -74.66603  -48.422639        Monroe\nSuperior       279.27573   -8.621892      Superior\nWausau          79.19504   60.997371        Wausau\nDubuque        -50.92029 -108.488036       Dubuque\nSt.Paul        199.16640  -39.595481       St.Paul\nChicago       -184.71900    8.770492       Chicago\n```\n:::\n:::\n\n \n\nThere are only 12 rows, so it's fine to display them all.\n\nI'm calling this one `dd` since I have another `d`\nelsewhere that I want to keep. I should use better names.\n\nI think the best use of your judgement is to go straight to\n`geom_text_repel` from package `ggrepel`:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dd, aes(x = X1, y = X2, label = city)) +\n  geom_point() +\n  geom_text_repel() +\n  coord_fixed()\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/wisconsin-7-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nYour map may come out different from mine, but subject to the usual\nstuff about rotation and reflection it should be equivalent to\nmine. You should include the `coord_fixed` to get the scales\nthe same (a corresponding distance on the two scales should take the\nsame space). This one didn't come out quite square because the MDS\nsays the points should be in a rectangle (stretching further one way\nthan the other). \n \n$\\blacksquare$\n\n(e) Are cities close together on your map also close together\nin real life? Give an example or two.\n \nSolution\n\n\nOn the map, the trio of cities Madison, Beloit and Fort Atkinson\nare closest together. How far apart are they actually? Well, you\ncan go back to the original file (or display of what I called\n`d`) and find them, or you can do this:\n\n::: {.cell}\n\n```{.r .cell-code}\ncities\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Appleton\"      \"Beloit\"        \"Fort.Atkinson\" \"Madison\"      \n [5] \"Marshfield\"    \"Milwaukee\"     \"Monroe\"        \"Superior\"     \n [9] \"Wausau\"        \"Dubuque\"       \"St.Paul\"       \"Chicago\"      \n```\n:::\n:::\n\n     \n\nCities 2, 3 and 4, so:\n\n::: {.cell}\n\n```{.r .cell-code}\nwisc %>% slice(2:4) %>% select(c(1, 3:5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 4\n  location      Beloit Fort.Atkinson Madison\n  <chr>          <dbl>         <dbl>   <dbl>\n1 Beloit             0            33      50\n2 Fort.Atkinson     33             0      36\n3 Madison           50            36       0\n```\n:::\n:::\n\n \n\nThe column numbers are off by one, since the first column is the names\nof the cities, which I decided to display here. It came out right, anyway.\n\nThese are all less than 50 miles or less apart. There are some others\nthis close in the original data: Monroe and Madison are 47 miles\napart, Wausau and Marshfield are 45 miles apart, but these appear\nfurther apart on the map.\nExtra: the slice-select thing doesn't work on `d` because that is not\na data frame. It is actually stored internally as a\n*one*-dimensional vector that displays nicely, but if you want to\npull things out of it you have to figure out where in the vector they are:\n\n::: {.cell}\n\n```{.r .cell-code}\nprint.default(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 130  98 102 103 100 149 315  91 196 257 186  33  50 185  73  33 377 186  94\n[20] 304  97  36 164  54  58 359 166 119 287 113 138  77  47 330 139  95 258 146\n[39] 184 170 219  45 186 161 276 107 394 181 168 322  93 362 186  61 289 130 223\n[58] 351 162 467 215 175 275 274 184 395\nattr(,\"Labels\")\n [1] \"Appleton\"      \"Beloit\"        \"Fort.Atkinson\" \"Madison\"      \n [5] \"Marshfield\"    \"Milwaukee\"     \"Monroe\"        \"Superior\"     \n [9] \"Wausau\"        \"Dubuque\"       \"St.Paul\"       \"Chicago\"      \nattr(,\"Size\")\n[1] 12\nattr(,\"call\")\nas.dist.default(m = .)\nattr(,\"class\")\n[1] \"dist\"\nattr(,\"Diag\")\n[1] FALSE\nattr(,\"Upper\")\n[1] FALSE\n```\n:::\n:::\n\n \n\nIf you compare that with the usual display of `d`, this way\ngoes all the way down the first column ending at 130, then all the way\ndown the second column (which has one fewer entry), ending at 467, and\nso on. Thus the three entries we picked out are at $11+1=12$,\n$11+2=13$, and $11+10+1=22$:\n\n::: {.cell}\n\n```{.r .cell-code}\nd[12]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 33\n```\n:::\n\n```{.r .cell-code}\nd[13]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 50\n```\n:::\n\n```{.r .cell-code}\nd[22]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 36\n```\n:::\n:::\n\n \n\nIt's very easy to be off by one in this sort of calculation. There are\n12 cities altogether, so *11* distances in the first column, 10\nin the second, and so on. This was about my third attempt.\n\nI don't much care which cities you look at. Finding some cities that\nare reasonably close on the map and doing some kind of critical\n assessment of their actual distances apart is all I want. \n \n\n$\\blacksquare$\n\n(f) Obtain a Google (or other) map of the area containing these\ntwelve cities. (The way I expected you to do this when this was a\nhand-in problem was to take a screenshot or similar and include that\nin your document.)\n\n \nSolution\n\n\nI do this using R in the maps chapter. See there for how to do it this way.\n \n\n$\\blacksquare$\n\n(g) Discuss how the map that came out of the multidimensional\nscaling corresponds to the actual (Google) map.\n\n \nSolution\n\n\nLet's pick a few places from the actual map, and make a table of\nwhere they are on the actual map and the `cmdscale` map:\n\n```\n\n Place        Real              Cmdscale       \n----------------------------------------------\n Superior     northwest         central east   \n St. Paul     central west      southeast      \n Dubuque      central south     central south  \n Chicago      southeast         central west   \n Appleton     central east      central north  \n\n\n```\n\n\nThis is a bit tricky. Dubuque is the only one in the right place, and\nthe others that were west have become east and vice versa. So I think\nthere is a flipping across a line going through Dubuque. That seems to\nbe the most important thing; if you imagine the other points being\nflipped across a line going north-south through Dubuque, they all end\nup in about the right place. There might be a little rotation as well,\nbut I'll call that close enough.\n\n(For you, any comment along the lines of \"flipped around this line\"\nor \"rotated about this much\" that seems to describe what has happened, is\nfine.)\n \n\n$\\blacksquare$\n\n(h) Calculate something that demonstrates that a one-dimensional\nmap of the cities is a much worse representation than the\ntwo-dimensional one that we made before. (I'm planning to get to this\nin class, but if we skip it, don't worry about this part.)\n\n \nSolution\n\n\nRun again with `eig=T` and take a look at `GOF` (uppercase):\n\n::: {.cell}\n\n```{.r .cell-code}\ncmdscale(d, 2, eig = T)$GOF\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9129333 0.9315871\n```\n:::\n\n```{.r .cell-code}\ncmdscale(d, 1, eig = T)$GOF\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7916925 0.8078690\n```\n:::\n:::\n\n   \n\nThe goodness-of-fit of the two-dimensional solution is pretty\ngood,^[As it ought to be, since there is a real answer  here: the cities *do* exist as locations in two dimensions, if you ignore the curvature of the earth. The goodness of fit isn't  100% because the roads bend a bit.]\nbut that of the one-dimensional solution (which arranges all the\ncities along a line) is pretty awful in comparison.\n\nHow awful? Let's find out. I should have saved it from just above, but\nnow I have to do it again. For the plot, `ones` is a string of\nones, as many as there are cities.\n\n::: {.cell}\n\n```{.r .cell-code}\nones <- rep(1, 12)\nv <- cmdscale(d, 1, eig = T)\nddd <- as_tibble(v$points) %>%\n  mutate(one = ones, city = cities)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\ni Using compatibility `.name_repair`.\n```\n:::\n\n```{.r .cell-code}\nddd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 x 3\n       V1   one city         \n    <dbl> <dbl> <chr>        \n 1  -13.4     1 Appleton     \n 2  -92.9     1 Beloit       \n 3  -74.1     1 Fort.Atkinson\n 4  -44.7     1 Madison      \n 5   80.6     1 Marshfield   \n 6 -103.      1 Milwaukee    \n 7  -74.7     1 Monroe       \n 8  279.      1 Superior     \n 9   79.2     1 Wausau       \n10  -50.9     1 Dubuque      \n11  199.      1 St.Paul      \n12 -185.      1 Chicago      \n```\n:::\n:::\n\n \n\n(the one-column matrix of points didn't have a name, so it acquired\nthe name `V1`), and the plot:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ddd, aes(x = one, y = V1, label = city)) +\n  geom_point() + geom_text_repel()\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/wisconsin-13-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nThe cities get mapped onto a line that goes northwest (top) to\nsoutheast (bottom). This is not completely terrible, since there\naren't really any cities in the northeast of the state, but it *is*\npretty awful.\n \n$\\blacksquare$\n\n\n\n\n\n##  Things that feel similar to each other\n\n\nWhich objects feel similar to one another and which ones\nfeel different? Can we draw them on a \"map\"? 30\nsubjects^[Probably students in a psychology course. You know  how it goes.] were each\ngiven 17 different objects to feel, for example \"inner surface of pine  bark\", \n\"rubber eraser\" and \n\"nylon scouring pad\". The\nsubjects had to group the objects into a maximum of 8 groups such that\nthe objects within a group felt similar, and the ones in different\ngroups felt different.^[The maximum number of groups was to  ensure that each subject actually *did* group some objects  together, rather than saying that they all feel different.] A\ndissimilarity matrix was formed by counting how many subjects put each\npair of objects into *different* groups, so that the\ndissimilarity ranged from 0 (the objects were always put together in\nthe same group) to 30 (the objects were not put together into the same\ngroup by any of the subjects). \n\nThe data are in\n[link](http://ritsokiguess.site/datafiles/stimuli.txt). \n\n\n\n(a) Look at the data, and read in the file appropriately. Do you\nhave something square in shape, apart from any columns of object\nnames?  Do your columns have the same names as the objects?\n\n\nSolution\n\n\nLooking at the file first, there are *no column names*. So we\nhave to tell `read_delim` that:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/stimuli.txt\"\nstimuli <- read_delim(my_url, \" \", col_names = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 17 Columns: 18\n-- Column specification --------------------------------------------------------\nDelimiter: \" \"\nchr  (1): X1\ndbl (17): X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16,...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nstimuli\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 17 x 18\n   X1       X2    X3    X4    X5    X6    X7    X8    X9   X10   X11   X12   X13\n   <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 inne~     0    22    23    24    26    27    26    23    24    23    23    18\n 2 brick    22     0    27    27    27    29    29    28    16    18    28    25\n 3 card~    23    27     0    18    19    28    23    24    24    29    27    28\n 4 cork     24    27    18     0    15    28    25    26    28    28    20    27\n 5 rubb~    26    27    19    15     0    28    20    27    24    27    24    25\n 6 felt     27    29    28    28    28     0    24    28    29    26    26    29\n 7 leat~    26    29    23    25    20    24     0    22    28    28    27    26\n 8 rigi~    23    28    24    26    27    28    22     0    27    29    29    27\n 9 very~    24    16    24    28    24    29    28    27     0    21    24    26\n10 nylo~    23    18    29    28    27    26    28    29    21     0    22    16\n11 cell~    23    28    27    20    24    26    27    29    24    22     0    19\n12 wove~    18    25    28    27    25    29    26    27    26    16    19     0\n13 bloc~    23    24    21    10    19    28    25    25    25    25    21    26\n14 ungl~    21    10    26    26    24    29    29    25    12    24    26    26\n15 velv~    28    29    28    28    29     4    24    29    29    27    27    28\n16 waxp~    24    28    24    28    24    28    21    12    29    29    29    27\n17 glos~    22    27    23    29    28    29    20    13    27    28    27    25\n# i 5 more variables: X14 <dbl>, X15 <dbl>, X16 <dbl>, X17 <dbl>, X18 <dbl>\n```\n:::\n:::\n\n     \n\nI have 17 rows and 18 columns, but one of the columns is the column of\nobject names. So I really do have the same number of rows and columns\nof dissimilarities: that is, it *is* square in shape apart from\nthe names.\n\nThe columns *do not* have the same names as the\nobjects; R has used the `X1, X2, ...` names that it uses when\nyou do not have column headers.\n\nI could have supplied the object names to `col_names`, but\nthat is a lot more work than what we do below.\n    \n$\\blacksquare$\n\n(b) Obtain the names of the objects. Note that they are rather\nlong. \n\n\nSolution\n\n\nThe object names are in the first column, `X1`, of the data frame:\n\n::: {.cell}\n\n```{.r .cell-code}\nobjects <- stimuli$X1\nobjects\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"innersurfaceofpinebark\" \"brick\"                  \"cardboard\"             \n [4] \"cork\"                   \"rubbereraser\"           \"felt\"                  \n [7] \"leatherwallet\"          \"rigidplasticsheet\"      \"veryfinesandpaper\"     \n[10] \"nylonscouringpad\"       \"cellulosekitchensponge\" \"wovenstraw\"            \n[13] \"blockofstyrofoam\"       \"unglazedceramictile\"    \"velvet\"                \n[16] \"waxpaper\"               \"glossypaintedwood\"     \n```\n:::\n:::\n\n     \n\nI'm saving these for later.\n    \n$\\blacksquare$\n\n(c) Set the column names of your data frame to be your object\nnames, using `names`. Before you rush to do that, figure out\nhow many column names you need, and supply values for any extra\nones. Check that your data frame now has the right column names.\n\n\nSolution\n\n\nI have 18 columns to name (including the column of object names),\nbut only 17 names, so I need to supply an extra one:\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(stimuli) <- c(\"object\", objects)\nstimuli\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 17 x 18\n   object        innersurfaceofpinebark brick cardboard  cork rubbereraser  felt\n   <chr>                          <dbl> <dbl>     <dbl> <dbl>        <dbl> <dbl>\n 1 innersurface~                      0    22        23    24           26    27\n 2 brick                             22     0        27    27           27    29\n 3 cardboard                         23    27         0    18           19    28\n 4 cork                              24    27        18     0           15    28\n 5 rubbereraser                      26    27        19    15            0    28\n 6 felt                              27    29        28    28           28     0\n 7 leatherwallet                     26    29        23    25           20    24\n 8 rigidplastic~                     23    28        24    26           27    28\n 9 veryfinesand~                     24    16        24    28           24    29\n10 nylonscourin~                     23    18        29    28           27    26\n11 cellulosekit~                     23    28        27    20           24    26\n12 wovenstraw                        18    25        28    27           25    29\n13 blockofstyro~                     23    24        21    10           19    28\n14 unglazedcera~                     21    10        26    26           24    29\n15 velvet                            28    29        28    28           29     4\n16 waxpaper                          24    28        24    28           24    28\n17 glossypainte~                     22    27        23    29           28    29\n# i 11 more variables: leatherwallet <dbl>, rigidplasticsheet <dbl>,\n#   veryfinesandpaper <dbl>, nylonscouringpad <dbl>,\n#   cellulosekitchensponge <dbl>, wovenstraw <dbl>, blockofstyrofoam <dbl>,\n#   unglazedceramictile <dbl>, velvet <dbl>, waxpaper <dbl>,\n#   glossypaintedwood <dbl>\n```\n:::\n:::\n\n     \n    \n$\\blacksquare$\n\n(d) <a name=\"part:distances\">*</a>  \nConvert your data frame into a distance object. Take a look at the\n(rather long) result.\n\n\nSolution\n\n\nThis is `as.dist`, since we have distances\n(dissimilarities) already. Don't forget to take off the first column!\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- stimuli %>% select(-1) %>% as.dist()\n```\n:::\n\n     \n\nI can try and show it all here, tiny, but even then it's long because\nthe column names are long:\n\n::: {.cell}\n\n```{.r .cell-code}\nw <- getOption(\"width\")\noptions(width = 132)\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       innersurfaceofpinebark brick cardboard cork rubbereraser felt leatherwallet rigidplasticsheet\nbrick                                      22                                                                       \ncardboard                                  23    27                                                                 \ncork                                       24    27        18                                                       \nrubbereraser                               26    27        19   15                                                  \nfelt                                       27    29        28   28           28                                     \nleatherwallet                              26    29        23   25           20   24                                \nrigidplasticsheet                          23    28        24   26           27   28            22                  \nveryfinesandpaper                          24    16        24   28           24   29            28                27\nnylonscouringpad                           23    18        29   28           27   26            28                29\ncellulosekitchensponge                     23    28        27   20           24   26            27                29\nwovenstraw                                 18    25        28   27           25   29            26                27\nblockofstyrofoam                           23    24        21   10           19   28            25                25\nunglazedceramictile                        21    10        26   26           24   29            29                25\nvelvet                                     28    29        28   28           29    4            24                29\nwaxpaper                                   24    28        24   28           24   28            21                12\nglossypaintedwood                          22    27        23   29           28   29            20                13\n                       veryfinesandpaper nylonscouringpad cellulosekitchensponge wovenstraw blockofstyrofoam unglazedceramictile\nbrick                                                                                                                           \ncardboard                                                                                                                       \ncork                                                                                                                            \nrubbereraser                                                                                                                    \nfelt                                                                                                                            \nleatherwallet                                                                                                                   \nrigidplasticsheet                                                                                                               \nveryfinesandpaper                                                                                                               \nnylonscouringpad                      21                                                                                        \ncellulosekitchensponge                24               22                                                                       \nwovenstraw                            26               16                     19                                                \nblockofstyrofoam                      25               25                     21         26                                     \nunglazedceramictile                   12               24                     26         26               25                    \nvelvet                                29               27                     27         28               29                  29\nwaxpaper                              29               29                     29         27               26                  28\nglossypaintedwood                     27               28                     27         25               29                  26\n                       velvet waxpaper\nbrick                                 \ncardboard                             \ncork                                  \nrubbereraser                          \nfelt                                  \nleatherwallet                         \nrigidplasticsheet                     \nveryfinesandpaper                     \nnylonscouringpad                      \ncellulosekitchensponge                \nwovenstraw                            \nblockofstyrofoam                      \nunglazedceramictile                   \nvelvet                                \nwaxpaper                   27         \nglossypaintedwood          26       12\n```\n:::\n\n```{.r .cell-code}\noptions(width = w)\n```\n:::\n\n \n\nThe stuff with `width` was to make it display lots of columns,\nand then setting it back afterwards so as not to mess things up later.\nIf\nyou try and take `head` of this, you'll lose the structure. I\ndon't know of a good way to display part of one of these.\n    \n$\\blacksquare$\n\n(e) Obtain and plot a  (metric) multidimensional scaling map of\nthese data.  Label the points with the name of the\nobject they represent. (Note that\n`geom_text_repel` has an option `size` that controls\nthe size of the text.)\n\n\nSolution\n\n\nThis is the procedure. Talking about it is coming in a minute.\n\n::: {.cell}\n\n```{.r .cell-code}\nd.1 <- cmdscale(d, 2)\ndata.frame(d.1, stim = objects) %>%\n  ggplot(aes(x = X1, y = X2, label = stim)) + geom_point() +\n  geom_text_repel(size = 2)\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/stimuli-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n     \n\n`cmdscale` gets the coordinates to plot, then we plot them, and\nthen we place the object names next to the points. I'm not\nquite sure what the scale is for `size`, but `size=2`\nworked for me here, making the text a bit smaller (so that the labels\ndon't overlap), but not so small that you can't read it. You'll\nprobably have to experiment to find a `size` that you like.\n\nIf you forget the `2` after the distance matrix in\n`cmdscale`, you'll get a two-dimensional solution anyway (since\ntwo dimensions is the default). The output is an array of coordinates\nin two dimensions:\n\n::: {.cell}\n\n```{.r .cell-code}\nd.1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                              [,1]       [,2]\ninnersurfaceofpinebark  -2.7066290   1.694420\nbrick                  -12.2011332   5.147970\ncardboard                3.8630322  -9.322759\ncork                    -0.8424358 -14.884926\nrubbereraser             0.1676463 -11.733873\nfelt                     5.1803473   9.328562\nleatherwallet           10.4636668  -1.016525\nrigidplasticsheet       11.0208731   1.201504\nveryfinesandpaper      -11.0869483   2.800988\nnylonscouringpad       -10.4469053   7.232787\ncellulosekitchensponge  -5.3886609  -2.770991\nwovenstraw              -5.2762142   3.836948\nblockofstyrofoam        -2.9950151 -11.927717\nunglazedceramictile    -10.5902291   2.926805\nvelvet                   6.3768882  10.477972\nwaxpaper                13.1702265   1.677039\nglossypaintedwood       11.2914904   5.331796\n```\n:::\n:::\n\n \nI note that any map that is the same as this apart from rotation and\nreflection is also fine (since the distances will be the same). I saw\na lot of maps that were like mine but upside down (with `cork`\nat the top).^[I lie. Last year, *I* got cork at the top,  and a lot of other people got cork at the bottom as you see here.] No problem there.\n    \n$\\blacksquare$\n\n(f) Find a pair of objects that are close together on your\nplot. Look back at your answer to part~(<a href=\"#part:distances\">here</a>): is\nthe distance between those objects small? Explain briefly.\n\n\nSolution\n\n\nI don't mind (much) which objects you pick (as long as they are\nreasonably close together). Find the actual distance between them\nfrom what I called `d` in part~(<a href=\"#part:distances\">here</a>). Some\npossibilities:\n\n\n* Felt and velvet, Distance 4.\n\n* Block of styrofoam and rubber eraser. Distance 19 (not that\nsmall, but one of the smaller ones).\n\n* Rigid plastic sheet and\nwax paper. Distance 12. Smallish.\n\n* unglazed ceramic\ntile^[The first association that *unglazed* made for me      was *donut*!] and very fine sandpaper. Distance 12. Smallish.\n\nThere won't be a perfect relationship between distance in the\ndistance matrix and on the map. In this case, there is an upper\nlimit on distance (30, because 30 people rated the objects for\nsimilarity) and that upper limit is approached by many of the\ndistances. (This suggests that non-metric multidimensional\nscaling, that just reproduces the order of the distances, might be\na better idea for these data.) If objects A and B, and also B and\nC, are each close to 30 apart, then objects A and C will also be\nclose to 30 apart, and that constrains them to be nearly in a\ntriangle on the map. \nThere are some 10s in the distance matrix,\nfor example between block of styrofoam and cork, and also\nbetween unglazed ceramic tile and brick; these are a bit\nfurther apart on the map, but still close.\n    \n$\\blacksquare$\n\n(g) Obtain a measure of goodness of fit for this\nmultidimensional scaling map.\n\n\nSolution\n\n\nThis means fitting again, but this time with `eig=T`, and\npulling out the thing called `GOF`. You can omit the 2,\nsince that's the default 2 dimensions:\n\n::: {.cell}\n\n```{.r .cell-code}\nd.2 <- cmdscale(d, 2, eig = T)\nd.2$GOF\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4019251 0.4110603\n```\n:::\n:::\n\n     \n\nI didn't ask you to comment on this, but the adjective that came to my\nmind was \"disappointing\". I think that's to do with the\nupper-limit-30 thing again. Also, this time (unlike with Wisconsin)\nthere was no \"right answer\", so maybe it just isn't going to be very\ngood. If you looked at several pairs of points above, you might have\nnoticed that the correspondence between map distance and actual\ndistance isn't very good; this is the same issue.\n\nI was curious about whether 3 dimensions would be any better:\n\n::: {.cell}\n\n```{.r .cell-code}\nd.2a <- cmdscale(d, 3, eig = T)\nd.2a$GOF\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5775841 0.5907117\n```\n:::\n:::\n\n \n\nThat is quite a bit better. The problem with this, though, is that we\nneed something like `rgl` to explore it with.\n\n$\\blacksquare$\n\n(h) Obtain a cluster analysis for the same data, using Ward's\nmethod. Obtain a dendrogram. What seems to be an appropriate number\nof clusters?  Mark them on your dendrogram too.\n\n\nSolution\n\n\nThis seems to be a throwback to last week, but I have my reasons,\nwhich you'll see in a moment:\n\n::: {.cell}\n\n```{.r .cell-code}\nd.3 <- hclust(d, method = \"ward.D\")\nplot(d.3)\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/stimuli-10-1.pdf){fig-pos='H'}\n:::\n:::\n\n     \n\nThat looks like 5 clusters to me (chopping the tree at a height of\n30). Drawing them:\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(d.3)\nrect.hclust(d.3, 5)\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/stimuli-11-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n    \n$\\blacksquare$\n\n(i) Discuss as briefly as seems reasonable whether your\nclusters tell the same story as the map that came from\nmultidimensional scaling. (There were only three marks for this, so you\ndon't need to go overboard.) Optionally, think about creating a plot\nthat will make it easier to see the correspondence between your\nclusters and the MDS map.\n\n\nSolution\n\n\nI would take my clusters and think about whether the objects in\nthem are (a) close together on the map and (b) distinct from other\nobjects on the map. Working from left to right of my dendrogram:\n\n\n* Together at the bottom of the plot.\n\n* Together at the top left.\n\n* Together at the top left, but rather mixed up with the\nprevious cluster (in particular, `nylonscouringpad` looks as if it\nbelongs in the previous cluster).\n\n* Together at the top of the plot.\n\n* Together at the top right.\n\nIf you had a different number of clusters, work with what you\nhave, and if you have done that, you'll be good. \n\nMy general\nconclusion from the above is that my five clusters are mostly\ndistinct from each other, but the MDS map really only has\nfour. (If you look at the dendrogram, the two clusters that are\nnot really distinct from each other were the last ones to be split.)\nThis is a lot more detail than you need. What I want to see is\nsome kind of association of clusters with (hopefully) nearby\npoints on the map, some kind of discussion of whether the clusters\nare really distinct groupings on the map, and a sense of whether\nyou feel the clusters are consistent with what appears on the map.\n\nExtra: this is where I have to say I cheated. I thought this would be\nhard to do by trying to match  those names in the clusters\nwith the ones on the MDS map. So I put myself through some\nshort-term R coding pain for some substantial long-term gain.\nI was thinking, \"can I extract the clusters from this    analysis, and plot them on the MDS map in different colours?\" That\nwould go like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nclusters <- cutree(d.3, 5)\ndata.frame(d.1, names = stimuli[, 1], cluster = factor(clusters)) %>%\n  ggplot(aes(x = X1, y = X2, label = objects, colour = cluster)) +\n  geom_point() +\n  geom_text_repel(size = 2)\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/stimuli-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n     \n\nThe first line obtains the clusters as numbers, which I then had to\nturn into a factor (to make the plot different colours). \nI copied the rest from\nabove, and then I added to them, colouring the points according to\nwhat cluster they belonged to. Three of my \"rough\" objects have\nbroken off into a cluster of their own; they are, kind of, in their\nown little area on the map.\n\nAnother, non-graphical, way of doing this is to list the MDS coordinates\nalong with the clusters, probably sorted by cluster:\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(d.1, object = stimuli[, 1], clusters) %>% arrange(clusters)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                X1         X2                 object clusters\ninnersurfaceofpinebark  -2.7066290   1.694420 innersurfaceofpinebark        1\nnylonscouringpad       -10.4469053   7.232787       nylonscouringpad        1\ncellulosekitchensponge  -5.3886609  -2.770991 cellulosekitchensponge        1\nwovenstraw              -5.2762142   3.836948             wovenstraw        1\nbrick                  -12.2011332   5.147970                  brick        2\nveryfinesandpaper      -11.0869483   2.800988      veryfinesandpaper        2\nunglazedceramictile    -10.5902291   2.926805    unglazedceramictile        2\ncardboard                3.8630322  -9.322759              cardboard        3\ncork                    -0.8424358 -14.884926                   cork        3\nrubbereraser             0.1676463 -11.733873           rubbereraser        3\nblockofstyrofoam        -2.9950151 -11.927717       blockofstyrofoam        3\nfelt                     5.1803473   9.328562                   felt        4\nvelvet                   6.3768882  10.477972                 velvet        4\nleatherwallet           10.4636668  -1.016525          leatherwallet        5\nrigidplasticsheet       11.0208731   1.201504      rigidplasticsheet        5\nwaxpaper                13.1702265   1.677039               waxpaper        5\nglossypaintedwood       11.2914904   5.331796      glossypaintedwood        5\n```\n:::\n:::\n\n \n\nThen you can think about what makes the clusters different in terms of\n`X1` and `X2`. For me, clusters 1 and 2 are kind of\nmixed up, with `X1` and (usually) `X2` negative; cluster\n3 has strongly positive `X2`; cluster 4 has very\n*negative* `X2`;^[Oxford semicolon, for the grammar mavens among you.] \nand cluster 5 has strongly positive `X1`.\n\nI wonder whether our three-dimensional solution distinguishes clusters\n1 and 2 at all? Same approach again:\n\n::: {.cell}\n\n```{.r .cell-code}\nsave.3d <- data.frame(d.2a$points, objects, clusters) %>%\n  arrange(clusters)\nsave.3d\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                X1         X2          X3\ninnersurfaceofpinebark  -2.7066290   1.694420   4.1176385\nnylonscouringpad       -10.4469053   7.232787  -1.9720211\ncellulosekitchensponge  -5.3886609  -2.770991  -6.8039573\nwovenstraw              -5.2762142   3.836948  -0.3083513\nbrick                  -12.2011332   5.147970   5.9802631\nveryfinesandpaper      -11.0869483   2.800988   4.9686770\nunglazedceramictile    -10.5902291   2.926805   7.2124679\ncardboard                3.8630322  -9.322759   1.2376174\ncork                    -0.8424358 -14.884926  -5.6157998\nrubbereraser             0.1676463 -11.733873  -2.3880857\nblockofstyrofoam        -2.9950151 -11.927717  -2.9877666\nfelt                     5.1803473   9.328562 -15.2730895\nvelvet                   6.3768882  10.477972 -14.1837552\nleatherwallet           10.4636668  -1.016525  -1.9005177\nrigidplasticsheet       11.0208731   1.201504  10.0016248\nwaxpaper                13.1702265   1.677039   8.2862272\nglossypaintedwood       11.2914904   5.331796   9.6288283\n                                      objects clusters\ninnersurfaceofpinebark innersurfaceofpinebark        1\nnylonscouringpad             nylonscouringpad        1\ncellulosekitchensponge cellulosekitchensponge        1\nwovenstraw                         wovenstraw        1\nbrick                                   brick        2\nveryfinesandpaper           veryfinesandpaper        2\nunglazedceramictile       unglazedceramictile        2\ncardboard                           cardboard        3\ncork                                     cork        3\nrubbereraser                     rubbereraser        3\nblockofstyrofoam             blockofstyrofoam        3\nfelt                                     felt        4\nvelvet                                 velvet        4\nleatherwallet                   leatherwallet        5\nrigidplasticsheet           rigidplasticsheet        5\nwaxpaper                             waxpaper        5\nglossypaintedwood           glossypaintedwood        5\n```\n:::\n:::\n\n \n\nIt looks as if the combo of negative `X1` and positive\n`X3` distinguishes cluster 2 from cluster 1.\n\nAs I was writing this, I was thinking that we should throw the\ncoordinates and the `clusters` into a\n*discriminant analysis*, to find out what distinguishes the\nclusters. Which is way too weird, and therefore deserves to be\nexplored (with the three-dimensional solution, for example):\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nsave.3d.lda <- lda(clusters ~ X1 + X2 + X3, data = save.3d)\nppp <- predict(save.3d.lda)\n```\n:::\n\n \n\nI snuck a look at the output and\nfound that `LD3` is basically worthless, so I can plot\n`LD1` against `LD2`, coloured by cluster:\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(ppp$x, cluster = factor(save.3d$clusters)) %>%\n  ggplot(aes(x = LD1, y = LD2, colour = cluster)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/stimuli-16-1.pdf){fig-pos='H'}\n:::\n:::\n\n     \n\nThis says that the three-dimensional MDS *has* separated clusters\n1 and 2, and if we were to plot `d.2a` in `rgl` and\nrotate it the right way, we *would* be able to see a difference\nbetween those two clusters as well. (They wouldn't look mixed up as\nthey do on the two-dimensional map.)\n\nSo we can look at the three-dimensional map coordinates and the\ndiscriminant analysis and ask \"what distinguishes the clusters?\". \nMap coordinates first. I need `points` since I ran\nthe scaling with `eig=T`:\n\n::: {.cell}\n\n```{.r .cell-code}\nsave.3d\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                X1         X2          X3\ninnersurfaceofpinebark  -2.7066290   1.694420   4.1176385\nnylonscouringpad       -10.4469053   7.232787  -1.9720211\ncellulosekitchensponge  -5.3886609  -2.770991  -6.8039573\nwovenstraw              -5.2762142   3.836948  -0.3083513\nbrick                  -12.2011332   5.147970   5.9802631\nveryfinesandpaper      -11.0869483   2.800988   4.9686770\nunglazedceramictile    -10.5902291   2.926805   7.2124679\ncardboard                3.8630322  -9.322759   1.2376174\ncork                    -0.8424358 -14.884926  -5.6157998\nrubbereraser             0.1676463 -11.733873  -2.3880857\nblockofstyrofoam        -2.9950151 -11.927717  -2.9877666\nfelt                     5.1803473   9.328562 -15.2730895\nvelvet                   6.3768882  10.477972 -14.1837552\nleatherwallet           10.4636668  -1.016525  -1.9005177\nrigidplasticsheet       11.0208731   1.201504  10.0016248\nwaxpaper                13.1702265   1.677039   8.2862272\nglossypaintedwood       11.2914904   5.331796   9.6288283\n                                      objects clusters\ninnersurfaceofpinebark innersurfaceofpinebark        1\nnylonscouringpad             nylonscouringpad        1\ncellulosekitchensponge cellulosekitchensponge        1\nwovenstraw                         wovenstraw        1\nbrick                                   brick        2\nveryfinesandpaper           veryfinesandpaper        2\nunglazedceramictile       unglazedceramictile        2\ncardboard                           cardboard        3\ncork                                     cork        3\nrubbereraser                     rubbereraser        3\nblockofstyrofoam             blockofstyrofoam        3\nfelt                                     felt        4\nvelvet                                 velvet        4\nleatherwallet                   leatherwallet        5\nrigidplasticsheet           rigidplasticsheet        5\nwaxpaper                             waxpaper        5\nglossypaintedwood           glossypaintedwood        5\n```\n:::\n:::\n\n \n\nand the business end of the LDA output:\n\n::: {.cell}\n\n```{.r .cell-code}\nsave.3d.lda$svd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 12.593922  5.767636  3.007893\n```\n:::\n\n```{.r .cell-code}\nsave.3d.lda$scaling\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          LD1         LD2        LD3\nX1  0.5463715  0.22819994 0.03521147\nX2  0.4370065 -0.28250040 0.10269853\nX3 -0.3512713  0.09616153 0.19930252\n```\n:::\n:::\n\n \n\nThe plot said that cluster 2 was lowest of all on `LD1`, a  bit\nlower than cluster 1. What would make `LD1` small (negative)\nwould be if `X1` was small and `X2` and `X3` were\nlarge. The cluster 2 observations are the smallest on `X1`\n(smaller than cluster 1) and larger on `X3` than cluster 1. So\nwe *can* enumerate what makes clusters 1 and 2 different. The\nplot of the first two `LD`s says, in fact, that under the\n3-dimensional multidimensional scaling, all five groups are distinct.\n\nA biplot would be another way to look at that:\n\n::: {.cell}\n\n```{.r .cell-code}\nggbiplot(save.3d.lda, groups = factor(save.3d$clusters))\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/stimuli-19-1.pdf){fig-pos='H'}\n:::\n:::\n\n \nPoints on the right have `X1` and `X2` large, and\n`X3` small (cluster 4, and to a lesser extent, cluster\n5). Points on the left are the other way around. None of the arrows\npoint up or down really, but `X1` points up a bit and\n`X2` down a bit, so points at the top of the plot are likely to\nbe high on `X1` and low on `X2`, like cluster 5.\n\nWas that all confusing enough for you?\n\nAnyway, the key to gaining some insight here is to find a way to\n*combine* the \noutput from the cluster analysis and the multidimensional\nscaling. That way you can see both in the same place, and see how they\ncompare. \n    \n$\\blacksquare$\n\n\n\n\n\n\n\n##  Confusing letters\n\n\n Two researchers studied how often people mistook one letter\nfor another one. They did this by showing their subjects each\n(uppercase) letter for a few milliseconds only, and asking them which\nletter (out of a list) they just saw. The researchers obtain a\n\"confusion matrix\" in which, for example, the W-Q entry is the total\nof W's taken as Q and Q's taken as W. This confusion matrix is in\n[link](http://ritsokiguess.site/datafiles/letterrec.txt). Note that\nthe confusions are actually *similarities* rather than\ndissimilarities: a large number means that the two letters concerned\nare easily confused, that is, similar. Similarities can be converted\nto dissimilarities by subtracting them from a larger number than\nanything in the table (that is, subtracting from 21 is good here).\n\n\n\n(a) Read in the confusion matrix and convert it to\ndissimilarities and then to a\n`dist` object, displaying the `dist` object that you\nobtain. \n\n\nSolution\n\n\n`read_table` to read in the data, having first noted that\nwe have aligned columns with spaces between:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/letterrec.txt\"\nletters <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  C = col_character(),\n  D = col_double(),\n  G = col_double(),\n  H = col_double(),\n  M = col_double(),\n  N = col_double(),\n  Q = col_double(),\n  W = col_double()\n)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 8 parsing failures.\nrow col  expected     actual                                               file\n  1  -- 8 columns 10 columns 'http://ritsokiguess.site/datafiles/letterrec.txt'\n  2  -- 8 columns 9 columns  'http://ritsokiguess.site/datafiles/letterrec.txt'\n  3  -- 8 columns 9 columns  'http://ritsokiguess.site/datafiles/letterrec.txt'\n  4  -- 8 columns 9 columns  'http://ritsokiguess.site/datafiles/letterrec.txt'\n  5  -- 8 columns 9 columns  'http://ritsokiguess.site/datafiles/letterrec.txt'\n... ... ......... .......... ..................................................\nSee problems(...) for more details.\n```\n:::\n\n```{.r .cell-code}\nletters\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 x 8\n  C         D     G     H     M     N     Q     W\n  <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 C         0     0     0     0     0     0     0\n2 D         5     0     0     0     0     0     0\n3 G        12     2     0     0     0     0     0\n4 H         2     4     3     0     0     0     0\n5 M         2     3     2    10     0     0     0\n6 N         2     4     1    18    16     0     0\n7 Q         9    20     9     1     2     8     0\n8 W         1     5     2     5    18    13     4\n```\n:::\n:::\n\n    \n\nThe first column didn't have a heading, so `read_table` filled\nin `X1` for it (there was data down below, so it needed to have\na name). This is in contrast to something like `read_delim`,\nwhere you have to have as many headers as columns. In\n`read_table`, you know where the headers have to be, so if any\nare missing they can be filled in, but with `read_delim` you\ndon't have that knowledge, so you have to have exactly the right\nnumber of headers, one per data column exactly.\n\nThese are similarities, so convert to dissimilarities by subtracting\nfrom 21. This is a shortcut way to do that, once you've gotten rid of\neverything that is not numbers:\n\n::: {.cell}\n\n```{.r .cell-code}\nletters %>% dplyr::select(-X1) -> letters2\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `dplyr::select()`:\n! Can't subset columns that don't exist.\nx Column `X1` doesn't exist.\n```\n:::\n\n```{.r .cell-code}\nletters2 <- 21 - letters2\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'letters2' not found\n```\n:::\n\n```{.r .cell-code}\nletters2\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'letters2' not found\n```\n:::\n:::\n\n \n\nThis looks weird, or at least the stuff above the diagonal does, but\n`dist` works with the stuff *below* the diagonal (unless\nyou tell it otherwise), so all will be good.\n\n`as.dist` comes next:\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- as.dist(letters2)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'letters2' not found\n```\n:::\n\n```{.r .cell-code}\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       innersurfaceofpinebark brick cardboard cork rubbereraser\nbrick                                      22                                  \ncardboard                                  23    27                            \ncork                                       24    27        18                  \nrubbereraser                               26    27        19   15             \nfelt                                       27    29        28   28           28\nleatherwallet                              26    29        23   25           20\nrigidplasticsheet                          23    28        24   26           27\nveryfinesandpaper                          24    16        24   28           24\nnylonscouringpad                           23    18        29   28           27\ncellulosekitchensponge                     23    28        27   20           24\nwovenstraw                                 18    25        28   27           25\nblockofstyrofoam                           23    24        21   10           19\nunglazedceramictile                        21    10        26   26           24\nvelvet                                     28    29        28   28           29\nwaxpaper                                   24    28        24   28           24\nglossypaintedwood                          22    27        23   29           28\n                       felt leatherwallet rigidplasticsheet veryfinesandpaper\nbrick                                                                        \ncardboard                                                                    \ncork                                                                         \nrubbereraser                                                                 \nfelt                                                                         \nleatherwallet            24                                                  \nrigidplasticsheet        28            22                                    \nveryfinesandpaper        29            28                27                  \nnylonscouringpad         26            28                29                21\ncellulosekitchensponge   26            27                29                24\nwovenstraw               29            26                27                26\nblockofstyrofoam         28            25                25                25\nunglazedceramictile      29            29                25                12\nvelvet                    4            24                29                29\nwaxpaper                 28            21                12                29\nglossypaintedwood        29            20                13                27\n                       nylonscouringpad cellulosekitchensponge wovenstraw\nbrick                                                                    \ncardboard                                                                \ncork                                                                     \nrubbereraser                                                             \nfelt                                                                     \nleatherwallet                                                            \nrigidplasticsheet                                                        \nveryfinesandpaper                                                        \nnylonscouringpad                                                         \ncellulosekitchensponge               22                                  \nwovenstraw                           16                     19           \nblockofstyrofoam                     25                     21         26\nunglazedceramictile                  24                     26         26\nvelvet                               27                     27         28\nwaxpaper                             29                     29         27\nglossypaintedwood                    28                     27         25\n                       blockofstyrofoam unglazedceramictile velvet waxpaper\nbrick                                                                      \ncardboard                                                                  \ncork                                                                       \nrubbereraser                                                               \nfelt                                                                       \nleatherwallet                                                              \nrigidplasticsheet                                                          \nveryfinesandpaper                                                          \nnylonscouringpad                                                           \ncellulosekitchensponge                                                     \nwovenstraw                                                                 \nblockofstyrofoam                                                           \nunglazedceramictile                  25                                    \nvelvet                               29                  29                \nwaxpaper                             26                  28     27         \nglossypaintedwood                    29                  26     26       12\n```\n:::\n:::\n\n \n\nThis works because the letters that are confused are actually\ncolumn names of the data frame. \n\nYou can check (and probably should, at least for yourself) that the\ndistances in `d` correspond properly to the ones in\n`letters`. For example, the letters C and G were confused 12\ntimes, $21-12=9$, and the entry for C and G in `d` is indeed\n9. \n\nNote that the actual confusion numbers were in the data file as the\nbottom half of the matrix, with the top half being\nzeroes. `as.dist` handled this with no problem. (You can check\nthe help for `as.dist` to find out how it deals with this kind\nof thing.)\n\n\n$\\blacksquare$\n\n(b) Run a multidimensional scaling, with the default two\ndimensions, on your `dist` object, and display the\nresults. (Making a graph is coming later.)\n\nSolution\n\n\nThis:\n\n::: {.cell}\n\n```{.r .cell-code}\nd.1 <- cmdscale(d)\nd.1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                              [,1]       [,2]\ninnersurfaceofpinebark  -2.7066290   1.694420\nbrick                  -12.2011332   5.147970\ncardboard                3.8630322  -9.322759\ncork                    -0.8424358 -14.884926\nrubbereraser             0.1676463 -11.733873\nfelt                     5.1803473   9.328562\nleatherwallet           10.4636668  -1.016525\nrigidplasticsheet       11.0208731   1.201504\nveryfinesandpaper      -11.0869483   2.800988\nnylonscouringpad       -10.4469053   7.232787\ncellulosekitchensponge  -5.3886609  -2.770991\nwovenstraw              -5.2762142   3.836948\nblockofstyrofoam        -2.9950151 -11.927717\nunglazedceramictile    -10.5902291   2.926805\nvelvet                   6.3768882  10.477972\nwaxpaper                13.1702265   1.677039\nglossypaintedwood       11.2914904   5.331796\n```\n:::\n:::\n\n     \n\nOr you can do it with `eig=T`, which gets you some more information:\n\n::: {.cell}\n\n```{.r .cell-code}\nd.1a <- cmdscale(d, eig = T)\nd.1a\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$points\n                              [,1]       [,2]\ninnersurfaceofpinebark  -2.7066290   1.694420\nbrick                  -12.2011332   5.147970\ncardboard                3.8630322  -9.322759\ncork                    -0.8424358 -14.884926\nrubbereraser             0.1676463 -11.733873\nfelt                     5.1803473   9.328562\nleatherwallet           10.4636668  -1.016525\nrigidplasticsheet       11.0208731   1.201504\nveryfinesandpaper      -11.0869483   2.800988\nnylonscouringpad       -10.4469053   7.232787\ncellulosekitchensponge  -5.3886609  -2.770991\nwovenstraw              -5.2762142   3.836948\nblockofstyrofoam        -2.9950151 -11.927717\nunglazedceramictile    -10.5902291   2.926805\nvelvet                   6.3768882  10.477972\nwaxpaper                13.1702265   1.677039\nglossypaintedwood       11.2914904   5.331796\n\n$eig\n [1]  1.181313e+03  9.394546e+02  9.268689e+02  6.314409e+02  3.467493e+02\n [6]  2.705989e+02  2.575474e+02  1.937616e+02  1.485443e+02  1.186640e+02\n[11]  8.449108e+01  4.651045e+01  1.331767e+01 -1.421085e-13 -1.739199e+01\n[16] -3.204147e+01 -6.782875e+01\n\n$x\nNULL\n\n$ac\n[1] 0\n\n$GOF\n[1] 0.4019251 0.4110603\n```\n:::\n:::\n\n \n\nThe most interesting thing here is the `GOF` at the bottom,\nwhich is not that high (whichever one of the two values you take),\nsuggesting that the two-dimensional representation is not very\ngood. Further evidence for that is in `eig`, the\n\"eigenvalues\", which are about 493, 232, 140, 50, 40, 0 and some\nnegative ones, which suggests that three dimensions might be better\nthan two for representing the data, because the first *three*\neigenvalues seem noticeably bigger than the others. (This is the same\nthinking as the `svd` or percent of trace in discriminant\nanalysis.)  But that's by the way: we'll stick with two dimensions.\n\nThe important thing to remember is that if you go the `eig=T`\nway, you have to pull out the points to plot from the thing called\n`points`, so that you plot `d.1` itself  but `d.1a$points`.\n\n$\\blacksquare$\n\n(c) Obtain a vector of the names of the letters that were\nconfused in this study. \n\nSolution\n\n\nEasiest way is to pull out the first column of the data frame that\nyou read in from the file (if you can remember what it was called):\n\n::: {.cell}\n\n```{.r .cell-code}\nletter_names <- letters$X1\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `X1`.\n```\n:::\n:::\n\n     \n\nThat silly column name `X1` that `read_table`\nsupplied. \n\nExtra: You can even get the letter names from the thing I called `d`,\nbut I can't remember how, so I have to cheat. I said that `d`\nhas a \"print method\"^[The way that a multicoloured function  like `print` works is that when you ask to show something,  like `d`, R first looks to see what kind of thing you want to show (by calling `class`), and determines that it is a `dist` object. Then it looks to see if there is a function called `print.dist` (there is), and if there is, it calls that (to produce that nice display). If there isn't, it calls `print.default`, which just displays its input without doing anything special. This is why printing the output from an `lm` looks very different from printing a data frame: the first calls `print.lm` and the second calls `print.data.frame`, or `print.tbl_df` for a tibble.] \nthat controls how it looks:\n\n::: {.cell}\n\n```{.r .cell-code}\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       innersurfaceofpinebark brick cardboard cork rubbereraser\nbrick                                      22                                  \ncardboard                                  23    27                            \ncork                                       24    27        18                  \nrubbereraser                               26    27        19   15             \nfelt                                       27    29        28   28           28\nleatherwallet                              26    29        23   25           20\nrigidplasticsheet                          23    28        24   26           27\nveryfinesandpaper                          24    16        24   28           24\nnylonscouringpad                           23    18        29   28           27\ncellulosekitchensponge                     23    28        27   20           24\nwovenstraw                                 18    25        28   27           25\nblockofstyrofoam                           23    24        21   10           19\nunglazedceramictile                        21    10        26   26           24\nvelvet                                     28    29        28   28           29\nwaxpaper                                   24    28        24   28           24\nglossypaintedwood                          22    27        23   29           28\n                       felt leatherwallet rigidplasticsheet veryfinesandpaper\nbrick                                                                        \ncardboard                                                                    \ncork                                                                         \nrubbereraser                                                                 \nfelt                                                                         \nleatherwallet            24                                                  \nrigidplasticsheet        28            22                                    \nveryfinesandpaper        29            28                27                  \nnylonscouringpad         26            28                29                21\ncellulosekitchensponge   26            27                29                24\nwovenstraw               29            26                27                26\nblockofstyrofoam         28            25                25                25\nunglazedceramictile      29            29                25                12\nvelvet                    4            24                29                29\nwaxpaper                 28            21                12                29\nglossypaintedwood        29            20                13                27\n                       nylonscouringpad cellulosekitchensponge wovenstraw\nbrick                                                                    \ncardboard                                                                \ncork                                                                     \nrubbereraser                                                             \nfelt                                                                     \nleatherwallet                                                            \nrigidplasticsheet                                                        \nveryfinesandpaper                                                        \nnylonscouringpad                                                         \ncellulosekitchensponge               22                                  \nwovenstraw                           16                     19           \nblockofstyrofoam                     25                     21         26\nunglazedceramictile                  24                     26         26\nvelvet                               27                     27         28\nwaxpaper                             29                     29         27\nglossypaintedwood                    28                     27         25\n                       blockofstyrofoam unglazedceramictile velvet waxpaper\nbrick                                                                      \ncardboard                                                                  \ncork                                                                       \nrubbereraser                                                               \nfelt                                                                       \nleatherwallet                                                              \nrigidplasticsheet                                                          \nveryfinesandpaper                                                          \nnylonscouringpad                                                           \ncellulosekitchensponge                                                     \nwovenstraw                                                                 \nblockofstyrofoam                                                           \nunglazedceramictile                  25                                    \nvelvet                               29                  29                \nwaxpaper                             26                  28     27         \nglossypaintedwood                    29                  26     26       12\n```\n:::\n:::\n\n\n\nbut its innards are a whole lot more complicated than that:\n\n::: {.cell}\n\n```{.r .cell-code}\nprint.default(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 22 23 24 26 27 26 23 24 23 23 18 23 21 28 24 22 27 27 27 29 29 28 16 18 28\n [26] 25 24 10 29 28 27 18 19 28 23 24 24 29 27 28 21 26 28 24 23 15 28 25 26 28\n [51] 28 20 27 10 26 28 28 29 28 20 27 24 27 24 25 19 24 29 24 28 24 28 29 26 26\n [76] 29 28 29  4 28 29 22 28 28 27 26 25 29 24 21 20 27 29 29 27 25 25 29 12 13\n[101] 21 24 26 25 12 29 29 27 22 16 25 24 27 29 28 19 21 26 27 29 27 26 26 28 27\n[126] 25 25 29 26 29 29 28 26 27 26 12\nattr(,\"Labels\")\n [1] \"innersurfaceofpinebark\" \"brick\"                  \"cardboard\"             \n [4] \"cork\"                   \"rubbereraser\"           \"felt\"                  \n [7] \"leatherwallet\"          \"rigidplasticsheet\"      \"veryfinesandpaper\"     \n[10] \"nylonscouringpad\"       \"cellulosekitchensponge\" \"wovenstraw\"            \n[13] \"blockofstyrofoam\"       \"unglazedceramictile\"    \"velvet\"                \n[16] \"waxpaper\"               \"glossypaintedwood\"     \nattr(,\"Size\")\n[1] 17\nattr(,\"call\")\nas.dist.default(m = .)\nattr(,\"class\")\n[1] \"dist\"\nattr(,\"Diag\")\n[1] FALSE\nattr(,\"Upper\")\n[1] FALSE\n```\n:::\n:::\n\n \n\nor\n\n::: {.cell}\n\n```{.r .cell-code}\nunclass(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 22 23 24 26 27 26 23 24 23 23 18 23 21 28 24 22 27 27 27 29 29 28 16 18 28\n [26] 25 24 10 29 28 27 18 19 28 23 24 24 29 27 28 21 26 28 24 23 15 28 25 26 28\n [51] 28 20 27 10 26 28 28 29 28 20 27 24 27 24 25 19 24 29 24 28 24 28 29 26 26\n [76] 29 28 29  4 28 29 22 28 28 27 26 25 29 24 21 20 27 29 29 27 25 25 29 12 13\n[101] 21 24 26 25 12 29 29 27 22 16 25 24 27 29 28 19 21 26 27 29 27 26 26 28 27\n[126] 25 25 29 26 29 29 28 26 27 26 12\nattr(,\"Labels\")\n [1] \"innersurfaceofpinebark\" \"brick\"                  \"cardboard\"             \n [4] \"cork\"                   \"rubbereraser\"           \"felt\"                  \n [7] \"leatherwallet\"          \"rigidplasticsheet\"      \"veryfinesandpaper\"     \n[10] \"nylonscouringpad\"       \"cellulosekitchensponge\" \"wovenstraw\"            \n[13] \"blockofstyrofoam\"       \"unglazedceramictile\"    \"velvet\"                \n[16] \"waxpaper\"               \"glossypaintedwood\"     \nattr(,\"Size\")\n[1] 17\nattr(,\"call\")\nas.dist.default(m = .)\nattr(,\"Diag\")\n[1] FALSE\nattr(,\"Upper\")\n[1] FALSE\n```\n:::\n:::\n\n \n\nThis one gets rid of any special kind of thing that `d` is, and\ndisplays it like a thing without any special properties.\n\nIt's the \"attribute\" called `Labels` that we need to grab:\n\n::: {.cell}\n\n```{.r .cell-code}\nattributes(d)$Labels\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"innersurfaceofpinebark\" \"brick\"                  \"cardboard\"             \n [4] \"cork\"                   \"rubbereraser\"           \"felt\"                  \n [7] \"leatherwallet\"          \"rigidplasticsheet\"      \"veryfinesandpaper\"     \n[10] \"nylonscouringpad\"       \"cellulosekitchensponge\" \"wovenstraw\"            \n[13] \"blockofstyrofoam\"       \"unglazedceramictile\"    \"velvet\"                \n[16] \"waxpaper\"               \"glossypaintedwood\"     \n```\n:::\n:::\n\n \n\n$\\blacksquare$\n\n(d) Plot your multidimensional scaling map. To do this, first\ncreate a data frame containing the points you want to plot and their\nlabels, and then plot the points labelled by the right thing.\n\nSolution\n\n\nThe \"labels\" need to be the letter names, which is why I made\nyou find them in the previous part. I'm going to do this with a\npipe, or else I'll create *another* thing called `d`\nand overwrite the one I wanted to keep, again:\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(d.1, names = letter_names)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in data.frame(d.1, names = letter_names): arguments imply differing number of rows: 17, 0\n```\n:::\n:::\n\n     \n\nSo far so good. The coordinates have gained names `X1` and\n`X2` (as they did before, but I wanted to check). This is what\nhappens when you turn a matrix with nameless columns into a data\nframe. So I can proceed:\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(d.1, names = letter_names) %>%\n  ggplot(aes(x = X1, y = X2, label = names)) +\n  geom_point() + geom_text_repel() +\n  coord_fixed()\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in data.frame(d.1, names = letter_names): arguments imply differing number of rows: 17, 0\n```\n:::\n:::\n\n     \n\nI need the  last line for the same reason as before: I want to treat\nthe two axes equally. If you don't have that, you have a distorted map\nwhere one of the coordinates appears to be more important than the other.\n\nIf you can't get `ggrepel` to behave itself, an equally good\nalternative is to plot the letter names instead of the labelled\ndots. To do that, take out the `geom_point` and add an\nordinary `geom_text`. This will plot, *at* the location\ngiven by the `x` and `y`, the text in `label`,\ncentred at the location. (If you have `geom_point()` as well,\nyou'll get a black dot in the middle of each piece of text.)\n`geom_text` has options to justify the text relative to the\npoint, so you can see both, but I've always found these rather\nfinicky, so I'd rather let `geom_text_repel` do the work of\nfiguring out where to put the text relative to the point.\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(d.1, names = letter_names) %>%\n  ggplot(aes(x = X1, y = X2, label = names)) +\n  geom_text() + coord_fixed()\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in data.frame(d.1, names = letter_names): arguments imply differing number of rows: 17, 0\n```\n:::\n:::\n\n \n\nThen pick (in the next part) a pair of letters that is close together,\nand proceed. I like the labelled dots better (as a matter of taste),\nbut this way is a perfectly good way to answer the question, so is\nperfectly acceptable here.\n\n$\\blacksquare$\n\n(e) Pick a pair of letters appear close together on your\nmap. Does it make sense, from looking at these letters, that they\nwould be easy to confuse? Explain briefly.\n\nSolution\n\n\nMy map has four pairs of close-together letters: C and G, H and M,\nN and W, Q and D. Pick one of those pairs. I don't mind which pair\nyou pick. (If you got something different, pick from what your map\nshows.) \nI think it is not at all surprising that these pairs of letters\ngot confused, because the letters of each pair have similar shapes\n(which is all you'd have to react to if you see them for \"a few    milliseconds\" each): C and G circular with a hole on the right,\nH, M, N and W vertical lines on the outside with something across\nthe middle, Q and D almost circular. (It's up to you whether you\nconsider H, M, N and W as a group of four or as two pairs.)\n\n$\\blacksquare$\n\n(f) Verify that your chosen pair of letters was often confused\nin the data.\n\nSolution\n\n\nThe data we read in from the file was this:\n\n::: {.cell}\n\n```{.r .cell-code}\nletters\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 x 8\n  C         D     G     H     M     N     Q     W\n  <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 C         0     0     0     0     0     0     0\n2 D         5     0     0     0     0     0     0\n3 G        12     2     0     0     0     0     0\n4 H         2     4     3     0     0     0     0\n5 M         2     3     2    10     0     0     0\n6 N         2     4     1    18    16     0     0\n7 Q         9    20     9     1     2     8     0\n8 W         1     5     2     5    18    13     4\n```\n:::\n:::\n\n     \n\nThen look for your pair of letters:\n\n\n\\begin{tabular}{lr}\nletters & confusion\\\\\n\\hline            \nC,G & 12\\\\\nH,M & 10\\\\\nN,W & 13\\\\\nQ,D & 20\\\\     \n\\hline\n\\end{tabular}\n\n\nThese are four of the biggest numbers in the matrix, which is as it\nshould be. You need to find the number of confusions for your pair of\nletters and assert that it is large (compared to the others).\n\nThese are actually not *all* the large ones: M and W, H and N, M\nand N are also large (which lends some support to these letters being\na foursome^[Set of four. Match-play golf has a game called  *foursomes* where the two players on each team take it in turns to hit the ball, as opposed to the game called *fourballs*, where each of the two players plays their own ball, and the team's score on a hole is the better of the two players' scores.] rather than two pairs).\n\nIf you prefer, you can work from your `dist` object, the thing\nI called `d`:\n\n::: {.cell}\n\n```{.r .cell-code}\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       innersurfaceofpinebark brick cardboard cork rubbereraser\nbrick                                      22                                  \ncardboard                                  23    27                            \ncork                                       24    27        18                  \nrubbereraser                               26    27        19   15             \nfelt                                       27    29        28   28           28\nleatherwallet                              26    29        23   25           20\nrigidplasticsheet                          23    28        24   26           27\nveryfinesandpaper                          24    16        24   28           24\nnylonscouringpad                           23    18        29   28           27\ncellulosekitchensponge                     23    28        27   20           24\nwovenstraw                                 18    25        28   27           25\nblockofstyrofoam                           23    24        21   10           19\nunglazedceramictile                        21    10        26   26           24\nvelvet                                     28    29        28   28           29\nwaxpaper                                   24    28        24   28           24\nglossypaintedwood                          22    27        23   29           28\n                       felt leatherwallet rigidplasticsheet veryfinesandpaper\nbrick                                                                        \ncardboard                                                                    \ncork                                                                         \nrubbereraser                                                                 \nfelt                                                                         \nleatherwallet            24                                                  \nrigidplasticsheet        28            22                                    \nveryfinesandpaper        29            28                27                  \nnylonscouringpad         26            28                29                21\ncellulosekitchensponge   26            27                29                24\nwovenstraw               29            26                27                26\nblockofstyrofoam         28            25                25                25\nunglazedceramictile      29            29                25                12\nvelvet                    4            24                29                29\nwaxpaper                 28            21                12                29\nglossypaintedwood        29            20                13                27\n                       nylonscouringpad cellulosekitchensponge wovenstraw\nbrick                                                                    \ncardboard                                                                \ncork                                                                     \nrubbereraser                                                             \nfelt                                                                     \nleatherwallet                                                            \nrigidplasticsheet                                                        \nveryfinesandpaper                                                        \nnylonscouringpad                                                         \ncellulosekitchensponge               22                                  \nwovenstraw                           16                     19           \nblockofstyrofoam                     25                     21         26\nunglazedceramictile                  24                     26         26\nvelvet                               27                     27         28\nwaxpaper                             29                     29         27\nglossypaintedwood                    28                     27         25\n                       blockofstyrofoam unglazedceramictile velvet waxpaper\nbrick                                                                      \ncardboard                                                                  \ncork                                                                       \nrubbereraser                                                               \nfelt                                                                       \nleatherwallet                                                              \nrigidplasticsheet                                                          \nveryfinesandpaper                                                          \nnylonscouringpad                                                           \ncellulosekitchensponge                                                     \nwovenstraw                                                                 \nblockofstyrofoam                                                           \nunglazedceramictile                  25                                    \nvelvet                               29                  29                \nwaxpaper                             26                  28     27         \nglossypaintedwood                    29                  26     26       12\n```\n:::\n:::\n\n\n\nThis time, you're looking for a *small* dissimilarity between\nyour pair of letters:\n\n\n\\begin{tabular}{lr}\nletters & dissimilarity\\\\\n\\hline            \nC,G & 9\\\\\nH,M & 11\\\\\nN,W & 8\\\\\nQ,D & 1\\\\     \n\\hline\n\\end{tabular}\n\n\nThese, again, are smaller than most, though not the smallest\noverall. So, if you go this way, you need to assert that the\ncorresponding number in your `dist` object is *small*.\n\n$\\blacksquare$\n\n\n\n\n##  More beer please\n\n\n Previously, you did a cluster analysis of\nten brands of beer, as rated by 32 students. This time, we will do a\nnon-metric multidimensional scaling of those same brands of beer. The\ndata are in [link](http://ritsokiguess.site/datafiles/beer.txt).\n\n\n\n(a) Noting that we want to assess distances between brands of beer,\nread in the data and do whatever you need to do to work out\ndistances between the beers. Show your result.\n \nSolution\n\n\n\n       \nThis is really a copy of last time. We need to transpose the data\nframe to get the beers in *rows* (`dist` works on\ndistances between rows), then feed everything but the student IDs\ninto `dist`:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/beer.txt\"\nbeer <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  student = col_character(),\n  AnchorS = col_double(),\n  Bass = col_double(),\n  Becks = col_double(),\n  Corona = col_double(),\n  GordonB = col_double(),\n  Guinness = col_double(),\n  Heineken = col_double(),\n  PetesW = col_double(),\n  SamAdams = col_double(),\n  SierraN = col_double()\n)\n```\n:::\n\n```{.r .cell-code}\nbeer\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 32 x 11\n   student AnchorS  Bass Becks Corona GordonB Guinness Heineken PetesW SamAdams\n   <chr>     <dbl> <dbl> <dbl>  <dbl>   <dbl>    <dbl>    <dbl>  <dbl>    <dbl>\n 1 S001          5     9     7      1       7        6        6      5        9\n 2 S008          7     5     6      8       8        4        8      8        7\n 3 S015          7     7     5      6       6        1        8      4        7\n 4 S022          7     7     5      2       5        8        4      6        8\n 5 S029          9     7     3      1       6        8        2      7        6\n 6 S036          7     6     4      3       7        6        6      5        4\n 7 S043          5     5     5      6       6        4        7      5        5\n 8 S050          5     3     1      5       5        5        3      5        5\n 9 S057          9     3     2      6       4        6        1      5        3\n10 S064          2     6     6      5       6        4        8      4        4\n# i 22 more rows\n# i 1 more variable: SierraN <dbl>\n```\n:::\n\n```{.r .cell-code}\nd <- beer %>%\n  dplyr::select(-student) %>%\n  t() %>%\n  dist()\n```\n:::\n\n\n\nI did it the funny-looking way. The cluster analysis question offers\nan alternative.\n \n$\\blacksquare$\n\n(b) Obtain a non-metric multidimensional scaling of the\nbeers. (Comment coming up in a moment.)\n \nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nbeer.1 <- isoMDS(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ninitial  value 13.344792 \niter   5 value 10.855662\niter  10 value 10.391446\nfinal  value 10.321949 \nconverged\n```\n:::\n:::\n\n     \n \n$\\blacksquare$\n\n(c) Obtain the `stress` value of the map, and comment on it.\n \nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeer.1$stress\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10.32195\n```\n:::\n:::\n\n     \n\nThe stress is around 10\\%, on the boundary between \"good\" and\n\"fair\". It seems as if the map should be more or less worth\nusing. (Insert your own hand-waving language here.)\n \n$\\blacksquare$\n\n(d) Obtain a map of the beers, labelled with the names of the\nbeers. \n \nSolution\n\n\nThis is slightly different from class, where I plotted the\nlanguages actually *at* their locations. But here, the beer\nnames are longer, so we should plot the points and label them. I'd\nmake a data frame first, and probably pipe it into the plot,\nthus. Don't forget we have to get the names of the 10 beers, and\nnot the 32 students! The names of the columns of the data frame\ninclude an identifier column for the students, so skip the first one:\n\n::: {.cell}\n\n```{.r .cell-code}\nbeer_names <- beer %>% dplyr::select(-student) %>% names()\nbeer_names\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"AnchorS\"  \"Bass\"     \"Becks\"    \"Corona\"   \"GordonB\"  \"Guinness\"\n [7] \"Heineken\" \"PetesW\"   \"SamAdams\" \"SierraN\" \n```\n:::\n\n```{.r .cell-code}\ndata.frame(beer.1$points, beer = beer_names) %>%\n  ggplot(aes(x = X1, y = X2, label = beer)) +\n  geom_point() + geom_text_repel()\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/beermds-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n     \n \n$\\blacksquare$\n\n(e) Find a pair of beers close together on your map. Are they\nsimilar in terms of student ratings? Explain briefly.\n \nSolution\n\n\nI think Sam Adams and Gordon Biersch, right in the middle of the\nmap. We can pull them out by name:\n\n::: {.cell}\n\n```{.r .cell-code}\nbeer %>% dplyr::select(SamAdams, GordonB)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 32 x 2\n   SamAdams GordonB\n      <dbl>   <dbl>\n 1        9       7\n 2        7       8\n 3        7       6\n 4        8       5\n 5        6       6\n 6        4       7\n 7        5       6\n 8        5       5\n 9        3       4\n10        4       6\n# i 22 more rows\n```\n:::\n:::\n\n     \n\nThese are, with a few exceptions (the most glaring being the 18th\nstudent), within a couple of points of each other. So I would say they\nare similar. Another way to show this is to make a scatterplot of\nthem, and draw on it the line where the ratings are the same. Since\nthe ratings are whole numbers, they are likely to be duplicated, so I\n\"jitter\" them as I plot them, to prevent overplotting:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(beer, aes(x = SamAdams, y = GordonB)) + geom_jitter() +\n  geom_abline(intercept = 0, slope = 1)\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/adkjalkjdsg-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nAre they close to the line, or not? Dunno. Maybe I should plot the\nratings of some far-apart beers, and see whether it looks any\ndifferent, for example `Becks` and `SierraN`:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(beer, aes(x = Becks, y = SierraN)) + geom_jitter() +\n  geom_abline(intercept = 0, slope = 1)\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/adkjalkjdsh-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nNot much. I was expecting something a lot more impressive. Another way\nis to summarize the rating *differences* for the pairs of beers:\n\n::: {.cell}\n\n```{.r .cell-code}\ndiff <- with(beer, SamAdams - GordonB)\nsummary(diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-3.0000 -1.0000  0.0000  0.1562  1.0000  6.0000 \n```\n:::\n:::\n\n \n\nand\n\n::: {.cell}\n\n```{.r .cell-code}\ndiff <- with(beer, Becks - SierraN)\nsummary(diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  -8.00   -4.00   -1.50   -1.75    0.00    3.00 \n```\n:::\n:::\n\n \n\nNow we see something: two beers that are similar ought to have a\nmedian rating difference close to 0 most of the time. That is the\ncase for the first pair; the median *is* zero, and the IQR is\nonly 2. But for the second pair, Becks is typically rated lower than\nSierra Nevada (negative median) and the IQR is larger (4 rather than\n2). \n \n$\\blacksquare$\n\n(f) In our cluster analysis, we found that Anchor Steam, Pete's\nWicked Ale, Guinness and Sierra Nevada were all in the same\ncluster. Would you expect them to be close together on your map? Are\nthey? Explain briefly.\n \nSolution\n\n\nIf they are in the same cluster, we would expect them to\n\"cluster\" together on the map. Except that they don't, really.\nThese are the four beers over on the right of our map. They are kind\nof in the same general neighbourhood, but not really what you would\ncall close together. (This is a judgement call, again.) In fact, none\nof the beers, with the exception of Sam Adams and Gordon Biersch in\nthe centre, are really very close to any of the others.\n\nThat may be the story, in the end. With the cluster analysis, we were\nforcing the clustering to happen, whether it was really there or\nnot. We haven't seen a test for the \"significance\" of clusters, so\nthe clusters we found may not mean very much.\n \n$\\blacksquare$\n\n\n\n\n\n##  Feeling similar, again\n\n\n Previously, we looked at an experiment about which objects feel similar to one another and which ones feel different.\n\n30 subjects were each\ngiven 17 different objects to feel, for example \n\"inner surface of pine  bark\", \n\"rubber eraser\" and \n\"nylon scouring pad\". The\nsubjects had to group the objects into a maximum of 8 groups such that\nthe objects within a group felt similar, and the ones in different\ngroups felt different.\nA\ndissimilarity matrix was formed by counting how many subjects put each\npair of objects into *different* groups, so that the\ndissimilarity ranged from 0 (the objects were always put together in\nthe same group) to 30 (the objects were not put together into the same\ngroup by any of the subjects). \n\nThe data are in\n[link](http://ritsokiguess.site/datafiles/stimuli.txt). These have\n*no* column names.\n\nThis time we are going to try *non-metric* multidimensional\nscaling, to see whether that produces a more reasonable map. The\nreading in of the data is the same as before (so I have reduced the\nmarks given for it).\n\n\n\n(a) Obtain and display the distance matrix that you used last\ntime for these data. (I don't care whether you run all the code\nagain, or whether you just produce the matrix from where you had it\nbefore on R Studio. Correct is all I care about.)\n\n\nSolution\n\n\nCopied and pasted from last time:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/stimuli.txt\"\nstimuli <- read_delim(my_url, \" \", col_names = F)\nobjects <- stimuli$X1\nnames(stimuli) <- c(\"object\", objects)\nstimuli\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 17 x 18\n   object        innersurfaceofpinebark brick cardboard  cork rubbereraser  felt\n   <chr>                          <dbl> <dbl>     <dbl> <dbl>        <dbl> <dbl>\n 1 innersurface~                      0    22        23    24           26    27\n 2 brick                             22     0        27    27           27    29\n 3 cardboard                         23    27         0    18           19    28\n 4 cork                              24    27        18     0           15    28\n 5 rubbereraser                      26    27        19    15            0    28\n 6 felt                              27    29        28    28           28     0\n 7 leatherwallet                     26    29        23    25           20    24\n 8 rigidplastic~                     23    28        24    26           27    28\n 9 veryfinesand~                     24    16        24    28           24    29\n10 nylonscourin~                     23    18        29    28           27    26\n11 cellulosekit~                     23    28        27    20           24    26\n12 wovenstraw                        18    25        28    27           25    29\n13 blockofstyro~                     23    24        21    10           19    28\n14 unglazedcera~                     21    10        26    26           24    29\n15 velvet                            28    29        28    28           29     4\n16 waxpaper                          24    28        24    28           24    28\n17 glossypainte~                     22    27        23    29           28    29\n# i 11 more variables: leatherwallet <dbl>, rigidplasticsheet <dbl>,\n#   veryfinesandpaper <dbl>, nylonscouringpad <dbl>,\n#   cellulosekitchensponge <dbl>, wovenstraw <dbl>, blockofstyrofoam <dbl>,\n#   unglazedceramictile <dbl>, velvet <dbl>, waxpaper <dbl>,\n#   glossypaintedwood <dbl>\n```\n:::\n:::\n\n     \n\nThat gets a data frame with the right column names. Then:\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- stimuli %>% dplyr::select(-1) %>% as.dist()\n```\n:::\n\n \n\nand just to check:\n\n::: {.cell}\n\n```{.r .cell-code}\nw <- getOption(\"width\")\noptions(width = 132)\nd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       innersurfaceofpinebark brick cardboard cork rubbereraser felt leatherwallet rigidplasticsheet\nbrick                                      22                                                                       \ncardboard                                  23    27                                                                 \ncork                                       24    27        18                                                       \nrubbereraser                               26    27        19   15                                                  \nfelt                                       27    29        28   28           28                                     \nleatherwallet                              26    29        23   25           20   24                                \nrigidplasticsheet                          23    28        24   26           27   28            22                  \nveryfinesandpaper                          24    16        24   28           24   29            28                27\nnylonscouringpad                           23    18        29   28           27   26            28                29\ncellulosekitchensponge                     23    28        27   20           24   26            27                29\nwovenstraw                                 18    25        28   27           25   29            26                27\nblockofstyrofoam                           23    24        21   10           19   28            25                25\nunglazedceramictile                        21    10        26   26           24   29            29                25\nvelvet                                     28    29        28   28           29    4            24                29\nwaxpaper                                   24    28        24   28           24   28            21                12\nglossypaintedwood                          22    27        23   29           28   29            20                13\n                       veryfinesandpaper nylonscouringpad cellulosekitchensponge wovenstraw blockofstyrofoam unglazedceramictile\nbrick                                                                                                                           \ncardboard                                                                                                                       \ncork                                                                                                                            \nrubbereraser                                                                                                                    \nfelt                                                                                                                            \nleatherwallet                                                                                                                   \nrigidplasticsheet                                                                                                               \nveryfinesandpaper                                                                                                               \nnylonscouringpad                      21                                                                                        \ncellulosekitchensponge                24               22                                                                       \nwovenstraw                            26               16                     19                                                \nblockofstyrofoam                      25               25                     21         26                                     \nunglazedceramictile                   12               24                     26         26               25                    \nvelvet                                29               27                     27         28               29                  29\nwaxpaper                              29               29                     29         27               26                  28\nglossypaintedwood                     27               28                     27         25               29                  26\n                       velvet waxpaper\nbrick                                 \ncardboard                             \ncork                                  \nrubbereraser                          \nfelt                                  \nleatherwallet                         \nrigidplasticsheet                     \nveryfinesandpaper                     \nnylonscouringpad                      \ncellulosekitchensponge                \nwovenstraw                            \nblockofstyrofoam                      \nunglazedceramictile                   \nvelvet                                \nwaxpaper                   27         \nglossypaintedwood          26       12\n```\n:::\n\n```{.r .cell-code}\noptions(width = w)\n```\n:::\n\n \n    \n$\\blacksquare$\n\n(b) Obtain a non-metric multidimensional scaling map of the\nobjects. (No plotting or comments yet.)\n\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstimuli.1 <- isoMDS(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ninitial  value 25.537169 \niter   5 value 20.521473\nfinal  value 20.216103 \nconverged\n```\n:::\n:::\n\n     \n\nI'm going to remind myself of what this has in it:\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(stimuli.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"points\" \"stress\"\n```\n:::\n:::\n\n \n\nThis is rather like running `cmdscale` with `eig=T`: a\nthing called `points` with coordinates to plot, and a measure\nof fit, here called `stress`, with, as you'd guess, a smaller\n`stress` being better.\n    \n\n$\\blacksquare$\n\n(c) <a name=\"part:stress\">*</a> Obtain a number that says how well the map reproduces the\ndistances in the data, and comment on that number.\n\n\nSolution\n\n\nWhat you need here is the \"stress\":\n\n::: {.cell}\n\n```{.r .cell-code}\nstimuli.1$stress\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 20.2161\n```\n:::\n:::\n\n     \n\nThis is just over 20\\%, which is described in the notes as\n\"poor\". We should thus be skeptical about the map that this produces.\n    \n\n$\\blacksquare$\n\n(d) Plot the non-metric multidimensional scaling map. Label each\npoint with its (full) object name, sized suitably.\n\n\nSolution\n\n\nMake a data frame first of things to plot, the points and the\nnames. I'm going to plot the names smaller). I am *not*\nnaming this data frame `d`, in an attempt to avoid\noverwriting things I want to keep:\n\n::: {.cell}\n\n```{.r .cell-code}\nstimuli.1.d <- data.frame(stimuli.1$points, names = objects)\nstimuli.1.d\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                X1          X2                  names\ninnersurfaceofpinebark  -1.5343296   1.3163495 innersurfaceofpinebark\nbrick                  -11.1198228   4.1255022                  brick\ncardboard                3.7481838  -9.4875599              cardboard\ncork                    -0.8637631 -11.6740046                   cork\nrubbereraser             0.9478406  -9.9955340           rubbereraser\nfelt                     3.7030786  15.0204325                   felt\nleatherwallet            9.5323886  -3.3715939          leatherwallet\nrigidplasticsheet       11.3370118  -0.5134769      rigidplasticsheet\nveryfinesandpaper      -12.7743812   1.1092242      veryfinesandpaper\nnylonscouringpad        -9.1348586   8.0045364       nylonscouringpad\ncellulosekitchensponge  -8.2296607  -6.3368839 cellulosekitchensponge\nwovenstraw              -4.3321533   5.1303993             wovenstraw\nblockofstyrofoam        -3.3540109  -9.7135472       blockofstyrofoam\nunglazedceramictile    -10.7345424  -0.4673140    unglazedceramictile\nvelvet                   7.0712701  15.3712514                 velvet\nwaxpaper                14.2695604  -0.7584453               waxpaper\nglossypaintedwood       11.4681889   2.2406642      glossypaintedwood\n```\n:::\n:::\n\n     \n\nThe repeated stimuli down the left are row names, but since they're\nrow names, we won't be able to use them in\n`ggplot`.^[In the future, I'll make everyone turn matrices  into data frames first so that we won't deal with old-fashioned data frames, row names and the like.]\n\nRemember that we are turning a matrix and a column into a data frame,\nso we need either the more forgiving `data.frame`, or to turn\n`points` into a data frame first, which would go like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nas_tibble(stimuli.1$points) %>%\n  mutate(name = objects)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 17 x 3\n        V1      V2 name                  \n     <dbl>   <dbl> <chr>                 \n 1  -1.53    1.32  innersurfaceofpinebark\n 2 -11.1     4.13  brick                 \n 3   3.75   -9.49  cardboard             \n 4  -0.864 -11.7   cork                  \n 5   0.948 -10.0   rubbereraser          \n 6   3.70   15.0   felt                  \n 7   9.53   -3.37  leatherwallet         \n 8  11.3    -0.513 rigidplasticsheet     \n 9 -12.8     1.11  veryfinesandpaper     \n10  -9.13    8.00  nylonscouringpad      \n11  -8.23   -6.34  cellulosekitchensponge\n12  -4.33    5.13  wovenstraw            \n13  -3.35   -9.71  blockofstyrofoam      \n14 -10.7    -0.467 unglazedceramictile   \n15   7.07   15.4   velvet                \n16  14.3    -0.758 waxpaper              \n17  11.5     2.24  glossypaintedwood     \n```\n:::\n:::\n\n \nThis time, the columns are called `V1` and `V2`, since\nthat's what `as_tibble` does. Also note the slightly different\nlook: fewer decimals, since displaying a tibble rounds numerical\nthings to three significant digits.\nBack to my data frame `stimuli.1.d`.\nThe points have acquired names `X1` and `X2`, as usual,\nso we have all we need:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(stimuli.1.d, aes(x = X1, y = X2, label = names)) +\n  geom_point() +\n  geom_text_repel(size = 2) +\n  coord_fixed()\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/hon-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nI think the full names are good with the text this small.\n\nActually, this came out a lot like the metric multidimensional scaling\nthat we did earlier.\n\nI was expecting a greater difference. See whether you can find\nout what moved, if anything.\n    \n\n$\\blacksquare$\n\n(e) <a name=\"part:incons\">*</a> Find all the distances in your distance matrix that are 10\nor less (there should be three of them). Find these pairs of objects\non your map. Describe where they are on your map. Do\nthey appear to be the three closest pairs of objects?\n\n\nSolution\n\n\nThese are:\n\n\n* `velvet` and `felt` (distance 4). On the map,\nclose together at the top.\n\n* `block of styrofoam` and `cork` (distance 10). On the\nmap, close together at the bottom (though they appear to be\nslightly farther apart than `rubbereraser` and\n`cardboard`). \n\n* `unglazed ceramic tile` and `brick` (distance\n10). On the map, on the left but not especially close together\n(for example, `very fine sandpaper` is in between them\nand thus closer to both).\n\nI would say that they are not anything like the three closest\npairs of objects on the map. Consider, for example, \\texttt{rigid\nplastic sheet} and `wax paper`, or \\texttt{very fine\nsandpaper} and `unglazed ceramic tile`, or \\texttt{rubber\neraser} and `cardboard`, all of which are closer together\non the map than the three pairs of objects with distances 10 or\nless.\nThree points for saying something about the three pairs of objects\nof distance 10 or less, and one point for making some relevant\ncomment about whether these are the three closest pairs on the\nmap, eg. by finding one pair (or more than one) of objects on the\nmap that are closer.\n    \n\n$\\blacksquare$\n\n(f) Consider again your conclusions in parts (<a href=\"#part:stress\">here</a>)\nand (<a href=\"#part:incons\">here</a>). Explain briefly how they are consistent.\n\n\nSolution\n\n\nThe stress is rather high, which means that the map distances and\nactual distances may not correspond very well. This is also\nexactly what we found in the last part, by finding one (or two)\npairs of objects that were really close in actuality, but not so\nmuch on the map.\nThe point here is that a high stress *means* that distances\nin real life and on the map won't correspond very well. That's\nwhat I want you to say.\nExtra: another way to assess this is with a Shepard^[This always makes me think of the number 985 bus, but that's the wrong spelling. Spelled like this, this is also the name of the illustrator of the original pre-Disney Winnie-the-Pooh stories. \n[See here](https://en.wikipedia.org/wiki/E._H._Shepard).]\ndiagram. That would go like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nstimuli.sh <- Shepard(d, stimuli.1$points)\nnames(stimuli.sh)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"x\"  \"y\"  \"yf\"\n```\n:::\n:::\n\n  \n\nIn here, we plot the actual distances `x` against the map\ndistances `y`, making a data frame first:\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(stimuli.sh, data.frame(x = x, y = y)) %>%\n  ggplot(aes(x = x, y = y)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](mds_files/figure-pdf/sporers-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nThe actual distances are on the $x$-axis and the map distances are on\nthe $y$ axis, as far as I can tell (the help file is not clear on\nthis). But I think I am right, since a lot of the actual distances\nwere 28 or 29. Notice how the upward trend, such as it is, is very\nfuzzy: when the actual distance is very large, the map distance could\nbe almost anything.\n    \n\n$\\blacksquare$\n\n(g) Would a three-dimensional map work better than a\ntwo-dimensional one, bearing in mind that a three-dimensional map\nwill need something like `rgl` to interpret? Calculate\nsomething that will help you decide, and explain what you think.\n\n\nSolution\n\n\nThe calculation part is to figure out the stress value for a\nthree-dimensional map, and compare it with the 20\\% that we had\nbefore. `k=3` gets the three dimensions:\n\n::: {.cell}\n\n```{.r .cell-code}\nisoMDS(d, k = 3)$stress\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ninitial  value 14.934110 \niter   5 value 11.280474\niter  10 value 10.094796\niter  15 value 9.938456\nfinal  value 9.859657 \nconverged\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9.859657\n```\n:::\n:::\n\n     \n\nWhat this does is to obtain the map and throw all of it away except\nfor the stress value.^[Which is a very SAS way of doing  things: compute a whole bunch of stuff, most of which you ignore.] \n\nI think this stress value, just under 10\\%, or on the \"fair\" end of\n\"good\", is a worthwhile improvement over the just-over-20\\% that we\nhad in two dimensions. So I think this is worth the trouble of having\nto use a 3-dimensional plotting tool like `rgl` to interpret it\nwith. You might agree with me, or you might  not: for example, you\nmight be looking for a bigger improvement. Either is good, as far as\nI'm concerned, as long as your answer does something to balance the\nsmaller stress value^[Using more dimensions will  *certainly* decrease the stress, in the same way that adding  an $x$-variable to a regression will increase R-squared; it's the  same issue, of whether the change is big enough to be worth having.] with the difficulty of interpreting it.\n\nThe kind of `rgl` code you'll need is something like this (not tested):\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rgl)\nstimuli.2 <- isoMDS(d, k = 3)$points\nplot3d(stimuli.2)\ntext3d(stimuli.2, text = object.abb)\n```\n:::\n\n \n\nWhat you should find, looking at this (try it!) is that objects close\ntogether in this 3-dimensional place are more nearly close together in\nactuality as well, because of the in my opinion notably smaller stress\nvalue. \n    \n\n$\\blacksquare$\n\n\n",
    "supporting": [
      "mds_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}