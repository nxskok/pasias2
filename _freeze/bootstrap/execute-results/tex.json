{
  "hash": "0301487c60e61bcaba45cce84e6cdf53",
  "result": {
<<<<<<< HEAD
    "engine": "knitr",
    "markdown": "# The Bootstrap\n\nPackages for this chapter:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(bootstrap)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Air conditioning failures\n\n\n Back in 1963, there was a report on failures in\nair-conditioning equipment in\n\\href{https://en.wikipedia.org/wiki/Boeing_720}{Boeing 720}\naircraft. For one aircraft, the air-conditioning equipment failed 12\ntimes, and the number of hours it ran before failing each time was\nrecorded. The data are in\n[link](https://raw.githubusercontent.com/nxskok/pasias/master/air_conditioning.csv). Boeing\nwas interested in the mean failure time, because the company wanted to\nplan for engineers to fix the failures (and thus needed to estimate a\nfailure *rate*).\n\nThere is randomization here. Your answers will differ slightly from\nmine, unless you throw in this before you start (or at least before\nyou generate your first random numbers).\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(457299)\n```\n:::\n\n \n\n\n\n(a) Read in the data, and observe that you have the correct number\nof rows. (Note that the failure times are in ascending order).\n\n\n(b) What do you notice about the *shape* of the distribution of failure times? Explain briefly.\n\n\n(c) Obtain the means of 1000 bootstrap samples (that is, samples from the data with replacement). Save them.\n\n\n(d) Make a normal quantile plot of your bootstrap distribution. What do you see? Explain briefly.\n\n\n(e) Obtain the 95\\% bootstrap percentile confidence interval for the mean.\n\n\n(f) Obtain the 95\\% bootstrap-$t$ confidence interval for\nthe mean, and compare your two intervals.\n\n\n(g) Obtain the BCa 95\\% confidence interval for the mean.\n\n\n(h) Compare the BCa confidence interval with the other ones. Which one would you recommend? Explain briefly.\n\n\n\n\n\n\n##  Air conditioning failures: bootstrapping the median\n\n\n With a skewed data distribution such as the air-conditioning\nfailure times, we might be interested in inference for the median. One\nway to get a confidence interval for the median is to invert the sign\ntest, as in `smmr`, but another way is to obtain a bootstrap\nsampling distribution for the median. How do these approaches compare\nfor the air-conditioning data? We explore this here.\n\n\n\n(a) Read in the air-conditioning data again (if you don't already\nhave it lying around). The link is in the previous question.\n\n\n(b) Use `smmr` to get a confidence interval for the median (based on the sign test).\n\n\n(c) Obtain the bootstrap distribution of the sample median. Make a normal quantile plot of it. What do you notice? Explain briefly.\n\n\n(d) Obtain a 95\\% bootstrap percentile confidence interval for the median. How does it compare with the one you obtained earlier?\n\n\n(e) Obtain a 95\\% BCa interval. Compare it with the two other intervals you found.\n\n\n\n\n\n\n## Comparing eyesight\n\n Do people see on average better with their left eye or their right eye, or is there no difference? To find out, 15 subjects were shown a sequence of images, some to their left eye and some to their right (with a blindfold on the other eye). The subjects were asked to identify some objects in each image, and were given an overall score for each eye, based on their ability to identify objects with each eye. (A higher score is better.) Data in [http://ritsokiguess.site/datafiles/eyesight.csv](http://ritsokiguess.site/datafiles/eyesight.csv).\n\n\n\n(a) Read in and display (some of) the data.\n\n\n\n(b) Explain briefly why looking at differences (say right minus left) makes sense for these data, and calculate and save a dataframe with the differences added to it.\n\n\n\n(c) Make a suitable normal quantile plot, and describe what it tells you.\n\n\n\n(d) Obtain a bootstrap distribution of the sample *median*.\n\n\n\n\n(e) Make a histogram of your bootstrap distribution of the median. Use a lot of bins, such as the default 30, for this. What do you notice about the distribution? Why did it come out this way?\n\n\n\n(f) Find a 95% percentile interval for the population median.^[I was also going to have you do a bootstrap-t interval, but I'm not completely convinced I got that right when I was explaining it to you before.]\n\n\n\n(g) Find the BCA 95% confidence interval for the population median difference.\n\n\n\n(h) What do your intervals tell us about any possible difference between left eye and right eye in terms of ability to identify objects in images? Do the intervals agree or disagree about this?\n\n\n\n\n\n\n## Bootstrapping the IRS data\n\n You might recall the IRS data from when we were learning about the sign test. The idea was that we wanted to see how long \"on average\" it took people to fill out a tax form. The data are in [http://ritsokiguess.site/datafiles/irs.txt](http://ritsokiguess.site/datafiles/irs.txt).\n\n\n\n(a) Read in and display (some of) the data. There is only one column of data, so you can pretend the values are separated by anything.\n\n\n\n(b) Obtain a bootstrap distribution of the sample *median*.\n\n\n\n(c) Make a suitable graph of the bootstrap distribution of the median. What seems odd about it? Why did that happen? (Hint: use more bins on your plot than usual, like 50.)\n\n\n\n(d) Find 95% percentile and bootstrap-$t$ intervals for the population median. (Hint: your dataframe of bootstrapped medians may still be `rowwise`, so you might need to run `ungroup` first.)\n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n##  Air conditioning failures\n\n\n Back in 1963, there was a report on failures in\nair-conditioning equipment in\n\\href{https://en.wikipedia.org/wiki/Boeing_720}{Boeing 720}\naircraft. For one aircraft, the air-conditioning equipment failed 12\ntimes, and the number of hours it ran before failing each time was\nrecorded. The data are in\n[link](https://raw.githubusercontent.com/nxskok/pasias/master/air_conditioning.csv). Boeing\nwas interested in the mean failure time, because the company wanted to\nplan for engineers to fix the failures (and thus needed to estimate a\nfailure *rate*).\n\nThere is randomization here. Your answers will differ slightly from\nmine, unless you throw in this before you start (or at least before\nyou generate your first random numbers).\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(457299)\n```\n:::\n\n \n\n\n\n(a) Read in the data, and observe that you have the correct number\nof rows. (Note that the failure times are in ascending order).\n\nSolution\n\n\nThis is a `.csv` so `read_csv` is the thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"https://raw.githubusercontent.com/nxskok/pasias/master/air_conditioning.csv\"\naircon <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 12 Columns: 2\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (2): failure, hours\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\naircon\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 2\n   failure hours\n     <dbl> <dbl>\n 1       1     3\n 2       2     5\n 3       3     7\n 4       4    18\n 5       5    43\n 6       6    85\n 7       7    91\n 8       8    98\n 9       9   100\n10      10   130\n11      11   230\n12      12   487\n```\n\n\n:::\n:::\n\n     \n\nTwelve rows (12 failure times).\n\n$\\blacksquare$\n\n(b) What do you notice about the *shape* of the distribution of failure times? Explain briefly.\n\nSolution\n\n\nMake a suitable graph. The obvious one is a histogram:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(aircon, aes(x = hours)) + geom_histogram(bins = 7)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nYou'll have to play with the number of bins (there are only 12 observations). I got 7 from the Freedman-Diaconis rule:\n\n::: {.cell}\n\n```{.r .cell-code}\nnclass.FD(aircon$hours)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7\n```\n\n\n:::\n:::\n\n \n\nI was a little suspicious that the data would not be much like normal (I have run into failure times before), so I kept away from the Sturges rule.\n\nAnother possibility is a one-group boxplot:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(aircon, aes(y = hours, x = 1)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nIf you like, you can do a normal quantile plot. I rank that third here, because there is nothing immediately implying a comparison with the *normal* distribution, but I would accept it:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(aircon, aes(sample = hours)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n \nPick a visual and defend it.\n\nAll three of these graphs are showing a strong skewness to the right. \n\nExtra: this is probably not a surprise, because a time until failure\ncannot be less than zero, and distributions with a limit tend to be\nskewed away from that limit. (If you look back at the data, there are\nsome very small failure times, but there are also some very big\nones. The very small ones are saying that the lower limit matters.) If\nyou were modelling these times until failure, you might use a\ndistribution like the exponential or gamma or Weibull.\n\n$\\blacksquare$\n\n(c) Obtain the means of 1000 bootstrap samples (that is, samples from the data with replacement). Save them.\n\nSolution\n\n\nSomething like this, therefore:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(sample = list(sample(aircon$hours, replace = TRUE))) %>% \n  mutate(sample_mean = mean(sample)) -> means\nmeans\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 x 3\n# Rowwise: \n     sim sample     sample_mean\n   <int> <list>           <dbl>\n 1     1 <dbl [12]>        82.1\n 2     2 <dbl [12]>        75.4\n 3     3 <dbl [12]>       121. \n 4     4 <dbl [12]>        67.7\n 5     5 <dbl [12]>       107. \n 6     6 <dbl [12]>       172. \n 7     7 <dbl [12]>        98.3\n 8     8 <dbl [12]>       102. \n 9     9 <dbl [12]>        84.9\n10    10 <dbl [12]>        75.1\n# i 990 more rows\n```\n\n\n:::\n:::\n\nForgetting the `rowwise` will cause all sorts of trouble.\n\n\n$\\blacksquare$\n\n(d) Make a normal quantile plot of your bootstrap distribution. What do you see? Explain briefly.\n\nSolution\n\n\nThis:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(means, aes(sample = sample_mean)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-8-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nThis is still skewed to the right (it has a curved shape, or, the low values and the high values are both too high compared to the normal). \n\nExtra: this is less skewed than the original data was, because, with a\nsample size of 12, we have a *little* help from the Central Limit\nTheorem, but not much. This picture is the one that has to be normal\nenough for $t$ procedures to work, and it is not. This comes back into\nthe picture when we compare our confidence intervals later.\n\nAlso, it makes sense to see how *normal* a sampling distribution of a\nmean is, so a normal quantile plot would be my first choice for this.\n\n$\\blacksquare$\n\n(e) Obtain the 95\\% bootstrap percentile confidence interval for the mean.\n\nSolution\n\n\nThis is the 2.5 and 97.5 percentiles of the bootstrapped sampling distribution of the mean:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(means$sample_mean, c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     2.5%     97.5% \n 47.05625 187.93333 \n```\n\n\n:::\n:::\n\n \n$\\blacksquare$\n\n(f) Obtain the 95\\% bootstrap-$t$ confidence interval for\nthe mean, and compare your two intervals.\n\nSolution\n\n\nThe key is to remember that the original sample (and thus each bootstrap sample) had $n=12$, so there are $12-1=11$ df. (The fact that there were 1000 bootstrap samples is neither here nor there). This is how I like to do it:\n\n::: {.cell}\n\n```{.r .cell-code}\nt_star <- qt(0.975, 11)\nt_star\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.200985\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(means$sample_mean) + c(-1, 1) * t_star * sd(means$sample_mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  25.33401 186.81249\n```\n\n\n:::\n:::\n\n \n\nThe `c(-1, 1)` thing is the calculation version of the $\\pm$,\nand gets both limits at once. Pull the above apart to see how it works. If\nyou don't like that, you might prefer something like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nthe_mean <- mean(means$sample_mean)\nthe_sd <- sd(means$sample_mean)\nmargin <- t_star * the_sd\nthe_mean - margin\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 25.33401\n```\n\n\n:::\n\n```{.r .cell-code}\nthe_mean + margin\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 186.8125\n```\n\n\n:::\n:::\n\n \n\nI apologize for the crazy first line of that!\nAs for comparison: the bootstrap-$t$ interval goes down a lot further,\nthough the upper limits are quite similar (on this scale). Both\nintervals are very long and don't tell us much about the population\nmean time to failure, which is not very surprising given the small\nsample size ($n=12$) and the large variability in the data.\n\nExtra: the non-normality of the bootstrap (sampling) distribution says that we should definitely not trust the bootstrap-$t$, and probably not the bootstrap percentile interval either. Which brings us to the next part.\n\n$\\blacksquare$\n\n(g) Obtain the BCa 95\\% confidence interval for the mean.\n\nSolution\n\n\nThis means (possibly) installing and (certainly) loading the `bootstrap` package, and then:\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta <- function(x) {\n  mean(x)\n}\nbca_all <- with(aircon, bcanon(hours, 1000, theta))\nbca <- bca_all$confpoints\nbca\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     alpha bca point\n[1,] 0.025  55.58333\n[2,] 0.050  61.25000\n[3,] 0.100  70.66667\n[4,] 0.160  78.50000\n[5,] 0.840 160.66667\n[6,] 0.900 178.50000\n[7,] 0.950 204.25000\n[8,] 0.975 228.75000\n```\n\n\n:::\n:::\n\n \n\nPull out the ones from this that you need: the top one and the bottom one, to get an interval of 55.6 \nto 228.8. \n\nI seem to need to define the function `theta` first and pass it into `bcanon` as the third input. You may have more luck with `bcanon(hours, 1000, mean)` than I did. Try it.\n\nOr, if you feel like some extra coding: turn this matrix into a data frame, grab the rows you want, and then the column you want:\n\n::: {.cell}\n\n```{.r .cell-code}\nbca %>%\n  as_tibble() %>%\n  filter(alpha %in% c(0.025, 0.975)) %>%\n  pull(`bca point`)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  55.58333 228.75000\n```\n\n\n:::\n:::\n\n \n$\\blacksquare$\n\n(h) Compare the BCa confidence interval with the other ones. Which one would you recommend? Explain briefly.\n\nSolution\n\n\nIn this example, the bootstrap-$t$ and percentile intervals are very different, so we should use neither of them, and prefer the BCa interval. \n\nExtra: as usual in this kind of case, the BCa contains values for the mean pulled out into the long tail, but that's a proper adjustment for the sampling distribution being skewed.\n\n$\\blacksquare$\n\n\n\n\n\n##  Air conditioning failures: bootstrapping the median\n\n\n With a skewed data distribution such as the air-conditioning\nfailure times, we might be interested in inference for the median. One\nway to get a confidence interval for the median is to invert the sign\ntest, as in `smmr`, but another way is to obtain a bootstrap\nsampling distribution for the median. How do these approaches compare\nfor the air-conditioning data? We explore this here.\n\n\n\n(a) Read in the air-conditioning data again (if you don't already\nhave it lying around). The link is in the previous question.\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"https://raw.githubusercontent.com/nxskok/pasias/master/air_conditioning.csv\"\naircon <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 12 Columns: 2\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (2): failure, hours\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\naircon\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 x 2\n   failure hours\n     <dbl> <dbl>\n 1       1     3\n 2       2     5\n 3       3     7\n 4       4    18\n 5       5    43\n 6       6    85\n 7       7    91\n 8       8    98\n 9       9   100\n10      10   130\n11      11   230\n12      12   487\n```\n\n\n:::\n:::\n\n     \n\n$\\blacksquare$\n\n(b) Use `smmr` to get a confidence interval for the median (based on the sign test).\n\nSolution\n\n\nInput to `ci_median` is data frame and column:\n\n::: {.cell}\n\n```{.r .cell-code}\nci_median(aircon, hours)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]   7.002319 129.998291\n```\n\n\n:::\n:::\n\n     \n\n$\\blacksquare$\n\n(c) Obtain the bootstrap distribution of the sample median. Make a normal quantile plot of it. What do you notice? Explain briefly.\n\nSolution\n\n\nThe usual do-it-yourself bootstrap:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(samples = list(sample(aircon$hours, replace = TRUE))) %>% \n  mutate(medians = median(samples)) -> meds\n```\n:::\n\n \n\nI actually copied and pasted my code from the previous problem, changing `mean` to `median`.\n\nAs for a plot, well, this:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(meds, aes(sample = medians)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-median-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nNot only does this not look very normal, but also there are those\ncurious horizontal patches of points (that, you might recall, are\ncharacteristic of a discrete distribution). This has happened because\nthere are only a few possible medians: the median has to be either a\ndata value or halfway between two data values, so there are only\nsomething like $2(12)-1=23$ different possible medians, with the ones\nin the middle being more likely.\n\nThis also shows up on a histogram, but only if you have enough\nbins. (If you don't have enough bins, some of the neighbouring\npossible values end up in the same bin; here, the aim is to have\nenough bins to show the discreteness, rather than the usual thing of\nhaving few enough bins to show the shape.)\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(meds, aes(x = medians)) + geom_histogram(bins = 30)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-median-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\n$\\blacksquare$\n\n(d) Obtain a 95\\% bootstrap percentile confidence interval for the median. How does it compare with the one you obtained earlier?\n\nSolution\n\n\nAlso, the usual:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(meds$medians, c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n 2.5% 97.5% \n 12.5 115.0 \n```\n\n\n:::\n:::\n\n \n\nThis goes down and up not quite so far as the interval from `smmr`. That might be because the `smmr` interval is too wide (based on a not-very-powerful test), or because the bootstrap quantile interval is too narrow (as it usually is). It's hard to tell which it is.\n\n$\\blacksquare$\n\n(e) Obtain a 95\\% BCa interval. Compare it with the two other intervals you found.\n\nSolution\n\n\nYet more copying and pasting (from the previous question):\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta <- function(x) {\n  median(x)\n}\nbca_all <- with(aircon, bcanon(hours, 1000, theta))\nbca <- bca_all$confpoints\nbca\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     alpha bca point\n[1,] 0.025      12.5\n[2,] 0.050      12.5\n[3,] 0.100      18.0\n[4,] 0.160      30.5\n[5,] 0.840      94.5\n[6,] 0.900      98.0\n[7,] 0.950     100.0\n[8,] 0.975     115.0\n```\n\n\n:::\n:::\n\nMy 95% BCa interval is from 12.5 to 115.     \n\nAgain, I seem to need to define the tiny function, while you can probably call `bcanon(hours, 1000, median)`. Try it and see.\n\nMy BCa interval is the same as the bootstrap percentile\ninterval and a little shorter than the one that came from the sign\ntest. I would guess that the BCa interval is the most trustworthy of\nthe three, though there is here not that much difference between\nthem. All the intervals are again very long, a reflection of the small\nsample size and large variability.\n\n$\\blacksquare$\n\n\n\n\n\n## Comparing eyesight\n\n Do people see on average better with their left eye or their right eye, or is there no difference? To find out, 15 subjects were shown a sequence of images, some to their left eye and some to their right (with a blindfold on the other eye). The subjects were asked to identify some objects in each image, and were given an overall score for each eye, based on their ability to identify objects with each eye. (A higher score is better.) Data in [http://ritsokiguess.site/datafiles/eyesight.csv](http://ritsokiguess.site/datafiles/eyesight.csv).\n\n\n\n(a) Read in and display (some of) the data.\n\nSolution\n\n\nThis is a `csv`, so no surprises:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/eyesight.csv\"\nsight <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 15 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (3): person, right, left\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nsight\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 x 3\n   person right  left\n    <dbl> <dbl> <dbl>\n 1      1    50    47\n 2      2    45    45\n 3      3    33    31\n 4      4    22    24\n 5      5    99    78\n 6      6    79    76\n 7      7     4    13\n 8      8    36    46\n 9      9    62    45\n10     10    51    44\n11     11    27    23\n12     12    15    14\n13     13    26    34\n14     14    83    79\n15     15    86    81\n```\n\n\n:::\n:::\n\n15 observations, with the subjects labelled by number, and a score for each subject and each eye. \n\n\n\n$\\blacksquare$\n\n\n(b) Explain briefly why looking at differences (say right minus left) makes sense for these data, and calculate and save a dataframe with the differences added to it.\n\nSolution\n\n\nThis is matched pairs data, with two observations for each subject. A matched pairs analysis, whether by a sign test or a matched-pairs $t$-test, would be based on one difference for each subject, and so those would make sense to calculate. (You'll recall that a matched pairs analysis uses the differences and *not* the original data.)\n\nThus, saving back into our original dataframe:\n\n::: {.cell}\n\n```{.r .cell-code}\nsight %>% \nmutate(difference = right - left) -> sight\nsight\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 x 4\n   person right  left difference\n    <dbl> <dbl> <dbl>      <dbl>\n 1      1    50    47          3\n 2      2    45    45          0\n 3      3    33    31          2\n 4      4    22    24         -2\n 5      5    99    78         21\n 6      6    79    76          3\n 7      7     4    13         -9\n 8      8    36    46        -10\n 9      9    62    45         17\n10     10    51    44          7\n11     11    27    23          4\n12     12    15    14          1\n13     13    26    34         -8\n14     14    83    79          4\n15     15    86    81          5\n```\n\n\n:::\n:::\n\nExtra: this is one of those cases where having long data would make it very much more difficult to work out the differences for each person. Try it and see. How will you match up the two measurements for each person?\n\n\n$\\blacksquare$\n\n\n(c) Make a suitable normal quantile plot, and describe what it tells you.\n\nSolution\n\n\nA normal quantile plot *of the differences*, therefore, since normality of the two individual scores is immaterial:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sight, aes(sample = difference)) + stat_qq() +\nstat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/vontouchingen-1.pdf){fig-pos='H'}\n:::\n:::\n\nWe have what I think is best described as \"long tails\", with the high values being too high and the low ones being a bit too low for a normal distribution. I think this is a better description than \"outliers\" because outliers are isolated unusual values, not five observations out of fifteen!\n\nThe plot is telling us that a matched-pairs $t$-test is questionable, and that we might do a sign test instead. Or, as we explore in this question, find a bootstrap distribution (in this case, for the median).\n\nExtra: the one kind of sensible plot that uses the original data in this situation would be a scatterplot, since the right and left scores are matched up:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sight, aes(x = right, y = left)) + \ngeom_point() + geom_abline(slope = 1, intercept = 0)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/wickten-1.pdf){fig-pos='H'}\n:::\n:::\n\nI added the line $y = x$ to the  plot. The value of doing that is that a point to the right and below the line has the right-eye score bigger than the left-eye one, and vice versa for a point to the left and above. This plot tells us that a small majority of the subjects had a higher score with the right eye, and for the ones that had a higher score with the left eye, the difference wasn't usually very big. \n\nThis plot tells us nothing about normality of differences, though (not without some careful looking), which is one of the things we usually care about.\n\n\n$\\blacksquare$\n\n\n(d) Obtain a bootstrap distribution of the sample *median*.\n\nSolution\n\n\n::: {.cell}\n\n:::\n\n\nBorrow the idea from lecture, replacing mean with median:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \nrowwise() %>% \nmutate(sample = list(sample(sight$difference, replace = TRUE))) %>% \nmutate(my_median = median(sample)) -> meds\nmeds\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 x 3\n# Rowwise: \n     sim sample     my_median\n   <int> <list>         <dbl>\n 1     1 <dbl [15]>         3\n 2     2 <dbl [15]>         3\n 3     3 <dbl [15]>         2\n 4     4 <dbl [15]>         2\n 5     5 <dbl [15]>         3\n 6     6 <dbl [15]>         4\n 7     7 <dbl [15]>         3\n 8     8 <dbl [15]>         3\n 9     9 <dbl [15]>         3\n10    10 <dbl [15]>         3\n# i 990 more rows\n```\n\n\n:::\n:::\n\nThe steps are:\n\n- create a dataframe with a column called `sim` to label the simulations\n- from here on out, work \"rowwise\", that is, with one row at a time\n- generate a bootstrap sample for each row. A bootstrap sample is fifteen observations rather than just one, so we are making a list-column and thus the `list` has to go on the front\n- work out the median of each bootstrap sample. Remember, the `rowwise` applies until you cancel it,^[That is done using `ungroup`, should you ever need to stop working rowwise. This seems like an odd choice of function, since the usual use of  `ungroup` is to undo a group-by, but what `ungroup` actually does is to remove *any* special properties a dataframe has, including both groups and any rowwise behaviour.] and so this will be the median of the bootstrap sample on each row, one at a time. \n\n\nAs ever, if you want to see what's going on, run this one line at a time. \n\n\n\n\n\n$\\blacksquare$\n\n\n\n(e) Make a histogram of your bootstrap distribution of the median. Use a lot of bins, such as the default 30, for this. What do you notice about the distribution? Why did it come out this way?\n\nSolution\n\nFor this histogram, there is no need to specify a number of bins (unless you want to):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(meds, aes(x = my_median)) + geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/nefen-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe distribution is very discrete (this shows up more clearly with more bins).\n\nThe data values are all integers (and therefore so are the differences). The median of an odd number of data values must be one of the data values, and the bootstrap samples only contain (varying numbers of copies of) the differences in the original dataset, so \neach bootstrap sample must have a median that is an integer too.\n\n\nExtra:\nin case you are thinking that this happened because the data values were integers, no, it would happen even if the data were decimal numbers. Let's make some fake data of 15 random normals and then do the same thing again:\n\n::: {.cell}\n\n```{.r .cell-code}\nfake_data <- tibble(x = rnorm(15))\nfake_data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 x 1\n          x\n      <dbl>\n 1 -2.02   \n 2  0.867  \n 3 -0.00982\n 4 -0.123  \n 5 -0.431  \n 6  0.702  \n 7  1.22   \n 8 -0.0818 \n 9  1.06   \n10  0.318  \n11 -0.0179 \n12 -0.370  \n13  0.0115 \n14 -1.57   \n15  0.0529 \n```\n\n\n:::\n:::\n\nand once again bootstrap the median:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \nrowwise() %>% \nmutate(sample = list(sample(fake_data$x, replace = TRUE))) %>% \nmutate(my_median = median(sample)) -> meds2\nmeds2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 x 3\n# Rowwise: \n     sim sample     my_median\n   <int> <list>         <dbl>\n 1     1 <dbl [15]>   0.0115 \n 2     2 <dbl [15]>   0.0115 \n 3     3 <dbl [15]>  -0.123  \n 4     4 <dbl [15]>  -0.0179 \n 5     5 <dbl [15]>   0.0115 \n 6     6 <dbl [15]>   0.318  \n 7     7 <dbl [15]>   0.0115 \n 8     8 <dbl [15]>  -0.00982\n 9     9 <dbl [15]>   0.0529 \n10    10 <dbl [15]>   0.0115 \n# i 990 more rows\n```\n\n\n:::\n:::\n\nYou can see even from these few that the bootstrap distribution of the median has repeats, so there should also be some discreteness here:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(meds2, aes(x = my_median)) + geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/botz-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe discreteness is a property of the fact that we were bootstrapping the *median*, and the median has to be one of the data values. \n\nTo confirm that, recall that our original data were integers:\n\n::: {.cell}\n\n```{.r .cell-code}\nsight\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 x 4\n   person right  left difference\n    <dbl> <dbl> <dbl>      <dbl>\n 1      1    50    47          3\n 2      2    45    45          0\n 3      3    33    31          2\n 4      4    22    24         -2\n 5      5    99    78         21\n 6      6    79    76          3\n 7      7     4    13         -9\n 8      8    36    46        -10\n 9      9    62    45         17\n10     10    51    44          7\n11     11    27    23          4\n12     12    15    14          1\n13     13    26    34         -8\n14     14    83    79          4\n15     15    86    81          5\n```\n\n\n:::\n:::\n\nbut even for these, if you bootstrap the mean, you don't get the same discreteness:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \nrowwise() %>% \nmutate(sample = list(sample(sight$difference, replace = TRUE))) %>% \nmutate(my_mean = mean(sample)) -> means\nmeans %>% \nggplot(aes(x = my_mean)) + geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/vesar-1.pdf){fig-pos='H'}\n:::\n:::\n\nThis is too many bins for 1000 bootstrap samples, so the shape is kind of irregular, but there are not the big gaps that the bootstrap distribution of the sample median has. Indeed, this ought to be somewhere near normal and is:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(means, aes(sample = my_mean)) + stat_qq() +\nstat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/stricher-1.pdf){fig-pos='H'}\n:::\n:::\n\n(This is saying that the Central Limit Theorem is really helping, even for a sample size of only 15 from clearly non-normal data, so the paired $t$ may not be as bad as we would have thought.)\n\n\n$\\blacksquare$\n\n\n(f) Find a 95% percentile interval for the population median.^[I was also going to have you do a bootstrap-t interval, but I'm not completely convinced I got that right when I was explaining it to you before.]\n\nSolution\n\n\nThe percentile interval comes from the middle 95% of the bootstrap distribution of medians:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(meds$my_median, c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n 2.5% 97.5% \n   -2     4 \n```\n\n\n:::\n:::\n\nThe bootstrap percentile interval goes from $-2$ to 4. Like the CI for the median based on the sign test, the ends of this interval must be data values.\n\nExtra: for comparison, the interval from the sign test is this:\n\n::: {.cell}\n\n```{.r .cell-code}\nci_median(sight, difference)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.997070  4.994629\n```\n\n\n:::\n:::\n\nwhich is, when rounded off, from $-2$ to 5, very like the percentile interval.\n\n\n$\\blacksquare$\n\n\n(g) Find the BCA 95% confidence interval for the population median difference.\n\nSolution\n\n\nLoad (and if necessary install) the `bootstrap` package, and then:\n\n::: {.cell}\n\n```{.r .cell-code}\nbca <- bcanon(sight$difference, 1000, median)\nbca$confpoints\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     alpha bca point\n[1,] 0.025        -2\n[2,] 0.050        -2\n[3,] 0.100         0\n[4,] 0.160         0\n[5,] 0.840         3\n[6,] 0.900         3\n[7,] 0.950         4\n[8,] 0.975         4\n```\n\n\n:::\n:::\n\n$-2$ to 4, in this case like the percentile interval.^[They don't often agree this well, but all of these intervals in this situation but have data values at their endpoints, and all of our data values are integers.] Note how this one is data values also. \n\n\n$\\blacksquare$\n\n\n(h) What do your intervals tell us about any possible difference between left eye and right eye in terms of ability to identify objects in images? Do the intervals agree or disagree about this?\n\nSolution\n\n\nThe intervals are not quite all the same, but one thing they have in common is that they all have a negative lower limit and a positive upper one (more positive than the negative one is negative). This says that 0 is a plausible difference in each case, and thus it is reasonable to conclude that there is no evidence of any difference between the two eyes, based on this sample of 15 subjects. \n\nThe intervals do all go more positive than negative, which says that if anything the scores are better with the right eye than the left on average (from the way around that we took the differences). However, there is no evidence here that this is any more than chance.\n\n\n$\\blacksquare$\n\n\n\n\n\n## Bootstrapping the IRS data\n\n You might recall the IRS data from when we were learning about the sign test. The idea was that we wanted to see how long \"on average\" it took people to fill out a tax form. The data are in [http://ritsokiguess.site/datafiles/irs.txt](http://ritsokiguess.site/datafiles/irs.txt).\n\n\n\n(a) Read in and display (some of) the data. There is only one column of data, so you can pretend the values are separated by anything.\n\nSolution\n\n\nPretty much any of the `read_` functions will work, even this one:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/irs.txt\"\nirs <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  Time = col_double()\n)\n```\n\n\n:::\n\n```{.r .cell-code}\nirs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 30 x 1\n    Time\n   <dbl>\n 1    91\n 2    64\n 3   243\n 4   167\n 5   123\n 6    65\n 7    71\n 8   204\n 9   110\n10   178\n# i 20 more rows\n```\n\n\n:::\n:::\n\nOne column called `Time`.\n\n\n$\\blacksquare$\n\n\n(b) Obtain a bootstrap distribution of the sample *median*.\n\nSolution\n\n\nThe lecture notes use the exact same dataset, so you can borrow ideas from there:\n\nSet up a dataframe with one row for each bootstrap sample you're going to draw, 1000 in this case:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 x 1\n     sim\n   <int>\n 1     1\n 2     2\n 3     3\n 4     4\n 5     5\n 6     6\n 7     7\n 8     8\n 9     9\n10    10\n# i 990 more rows\n```\n\n\n:::\n:::\n\nCreate a column with a new bootstrap sample for each `sim`. This means doing `rowwise` *first* and then wrapping the sampling in `list` because you are creating a list-column of samples:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \nrowwise() %>% \nmutate(sample = list(sample(irs$Time, replace = TRUE)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 x 2\n# Rowwise: \n     sim sample    \n   <int> <list>    \n 1     1 <dbl [30]>\n 2     2 <dbl [30]>\n 3     3 <dbl [30]>\n 4     4 <dbl [30]>\n 5     5 <dbl [30]>\n 6     6 <dbl [30]>\n 7     7 <dbl [30]>\n 8     8 <dbl [30]>\n 9     9 <dbl [30]>\n10    10 <dbl [30]>\n# i 990 more rows\n```\n\n\n:::\n:::\n\nEach thing in `sample` has 30 observations in it (one bootstrap sample). If you want, you can `unnest` to take a look at the values; they should be the ones in the dataset, possibly with extra repeats.\n\nNext, work out the median of each bootstrapped sample, which is simple because we are still working rowwise:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \nrowwise() %>% \nmutate(sample = list(sample(irs$Time, replace = TRUE))) %>% \nmutate(my_median = median(sample)) -> bs\nbs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 x 3\n# Rowwise: \n     sim sample     my_median\n   <int> <list>         <dbl>\n 1     1 <dbl [30]>      178.\n 2     2 <dbl [30]>      170 \n 3     3 <dbl [30]>      183 \n 4     4 <dbl [30]>      172.\n 5     5 <dbl [30]>      178 \n 6     6 <dbl [30]>      209 \n 7     7 <dbl [30]>      150 \n 8     8 <dbl [30]>      154.\n 9     9 <dbl [30]>      194 \n10    10 <dbl [30]>      194 \n# i 990 more rows\n```\n\n\n:::\n:::\n\nAs you realize, `bs` stands for \"bootstrap\". Of course.\n\n\n$\\blacksquare$\n\n\n(c) Make a suitable graph of the bootstrap distribution of the median. What seems odd about it? Why did that happen? (Hint: use more bins on your plot than usual, like 50.)\n\nSolution\n\n\nThe medians are already in a dataframe, so go straight ahead:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bs, aes(x = my_median)) + geom_histogram(bins = 50)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/stainachin-1.pdf){fig-pos='H'}\n:::\n:::\n\nWhat we are seeing at this resolution is that the distribution is *very* irregular, with funny holes in it, more than you would expect even with this many bins. By way of comparison, the bootstrap distribution of the *mean* looks a lot smoother:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(my_sample = list(sample(irs$Time, replace = TRUE))) %>% \n  mutate(my_mean = mean(my_sample)) %>% \n  ggplot(aes(x = my_mean)) + geom_histogram(bins = 50)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/rom-1.pdf){fig-pos='H'}\n:::\n:::\nThis is somewhat irregular, because we really have too many bins, but there are not nearly so many holes and irregular heights as on the plot for the median. I had you use a lot of bins in this special case because I wanted you to see just how irregular the bootstrapped distribution for the median really was.\n\nSo why did that happen? Think about what the sample median is for 30 observations: it is the mean of the 15th and 16th smallest values when you arrange them in order. A bootstrap sample must contain the same values as the original dataset (just probably not the same frequencies of them). So the median of a bootstrap sample must be the average of two of the values in the original dataset, and probably two that were close together. What that means is that there are *not very many possible medians* of the bootstrap samples, and they form a clearly discrete rather than a continuous distribution. (The sample mean, on the other hand, uses all the values in the bootstrap sample, and so there are a lot more possible bootstrap means than bootstrap medians; the distribution of those is as good as continuous.)\n\nWhat this means is that bootstrapping for medians is odd (it always looks like this), but that's what the bootstrap distribution looks like.\n\n\n$\\blacksquare$\n\n\n(d) Find 95% percentile and bootstrap-$t$ intervals for the population median. (Hint: your dataframe of bootstrapped medians may still be `rowwise`, so you might need to run `ungroup` first.)\n\nSolution\n\n\nThe percentile interval comes from the middle 95% of the bootstrap distribution of medians. The dataframe `bs` is still rowwise, so we have to undo that first to do it the obvious way:\n\n::: {.cell}\n\n```{.r .cell-code}\nbs %>% \n  ungroup() %>% \n  summarize(ci1 = quantile(my_median, 0.025),\n            ci2 = quantile(my_median, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 2\n    ci1   ci2\n  <dbl> <dbl>\n1   121   215\n```\n\n\n:::\n:::\n\nOr, pull out just that column and find the two quantiles of that, for which there are two ways, the base R way:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(bs$my_median, c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n 2.5% 97.5% \n  121   215 \n```\n\n\n:::\n:::\n\nand the slightly odd-looking:\n\n::: {.cell}\n\n```{.r .cell-code}\nbs %>% pull(my_median) %>% \n  quantile(c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n 2.5% 97.5% \n  121   215 \n```\n\n\n:::\n:::\n\nAll of these get you to the same place. There is even one more:\n\n::: {.cell}\n\n```{.r .cell-code}\nbs %>% \n  ungroup() %>% \n  reframe(ci = quantile(my_median, c(0.025, 0.975)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 1\n     ci\n  <dbl>\n1   121\n2   215\n```\n\n\n:::\n:::\n\nThis is `reframe` rather than `summarize` because `quantile` in this case returns two numbers, the two percentiles we want, and `summarize` expects only one. (This is newish behaviour.) Another way is to use `summarize`, but wrap the call to `quantile` in `list` so that it returns only one thing (the list, containing two numbers, but bundled up in one list). Then you need to `unnest` it to see the values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbs %>% \n  ungroup() %>% \n  summarize(ci = list(quantile(my_median, c(0.025, 0.975)))) %>% \n  unnest(ci)  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 1\n     ci\n  <dbl>\n1   121\n2   215\n```\n\n\n:::\n:::\n\nIf you had `rowwise` in the back of your mind, you might have tried this. Try it up to but *not* including the `unnest` to see how it works.\n\nFor the bootstrap $t$, estimate the population median as the sample median:\n\n::: {.cell}\n\n```{.r .cell-code}\nmed <- median(irs$Time)\nmed\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 172.5\n```\n\n\n:::\n:::\n\nget its standard error from the SD of the bootstrap distribution of medians:\n\n::: {.cell}\n\n```{.r .cell-code}\nse <- sd(bs$my_median)\nse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 23.31839\n```\n\n\n:::\n:::\n\nthen go up and down twice this (or 1.96 if you believe in $z$): \n\n::: {.cell}\n\n```{.r .cell-code}\nmed + c(-2, 2)*se\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 125.8632 219.1368\n```\n\n\n:::\n:::\n\nExtra: in this case, we also have the CI for the median that came out of the sign test:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(smmr)\nci_median(irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 119.0065 214.9955\n```\n\n\n:::\n:::\n\nThis one is actually very close to the bootstrap percentile interval, while the bootstrap $t$ interval is higher at both ends.\n\n\n$\\blacksquare$\n\n\n\n",
=======
    "markdown": "# The Bootstrap\n\nPackages for this chapter:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(bootstrap)\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\n##  Air conditioning failures\n\n\n Back in 1963, there was a report on failures in\nair-conditioning equipment in\n\\href{https://en.wikipedia.org/wiki/Boeing_720}{Boeing 720}\naircraft. For one aircraft, the air-conditioning equipment failed 12\ntimes, and the number of hours it ran before failing each time was\nrecorded. The data are in\n[link](https://raw.githubusercontent.com/nxskok/pasias/master/air_conditioning.csv). Boeing\nwas interested in the mean failure time, because the company wanted to\nplan for engineers to fix the failures (and thus needed to estimate a\nfailure *rate*).\n\nThere is randomization here. Your answers will differ slightly from\nmine, unless you throw in this before you start (or at least before\nyou generate your first random numbers).\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(457299)\n```\n:::\n\n \n\n\n\n(a) Read in the data, and observe that you have the correct number\nof rows. (Note that the failure times are in ascending order).\n\n\n(b) What do you notice about the *shape* of the distribution of failure times? Explain briefly.\n\n\n(c) Obtain the means of 1000 bootstrap samples (that is, samples from the data with replacement). Save them.\n\n\n(d) Make a normal quantile plot of your bootstrap distribution. What do you see? Explain briefly.\n\n\n(e) Obtain the 95\\% bootstrap percentile confidence interval for the mean.\n\n\n(f) Obtain the 95\\% bootstrap-$t$ confidence interval for\nthe mean, and compare your two intervals.\n\n\n(g) Obtain the BCa 95\\% confidence interval for the mean.\n\n\n(h) Compare the BCa confidence interval with the other ones. Which one would you recommend? Explain briefly.\n\n\n\n\n\n\n##  Air conditioning failures: bootstrapping the median\n\n\n With a skewed data distribution such as the air-conditioning\nfailure times, we might be interested in inference for the median. One\nway to get a confidence interval for the median is to invert the sign\ntest, as in `smmr`, but another way is to obtain a bootstrap\nsampling distribution for the median. How do these approaches compare\nfor the air-conditioning data? We explore this here.\n\n\n\n(a) Read in the air-conditioning data again (if you don't already\nhave it lying around). The link is in the previous question.\n\n\n(b) Use `smmr` to get a confidence interval for the median (based on the sign test).\n\n\n(c) Obtain the bootstrap distribution of the sample median. Make a normal quantile plot of it. What do you notice? Explain briefly.\n\n\n(d) Obtain a 95\\% bootstrap percentile confidence interval for the median. How does it compare with the one you obtained earlier?\n\n\n(e) Obtain a 95\\% BCa interval. Compare it with the two other intervals you found.\n\n\n\n\n\n\n## Comparing eyesight\n\n Do people see on average better with their left eye or their right eye, or is there no difference? To find out, 15 subjects were shown a sequence of images, some to their left eye and some to their right (with a blindfold on the other eye). The subjects were asked to identify some objects in each image, and were given an overall score for each eye, based on their ability to identify objects with each eye. (A higher score is better.) Data in [http://ritsokiguess.site/datafiles/eyesight.csv](http://ritsokiguess.site/datafiles/eyesight.csv).\n\n\n\n(a) Read in and display (some of) the data.\n\n\n\n(b) Explain briefly why looking at differences (say right minus left) makes sense for these data, and calculate and save a dataframe with the differences added to it.\n\n\n\n(c) Make a suitable normal quantile plot, and describe what it tells you.\n\n\n\n(d) Obtain a bootstrap distribution of the sample *median*.\n\n\n\n\n(e) Make a histogram of your bootstrap distribution of the median. Use a lot of bins, such as the default 30, for this. What do you notice about the distribution? Why did it come out this way?\n\n\n\n(f) Find a 95% percentile interval for the population median.^[I was also going to have you do a bootstrap-t interval, but I'm not completely convinced I got that right when I was explaining it to you before.]\n\n\n\n(g) Find the BCA 95% confidence interval for the population median difference.\n\n\n\n(h) What do your intervals tell us about any possible difference between left eye and right eye in terms of ability to identify objects in images? Do the intervals agree or disagree about this?\n\n\n\n\n\n\n## Bootstrapping the IRS data\n\n You might recall the IRS data from when we were learning about the sign test. The idea was that we wanted to see how long \"on average\" it took people to fill out a tax form. The data are in [http://ritsokiguess.site/datafiles/irs.txt](http://ritsokiguess.site/datafiles/irs.txt).\n\n\n\n(a) Read in and display (some of) the data. There is only one column of data, so you can pretend the values are separated by anything.\n\n\n\n(b) Obtain a bootstrap distribution of the sample *median*.\n\n\n\n(c) Make a suitable graph of the bootstrap distribution of the median. What seems odd about it? Why did that happen? (Hint: use more bins on your plot than usual, like 50.)\n\n\n\n(d) Find 95% percentile and bootstrap-$t$ intervals for the population median. (Hint: your dataframe of bootstrapped medians may still be `rowwise`, so you might need to run `ungroup` first.)\n\n\n\n\n\n\n\nMy solutions follow:\n\n\n\n\n##  Air conditioning failures\n\n\n Back in 1963, there was a report on failures in\nair-conditioning equipment in\n\\href{https://en.wikipedia.org/wiki/Boeing_720}{Boeing 720}\naircraft. For one aircraft, the air-conditioning equipment failed 12\ntimes, and the number of hours it ran before failing each time was\nrecorded. The data are in\n[link](https://raw.githubusercontent.com/nxskok/pasias/master/air_conditioning.csv). Boeing\nwas interested in the mean failure time, because the company wanted to\nplan for engineers to fix the failures (and thus needed to estimate a\nfailure *rate*).\n\nThere is randomization here. Your answers will differ slightly from\nmine, unless you throw in this before you start (or at least before\nyou generate your first random numbers).\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(457299)\n```\n:::\n\n \n\n\n\n(a) Read in the data, and observe that you have the correct number\nof rows. (Note that the failure times are in ascending order).\n\nSolution\n\n\nThis is a `.csv` so `read_csv` is the thing:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"https://raw.githubusercontent.com/nxskok/pasias/master/air_conditioning.csv\"\naircon <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 12 Columns: 2\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (2): failure, hours\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\naircon\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 x 2\n   failure hours\n     <dbl> <dbl>\n 1       1     3\n 2       2     5\n 3       3     7\n 4       4    18\n 5       5    43\n 6       6    85\n 7       7    91\n 8       8    98\n 9       9   100\n10      10   130\n11      11   230\n12      12   487\n```\n:::\n:::\n\n     \n\nTwelve rows (12 failure times).\n\n$\\blacksquare$\n\n(b) What do you notice about the *shape* of the distribution of failure times? Explain briefly.\n\nSolution\n\n\nMake a suitable graph. The obvious one is a histogram:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(aircon, aes(x = hours)) + geom_histogram(bins = 7)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nYou'll have to play with the number of bins (there are only 12 observations). I got 7 from the Freedman-Diaconis rule:\n\n::: {.cell}\n\n```{.r .cell-code}\nnclass.FD(aircon$hours)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7\n```\n:::\n:::\n\n \n\nI was a little suspicious that the data would not be much like normal (I have run into failure times before), so I kept away from the Sturges rule.\n\nAnother possibility is a one-group boxplot:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(aircon, aes(y = hours, x = 1)) + geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nIf you like, you can do a normal quantile plot. I rank that third here, because there is nothing immediately implying a comparison with the *normal* distribution, but I would accept it:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(aircon, aes(sample = hours)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n \nPick a visual and defend it.\n\nAll three of these graphs are showing a strong skewness to the right. \n\nExtra: this is probably not a surprise, because a time until failure\ncannot be less than zero, and distributions with a limit tend to be\nskewed away from that limit. (If you look back at the data, there are\nsome very small failure times, but there are also some very big\nones. The very small ones are saying that the lower limit matters.) If\nyou were modelling these times until failure, you might use a\ndistribution like the exponential or gamma or Weibull.\n\n$\\blacksquare$\n\n(c) Obtain the means of 1000 bootstrap samples (that is, samples from the data with replacement). Save them.\n\nSolution\n\n\nSomething like this, therefore:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(sample = list(sample(aircon$hours, replace = TRUE))) %>% \n  mutate(sample_mean = mean(sample)) -> means\nmeans\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,000 x 3\n# Rowwise: \n     sim sample     sample_mean\n   <int> <list>           <dbl>\n 1     1 <dbl [12]>        82.1\n 2     2 <dbl [12]>        75.4\n 3     3 <dbl [12]>       121. \n 4     4 <dbl [12]>        67.7\n 5     5 <dbl [12]>       107. \n 6     6 <dbl [12]>       172. \n 7     7 <dbl [12]>        98.3\n 8     8 <dbl [12]>       102. \n 9     9 <dbl [12]>        84.9\n10    10 <dbl [12]>        75.1\n# i 990 more rows\n```\n:::\n:::\n\nForgetting the `rowwise` will cause all sorts of trouble.\n\n\n$\\blacksquare$\n\n(d) Make a normal quantile plot of your bootstrap distribution. What do you see? Explain briefly.\n\nSolution\n\n\nThis:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(means, aes(sample = sample_mean)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-8-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nThis is still skewed to the right (it has a curved shape, or, the low values and the high values are both too high compared to the normal). \n\nExtra: this is less skewed than the original data was, because, with a\nsample size of 12, we have a *little* help from the Central Limit\nTheorem, but not much. This picture is the one that has to be normal\nenough for $t$ procedures to work, and it is not. This comes back into\nthe picture when we compare our confidence intervals later.\n\nAlso, it makes sense to see how *normal* a sampling distribution of a\nmean is, so a normal quantile plot would be my first choice for this.\n\n$\\blacksquare$\n\n(e) Obtain the 95\\% bootstrap percentile confidence interval for the mean.\n\nSolution\n\n\nThis is the 2.5 and 97.5 percentiles of the bootstrapped sampling distribution of the mean:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(means$sample_mean, c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     2.5%     97.5% \n 47.05625 187.93333 \n```\n:::\n:::\n\n \n$\\blacksquare$\n\n(f) Obtain the 95\\% bootstrap-$t$ confidence interval for\nthe mean, and compare your two intervals.\n\nSolution\n\n\nThe key is to remember that the original sample (and thus each bootstrap sample) had $n=12$, so there are $12-1=11$ df. (The fact that there were 1000 bootstrap samples is neither here nor there). This is how I like to do it:\n\n::: {.cell}\n\n```{.r .cell-code}\nt_star <- qt(0.975, 11)\nt_star\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.200985\n```\n:::\n\n```{.r .cell-code}\nmean(means$sample_mean) + c(-1, 1) * t_star * sd(means$sample_mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  25.33401 186.81249\n```\n:::\n:::\n\n \n\nThe `c(-1, 1)` thing is the calculation version of the $\\pm$,\nand gets both limits at once. Pull the above apart to see how it works. If\nyou don't like that, you might prefer something like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nthe_mean <- mean(means$sample_mean)\nthe_sd <- sd(means$sample_mean)\nmargin <- t_star * the_sd\nthe_mean - margin\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 25.33401\n```\n:::\n\n```{.r .cell-code}\nthe_mean + margin\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 186.8125\n```\n:::\n:::\n\n \n\nI apologize for the crazy first line of that!\nAs for comparison: the bootstrap-$t$ interval goes down a lot further,\nthough the upper limits are quite similar (on this scale). Both\nintervals are very long and don't tell us much about the population\nmean time to failure, which is not very surprising given the small\nsample size ($n=12$) and the large variability in the data.\n\nExtra: the non-normality of the bootstrap (sampling) distribution says that we should definitely not trust the bootstrap-$t$, and probably not the bootstrap percentile interval either. Which brings us to the next part.\n\n$\\blacksquare$\n\n(g) Obtain the BCa 95\\% confidence interval for the mean.\n\nSolution\n\n\nThis means (possibly) installing and (certainly) loading the `bootstrap` package, and then:\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta <- function(x) {\n  mean(x)\n}\nbca_all <- with(aircon, bcanon(hours, 1000, theta))\nbca <- bca_all$confpoints\nbca\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     alpha bca point\n[1,] 0.025  55.58333\n[2,] 0.050  61.25000\n[3,] 0.100  70.66667\n[4,] 0.160  78.50000\n[5,] 0.840 160.66667\n[6,] 0.900 178.50000\n[7,] 0.950 204.25000\n[8,] 0.975 228.75000\n```\n:::\n:::\n\n \n\nPull out the ones from this that you need: the top one and the bottom one, to get an interval of 55.6 \nto 228.8. \n\nI seem to need to define the function `theta` first and pass it into `bcanon` as the third input. You may have more luck with `bcanon(hours, 1000, mean)` than I did. Try it.\n\nOr, if you feel like some extra coding: turn this matrix into a data frame, grab the rows you want, and then the column you want:\n\n::: {.cell}\n\n```{.r .cell-code}\nbca %>%\n  as_tibble() %>%\n  filter(alpha %in% c(0.025, 0.975)) %>%\n  pull(`bca point`)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  55.58333 228.75000\n```\n:::\n:::\n\n \n$\\blacksquare$\n\n(h) Compare the BCa confidence interval with the other ones. Which one would you recommend? Explain briefly.\n\nSolution\n\n\nIn this example, the bootstrap-$t$ and percentile intervals are very different, so we should use neither of them, and prefer the BCa interval. \n\nExtra: as usual in this kind of case, the BCa contains values for the mean pulled out into the long tail, but that's a proper adjustment for the sampling distribution being skewed.\n\n$\\blacksquare$\n\n\n\n\n\n##  Air conditioning failures: bootstrapping the median\n\n\n With a skewed data distribution such as the air-conditioning\nfailure times, we might be interested in inference for the median. One\nway to get a confidence interval for the median is to invert the sign\ntest, as in `smmr`, but another way is to obtain a bootstrap\nsampling distribution for the median. How do these approaches compare\nfor the air-conditioning data? We explore this here.\n\n\n\n(a) Read in the air-conditioning data again (if you don't already\nhave it lying around). The link is in the previous question.\n\nSolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"https://raw.githubusercontent.com/nxskok/pasias/master/air_conditioning.csv\"\naircon <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 12 Columns: 2\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (2): failure, hours\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\naircon\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 x 2\n   failure hours\n     <dbl> <dbl>\n 1       1     3\n 2       2     5\n 3       3     7\n 4       4    18\n 5       5    43\n 6       6    85\n 7       7    91\n 8       8    98\n 9       9   100\n10      10   130\n11      11   230\n12      12   487\n```\n:::\n:::\n\n     \n\n$\\blacksquare$\n\n(b) Use `smmr` to get a confidence interval for the median (based on the sign test).\n\nSolution\n\n\nInput to `ci_median` is data frame and column:\n\n::: {.cell}\n\n```{.r .cell-code}\nci_median(aircon, hours)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]   7.002319 129.998291\n```\n:::\n:::\n\n     \n\n$\\blacksquare$\n\n(c) Obtain the bootstrap distribution of the sample median. Make a normal quantile plot of it. What do you notice? Explain briefly.\n\nSolution\n\n\nThe usual do-it-yourself bootstrap:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(samples = list(sample(aircon$hours, replace = TRUE))) %>% \n  mutate(medians = median(samples)) -> meds\n```\n:::\n\n \n\nI actually copied and pasted my code from the previous problem, changing `mean` to `median`.\n\nAs for a plot, well, this:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(meds, aes(sample = medians)) + stat_qq() + stat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-median-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\nNot only does this not look very normal, but also there are those\ncurious horizontal patches of points (that, you might recall, are\ncharacteristic of a discrete distribution). This has happened because\nthere are only a few possible medians: the median has to be either a\ndata value or halfway between two data values, so there are only\nsomething like $2(12)-1=23$ different possible medians, with the ones\nin the middle being more likely.\n\nThis also shows up on a histogram, but only if you have enough\nbins. (If you don't have enough bins, some of the neighbouring\npossible values end up in the same bin; here, the aim is to have\nenough bins to show the discreteness, rather than the usual thing of\nhaving few enough bins to show the shape.)\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(meds, aes(x = medians)) + geom_histogram(bins = 30)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/bootstrap-median-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n \n\n$\\blacksquare$\n\n(d) Obtain a 95\\% bootstrap percentile confidence interval for the median. How does it compare with the one you obtained earlier?\n\nSolution\n\n\nAlso, the usual:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(meds$medians, c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 2.5% 97.5% \n 12.5 115.0 \n```\n:::\n:::\n\n \n\nThis goes down and up not quite so far as the interval from `smmr`. That might be because the `smmr` interval is too wide (based on a not-very-powerful test), or because the bootstrap quantile interval is too narrow (as it usually is). It's hard to tell which it is.\n\n$\\blacksquare$\n\n(e) Obtain a 95\\% BCa interval. Compare it with the two other intervals you found.\n\nSolution\n\n\nYet more copying and pasting (from the previous question):\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta <- function(x) {\n  median(x)\n}\nbca_all <- with(aircon, bcanon(hours, 1000, theta))\nbca <- bca_all$confpoints\nbca\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     alpha bca point\n[1,] 0.025      12.5\n[2,] 0.050      12.5\n[3,] 0.100      18.0\n[4,] 0.160      30.5\n[5,] 0.840      94.5\n[6,] 0.900      98.0\n[7,] 0.950     100.0\n[8,] 0.975     115.0\n```\n:::\n:::\n\nMy 95% BCa interval is from 12.5 to 115.     \n\nAgain, I seem to need to define the tiny function, while you can probably call `bcanon(hours, 1000, median)`. Try it and see.\n\nMy BCa interval is the same as the bootstrap percentile\ninterval and a little shorter than the one that came from the sign\ntest. I would guess that the BCa interval is the most trustworthy of\nthe three, though there is here not that much difference between\nthem. All the intervals are again very long, a reflection of the small\nsample size and large variability.\n\n$\\blacksquare$\n\n\n\n\n\n## Comparing eyesight\n\n Do people see on average better with their left eye or their right eye, or is there no difference? To find out, 15 subjects were shown a sequence of images, some to their left eye and some to their right (with a blindfold on the other eye). The subjects were asked to identify some objects in each image, and were given an overall score for each eye, based on their ability to identify objects with each eye. (A higher score is better.) Data in [http://ritsokiguess.site/datafiles/eyesight.csv](http://ritsokiguess.site/datafiles/eyesight.csv).\n\n\n\n(a) Read in and display (some of) the data.\n\nSolution\n\n\nThis is a `csv`, so no surprises:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/eyesight.csv\"\nsight <- read_csv(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 15 Columns: 3\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (3): person, right, left\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nsight\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 x 3\n   person right  left\n    <dbl> <dbl> <dbl>\n 1      1    50    47\n 2      2    45    45\n 3      3    33    31\n 4      4    22    24\n 5      5    99    78\n 6      6    79    76\n 7      7     4    13\n 8      8    36    46\n 9      9    62    45\n10     10    51    44\n11     11    27    23\n12     12    15    14\n13     13    26    34\n14     14    83    79\n15     15    86    81\n```\n:::\n:::\n\n15 observations, with the subjects labelled by number, and a score for each subject and each eye. \n\n\n\n$\\blacksquare$\n\n\n(b) Explain briefly why looking at differences (say right minus left) makes sense for these data, and calculate and save a dataframe with the differences added to it.\n\nSolution\n\n\nThis is matched pairs data, with two observations for each subject. A matched pairs analysis, whether by a sign test or a matched-pairs $t$-test, would be based on one difference for each subject, and so those would make sense to calculate. (You'll recall that a matched pairs analysis uses the differences and *not* the original data.)\n\nThus, saving back into our original dataframe:\n\n::: {.cell}\n\n```{.r .cell-code}\nsight %>% \nmutate(difference = right - left) -> sight\nsight\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 x 4\n   person right  left difference\n    <dbl> <dbl> <dbl>      <dbl>\n 1      1    50    47          3\n 2      2    45    45          0\n 3      3    33    31          2\n 4      4    22    24         -2\n 5      5    99    78         21\n 6      6    79    76          3\n 7      7     4    13         -9\n 8      8    36    46        -10\n 9      9    62    45         17\n10     10    51    44          7\n11     11    27    23          4\n12     12    15    14          1\n13     13    26    34         -8\n14     14    83    79          4\n15     15    86    81          5\n```\n:::\n:::\n\nExtra: this is one of those cases where having long data would make it very much more difficult to work out the differences for each person. Try it and see. How will you match up the two measurements for each person?\n\n\n$\\blacksquare$\n\n\n(c) Make a suitable normal quantile plot, and describe what it tells you.\n\nSolution\n\n\nA normal quantile plot *of the differences*, therefore, since normality of the two individual scores is immaterial:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sight, aes(sample = difference)) + stat_qq() +\nstat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/vontouchingen-1.pdf){fig-pos='H'}\n:::\n:::\n\nWe have what I think is best described as \"long tails\", with the high values being too high and the low ones being a bit too low for a normal distribution. I think this is a better description than \"outliers\" because outliers are isolated unusual values, not five observations out of fifteen!\n\nThe plot is telling us that a matched-pairs $t$-test is questionable, and that we might do a sign test instead. Or, as we explore in this question, find a bootstrap distribution (in this case, for the median).\n\nExtra: the one kind of sensible plot that uses the original data in this situation would be a scatterplot, since the right and left scores are matched up:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sight, aes(x = right, y = left)) + \ngeom_point() + geom_abline(slope = 1, intercept = 0)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/wickten-1.pdf){fig-pos='H'}\n:::\n:::\n\nI added the line $y = x$ to the  plot. The value of doing that is that a point to the right and below the line has the right-eye score bigger than the left-eye one, and vice versa for a point to the left and above. This plot tells us that a small majority of the subjects had a higher score with the right eye, and for the ones that had a higher score with the left eye, the difference wasn't usually very big. \n\nThis plot tells us nothing about normality of differences, though (not without some careful looking), which is one of the things we usually care about.\n\n\n$\\blacksquare$\n\n\n(d) Obtain a bootstrap distribution of the sample *median*.\n\nSolution\n\n\n::: {.cell}\n\n:::\n\n\nBorrow the idea from lecture, replacing mean with median:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \nrowwise() %>% \nmutate(sample = list(sample(sight$difference, replace = TRUE))) %>% \nmutate(my_median = median(sample)) -> meds\nmeds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,000 x 3\n# Rowwise: \n     sim sample     my_median\n   <int> <list>         <dbl>\n 1     1 <dbl [15]>         3\n 2     2 <dbl [15]>         3\n 3     3 <dbl [15]>         2\n 4     4 <dbl [15]>         2\n 5     5 <dbl [15]>         3\n 6     6 <dbl [15]>         4\n 7     7 <dbl [15]>         3\n 8     8 <dbl [15]>         3\n 9     9 <dbl [15]>         3\n10    10 <dbl [15]>         3\n# i 990 more rows\n```\n:::\n:::\n\nThe steps are:\n\n- create a dataframe with a column called `sim` to label the simulations\n- from here on out, work \"rowwise\", that is, with one row at a time\n- generate a bootstrap sample for each row. A bootstrap sample is fifteen observations rather than just one, so we are making a list-column and thus the `list` has to go on the front\n- work out the median of each bootstrap sample. Remember, the `rowwise` applies until you cancel it,^[That is done using `ungroup`, should you ever need to stop working rowwise. This seems like an odd choice of function, since the usual use of  `ungroup` is to undo a group-by, but what `ungroup` actually does is to remove *any* special properties a dataframe has, including both groups and any rowwise behaviour.] and so this will be the median of the bootstrap sample on each row, one at a time. \n\n\nAs ever, if you want to see what's going on, run this one line at a time. \n\n\n\n\n\n$\\blacksquare$\n\n\n\n(e) Make a histogram of your bootstrap distribution of the median. Use a lot of bins, such as the default 30, for this. What do you notice about the distribution? Why did it come out this way?\n\nSolution\n\nFor this histogram, there is no need to specify a number of bins (unless you want to):\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(meds, aes(x = my_median)) + geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/nefen-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe distribution is very discrete (this shows up more clearly with more bins).\n\nThe data values are all integers (and therefore so are the differences). The median of an odd number of data values must be one of the data values, and the bootstrap samples only contain (varying numbers of copies of) the differences in the original dataset, so \neach bootstrap sample must have a median that is an integer too.\n\n\nExtra:\nin case you are thinking that this happened because the data values were integers, no, it would happen even if the data were decimal numbers. Let's make some fake data of 15 random normals and then do the same thing again:\n\n::: {.cell}\n\n```{.r .cell-code}\nfake_data <- tibble(x = rnorm(15))\nfake_data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 x 1\n          x\n      <dbl>\n 1 -2.02   \n 2  0.867  \n 3 -0.00982\n 4 -0.123  \n 5 -0.431  \n 6  0.702  \n 7  1.22   \n 8 -0.0818 \n 9  1.06   \n10  0.318  \n11 -0.0179 \n12 -0.370  \n13  0.0115 \n14 -1.57   \n15  0.0529 \n```\n:::\n:::\n\nand once again bootstrap the median:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \nrowwise() %>% \nmutate(sample = list(sample(fake_data$x, replace = TRUE))) %>% \nmutate(my_median = median(sample)) -> meds2\nmeds2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,000 x 3\n# Rowwise: \n     sim sample     my_median\n   <int> <list>         <dbl>\n 1     1 <dbl [15]>   0.0115 \n 2     2 <dbl [15]>   0.0115 \n 3     3 <dbl [15]>  -0.123  \n 4     4 <dbl [15]>  -0.0179 \n 5     5 <dbl [15]>   0.0115 \n 6     6 <dbl [15]>   0.318  \n 7     7 <dbl [15]>   0.0115 \n 8     8 <dbl [15]>  -0.00982\n 9     9 <dbl [15]>   0.0529 \n10    10 <dbl [15]>   0.0115 \n# i 990 more rows\n```\n:::\n:::\n\nYou can see even from these few that the bootstrap distribution of the median has repeats, so there should also be some discreteness here:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(meds2, aes(x = my_median)) + geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/botz-1.pdf){fig-pos='H'}\n:::\n:::\n\nThe discreteness is a property of the fact that we were bootstrapping the *median*, and the median has to be one of the data values. \n\nTo confirm that, recall that our original data were integers:\n\n::: {.cell}\n\n```{.r .cell-code}\nsight\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 x 4\n   person right  left difference\n    <dbl> <dbl> <dbl>      <dbl>\n 1      1    50    47          3\n 2      2    45    45          0\n 3      3    33    31          2\n 4      4    22    24         -2\n 5      5    99    78         21\n 6      6    79    76          3\n 7      7     4    13         -9\n 8      8    36    46        -10\n 9      9    62    45         17\n10     10    51    44          7\n11     11    27    23          4\n12     12    15    14          1\n13     13    26    34         -8\n14     14    83    79          4\n15     15    86    81          5\n```\n:::\n:::\n\nbut even for these, if you bootstrap the mean, you don't get the same discreteness:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \nrowwise() %>% \nmutate(sample = list(sample(sight$difference, replace = TRUE))) %>% \nmutate(my_mean = mean(sample)) -> means\nmeans %>% \nggplot(aes(x = my_mean)) + geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/vesar-1.pdf){fig-pos='H'}\n:::\n:::\n\nThis is too many bins for 1000 bootstrap samples, so the shape is kind of irregular, but there are not the big gaps that the bootstrap distribution of the sample median has. Indeed, this ought to be somewhere near normal and is:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(means, aes(sample = my_mean)) + stat_qq() +\nstat_qq_line()\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/stricher-1.pdf){fig-pos='H'}\n:::\n:::\n\n(This is saying that the Central Limit Theorem is really helping, even for a sample size of only 15 from clearly non-normal data, so the paired $t$ may not be as bad as we would have thought.)\n\n\n$\\blacksquare$\n\n\n(f) Find a 95% percentile interval for the population median.^[I was also going to have you do a bootstrap-t interval, but I'm not completely convinced I got that right when I was explaining it to you before.]\n\nSolution\n\n\nThe percentile interval comes from the middle 95% of the bootstrap distribution of medians:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(meds$my_median, c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 2.5% 97.5% \n   -2     4 \n```\n:::\n:::\n\nThe bootstrap percentile interval goes from $-2$ to 4. Like the CI for the median based on the sign test, the ends of this interval must be data values.\n\nExtra: for comparison, the interval from the sign test is this:\n\n::: {.cell}\n\n```{.r .cell-code}\nci_median(sight, difference)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1.997070  4.994629\n```\n:::\n:::\n\nwhich is, when rounded off, from $-2$ to 5, very like the percentile interval.\n\n\n$\\blacksquare$\n\n\n(g) Find the BCA 95% confidence interval for the population median difference.\n\nSolution\n\n\nLoad (and if necessary install) the `bootstrap` package, and then:\n\n::: {.cell}\n\n```{.r .cell-code}\nbca <- bcanon(sight$difference, 1000, median)\nbca$confpoints\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     alpha bca point\n[1,] 0.025        -2\n[2,] 0.050        -2\n[3,] 0.100         0\n[4,] 0.160         0\n[5,] 0.840         3\n[6,] 0.900         3\n[7,] 0.950         4\n[8,] 0.975         4\n```\n:::\n:::\n\n$-2$ to 4, in this case like the percentile interval.^[They don't often agree this well, but all of these intervals in this situation but have data values at their endpoints, and all of our data values are integers.] Note how this one is data values also. \n\n\n$\\blacksquare$\n\n\n(h) What do your intervals tell us about any possible difference between left eye and right eye in terms of ability to identify objects in images? Do the intervals agree or disagree about this?\n\nSolution\n\n\nThe intervals are not quite all the same, but one thing they have in common is that they all have a negative lower limit and a positive upper one (more positive than the negative one is negative). This says that 0 is a plausible difference in each case, and thus it is reasonable to conclude that there is no evidence of any difference between the two eyes, based on this sample of 15 subjects. \n\nThe intervals do all go more positive than negative, which says that if anything the scores are better with the right eye than the left on average (from the way around that we took the differences). However, there is no evidence here that this is any more than chance.\n\n\n$\\blacksquare$\n\n\n\n\n\n## Bootstrapping the IRS data\n\n You might recall the IRS data from when we were learning about the sign test. The idea was that we wanted to see how long \"on average\" it took people to fill out a tax form. The data are in [http://ritsokiguess.site/datafiles/irs.txt](http://ritsokiguess.site/datafiles/irs.txt).\n\n\n\n(a) Read in and display (some of) the data. There is only one column of data, so you can pretend the values are separated by anything.\n\nSolution\n\n\nPretty much any of the `read_` functions will work, even this one:\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/irs.txt\"\nirs <- read_table(my_url)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n-- Column specification --------------------------------------------------------\ncols(\n  Time = col_double()\n)\n```\n:::\n\n```{.r .cell-code}\nirs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 x 1\n    Time\n   <dbl>\n 1    91\n 2    64\n 3   243\n 4   167\n 5   123\n 6    65\n 7    71\n 8   204\n 9   110\n10   178\n# i 20 more rows\n```\n:::\n:::\n\nOne column called `Time`.\n\n\n$\\blacksquare$\n\n\n(b) Obtain a bootstrap distribution of the sample *median*.\n\nSolution\n\n\nThe lecture notes use the exact same dataset, so you can borrow ideas from there:\n\nSet up a dataframe with one row for each bootstrap sample you're going to draw, 1000 in this case:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,000 x 1\n     sim\n   <int>\n 1     1\n 2     2\n 3     3\n 4     4\n 5     5\n 6     6\n 7     7\n 8     8\n 9     9\n10    10\n# i 990 more rows\n```\n:::\n:::\n\nCreate a column with a new bootstrap sample for each `sim`. This means doing `rowwise` *first* and then wrapping the sampling in `list` because you are creating a list-column of samples:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \nrowwise() %>% \nmutate(sample = list(sample(irs$Time, replace = TRUE)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,000 x 2\n# Rowwise: \n     sim sample    \n   <int> <list>    \n 1     1 <dbl [30]>\n 2     2 <dbl [30]>\n 3     3 <dbl [30]>\n 4     4 <dbl [30]>\n 5     5 <dbl [30]>\n 6     6 <dbl [30]>\n 7     7 <dbl [30]>\n 8     8 <dbl [30]>\n 9     9 <dbl [30]>\n10    10 <dbl [30]>\n# i 990 more rows\n```\n:::\n:::\n\nEach thing in `sample` has 30 observations in it (one bootstrap sample). If you want, you can `unnest` to take a look at the values; they should be the ones in the dataset, possibly with extra repeats.\n\nNext, work out the median of each bootstrapped sample, which is simple because we are still working rowwise:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \nrowwise() %>% \nmutate(sample = list(sample(irs$Time, replace = TRUE))) %>% \nmutate(my_median = median(sample)) -> bs\nbs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,000 x 3\n# Rowwise: \n     sim sample     my_median\n   <int> <list>         <dbl>\n 1     1 <dbl [30]>      178.\n 2     2 <dbl [30]>      170 \n 3     3 <dbl [30]>      183 \n 4     4 <dbl [30]>      172.\n 5     5 <dbl [30]>      178 \n 6     6 <dbl [30]>      209 \n 7     7 <dbl [30]>      150 \n 8     8 <dbl [30]>      154.\n 9     9 <dbl [30]>      194 \n10    10 <dbl [30]>      194 \n# i 990 more rows\n```\n:::\n:::\n\nAs you realize, `bs` stands for \"bootstrap\". Of course.\n\n\n$\\blacksquare$\n\n\n(c) Make a suitable graph of the bootstrap distribution of the median. What seems odd about it? Why did that happen? (Hint: use more bins on your plot than usual, like 50.)\n\nSolution\n\n\nThe medians are already in a dataframe, so go straight ahead:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bs, aes(x = my_median)) + geom_histogram(bins = 50)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/stainachin-1.pdf){fig-pos='H'}\n:::\n:::\n\nWhat we are seeing at this resolution is that the distribution is *very* irregular, with funny holes in it, more than you would expect even with this many bins. By way of comparison, the bootstrap distribution of the *mean* looks a lot smoother:\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(sim = 1:1000) %>% \n  rowwise() %>% \n  mutate(my_sample = list(sample(irs$Time, replace = TRUE))) %>% \n  mutate(my_mean = mean(my_sample)) %>% \n  ggplot(aes(x = my_mean)) + geom_histogram(bins = 50)\n```\n\n::: {.cell-output-display}\n![](bootstrap_files/figure-pdf/rom-1.pdf){fig-pos='H'}\n:::\n:::\nThis is somewhat irregular, because we really have too many bins, but there are not nearly so many holes and irregular heights as on the plot for the median. I had you use a lot of bins in this special case because I wanted you to see just how irregular the bootstrapped distribution for the median really was.\n\nSo why did that happen? Think about what the sample median is for 30 observations: it is the mean of the 15th and 16th smallest values when you arrange them in order. A bootstrap sample must contain the same values as the original dataset (just probably not the same frequencies of them). So the median of a bootstrap sample must be the average of two of the values in the original dataset, and probably two that were close together. What that means is that there are *not very many possible medians* of the bootstrap samples, and they form a clearly discrete rather than a continuous distribution. (The sample mean, on the other hand, uses all the values in the bootstrap sample, and so there are a lot more possible bootstrap means than bootstrap medians; the distribution of those is as good as continuous.)\n\nWhat this means is that bootstrapping for medians is odd (it always looks like this), but that's what the bootstrap distribution looks like.\n\n\n$\\blacksquare$\n\n\n(d) Find 95% percentile and bootstrap-$t$ intervals for the population median. (Hint: your dataframe of bootstrapped medians may still be `rowwise`, so you might need to run `ungroup` first.)\n\nSolution\n\n\nThe percentile interval comes from the middle 95% of the bootstrap distribution of medians. The dataframe `bs` is still rowwise, so we have to undo that first to do it the obvious way:\n\n::: {.cell}\n\n```{.r .cell-code}\nbs %>% \n  ungroup() %>% \n  summarize(ci1 = quantile(my_median, 0.025),\n            ci2 = quantile(my_median, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 2\n    ci1   ci2\n  <dbl> <dbl>\n1   121   215\n```\n:::\n:::\n\nOr, pull out just that column and find the two quantiles of that, for which there are two ways, the base R way:\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(bs$my_median, c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 2.5% 97.5% \n  121   215 \n```\n:::\n:::\n\nand the slightly odd-looking:\n\n::: {.cell}\n\n```{.r .cell-code}\nbs %>% pull(my_median) %>% \n  quantile(c(0.025, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 2.5% 97.5% \n  121   215 \n```\n:::\n:::\n\nAll of these get you to the same place. There is even one more:\n\n::: {.cell}\n\n```{.r .cell-code}\nbs %>% \n  ungroup() %>% \n  reframe(ci = quantile(my_median, c(0.025, 0.975)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 1\n     ci\n  <dbl>\n1   121\n2   215\n```\n:::\n:::\n\nThis is `reframe` rather than `summarize` because `quantile` in this case returns two numbers, the two percentiles we want, and `summarize` expects only one. (This is newish behaviour.) Another way is to use `summarize`, but wrap the call to `quantile` in `list` so that it returns only one thing (the list, containing two numbers, but bundled up in one list). Then you need to `unnest` it to see the values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbs %>% \n  ungroup() %>% \n  summarize(ci = list(quantile(my_median, c(0.025, 0.975)))) %>% \n  unnest(ci)  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 1\n     ci\n  <dbl>\n1   121\n2   215\n```\n:::\n:::\n\nIf you had `rowwise` in the back of your mind, you might have tried this. Try it up to but *not* including the `unnest` to see how it works.\n\nFor the bootstrap $t$, estimate the population median as the sample median:\n\n::: {.cell}\n\n```{.r .cell-code}\nmed <- median(irs$Time)\nmed\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 172.5\n```\n:::\n:::\n\nget its standard error from the SD of the bootstrap distribution of medians:\n\n::: {.cell}\n\n```{.r .cell-code}\nse <- sd(bs$my_median)\nse\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 23.31839\n```\n:::\n:::\n\nthen go up and down twice this (or 1.96 if you believe in $z$): \n\n::: {.cell}\n\n```{.r .cell-code}\nmed + c(-2, 2)*se\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 125.8632 219.1368\n```\n:::\n:::\n\nExtra: in this case, we also have the CI for the median that came out of the sign test:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(smmr)\nci_median(irs, Time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 119.0065 214.9955\n```\n:::\n:::\n\nThis one is actually very close to the bootstrap percentile interval, while the bootstrap $t$ interval is higher at both ends.\n\n\n$\\blacksquare$\n\n\n\n",
>>>>>>> 038bb2509ac8e38facb2622be6ad3052b44aca34
    "supporting": [
      "bootstrap_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}